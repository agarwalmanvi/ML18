{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import errno\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_rates(input_data, output_data, attribute_name, privileged=None, unprivileged=None, favourable=None, unfavourable=None):\n",
    "\n",
    "    index_attribute = input_data.feature_names.index(attribute_name)\n",
    "    privileged = float(privileged)\n",
    "    unprivileged = float(unprivileged)\n",
    "    \n",
    "    input_priv = input_data.labels[np.where(input_data.features[:,index_attribute] == privileged)]\n",
    "    output_priv = output_data.labels[np.where(output_data.features[:,index_attribute] == privileged)]\n",
    "    priv_labels = np.concatenate((input_priv, output_priv), axis=1)\n",
    "    \n",
    "    input_unpriv = input_data.labels[np.where(input_data.features[:,index_attribute] == unprivileged)]\n",
    "    output_unpriv = output_data.labels[np.where(output_data.features[:,index_attribute] == unprivileged)]\n",
    "    unpriv_labels = np.concatenate((input_unpriv, output_unpriv), axis=1)\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(priv_labels.shape[0]):\n",
    "        input_label = priv_labels[i][0]\n",
    "        output_label = priv_labels[i][1]\n",
    "        if input_label == output_label:\n",
    "            if input_label == unfavourable:\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                tp = tp + 1\n",
    "        else:\n",
    "            if input_label == favourable and output_label == unfavourable:\n",
    "                fn = fn + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "    \n",
    "    rates_privileged = [tp,fp,tn,fn]\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(unpriv_labels.shape[0]):\n",
    "        input_label = unpriv_labels[i][0]\n",
    "        output_label = unpriv_labels[i][0]\n",
    "        if input_label == output_label:\n",
    "            if input_label == unfavourable:\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                tp = tp + 1\n",
    "        else:\n",
    "            if input_label == favourable and output_label == unfavourable:\n",
    "                fn = fn + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "                \n",
    "    rates_unprivileged = [tp,fp,tn,fn]           \n",
    "    \n",
    "    rates_list = [rates_privileged, rates_unprivileged]\n",
    "    \n",
    "    return rates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input privileged and unprivileged as integers\n",
    "# input favourable and unfavourable as integers\n",
    "# data as a pandas dataframe\n",
    "# attribute_name as string\n",
    "\n",
    "def statistical_parity_diff(data, attribute_name, privileged=None, unprivileged=None, favourable=None, unfavourable=None):\n",
    "    protected_counts = data[attribute_name].value_counts().to_dict()\n",
    "    favourable_outcomes_privileged_group = data.loc[data[attribute_name] == privileged]\n",
    "    ratio_privileged = favourable_outcomes_privileged_group.iloc[:,-1].value_counts().to_dict()\n",
    "    print(ratio_privileged)\n",
    "    if favourable in ratio_privileged.keys():\n",
    "        ratio_privileged = ratio_privileged[favourable]/favourable_outcomes_privileged_group.shape[0]\n",
    "    else:\n",
    "        ratio_privileged = 0\n",
    "    print(ratio_privileged)\n",
    "    favourable_outcomes_unprivileged_group = data.loc[data[attribute_name] == unprivileged]\n",
    "    ratio_unprivileged = favourable_outcomes_unprivileged_group.iloc[:,-1].value_counts().to_dict()\n",
    "    print(ratio_unprivileged)\n",
    "    if favourable in ratio_unprivileged.keys():\n",
    "        ratio_unprivileged = ratio_unprivileged[favourable]/favourable_outcomes_unprivileged_group.shape[0]\n",
    "    else:\n",
    "        ratio_unprivileged = 0\n",
    "    print(ratio_unprivileged)\n",
    "\n",
    "    fairness = ratio_privileged - ratio_unprivileged\n",
    "    \n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input privileged and unprivileged as integers\n",
    "# input favourable and unfavourable as integers\n",
    "# data as a pandas dataframe\n",
    "# attribute_name as string\n",
    "\n",
    "def disparate_impact(data, attribute_name, privileged=None, unprivileged=None, favourable=None, unfavourable=None):\n",
    "    protected_counts = data[attribute_name].value_counts().to_dict()\n",
    "    favourable_outcomes_privileged_group = data.loc[data[attribute_name] == privileged]\n",
    "    \n",
    "    favourable_outcomes_unprivileged_group = data.loc[data[attribute_name] == unprivileged]\n",
    "    ratio_unprivileged = favourable_outcomes_unprivileged_group.iloc[:,-1].value_counts().to_dict()\n",
    "    print(ratio_unprivileged)\n",
    "    if favourable in ratio_unprivileged.keys():\n",
    "        ratio_unprivileged = ratio_unprivileged[favourable]/favourable_outcomes_unprivileged_group.shape[0]\n",
    "    else:\n",
    "        ratio_unprivileged = 0\n",
    "        return 0\n",
    "    print(\"ratio_unpr: \",ratio_unprivileged)\n",
    "    \n",
    "    ratio_privileged = favourable_outcomes_privileged_group.iloc[:,-1].value_counts().to_dict()\n",
    "    print(ratio_privileged)\n",
    "    if favourable in ratio_privileged.keys():\n",
    "        ratio_privileged = ratio_privileged[favourable]/favourable_outcomes_privileged_group.shape[0]\n",
    "    else:\n",
    "        ratio_privileged = 0\n",
    "        return math.inf\n",
    "    print(\"ratio_priv: \",ratio_privileged)\n",
    "    \n",
    "    fairness = ratio_unprivileged/ratio_privileged\n",
    "    \n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def equal_opp_diff(input_data, output_data, attribute_name, privileged, unprivileged, favourable, unfavourable):\n",
    "    outcome_both = output_rates(input_data, output_data, attribute_name, privileged, unprivileged, favourable, unfavourable)\n",
    "    \n",
    "    # [tp, fp, tn, fn]\n",
    "    outcome_privileged = rates_both[0]\n",
    "    outcome_unprivileged = rates_both[1]\n",
    "    \n",
    "    # true positive rate = tp / (tp + fn)\n",
    "    tpr_privileged = outcome_privileged[0] / (outcome_privileged[0] + outcome_privileged[3])\n",
    "    tpr_unprivileged = outcome_unprivileged[0] / (outcome_unprivileged[0] + outcome_unprivileged[3])\n",
    "\n",
    "    fairness = tpr_unprivileged - tpr_privileged\n",
    "    \n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_odds_diff(input_data, output_data, attribute_name, privileged, unprivileged, favourable, unfavourable):\n",
    "    outcome_both = output_rates(input_data, output_data, attribute_name, privileged, unprivileged, favourable, unfavourable)\n",
    "    \n",
    "    # [tp, fp, tn, fn]\n",
    "    outcome_privileged = rates_both[0]\n",
    "    outcome_unprivileged = rates_both[1]\n",
    "    \n",
    "    # true positive rate = tp / (tp + fn)\n",
    "    tpr_privileged = outcome_privileged[0] / (outcome_privileged[0] + outcome_privileged[3])\n",
    "    tpr_unprivileged = outcome_unprivileged[0] / (outcome_unprivileged[0] + outcome_unprivileged[3])\n",
    "\n",
    "    # false positive rate = fp / (fp + tn)\n",
    "    fpr_privileged = outcome_privileged[1] / (outcome_privileged[1] + outcome_privileged[2])\n",
    "    fpr_unprivileged = outcome_unprivileged[1] / (outcome_unprivileged[1] + outcome_unprivileged[2])\n",
    "    \n",
    "    fpr_diff = fpr_unprivileged - fpr_privileged\n",
    "    tpr_diff = tpr_unprivileged - tpr_unprivileged\n",
    "    \n",
    "    fairness = (fpr_diff + tpr_diff) * 0.5\n",
    "    \n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_data():\n",
    "    return pd.DataFrame(np.random.randint(0,2,size=(10, 5)), columns=list('ABCPO'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 3, 0: 1}\n",
      "ratio_unpr:  0.75\n",
      "{0: 4, 1: 2}\n",
      "ratio_priv:  0.3333333333333333\n",
      "{0: 5, 1: 2}\n",
      "ratio_unpr:  0.2857142857142857\n",
      "{1: 2, 0: 1}\n",
      "ratio_priv:  0.6666666666666666\n",
      "{0: 3}\n",
      "{1: 3}\n",
      "ratio_unpr:  1.0\n",
      "{0: 4, 1: 3}\n",
      "ratio_priv:  0.42857142857142855\n",
      "{1: 5, 0: 2}\n",
      "ratio_unpr:  0.7142857142857143\n",
      "{1: 2, 0: 1}\n",
      "ratio_priv:  0.6666666666666666\n",
      "{1: 3, 0: 2}\n",
      "ratio_unpr:  0.6\n",
      "{0: 3, 1: 2}\n",
      "ratio_priv:  0.4\n",
      "{1: 4, 0: 3}\n",
      "ratio_unpr:  0.5714285714285714\n",
      "{1: 2, 0: 1}\n",
      "ratio_priv:  0.6666666666666666\n",
      "{1: 3, 0: 2}\n",
      "ratio_unpr:  0.6\n",
      "{0: 3, 1: 2}\n",
      "ratio_priv:  0.4\n",
      "{0: 3, 1: 2}\n",
      "ratio_unpr:  0.4\n",
      "{0: 3, 1: 2}\n",
      "ratio_priv:  0.4\n",
      "{0: 4, 1: 3}\n",
      "ratio_unpr:  0.42857142857142855\n",
      "{1: 2, 0: 1}\n",
      "ratio_priv:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    D = random_data()\n",
    "    fairness = disparate_impact(D,'P',1,0,1,0)\n",
    "    if fairness > 100:\n",
    "        print(\"true\")\n",
    "        print(fairness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import errno\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_compasdataset(df):\n",
    "    df = df[['age', 'c_charge_degree', 'race', 'age_cat', 'score_text',\n",
    "                 'sex', 'priors_count', 'days_b_screening_arrest', 'decile_score',\n",
    "                 'is_recid', 'two_year_recid', 'c_jail_in', 'c_jail_out']]\n",
    "\n",
    "    # Indices of data samples to keep\n",
    "    ix = df['days_b_screening_arrest'] <= 30\n",
    "    ix = (df['days_b_screening_arrest'] >= -30) & ix\n",
    "    ix = (df['is_recid'] != -1) & ix\n",
    "    ix = (df['c_charge_degree'] != \"O\") & ix\n",
    "    ix = (df['score_text'] != 'N/A') & ix\n",
    "    df = df.loc[ix,:]\n",
    "    df['length_of_stay'] = (pd.to_datetime(df['c_jail_out']) - pd.to_datetime(df['c_jail_in'])).apply(lambda x: x.days)\n",
    "\n",
    "    # Restrict races to African-American and Caucasian\n",
    "    df = df.loc[~df['race'].isin(['Native American','Hispanic','Asian','Other']),:]\n",
    "\n",
    "    df = df[['sex','race','age_cat','c_charge_degree','score_text','priors_count','is_recid', 'two_year_recid','length_of_stay']]\n",
    "\n",
    "    df['priors_count'] = df['priors_count'].apply(lambda x: 0 if x <= 0 else ('1 to 3' if 1 <= x <= 3 else 'More than 3'))\n",
    "    df['length_of_stay'] = df['length_of_stay'].apply(lambda x: '<week' if x <= 7 else ('<3months' if 8 < x <= 93 else '>3months'))\n",
    "    df['score_text'] = df['score_text'].apply(lambda x: 'MediumHigh' if (x == 'High')| (x == 'Medium') else x)\n",
    "    df['age_cat'] = df['age_cat'].apply(lambda x: '25 to 45' if x == '25 - 45' else x)\n",
    "\n",
    "    df['sex'] = df['sex'].replace({'Female': 1.0, 'Male': 0.0})\n",
    "    df['race'] = df['race'].apply(lambda x: 1.0 if x == 'Caucasian' else 0.0)\n",
    "\n",
    "    df = df[['two_year_recid', 'sex', 'race', 'age_cat', 'priors_count', 'c_charge_degree']]\n",
    "\n",
    "    protected_attributes = ['sex', 'race']\n",
    "    label_name = 'two_year_recid'\n",
    "    categorical_features = ['age_cat', 'priors_count', 'c_charge_degree']\n",
    "    features = categorical_features + [label_name] + protected_attributes\n",
    "\n",
    "    # privileged classes\n",
    "    privileged_classes = {\"sex\": [1.0], \"race\": [1.0]}\n",
    "\n",
    "    # protected attribute maps\n",
    "    protected_attribute_map = {\"sex\": {0.0: 'Male', 1.0: 'Female'},\n",
    "                                \"race\": {1.0: 'Caucasian', 0.0: 'Not Caucasian'}}\n",
    "\n",
    "\n",
    "    data = StandardDataset(df, label_name, favorable_classes=[0],\n",
    "                           protected_attribute_names=protected_attributes,\n",
    "                           privileged_classes=[privileged_classes[x] for x in protected_attributes],\n",
    "                           categorical_features=categorical_features,\n",
    "                           features_to_keep=features,\n",
    "                           metadata={'label_maps': [{1.0: 'Did recid.', 0.0: 'No recid.'}],\n",
    "                                     'protected_attribute_maps': [protected_attribute_map[x] for x in protected_attributes]})\n",
    "\n",
    "    return data\n",
    "\n",
    "############ Reweighing ##############\n",
    "\n",
    "def reweighing_data(train, unprivileged_group, privileged_group):\n",
    "    RW = Reweighing(unprivileged_groups=unprivileged_group, privileged_groups=privileged_group)\n",
    "    RW.fit(train)\n",
    "    train_transformed = RW.transform(train)\n",
    "    \n",
    "    train_set = train_transformed\n",
    "\n",
    "    # change weights to whole numbers\n",
    "    for i in range(train_transformed.instance_weights.size):\n",
    "        train_transformed.instance_weights[i] = (round(train_transformed.instance_weights[i] / 0.1) * 0.1) * 10\n",
    "        weights = copy.deepcopy(train_transformed.instance_weights)\n",
    "\n",
    "    # change train_transformed.features and train_transformed.labels and train_transformed.protected_attributes according to the weights of each instance\n",
    "    for i in range(train_transformed.features.shape[0]):\n",
    "        row = copy.deepcopy(train_transformed.features[i])\n",
    "        row_label = copy.deepcopy(train_transformed.labels[i])\n",
    "        row_protected_attributes = copy.deepcopy(train_transformed.protected_attributes[i])\n",
    "        row_protected_attributes.resize(1,2)\n",
    "        row.resize(1,train_transformed.features.shape[1])\n",
    "        row_label.resize(1,1)\n",
    "        weight = int(weights[i])\n",
    "        for j in range(weight-1):\n",
    "            train_transformed.features = np.concatenate((train_transformed.features,row))\n",
    "            train_transformed.labels = np.concatenate((train_transformed.labels,row_label))\n",
    "            train_transformed.protected_attributes = np.concatenate((train_transformed.protected_attributes,row_protected_attributes))\n",
    "\n",
    "    # change the train_transformed to a numpy array of ones to match number of rows in features\n",
    "    train_transformed.instance_weights = np.ones(train_transformed.features.shape[0])\n",
    "\n",
    "    print(\"reweighing complete\\n\")\n",
    "\n",
    "    return train_set, train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification with Compas data set\n",
      "reweighing complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "print(\"Classification with Compas data set\")\n",
    "df = pd.read_csv('dataset/compas-scores-two-years.csv')\n",
    "dataset_orig = preprocess_compasdataset(df)\n",
    "\n",
    "train, test = dataset_orig.split([0.7], shuffle=True)\n",
    "\n",
    "train_transformed, dataset_transf_train = reweighing_data(train, unprivileged_groups, privileged_groups)\n",
    "\n",
    " ##################### prejudice remover #####################\n",
    "prejudice_model_reweighing = PrejudiceRemover(eta=100, sensitive_attr='sex')\n",
    "prejudice_model_reweighing.fit(dataset_transf_train)\n",
    "dataset_prejudice_test_reweighing = prejudice_model_reweighing.predict(test)\n",
    "\n",
    "print(\"Prejudice Remover\")\n",
    "\n",
    "##################### metrics #####################\n",
    "\n",
    "metric_test = BinaryLabelDatasetMetric(dataset_prejudice_test_reweighing,\n",
    "                                       unprivileged_groups=unprivileged_groups,\n",
    "                                       privileged_groups=privileged_groups)\n",
    "\n",
    "acc_test = ClassificationMetric(test, dataset_prejudice_test_reweighing,\n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)\n",
    "\n",
    "accuracy_prejudice = accuracy_score(y_true=test.labels, y_pred=dataset_prejudice_test_reweighing.labels)\n",
    "# print('accuracy score = {}'.format(accuracy_prejudice))\n",
    "\n",
    "print(acc_test.equal_opportunity_difference())\n",
    "print(acc_test.average_odds_difference())\n",
    "    \n",
    "metrics_prejudice = [metric_test.mean_difference(), acc_test.disparate_impact(), np.nan, np.nan, acc_test.theil_index()]\n",
    "\n",
    "##################### metrics #####################\n",
    "\n",
    "# metric_test = BinaryLabelDatasetMetric(dataset_prejudice_test_reweighing,\n",
    "#                                        unprivileged_groups=unprivileged_groups,\n",
    "#                                        privileged_groups=privileged_groups)\n",
    "# acc_test = ClassificationMetric(test, dataset_prejudice_test_reweighing,\n",
    "#                                 unprivileged_groups=unprivileged_groups,\n",
    "#                                 privileged_groups=privileged_groups)\n",
    "# acc_test = BinaryLabelDatasetMetric(dataset_prejudice_test_reweighing,\n",
    "#                                 unprivileged_groups=unprivileged_groups,\n",
    "#                                 privileged_groups=privileged_groups)\n",
    "# accuracy_prejudice = accuracy_score(y_true=test.labels, y_pred=dataset_prejudice_test_reweighing.labels)\n",
    "\n",
    "#     equal_odds_difference = equal_opp_diff(test_df, datatest_df, 'sex', 1, 0, 1, 0)\n",
    "#     equal_odds_difference = equal_opp_diff(test, dataset_prejudice_test_reweighing, 'sex', privileged=1, unprivileged=0, favourable=1, unfavourable=0)\n",
    "\n",
    "# metrics_prejudice = [metric_test.mean_difference(), acc_test.disparate_impact(), np.nan, np.nan, acc_test.theil_index()]\n",
    "#     metrics_prejudice = [metric_test.mean_difference(), acc_test.disparate_impact(), equal_odds_difference, np.nan, acc_test.theil_index()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
