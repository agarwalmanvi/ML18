{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import errno\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from preprocess import preprocess_data\n",
    "from adversarial_debiasing import adversarial\n",
    "from prejudice_remover import prejudice\n",
    "from neuralnet import nondebiased_classifier\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset, StructuredDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "dataset_orig = load_preproc_data_adult()\n",
    "# train1, test1 are the original dataset\n",
    "train1, test1 = dataset_orig.split([0.7], shuffle=True)\n",
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)\n",
    "RW.fit(train1)\n",
    "# dataset_transf_train, test1 are for the reweighed dataset\n",
    "dataset_transf_train = RW.transform(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change weights to whole numbers\n",
    "for i in range(dataset_transf_train.instance_weights.size):\n",
    "    dataset_transf_train.instance_weights[i] = (round(dataset_transf_train.instance_weights[i] / 0.1) * 0.1) * 10\n",
    "weights = copy.deepcopy(dataset_transf_train.instance_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dataset_transf_train.features according to the weights of each instance\n",
    "sum_weights = 0\n",
    "for i in range(dataset_transf_train.features.shape[0]):\n",
    "    row = copy.deepcopy(dataset_transf_train.features[i])\n",
    "    row.resize(1,18)\n",
    "    weight = int(weights[i])\n",
    "    sum_weights = sum_weights+weight\n",
    "    for j in range(weight-1):\n",
    "        dataset_transf_train.features = np.concatenate((dataset_transf_train.features,row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump dataset_transf_train (numpy.ndarray) to csv\n",
    "np.savetxt(\"dataset_transf_train_features.csv\", dataset_transf_train.features, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.689295; batch adversarial loss: 0.826605\n",
      "epoch 0; iter: 200; batch classifier loss: 1.091300; batch adversarial loss: 1.006659\n",
      "epoch 1; iter: 0; batch classifier loss: 1.074867; batch adversarial loss: 0.922128\n",
      "epoch 1; iter: 200; batch classifier loss: 0.985737; batch adversarial loss: 0.789555\n",
      "epoch 2; iter: 0; batch classifier loss: 1.074876; batch adversarial loss: 0.708658\n",
      "epoch 2; iter: 200; batch classifier loss: 0.576550; batch adversarial loss: 0.653842\n",
      "epoch 3; iter: 0; batch classifier loss: 0.485614; batch adversarial loss: 0.662933\n",
      "epoch 3; iter: 200; batch classifier loss: 0.366582; batch adversarial loss: 0.631648\n",
      "epoch 4; iter: 0; batch classifier loss: 0.380329; batch adversarial loss: 0.647698\n",
      "epoch 4; iter: 200; batch classifier loss: 0.339574; batch adversarial loss: 0.659192\n",
      "epoch 5; iter: 0; batch classifier loss: 0.436314; batch adversarial loss: 0.623152\n",
      "epoch 5; iter: 200; batch classifier loss: 0.500673; batch adversarial loss: 0.621304\n",
      "epoch 6; iter: 0; batch classifier loss: 0.396251; batch adversarial loss: 0.618940\n",
      "epoch 6; iter: 200; batch classifier loss: 0.457321; batch adversarial loss: 0.626519\n",
      "epoch 7; iter: 0; batch classifier loss: 0.466840; batch adversarial loss: 0.632406\n",
      "epoch 7; iter: 200; batch classifier loss: 0.443468; batch adversarial loss: 0.631927\n",
      "epoch 8; iter: 0; batch classifier loss: 0.426992; batch adversarial loss: 0.654623\n",
      "epoch 8; iter: 200; batch classifier loss: 0.397831; batch adversarial loss: 0.619824\n",
      "epoch 9; iter: 0; batch classifier loss: 0.519531; batch adversarial loss: 0.652221\n",
      "epoch 9; iter: 200; batch classifier loss: 0.495234; batch adversarial loss: 0.629882\n",
      "epoch 10; iter: 0; batch classifier loss: 0.470171; batch adversarial loss: 0.582008\n",
      "epoch 10; iter: 200; batch classifier loss: 0.434987; batch adversarial loss: 0.616850\n",
      "epoch 11; iter: 0; batch classifier loss: 0.470119; batch adversarial loss: 0.614434\n",
      "epoch 11; iter: 200; batch classifier loss: 0.369590; batch adversarial loss: 0.636762\n",
      "epoch 12; iter: 0; batch classifier loss: 0.418257; batch adversarial loss: 0.559073\n",
      "epoch 12; iter: 200; batch classifier loss: 0.439821; batch adversarial loss: 0.617823\n",
      "epoch 13; iter: 0; batch classifier loss: 0.447531; batch adversarial loss: 0.625511\n",
      "epoch 13; iter: 200; batch classifier loss: 0.374431; batch adversarial loss: 0.646887\n",
      "epoch 14; iter: 0; batch classifier loss: 0.426844; batch adversarial loss: 0.622982\n",
      "epoch 14; iter: 200; batch classifier loss: 0.412862; batch adversarial loss: 0.613426\n",
      "epoch 15; iter: 0; batch classifier loss: 0.492940; batch adversarial loss: 0.638993\n",
      "epoch 15; iter: 200; batch classifier loss: 0.434344; batch adversarial loss: 0.603833\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505028; batch adversarial loss: 0.593792\n",
      "epoch 16; iter: 200; batch classifier loss: 0.430989; batch adversarial loss: 0.634013\n",
      "epoch 17; iter: 0; batch classifier loss: 0.403095; batch adversarial loss: 0.611305\n",
      "epoch 17; iter: 200; batch classifier loss: 0.403779; batch adversarial loss: 0.583881\n",
      "epoch 18; iter: 0; batch classifier loss: 0.460023; batch adversarial loss: 0.613825\n",
      "epoch 18; iter: 200; batch classifier loss: 0.447582; batch adversarial loss: 0.636790\n",
      "epoch 19; iter: 0; batch classifier loss: 0.463015; batch adversarial loss: 0.659452\n",
      "epoch 19; iter: 200; batch classifier loss: 0.328099; batch adversarial loss: 0.628372\n",
      "epoch 20; iter: 0; batch classifier loss: 0.385373; batch adversarial loss: 0.592667\n",
      "epoch 20; iter: 200; batch classifier loss: 0.443079; batch adversarial loss: 0.619455\n",
      "epoch 21; iter: 0; batch classifier loss: 0.312569; batch adversarial loss: 0.624492\n",
      "epoch 21; iter: 200; batch classifier loss: 0.436146; batch adversarial loss: 0.674013\n",
      "epoch 22; iter: 0; batch classifier loss: 0.403231; batch adversarial loss: 0.570903\n",
      "epoch 22; iter: 200; batch classifier loss: 0.446087; batch adversarial loss: 0.645273\n",
      "epoch 23; iter: 0; batch classifier loss: 0.413261; batch adversarial loss: 0.598522\n",
      "epoch 23; iter: 200; batch classifier loss: 0.366858; batch adversarial loss: 0.575488\n",
      "epoch 24; iter: 0; batch classifier loss: 0.410901; batch adversarial loss: 0.602483\n",
      "epoch 24; iter: 200; batch classifier loss: 0.397163; batch adversarial loss: 0.671749\n",
      "epoch 25; iter: 0; batch classifier loss: 0.394043; batch adversarial loss: 0.635964\n",
      "epoch 25; iter: 200; batch classifier loss: 0.384488; batch adversarial loss: 0.615809\n",
      "epoch 26; iter: 0; batch classifier loss: 0.407323; batch adversarial loss: 0.593247\n",
      "epoch 26; iter: 200; batch classifier loss: 0.497557; batch adversarial loss: 0.598048\n",
      "epoch 27; iter: 0; batch classifier loss: 0.414974; batch adversarial loss: 0.640110\n",
      "epoch 27; iter: 200; batch classifier loss: 0.398938; batch adversarial loss: 0.633289\n",
      "epoch 28; iter: 0; batch classifier loss: 0.453007; batch adversarial loss: 0.616677\n",
      "epoch 28; iter: 200; batch classifier loss: 0.355886; batch adversarial loss: 0.661981\n",
      "epoch 29; iter: 0; batch classifier loss: 0.435756; batch adversarial loss: 0.610038\n",
      "epoch 29; iter: 200; batch classifier loss: 0.427685; batch adversarial loss: 0.563872\n",
      "epoch 30; iter: 0; batch classifier loss: 0.398880; batch adversarial loss: 0.637467\n",
      "epoch 30; iter: 200; batch classifier loss: 0.462586; batch adversarial loss: 0.579635\n",
      "epoch 31; iter: 0; batch classifier loss: 0.364291; batch adversarial loss: 0.610963\n",
      "epoch 31; iter: 200; batch classifier loss: 0.400248; batch adversarial loss: 0.615290\n",
      "epoch 32; iter: 0; batch classifier loss: 0.400524; batch adversarial loss: 0.585574\n",
      "epoch 32; iter: 200; batch classifier loss: 0.453460; batch adversarial loss: 0.587234\n",
      "epoch 33; iter: 0; batch classifier loss: 0.398170; batch adversarial loss: 0.616551\n",
      "epoch 33; iter: 200; batch classifier loss: 0.456418; batch adversarial loss: 0.667778\n",
      "epoch 34; iter: 0; batch classifier loss: 0.495415; batch adversarial loss: 0.657367\n",
      "epoch 34; iter: 200; batch classifier loss: 0.446332; batch adversarial loss: 0.610156\n",
      "epoch 35; iter: 0; batch classifier loss: 0.407413; batch adversarial loss: 0.696918\n",
      "epoch 35; iter: 200; batch classifier loss: 0.401226; batch adversarial loss: 0.580576\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443469; batch adversarial loss: 0.589904\n",
      "epoch 36; iter: 200; batch classifier loss: 0.468995; batch adversarial loss: 0.571537\n",
      "epoch 37; iter: 0; batch classifier loss: 0.489852; batch adversarial loss: 0.589706\n",
      "epoch 37; iter: 200; batch classifier loss: 0.341123; batch adversarial loss: 0.675788\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447990; batch adversarial loss: 0.598207\n",
      "epoch 38; iter: 200; batch classifier loss: 0.419052; batch adversarial loss: 0.579086\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407733; batch adversarial loss: 0.614560\n",
      "epoch 39; iter: 200; batch classifier loss: 0.342773; batch adversarial loss: 0.611557\n",
      "epoch 40; iter: 0; batch classifier loss: 0.421539; batch adversarial loss: 0.656878\n",
      "epoch 40; iter: 200; batch classifier loss: 0.333714; batch adversarial loss: 0.649065\n",
      "epoch 41; iter: 0; batch classifier loss: 0.484244; batch adversarial loss: 0.632156\n",
      "epoch 41; iter: 200; batch classifier loss: 0.448773; batch adversarial loss: 0.584551\n",
      "epoch 42; iter: 0; batch classifier loss: 0.459674; batch adversarial loss: 0.656997\n",
      "epoch 42; iter: 200; batch classifier loss: 0.429559; batch adversarial loss: 0.663003\n",
      "epoch 43; iter: 0; batch classifier loss: 0.382470; batch adversarial loss: 0.589408\n",
      "epoch 43; iter: 200; batch classifier loss: 0.558969; batch adversarial loss: 0.537588\n",
      "epoch 44; iter: 0; batch classifier loss: 0.435305; batch adversarial loss: 0.658989\n",
      "epoch 44; iter: 200; batch classifier loss: 0.436841; batch adversarial loss: 0.637824\n",
      "epoch 45; iter: 0; batch classifier loss: 0.379143; batch adversarial loss: 0.595413\n",
      "epoch 45; iter: 200; batch classifier loss: 0.515161; batch adversarial loss: 0.643389\n",
      "epoch 46; iter: 0; batch classifier loss: 0.451457; batch adversarial loss: 0.612211\n",
      "epoch 46; iter: 200; batch classifier loss: 0.354551; batch adversarial loss: 0.595172\n",
      "epoch 47; iter: 0; batch classifier loss: 0.383609; batch adversarial loss: 0.655735\n",
      "epoch 47; iter: 200; batch classifier loss: 0.532606; batch adversarial loss: 0.566221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 0; batch classifier loss: 0.420530; batch adversarial loss: 0.591593\n",
      "epoch 48; iter: 200; batch classifier loss: 0.517643; batch adversarial loss: 0.601277\n",
      "epoch 49; iter: 0; batch classifier loss: 0.583936; batch adversarial loss: 0.595547\n",
      "epoch 49; iter: 200; batch classifier loss: 0.464953; batch adversarial loss: 0.610254\n"
     ]
    }
   ],
   "source": [
    "metric_dataset_debiasing_train = []\n",
    "metric_dataset_debiasing_test = []\n",
    "metric_dataset_prejudice_train = []\n",
    "metric_dataset_prejudice_test = []\n",
    "\n",
    "################## without reweighing ##########################\n",
    "\n",
    "# adversarial debiasing\n",
    "sess = tf.Session()\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)\n",
    "debiased_model.fit(train1)\n",
    "dataset_debiasing_train = debiased_model.predict(train1)\n",
    "dataset_debiasing_test = debiased_model.predict(test1)\n",
    "\n",
    "# prejudice remover\n",
    "prejudice_model = PrejudiceRemover(eta=100, sensitive_attr='sex')\n",
    "prejudice_model.fit(train1)\n",
    "dataset_prejudice_train = prejudice_model.predict(train1)\n",
    "dataset_prejudice_test = prejudice_model.predict(test1)\n",
    "\n",
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# metrics\n",
    "metric_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "metric_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "metric_dataset_debiasing_train.append(metric_debiasing_train.mean_difference())\n",
    "metric_dataset_debiasing_test.append(metric_debiasing_test.mean_difference())\n",
    "\n",
    "metric_prejudice_train = BinaryLabelDatasetMetric(dataset_prejudice_train, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "metric_prejudice_test = BinaryLabelDatasetMetric(dataset_prejudice_test, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "metric_dataset_prejudice_train.append(metric_prejudice_train.mean_difference())\n",
    "metric_dataset_prejudice_test.append(metric_prejudice_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without reweighing: \n",
      "With adv debiasing: \n",
      "[-0.07800066931484553] \t\t [-0.07669695900538484]\n",
      "With Prejudice remover: \n",
      "[-0.22904440746255583] \t\t [-0.2289119804400978]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Without reweighing: \")\n",
    "print(\"With adv debiasing: \")\n",
    "print(metric_dataset_debiasing_train, '\\t\\t',metric_dataset_debiasing_test)\n",
    "print(\"With Prejudice remover: \")\n",
    "print(metric_dataset_prejudice_train, '\\t\\t',metric_dataset_prejudice_test)\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 255668 is out of bounds for axis 0 with size 34189",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-8778b4c06bca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                           \u001b[0mdebias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                           sess=sess)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdebiased_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_transf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mdataset_debiasing_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdebiased_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_transf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdataset_debiasing_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdebiased_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/aif360-0.1.1-py3.6.egg/aif360/algorithms/transformer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mnew_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mnew_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/aif360-0.1.1-py3.6.egg/aif360/algorithms/inprocessing/adversarial_debiasing.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mbatch_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffled_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mbatch_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                     batch_protected_attributes = np.reshape(dataset.protected_attributes[batch_ids][:,\n\u001b[1;32m    198\u001b[0m                                                  dataset.protected_attribute_names.index(self.protected_attribute_name)], [-1,1])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 255668 is out of bounds for axis 0 with size 34189"
     ]
    }
   ],
   "source": [
    "################## with reweighing ##########################\n",
    "\n",
    "# adversarial debiasing\n",
    "sess = tf.Session()\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)\n",
    "debiased_model.fit(dataset_transf_train)\n",
    "dataset_debiasing_train = debiased_model.predict(dataset_transf_train)\n",
    "dataset_debiasing_test = debiased_model.predict(test1)\n",
    "\n",
    "# prejudice remover\n",
    "prejudice_model = PrejudiceRemover(eta=100, sensitive_attr='sex')\n",
    "prejudice_model.fit(dataset_transf_train)\n",
    "dataset_prejudice_train = prejudice_model.predict(dataset_transf_train)\n",
    "dataset_prejudice_test = prejudice_model.predict(test1)\n",
    "\n",
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# metrics\n",
    "metric_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "metric_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "metric_dataset_debiasing_train.append(metric_debiasing_train.mean_difference())\n",
    "metric_dataset_debiasing_test.append(metric_debiasing_test.mean_difference())\n",
    "\n",
    "metric_prejudice_train = BinaryLabelDatasetMetric(dataset_prejudice_train, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "metric_prejudice_test = BinaryLabelDatasetMetric(dataset_prejudice_test, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "metric_dataset_prejudice_train.append(metric_prejudice_train.mean_difference())\n",
    "metric_dataset_prejudice_test.append(metric_prejudice_test.mean_difference())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
