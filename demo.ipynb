{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import errno\n",
    "import math\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_compasdataset(df):\n",
    "    df = df[['age', 'c_charge_degree', 'race', 'age_cat', 'score_text',\n",
    "                 'sex', 'priors_count', 'days_b_screening_arrest', 'decile_score',\n",
    "                 'is_recid', 'two_year_recid', 'c_jail_in', 'c_jail_out']]\n",
    "\n",
    "    # Indices of data samples to keep\n",
    "    ix = df['days_b_screening_arrest'] <= 30\n",
    "    ix = (df['days_b_screening_arrest'] >= -30) & ix\n",
    "    ix = (df['is_recid'] != -1) & ix\n",
    "    ix = (df['c_charge_degree'] != \"O\") & ix\n",
    "    ix = (df['score_text'] != 'N/A') & ix\n",
    "    df = df.loc[ix,:]\n",
    "    df['length_of_stay'] = (pd.to_datetime(df['c_jail_out']) - pd.to_datetime(df['c_jail_in'])).apply(lambda x: x.days)\n",
    "\n",
    "    # Restrict races to African-American and Caucasian\n",
    "    df = df.loc[~df['race'].isin(['Native American','Hispanic','Asian','Other']),:]\n",
    "\n",
    "    df = df[['sex','race','age_cat','c_charge_degree','score_text','priors_count','is_recid', 'two_year_recid','length_of_stay']]\n",
    "\n",
    "    df['priors_count'] = df['priors_count'].apply(lambda x: 0 if x <= 0 else ('1 to 3' if 1 <= x <= 3 else 'More than 3'))\n",
    "    df['length_of_stay'] = df['length_of_stay'].apply(lambda x: '<week' if x <= 7 else ('<3months' if 8 < x <= 93 else '>3months'))\n",
    "    df['score_text'] = df['score_text'].apply(lambda x: 'MediumHigh' if (x == 'High')| (x == 'Medium') else x)\n",
    "    df['age_cat'] = df['age_cat'].apply(lambda x: '25 to 45' if x == '25 - 45' else x)\n",
    "\n",
    "    df['sex'] = df['sex'].replace({'Female': 1.0, 'Male': 0.0})\n",
    "    df['race'] = df['race'].apply(lambda x: 1.0 if x == 'Caucasian' else 0.0)\n",
    "\n",
    "    df = df[['two_year_recid', 'sex', 'race', 'age_cat', 'priors_count', 'c_charge_degree']]\n",
    "\n",
    "    protected_attributes = ['sex', 'race']\n",
    "    label_name = 'two_year_recid'\n",
    "    categorical_features = ['age_cat', 'priors_count', 'c_charge_degree']\n",
    "    features = categorical_features + [label_name] + protected_attributes\n",
    "\n",
    "    # privileged classes\n",
    "    privileged_classes = {\"sex\": [1.0], \"race\": [1.0]}\n",
    "\n",
    "    # protected attribute maps\n",
    "    protected_attribute_map = {\"sex\": {0.0: 'Male', 1.0: 'Female'},\n",
    "                                \"race\": {1.0: 'Caucasian', 0.0: 'Not Caucasian'}}\n",
    "\n",
    "\n",
    "    data = StandardDataset(df, label_name, favorable_classes=[0],\n",
    "                           protected_attribute_names=protected_attributes,\n",
    "                           privileged_classes=[privileged_classes[x] for x in protected_attributes],\n",
    "                           categorical_features=categorical_features,\n",
    "                           features_to_keep=features,\n",
    "                           metadata={'label_maps': [{1.0: 'Did recid.', 0.0: 'No recid.'}],\n",
    "                                     'protected_attribute_maps': [protected_attribute_map[x] for x in protected_attributes]})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_germandataset(df):\n",
    "    def group_credit_hist(x):\n",
    "        if x in ['no credits taken/ all credits paid back duly', 'all credits at this bank paid back duly', 'existing credits paid back duly till now']:\n",
    "            return 'None/Paid'\n",
    "        elif x == 'delay in paying off in the past':\n",
    "            return 'Delay'\n",
    "        elif x == 'critical account/ other credits existing (not at this bank)':\n",
    "            return 'Other'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    def group_employ(x):\n",
    "        if x == 'unemployed':\n",
    "            return 'Unemployed'\n",
    "        elif x in ['... < 1 year ', '1 <= ... < 4 years']:\n",
    "            return '1-4 years'\n",
    "        elif x in ['4 <= ... < 7 years', '.. >= 7 years']:\n",
    "            return '4+ years'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    def group_savings(x):\n",
    "        if x in ['... < 100 DM', '100 <= ... < 500 DM']:\n",
    "            return '<500'\n",
    "        elif x in ['500 <= ... < 1000 DM ', '.. >= 1000 DM ']:\n",
    "            return '500+'\n",
    "        elif x == 'unknown/ no savings account':\n",
    "            return 'Unknown/None'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    def group_status(x):\n",
    "        if x in ['< 0 DM', '0 <= ... < 200 DM']:\n",
    "            return '<200'\n",
    "        elif x in ['>= 200 DM / salary assignments for at least 1 year']:\n",
    "            return '200+'\n",
    "        elif x == 'no checking account':\n",
    "            return 'None'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    status_map = {'male : divorced/separated': 1.0,\n",
    "                'male : single': 1.0,\n",
    "                'male : married/widowed': 1.0,\n",
    "                'female : divorced/separated/married': 0.0,\n",
    "                'female : single': 0.0}\n",
    "\n",
    "    df['personal_status_sex'] = df['personal_status_sex'].replace(status_map)\n",
    "    df['credit_history'] = df['credit_history'].apply(lambda x: group_credit_hist(x))\n",
    "    df['savings'] = df['savings'].apply(lambda x: group_savings(x))\n",
    "    df['present_emp_since'] = df['present_emp_since'].apply(lambda x: group_employ(x))\n",
    "    df['age'] = df['age'].apply(lambda x: np.float(x >= 25))\n",
    "    df['account_check_status'] = df['account_check_status'].apply(lambda x: group_status(x))\n",
    "\n",
    "    df = df.rename(columns = {'default': 'credit', 'present_emp_since': 'employment', 'account_check_status': 'status', 'personal_status_sex': 'sex'})\n",
    "\n",
    "    protected_attribute = ['sex', 'age']\n",
    "    label_name = 'credit'\n",
    "    categorical_features = ['credit_history', 'savings', 'employment']\n",
    "    features = categorical_features + [label_name] + protected_attribute\n",
    "\n",
    "    privileged_class = {'sex': [1.0], 'age': [1.0]}\n",
    "\n",
    "    protected_attribute_map = {\"sex\": {1.0: 'male', 0.0: 'female'},\n",
    "                            \"age\": {1.0: 'old', 0.0: 'young'}}\n",
    "\n",
    "    data = StandardDataset(df, label_name, favorable_classes=[1],\n",
    "                            protected_attribute_names=protected_attribute,\n",
    "                            privileged_classes=[privileged_class[x] for x in protected_attribute],\n",
    "                            categorical_features=categorical_features,\n",
    "                            features_to_keep=features,\n",
    "                            metadata={'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n",
    "                                    'protected_attribute_maps': [protected_attribute_map[x] for x in protected_attribute]})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Reweighing ##############\n",
    "\n",
    "def reweighing_data(train, unprivileged_group, privileged_group):\n",
    "    RW = Reweighing(unprivileged_groups=unprivileged_group, privileged_groups=privileged_group)\n",
    "    RW.fit(train)\n",
    "    train_transformed = RW.transform(train)\n",
    "\n",
    "    # change weights to whole numbers\n",
    "    for i in range(train_transformed.instance_weights.size):\n",
    "        train_transformed.instance_weights[i] = (round(train_transformed.instance_weights[i] / 0.1) * 0.1) * 10\n",
    "        weights = copy.deepcopy(train_transformed.instance_weights)\n",
    "\n",
    "    # change train_transformed.features and train_transformed.labels and train_transformed.protected_attributes according to the weights of each instance\n",
    "    for i in range(train_transformed.features.shape[0]):\n",
    "        row = copy.deepcopy(train_transformed.features[i])\n",
    "        row_label = copy.deepcopy(train_transformed.labels[i])\n",
    "        row_protected_attributes = copy.deepcopy(train_transformed.protected_attributes[i])\n",
    "        row_protected_attributes.resize(1,2)\n",
    "        row.resize(1,train_transformed.features.shape[1])\n",
    "        row_label.resize(1,1)\n",
    "        weight = int(weights[i])\n",
    "        for j in range(weight-1):\n",
    "            train_transformed.features = np.concatenate((train_transformed.features,row))\n",
    "            train_transformed.labels = np.concatenate((train_transformed.labels,row_label))\n",
    "            train_transformed.protected_attributes = np.concatenate((train_transformed.protected_attributes,row_protected_attributes))\n",
    "\n",
    "    # change the train_transformed to a numpy array of ones to match number of rows in features\n",
    "    train_transformed.instance_weights = np.ones(train_transformed.features.shape[0])\n",
    "\n",
    "    return train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_rates(input_data, output_data, attribute_name, privileged=None, unprivileged=None, favourable=None, unfavourable=None):\n",
    "    \n",
    "    index_attribute = input_data.feature_names.index(attribute_name)\n",
    "    privileged = float(privileged)\n",
    "    unprivileged = float(unprivileged)\n",
    "    \n",
    "    input_priv = input_data.labels[np.where(input_data.features[:,index_attribute] == privileged)]\n",
    "    input_priv = np.reshape(input_priv, (input_priv.shape[0],1))\n",
    "    output_priv = output_data.labels[np.where(output_data.features[:,index_attribute] == privileged)]\n",
    "    output_priv = np.reshape(output_priv, (output_priv.shape[0],1))\n",
    "    \n",
    "    priv_labels = np.concatenate((input_priv, output_priv), axis=1)\n",
    "    \n",
    "    input_unpriv = input_data.labels[np.where(input_data.features[:,index_attribute] == unprivileged)]\n",
    "    input_unpriv = np.reshape(input_unpriv, (input_unpriv.shape[0],1))\n",
    "    output_unpriv = output_data.labels[np.where(output_data.features[:,index_attribute] == unprivileged)]\n",
    "    output_unpriv = np.reshape(output_unpriv, (output_unpriv.shape[0],1))\n",
    "    \n",
    "    unpriv_labels = np.concatenate((input_unpriv, output_unpriv), axis=1)\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(priv_labels.shape[0]):\n",
    "        input_label = priv_labels[i][0]\n",
    "        output_label = priv_labels[i][1]\n",
    "        if input_label == output_label:\n",
    "            if input_label == unfavourable:\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                tp = tp + 1\n",
    "        else:\n",
    "            if input_label == favourable and output_label == unfavourable:\n",
    "                fn = fn + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "    \n",
    "    rates_privileged = [tp,fp,tn,fn]\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(unpriv_labels.shape[0]):\n",
    "        input_label = unpriv_labels[i][0]\n",
    "        output_label = unpriv_labels[i][1]\n",
    "        if input_label == output_label:\n",
    "            if input_label == unfavourable:\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                tp = tp + 1\n",
    "        else:\n",
    "            if input_label == favourable and output_label == unfavourable:\n",
    "                fn = fn + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "                \n",
    "    rates_unprivileged = [tp,fp,tn,fn]  \n",
    "    \n",
    "    rates_list = [rates_privileged, rates_unprivileged]\n",
    "    \n",
    "    return rates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_opp_diff(input_data, output_data, attribute_name, privileged, unprivileged, favourable, unfavourable):\n",
    "    rates_both = output_rates(input_data, output_data, attribute_name, privileged, unprivileged, favourable, unfavourable)\n",
    "    \n",
    "    # [tp, fp, tn, fn]\n",
    "    outcome_privileged = rates_both[0]\n",
    "    outcome_unprivileged = rates_both[1]\n",
    "    \n",
    "    # true positive rate = tp / (tp + fn)\n",
    "    tpr_privileged = outcome_privileged[0] / (outcome_privileged[0] + outcome_privileged[3])\n",
    "    tpr_unprivileged = outcome_unprivileged[0] / (outcome_unprivileged[0] + outcome_unprivileged[3])\n",
    "\n",
    "    fairness = tpr_unprivileged - tpr_privileged\n",
    "    \n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_odds_diff(input_data, output_data, attribute_name, privileged, unprivileged, favourable, unfavourable):\n",
    "    rates_both = output_rates(input_data, output_data, attribute_name, privileged, unprivileged, favourable, unfavourable)\n",
    "    \n",
    "    # [tp, fp, tn, fn]\n",
    "    outcome_privileged = rates_both[0]\n",
    "    outcome_unprivileged = rates_both[1]\n",
    "    \n",
    "    # true positive rate = tp / (tp + fn)\n",
    "    tpr_privileged = outcome_privileged[0] / (outcome_privileged[0] + outcome_privileged[3])\n",
    "    tpr_unprivileged = outcome_unprivileged[0] / (outcome_unprivileged[0] + outcome_unprivileged[3])\n",
    "\n",
    "    # false positive rate = fp / (fp + tn)\n",
    "    fpr_privileged = outcome_privileged[1] / (outcome_privileged[1] + outcome_privileged[2])\n",
    "    fpr_unprivileged = outcome_unprivileged[1] / (outcome_unprivileged[1] + outcome_unprivileged[2])\n",
    "    \n",
    "    fpr_diff = fpr_unprivileged - fpr_privileged\n",
    "    tpr_diff = tpr_unprivileged - tpr_unprivileged\n",
    "    \n",
    "    fairness = (fpr_diff + tpr_diff) * 0.5\n",
    "    \n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(train, test, unprivileged_groups, privileged_groups):\n",
    "    \n",
    "    ################## adversarial debiasing #################\n",
    "\n",
    "    sess = tf.Session()\n",
    "    debiased_model_reweighing = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                                                     unprivileged_groups = unprivileged_groups,\n",
    "                                                     scope_name='debiased_classifier', debias=True, sess=sess)\n",
    "    debiased_model_reweighing.fit(train)\n",
    "    dataset_debiasing_test_reweighing = debiased_model_reweighing.predict(test)\n",
    "    sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    ##################### metrics #####################\n",
    "\n",
    "    metric_test = BinaryLabelDatasetMetric(dataset_debiasing_test_reweighing,\n",
    "                                           unprivileged_groups=unprivileged_groups,\n",
    "                                           privileged_groups=privileged_groups)\n",
    "    acc_test = ClassificationMetric(test, dataset_debiasing_test_reweighing,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "\n",
    "    accuracy_adversarial = accuracy_score(y_true = test.labels, y_pred = dataset_debiasing_test_reweighing.labels)\n",
    "    \n",
    "    equal_opportunity_difference = equal_opp_diff(test, dataset_debiasing_test_reweighing,\n",
    "                                                  'sex', privileged=1, unprivileged=0, favourable=1, unfavourable=0)\n",
    "    \n",
    "    average_odds_difference = avg_odds_diff(test, dataset_debiasing_test_reweighing,\n",
    "                                                  'sex', privileged=1, unprivileged=0, favourable=1, unfavourable=0)\n",
    "    \n",
    "    metrics_adversarial = [metric_test.mean_difference(),acc_test.disparate_impact(), equal_opportunity_difference, average_odds_difference, acc_test.theil_index()]\n",
    "\n",
    "\n",
    "    ##################### prejudice remover #####################\n",
    "    prejudice_model_reweighing = PrejudiceRemover(eta=100, sensitive_attr='sex')\n",
    "    prejudice_model_reweighing.fit(train)\n",
    "    dataset_prejudice_test_reweighing = prejudice_model_reweighing.predict(test)\n",
    "\n",
    "    ##################### metrics #####################\n",
    "\n",
    "    metric_test = BinaryLabelDatasetMetric(dataset_prejudice_test_reweighing,\n",
    "                                           unprivileged_groups=unprivileged_groups,\n",
    "                                           privileged_groups=privileged_groups)\n",
    "    acc_test = ClassificationMetric(test, dataset_prejudice_test_reweighing,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    accuracy_prejudice = accuracy_score(y_true=test.labels, y_pred=dataset_prejudice_test_reweighing.labels)\n",
    "    \n",
    "    equal_opportunity_difference = equal_opp_diff(test, dataset_prejudice_test_reweighing,\n",
    "                                                  'sex', privileged=1, unprivileged=0, favourable=1, unfavourable=0)\n",
    "    \n",
    "    average_odds_difference = avg_odds_diff(test, dataset_prejudice_test_reweighing,\n",
    "                                                  'sex', privileged=1, unprivileged=0, favourable=1, unfavourable=0)\n",
    "    \n",
    "    if acc_test.disparate_impact() == math.inf:\n",
    "        disparate_impact = 5.0\n",
    "    else:\n",
    "        disparate_impact = acc_test.disparate_impact()\n",
    "    \n",
    "    metrics_prejudice = [metric_test.mean_difference(), disparate_impact, equal_opportunity_difference, average_odds_difference, acc_test.theil_index()]\n",
    "\n",
    "\n",
    "    ##################### normal neural net #####################\n",
    "    sess = tf.Session()\n",
    "    neural_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                                        unprivileged_groups = unprivileged_groups,\n",
    "                                        scope_name='debiased_classifier', debias=False, sess=sess)\n",
    "    neural_model.fit(train)\n",
    "    dataset_neural_test = neural_model.predict(test)\n",
    "    sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    ##################### metrics #####################\n",
    "\n",
    "    metric_test = BinaryLabelDatasetMetric(dataset_neural_test,\n",
    "                                           unprivileged_groups=unprivileged_groups,\n",
    "                                           privileged_groups=privileged_groups)\n",
    "    acc_test = ClassificationMetric(test, dataset_neural_test,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    accuracy_nondebiasing = accuracy_score(y_true=test.labels, y_pred=dataset_neural_test.labels)\n",
    "    \n",
    "    equal_opportunity_difference = equal_opp_diff(test, dataset_neural_test,\n",
    "                                                  'sex', privileged=1, unprivileged=0, favourable=1, unfavourable=0)\n",
    "    \n",
    "    average_odds_difference = avg_odds_diff(test, dataset_neural_test,\n",
    "                                                  'sex', privileged=1, unprivileged=0, favourable=1, unfavourable=0)\n",
    "\n",
    "    metrics_nondebiasing = [metric_test.mean_difference(),acc_test.disparate_impact(), equal_opportunity_difference, average_odds_difference, acc_test.theil_index()]\n",
    "\n",
    "\n",
    "    ##################### ensemble #####################\n",
    "    pred_labels_test = []\n",
    "    for i in range(0, len(test.features)):\n",
    "        arr_test = mode([dataset_debiasing_test_reweighing.labels[i], dataset_prejudice_test_reweighing.labels[i], dataset_neural_test.labels[i]])\n",
    "        pred_labels_test.append(arr_test[0][0])\n",
    "        dataset_ensemble_test = test.copy()\n",
    "        dataset_ensemble_test.labels = np.array(pred_labels_test)\n",
    "\n",
    "\n",
    "    ##################### metrics #####################\n",
    "\n",
    "    metric_test = BinaryLabelDatasetMetric(dataset_ensemble_test,\n",
    "                                           unprivileged_groups=unprivileged_groups,\n",
    "                                           privileged_groups=privileged_groups)\n",
    "    acc_test = ClassificationMetric(test, dataset_ensemble_test,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    accuracy_ensemble = accuracy_score(y_true=test.labels, y_pred=dataset_ensemble_test.labels)\n",
    "    \n",
    "    equal_opportunity_difference = equal_opp_diff(test, dataset_ensemble_test,\n",
    "                                                  'sex', privileged=1, unprivileged=0, favourable=1, unfavourable=0)\n",
    "    \n",
    "    average_odds_difference = avg_odds_diff(test, dataset_ensemble_test,\n",
    "                                                  'sex', privileged=1, unprivileged=0, favourable=1, unfavourable=0)\n",
    "    \n",
    "    metrics_ensemble = [metric_test.mean_difference(),acc_test.disparate_impact(), equal_opportunity_difference, average_odds_difference, acc_test.theil_index()]\n",
    "\n",
    "    accuracy_scores = [accuracy_adversarial, accuracy_prejudice, accuracy_nondebiasing, accuracy_ensemble]\n",
    "    fairness_metrics = [metrics_adversarial, metrics_prejudice, metrics_nondebiasing, metrics_ensemble]\n",
    "    \n",
    "    return accuracy_scores, fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification with Compas data set\n",
      "\n",
      "run = 1\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695470; batch adversarial loss: 0.682815\n",
      "epoch 0; iter: 200; batch classifier loss: 0.642505; batch adversarial loss: 0.685670\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586604; batch adversarial loss: 0.705760\n",
      "epoch 1; iter: 200; batch classifier loss: 0.642258; batch adversarial loss: 0.656937\n",
      "epoch 2; iter: 0; batch classifier loss: 0.679931; batch adversarial loss: 0.677651\n",
      "epoch 2; iter: 200; batch classifier loss: 0.666182; batch adversarial loss: 0.687480\n",
      "epoch 3; iter: 0; batch classifier loss: 0.616984; batch adversarial loss: 0.669878\n",
      "epoch 3; iter: 200; batch classifier loss: 0.635190; batch adversarial loss: 0.660383\n",
      "epoch 4; iter: 0; batch classifier loss: 0.614649; batch adversarial loss: 0.675361\n",
      "epoch 4; iter: 200; batch classifier loss: 0.638734; batch adversarial loss: 0.624785\n",
      "epoch 5; iter: 0; batch classifier loss: 0.607590; batch adversarial loss: 0.679574\n",
      "epoch 5; iter: 200; batch classifier loss: 0.625506; batch adversarial loss: 0.665802\n",
      "epoch 6; iter: 0; batch classifier loss: 0.603541; batch adversarial loss: 0.681397\n",
      "epoch 6; iter: 200; batch classifier loss: 0.619757; batch adversarial loss: 0.696026\n",
      "epoch 7; iter: 0; batch classifier loss: 0.637970; batch adversarial loss: 0.675508\n",
      "epoch 7; iter: 200; batch classifier loss: 0.576265; batch adversarial loss: 0.699085\n",
      "epoch 8; iter: 0; batch classifier loss: 0.642993; batch adversarial loss: 0.670941\n",
      "epoch 8; iter: 200; batch classifier loss: 0.587942; batch adversarial loss: 0.660298\n",
      "epoch 9; iter: 0; batch classifier loss: 0.607826; batch adversarial loss: 0.717170\n",
      "epoch 9; iter: 200; batch classifier loss: 0.660159; batch adversarial loss: 0.645595\n",
      "epoch 10; iter: 0; batch classifier loss: 0.636153; batch adversarial loss: 0.649491\n",
      "epoch 10; iter: 200; batch classifier loss: 0.558763; batch adversarial loss: 0.676072\n",
      "epoch 11; iter: 0; batch classifier loss: 0.622191; batch adversarial loss: 0.672482\n",
      "epoch 11; iter: 200; batch classifier loss: 0.574205; batch adversarial loss: 0.659049\n",
      "epoch 12; iter: 0; batch classifier loss: 0.612826; batch adversarial loss: 0.649234\n",
      "epoch 12; iter: 200; batch classifier loss: 0.617022; batch adversarial loss: 0.662632\n",
      "epoch 13; iter: 0; batch classifier loss: 0.607673; batch adversarial loss: 0.643494\n",
      "epoch 13; iter: 200; batch classifier loss: 0.600744; batch adversarial loss: 0.669371\n",
      "epoch 14; iter: 0; batch classifier loss: 0.595591; batch adversarial loss: 0.688779\n",
      "epoch 14; iter: 200; batch classifier loss: 0.598251; batch adversarial loss: 0.658209\n",
      "epoch 15; iter: 0; batch classifier loss: 0.651896; batch adversarial loss: 0.671934\n",
      "epoch 15; iter: 200; batch classifier loss: 0.598233; batch adversarial loss: 0.676295\n",
      "epoch 16; iter: 0; batch classifier loss: 0.639619; batch adversarial loss: 0.655480\n",
      "epoch 16; iter: 200; batch classifier loss: 0.614850; batch adversarial loss: 0.668254\n",
      "epoch 17; iter: 0; batch classifier loss: 0.623561; batch adversarial loss: 0.676147\n",
      "epoch 17; iter: 200; batch classifier loss: 0.609236; batch adversarial loss: 0.655538\n",
      "epoch 18; iter: 0; batch classifier loss: 0.632266; batch adversarial loss: 0.639271\n",
      "epoch 18; iter: 200; batch classifier loss: 0.643885; batch adversarial loss: 0.684872\n",
      "epoch 19; iter: 0; batch classifier loss: 0.618617; batch adversarial loss: 0.661578\n",
      "epoch 19; iter: 200; batch classifier loss: 0.588956; batch adversarial loss: 0.645911\n",
      "epoch 20; iter: 0; batch classifier loss: 0.593366; batch adversarial loss: 0.656102\n",
      "epoch 20; iter: 200; batch classifier loss: 0.634154; batch adversarial loss: 0.678776\n",
      "epoch 21; iter: 0; batch classifier loss: 0.664333; batch adversarial loss: 0.641278\n",
      "epoch 21; iter: 200; batch classifier loss: 0.661164; batch adversarial loss: 0.657667\n",
      "epoch 22; iter: 0; batch classifier loss: 0.612167; batch adversarial loss: 0.669898\n",
      "epoch 22; iter: 200; batch classifier loss: 0.620912; batch adversarial loss: 0.669752\n",
      "epoch 23; iter: 0; batch classifier loss: 0.606370; batch adversarial loss: 0.669789\n",
      "epoch 23; iter: 200; batch classifier loss: 0.621710; batch adversarial loss: 0.690511\n",
      "epoch 24; iter: 0; batch classifier loss: 0.635208; batch adversarial loss: 0.641204\n",
      "epoch 24; iter: 200; batch classifier loss: 0.594865; batch adversarial loss: 0.688630\n",
      "epoch 25; iter: 0; batch classifier loss: 0.661357; batch adversarial loss: 0.659814\n",
      "epoch 25; iter: 200; batch classifier loss: 0.614974; batch adversarial loss: 0.672203\n",
      "epoch 26; iter: 0; batch classifier loss: 0.632672; batch adversarial loss: 0.688071\n",
      "epoch 26; iter: 200; batch classifier loss: 0.625609; batch adversarial loss: 0.648494\n",
      "epoch 27; iter: 0; batch classifier loss: 0.652354; batch adversarial loss: 0.692604\n",
      "epoch 27; iter: 200; batch classifier loss: 0.631660; batch adversarial loss: 0.672021\n",
      "epoch 28; iter: 0; batch classifier loss: 0.673265; batch adversarial loss: 0.672643\n",
      "epoch 28; iter: 200; batch classifier loss: 0.607717; batch adversarial loss: 0.642703\n",
      "epoch 29; iter: 0; batch classifier loss: 0.616281; batch adversarial loss: 0.688927\n",
      "epoch 29; iter: 200; batch classifier loss: 0.612854; batch adversarial loss: 0.686439\n",
      "epoch 30; iter: 0; batch classifier loss: 0.639071; batch adversarial loss: 0.672475\n",
      "epoch 30; iter: 200; batch classifier loss: 0.564870; batch adversarial loss: 0.685492\n",
      "epoch 31; iter: 0; batch classifier loss: 0.634748; batch adversarial loss: 0.678832\n",
      "epoch 31; iter: 200; batch classifier loss: 0.606197; batch adversarial loss: 0.641544\n",
      "epoch 32; iter: 0; batch classifier loss: 0.755227; batch adversarial loss: 0.664792\n",
      "epoch 32; iter: 200; batch classifier loss: 0.647212; batch adversarial loss: 0.628642\n",
      "epoch 33; iter: 0; batch classifier loss: 0.599562; batch adversarial loss: 0.656042\n",
      "epoch 33; iter: 200; batch classifier loss: 0.643784; batch adversarial loss: 0.675151\n",
      "epoch 34; iter: 0; batch classifier loss: 0.618426; batch adversarial loss: 0.649045\n",
      "epoch 34; iter: 200; batch classifier loss: 0.641706; batch adversarial loss: 0.665118\n",
      "epoch 35; iter: 0; batch classifier loss: 0.606592; batch adversarial loss: 0.679203\n",
      "epoch 35; iter: 200; batch classifier loss: 0.633566; batch adversarial loss: 0.680884\n",
      "epoch 36; iter: 0; batch classifier loss: 0.592243; batch adversarial loss: 0.648134\n",
      "epoch 36; iter: 200; batch classifier loss: 0.614226; batch adversarial loss: 0.688712\n",
      "epoch 37; iter: 0; batch classifier loss: 0.652919; batch adversarial loss: 0.653182\n",
      "epoch 37; iter: 200; batch classifier loss: 0.615152; batch adversarial loss: 0.631849\n",
      "epoch 38; iter: 0; batch classifier loss: 0.644275; batch adversarial loss: 0.686735\n",
      "epoch 38; iter: 200; batch classifier loss: 0.602371; batch adversarial loss: 0.710512\n",
      "epoch 39; iter: 0; batch classifier loss: 0.636552; batch adversarial loss: 0.680821\n",
      "epoch 39; iter: 200; batch classifier loss: 0.569236; batch adversarial loss: 0.665235\n",
      "epoch 40; iter: 0; batch classifier loss: 0.624797; batch adversarial loss: 0.673592\n",
      "epoch 40; iter: 200; batch classifier loss: 0.619956; batch adversarial loss: 0.665987\n",
      "epoch 41; iter: 0; batch classifier loss: 0.649586; batch adversarial loss: 0.662727\n",
      "epoch 41; iter: 200; batch classifier loss: 0.626810; batch adversarial loss: 0.706375\n",
      "epoch 42; iter: 0; batch classifier loss: 0.659610; batch adversarial loss: 0.679745\n",
      "epoch 42; iter: 200; batch classifier loss: 0.627093; batch adversarial loss: 0.641514\n",
      "epoch 43; iter: 0; batch classifier loss: 0.620928; batch adversarial loss: 0.685762\n",
      "epoch 43; iter: 200; batch classifier loss: 0.681564; batch adversarial loss: 0.676185\n",
      "epoch 44; iter: 0; batch classifier loss: 0.624177; batch adversarial loss: 0.675890\n",
      "epoch 44; iter: 200; batch classifier loss: 0.704913; batch adversarial loss: 0.662542\n",
      "epoch 45; iter: 0; batch classifier loss: 0.611443; batch adversarial loss: 0.642359\n",
      "epoch 45; iter: 200; batch classifier loss: 0.658817; batch adversarial loss: 0.679190\n",
      "epoch 46; iter: 0; batch classifier loss: 0.601916; batch adversarial loss: 0.655452\n",
      "epoch 46; iter: 200; batch classifier loss: 0.602354; batch adversarial loss: 0.708550\n",
      "epoch 47; iter: 0; batch classifier loss: 0.579628; batch adversarial loss: 0.638672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 200; batch classifier loss: 0.641248; batch adversarial loss: 0.655261\n",
      "epoch 48; iter: 0; batch classifier loss: 0.653534; batch adversarial loss: 0.655720\n",
      "epoch 48; iter: 200; batch classifier loss: 0.601478; batch adversarial loss: 0.644198\n",
      "epoch 49; iter: 0; batch classifier loss: 0.588578; batch adversarial loss: 0.681721\n",
      "epoch 49; iter: 200; batch classifier loss: 0.598818; batch adversarial loss: 0.685440\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698325\n",
      "epoch 0; iter: 200; batch classifier loss: 0.603732\n",
      "epoch 1; iter: 0; batch classifier loss: 0.610171\n",
      "epoch 1; iter: 200; batch classifier loss: 0.621058\n",
      "epoch 2; iter: 0; batch classifier loss: 0.639811\n",
      "epoch 2; iter: 200; batch classifier loss: 0.621119\n",
      "epoch 3; iter: 0; batch classifier loss: 0.598129\n",
      "epoch 3; iter: 200; batch classifier loss: 0.605107\n",
      "epoch 4; iter: 0; batch classifier loss: 0.654245\n",
      "epoch 4; iter: 200; batch classifier loss: 0.626804\n",
      "epoch 5; iter: 0; batch classifier loss: 0.564539\n",
      "epoch 5; iter: 200; batch classifier loss: 0.631020\n",
      "epoch 6; iter: 0; batch classifier loss: 0.643325\n",
      "epoch 6; iter: 200; batch classifier loss: 0.592005\n",
      "epoch 7; iter: 0; batch classifier loss: 0.681145\n",
      "epoch 7; iter: 200; batch classifier loss: 0.644513\n",
      "epoch 8; iter: 0; batch classifier loss: 0.604389\n",
      "epoch 8; iter: 200; batch classifier loss: 0.672690\n",
      "epoch 9; iter: 0; batch classifier loss: 0.611672\n",
      "epoch 9; iter: 200; batch classifier loss: 0.655281\n",
      "epoch 10; iter: 0; batch classifier loss: 0.684316\n",
      "epoch 10; iter: 200; batch classifier loss: 0.602853\n",
      "epoch 11; iter: 0; batch classifier loss: 0.606377\n",
      "epoch 11; iter: 200; batch classifier loss: 0.627713\n",
      "epoch 12; iter: 0; batch classifier loss: 0.649393\n",
      "epoch 12; iter: 200; batch classifier loss: 0.633777\n",
      "epoch 13; iter: 0; batch classifier loss: 0.615999\n",
      "epoch 13; iter: 200; batch classifier loss: 0.651255\n",
      "epoch 14; iter: 0; batch classifier loss: 0.611657\n",
      "epoch 14; iter: 200; batch classifier loss: 0.637073\n",
      "epoch 15; iter: 0; batch classifier loss: 0.633575\n",
      "epoch 15; iter: 200; batch classifier loss: 0.576858\n",
      "epoch 16; iter: 0; batch classifier loss: 0.582402\n",
      "epoch 16; iter: 200; batch classifier loss: 0.551961\n",
      "epoch 17; iter: 0; batch classifier loss: 0.646392\n",
      "epoch 17; iter: 200; batch classifier loss: 0.597470\n",
      "epoch 18; iter: 0; batch classifier loss: 0.610748\n",
      "epoch 18; iter: 200; batch classifier loss: 0.637182\n",
      "epoch 19; iter: 0; batch classifier loss: 0.588187\n",
      "epoch 19; iter: 200; batch classifier loss: 0.594686\n",
      "epoch 20; iter: 0; batch classifier loss: 0.611007\n",
      "epoch 20; iter: 200; batch classifier loss: 0.619330\n",
      "epoch 21; iter: 0; batch classifier loss: 0.628115\n",
      "epoch 21; iter: 200; batch classifier loss: 0.613303\n",
      "epoch 22; iter: 0; batch classifier loss: 0.594096\n",
      "epoch 22; iter: 200; batch classifier loss: 0.625749\n",
      "epoch 23; iter: 0; batch classifier loss: 0.547786\n",
      "epoch 23; iter: 200; batch classifier loss: 0.680547\n",
      "epoch 24; iter: 0; batch classifier loss: 0.612789\n",
      "epoch 24; iter: 200; batch classifier loss: 0.580492\n",
      "epoch 25; iter: 0; batch classifier loss: 0.583147\n",
      "epoch 25; iter: 200; batch classifier loss: 0.588551\n",
      "epoch 26; iter: 0; batch classifier loss: 0.628578\n",
      "epoch 26; iter: 200; batch classifier loss: 0.694746\n",
      "epoch 27; iter: 0; batch classifier loss: 0.583165\n",
      "epoch 27; iter: 200; batch classifier loss: 0.577593\n",
      "epoch 28; iter: 0; batch classifier loss: 0.546790\n",
      "epoch 28; iter: 200; batch classifier loss: 0.599778\n",
      "epoch 29; iter: 0; batch classifier loss: 0.597716\n",
      "epoch 29; iter: 200; batch classifier loss: 0.673931\n",
      "epoch 30; iter: 0; batch classifier loss: 0.568605\n",
      "epoch 30; iter: 200; batch classifier loss: 0.578997\n",
      "epoch 31; iter: 0; batch classifier loss: 0.644950\n",
      "epoch 31; iter: 200; batch classifier loss: 0.606178\n",
      "epoch 32; iter: 0; batch classifier loss: 0.568496\n",
      "epoch 32; iter: 200; batch classifier loss: 0.587979\n",
      "epoch 33; iter: 0; batch classifier loss: 0.658278\n",
      "epoch 33; iter: 200; batch classifier loss: 0.639848\n",
      "epoch 34; iter: 0; batch classifier loss: 0.676833\n",
      "epoch 34; iter: 200; batch classifier loss: 0.610571\n",
      "epoch 35; iter: 0; batch classifier loss: 0.605147\n",
      "epoch 35; iter: 200; batch classifier loss: 0.667468\n",
      "epoch 36; iter: 0; batch classifier loss: 0.627030\n",
      "epoch 36; iter: 200; batch classifier loss: 0.622332\n",
      "epoch 37; iter: 0; batch classifier loss: 0.600509\n",
      "epoch 37; iter: 200; batch classifier loss: 0.603029\n",
      "epoch 38; iter: 0; batch classifier loss: 0.638735\n",
      "epoch 38; iter: 200; batch classifier loss: 0.570510\n",
      "epoch 39; iter: 0; batch classifier loss: 0.680405\n",
      "epoch 39; iter: 200; batch classifier loss: 0.656334\n",
      "epoch 40; iter: 0; batch classifier loss: 0.603973\n",
      "epoch 40; iter: 200; batch classifier loss: 0.583184\n",
      "epoch 41; iter: 0; batch classifier loss: 0.623344\n",
      "epoch 41; iter: 200; batch classifier loss: 0.656430\n",
      "epoch 42; iter: 0; batch classifier loss: 0.586945\n",
      "epoch 42; iter: 200; batch classifier loss: 0.587487\n",
      "epoch 43; iter: 0; batch classifier loss: 0.594066\n",
      "epoch 43; iter: 200; batch classifier loss: 0.639930\n",
      "epoch 44; iter: 0; batch classifier loss: 0.618049\n",
      "epoch 44; iter: 200; batch classifier loss: 0.599120\n",
      "epoch 45; iter: 0; batch classifier loss: 0.611837\n",
      "epoch 45; iter: 200; batch classifier loss: 0.592512\n",
      "epoch 46; iter: 0; batch classifier loss: 0.613306\n",
      "epoch 46; iter: 200; batch classifier loss: 0.599066\n",
      "epoch 47; iter: 0; batch classifier loss: 0.636840\n",
      "epoch 47; iter: 200; batch classifier loss: 0.622770\n",
      "epoch 48; iter: 0; batch classifier loss: 0.596951\n",
      "epoch 48; iter: 200; batch classifier loss: 0.638331\n",
      "epoch 49; iter: 0; batch classifier loss: 0.604378\n",
      "epoch 49; iter: 200; batch classifier loss: 0.601536\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696455; batch adversarial loss: 0.901243\n",
      "epoch 1; iter: 0; batch classifier loss: 0.676293; batch adversarial loss: 0.888929\n",
      "epoch 2; iter: 0; batch classifier loss: 0.654490; batch adversarial loss: 0.915375\n",
      "epoch 3; iter: 0; batch classifier loss: 0.646651; batch adversarial loss: 0.916379\n",
      "epoch 4; iter: 0; batch classifier loss: 0.648261; batch adversarial loss: 0.935104\n",
      "epoch 5; iter: 0; batch classifier loss: 0.723380; batch adversarial loss: 0.853040\n",
      "epoch 6; iter: 0; batch classifier loss: 0.598037; batch adversarial loss: 0.898661\n",
      "epoch 7; iter: 0; batch classifier loss: 0.710014; batch adversarial loss: 0.760877\n",
      "epoch 8; iter: 0; batch classifier loss: 0.643728; batch adversarial loss: 0.803471\n",
      "epoch 9; iter: 0; batch classifier loss: 0.606045; batch adversarial loss: 0.807927\n",
      "epoch 10; iter: 0; batch classifier loss: 0.594652; batch adversarial loss: 0.802202\n",
      "epoch 11; iter: 0; batch classifier loss: 0.620011; batch adversarial loss: 0.784030\n",
      "epoch 12; iter: 0; batch classifier loss: 0.612037; batch adversarial loss: 0.763875\n",
      "epoch 13; iter: 0; batch classifier loss: 0.615279; batch adversarial loss: 0.774840\n",
      "epoch 14; iter: 0; batch classifier loss: 0.665794; batch adversarial loss: 0.686079\n",
      "epoch 15; iter: 0; batch classifier loss: 0.568752; batch adversarial loss: 0.734029\n",
      "epoch 16; iter: 0; batch classifier loss: 0.668412; batch adversarial loss: 0.751478\n",
      "epoch 17; iter: 0; batch classifier loss: 0.588487; batch adversarial loss: 0.684722\n",
      "epoch 18; iter: 0; batch classifier loss: 0.643321; batch adversarial loss: 0.727719\n",
      "epoch 19; iter: 0; batch classifier loss: 0.637015; batch adversarial loss: 0.690176\n",
      "epoch 20; iter: 0; batch classifier loss: 0.572388; batch adversarial loss: 0.680931\n",
      "epoch 21; iter: 0; batch classifier loss: 0.649361; batch adversarial loss: 0.647519\n",
      "epoch 22; iter: 0; batch classifier loss: 0.610896; batch adversarial loss: 0.697079\n",
      "epoch 23; iter: 0; batch classifier loss: 0.574671; batch adversarial loss: 0.725883\n",
      "epoch 24; iter: 0; batch classifier loss: 0.637988; batch adversarial loss: 0.674153\n",
      "epoch 25; iter: 0; batch classifier loss: 0.600725; batch adversarial loss: 0.663046\n",
      "epoch 26; iter: 0; batch classifier loss: 0.634999; batch adversarial loss: 0.626299\n",
      "epoch 27; iter: 0; batch classifier loss: 0.640813; batch adversarial loss: 0.645553\n",
      "epoch 28; iter: 0; batch classifier loss: 0.575405; batch adversarial loss: 0.635813\n",
      "epoch 29; iter: 0; batch classifier loss: 0.584710; batch adversarial loss: 0.694588\n",
      "epoch 30; iter: 0; batch classifier loss: 0.628858; batch adversarial loss: 0.705817\n",
      "epoch 31; iter: 0; batch classifier loss: 0.605011; batch adversarial loss: 0.648099\n",
      "epoch 32; iter: 0; batch classifier loss: 0.606487; batch adversarial loss: 0.651597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 0; batch classifier loss: 0.590957; batch adversarial loss: 0.679993\n",
      "epoch 34; iter: 0; batch classifier loss: 0.598771; batch adversarial loss: 0.663141\n",
      "epoch 35; iter: 0; batch classifier loss: 0.558820; batch adversarial loss: 0.631812\n",
      "epoch 36; iter: 0; batch classifier loss: 0.619083; batch adversarial loss: 0.656718\n",
      "epoch 37; iter: 0; batch classifier loss: 0.648645; batch adversarial loss: 0.670215\n",
      "epoch 38; iter: 0; batch classifier loss: 0.617649; batch adversarial loss: 0.652082\n",
      "epoch 39; iter: 0; batch classifier loss: 0.639729; batch adversarial loss: 0.708107\n",
      "epoch 40; iter: 0; batch classifier loss: 0.578672; batch adversarial loss: 0.633830\n",
      "epoch 41; iter: 0; batch classifier loss: 0.586027; batch adversarial loss: 0.667069\n",
      "epoch 42; iter: 0; batch classifier loss: 0.570580; batch adversarial loss: 0.649699\n",
      "epoch 43; iter: 0; batch classifier loss: 0.598360; batch adversarial loss: 0.641830\n",
      "epoch 44; iter: 0; batch classifier loss: 0.669714; batch adversarial loss: 0.652627\n",
      "epoch 45; iter: 0; batch classifier loss: 0.632545; batch adversarial loss: 0.641349\n",
      "epoch 46; iter: 0; batch classifier loss: 0.582145; batch adversarial loss: 0.630802\n",
      "epoch 47; iter: 0; batch classifier loss: 0.558902; batch adversarial loss: 0.655056\n",
      "epoch 48; iter: 0; batch classifier loss: 0.616981; batch adversarial loss: 0.628638\n",
      "epoch 49; iter: 0; batch classifier loss: 0.670132; batch adversarial loss: 0.657427\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687583\n",
      "epoch 1; iter: 0; batch classifier loss: 0.660488\n",
      "epoch 2; iter: 0; batch classifier loss: 0.602210\n",
      "epoch 3; iter: 0; batch classifier loss: 0.641019\n",
      "epoch 4; iter: 0; batch classifier loss: 0.600074\n",
      "epoch 5; iter: 0; batch classifier loss: 0.579132\n",
      "epoch 6; iter: 0; batch classifier loss: 0.599427\n",
      "epoch 7; iter: 0; batch classifier loss: 0.634659\n",
      "epoch 8; iter: 0; batch classifier loss: 0.675054\n",
      "epoch 9; iter: 0; batch classifier loss: 0.631945\n",
      "epoch 10; iter: 0; batch classifier loss: 0.648060\n",
      "epoch 11; iter: 0; batch classifier loss: 0.579479\n",
      "epoch 12; iter: 0; batch classifier loss: 0.643441\n",
      "epoch 13; iter: 0; batch classifier loss: 0.613032\n",
      "epoch 14; iter: 0; batch classifier loss: 0.668150\n",
      "epoch 15; iter: 0; batch classifier loss: 0.625769\n",
      "epoch 16; iter: 0; batch classifier loss: 0.604999\n",
      "epoch 17; iter: 0; batch classifier loss: 0.702262\n",
      "epoch 18; iter: 0; batch classifier loss: 0.606961\n",
      "epoch 19; iter: 0; batch classifier loss: 0.636022\n",
      "epoch 20; iter: 0; batch classifier loss: 0.583160\n",
      "epoch 21; iter: 0; batch classifier loss: 0.626839\n",
      "epoch 22; iter: 0; batch classifier loss: 0.597736\n",
      "epoch 23; iter: 0; batch classifier loss: 0.614365\n",
      "epoch 24; iter: 0; batch classifier loss: 0.588160\n",
      "epoch 25; iter: 0; batch classifier loss: 0.593456\n",
      "epoch 26; iter: 0; batch classifier loss: 0.611940\n",
      "epoch 27; iter: 0; batch classifier loss: 0.632175\n",
      "epoch 28; iter: 0; batch classifier loss: 0.645651\n",
      "epoch 29; iter: 0; batch classifier loss: 0.641487\n",
      "epoch 30; iter: 0; batch classifier loss: 0.585438\n",
      "epoch 31; iter: 0; batch classifier loss: 0.667189\n",
      "epoch 32; iter: 0; batch classifier loss: 0.643486\n",
      "epoch 33; iter: 0; batch classifier loss: 0.601275\n",
      "epoch 34; iter: 0; batch classifier loss: 0.639712\n",
      "epoch 35; iter: 0; batch classifier loss: 0.651795\n",
      "epoch 36; iter: 0; batch classifier loss: 0.609683\n",
      "epoch 37; iter: 0; batch classifier loss: 0.661327\n",
      "epoch 38; iter: 0; batch classifier loss: 0.618170\n",
      "epoch 39; iter: 0; batch classifier loss: 0.607188\n",
      "epoch 40; iter: 0; batch classifier loss: 0.617271\n",
      "epoch 41; iter: 0; batch classifier loss: 0.575160\n",
      "epoch 42; iter: 0; batch classifier loss: 0.623089\n",
      "epoch 43; iter: 0; batch classifier loss: 0.592206\n",
      "epoch 44; iter: 0; batch classifier loss: 0.612559\n",
      "epoch 45; iter: 0; batch classifier loss: 0.596186\n",
      "epoch 46; iter: 0; batch classifier loss: 0.642968\n",
      "epoch 47; iter: 0; batch classifier loss: 0.664521\n",
      "epoch 48; iter: 0; batch classifier loss: 0.612131\n",
      "epoch 49; iter: 0; batch classifier loss: 0.661078\n",
      "run = 2\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711902; batch adversarial loss: 0.664540\n",
      "epoch 0; iter: 200; batch classifier loss: 0.639078; batch adversarial loss: 0.782038\n",
      "epoch 1; iter: 0; batch classifier loss: 0.678419; batch adversarial loss: 0.724313\n",
      "epoch 1; iter: 200; batch classifier loss: 0.659259; batch adversarial loss: 0.680656\n",
      "epoch 2; iter: 0; batch classifier loss: 0.630039; batch adversarial loss: 0.689086\n",
      "epoch 2; iter: 200; batch classifier loss: 0.646883; batch adversarial loss: 0.704838\n",
      "epoch 3; iter: 0; batch classifier loss: 0.658463; batch adversarial loss: 0.687232\n",
      "epoch 3; iter: 200; batch classifier loss: 0.618613; batch adversarial loss: 0.688734\n",
      "epoch 4; iter: 0; batch classifier loss: 0.647205; batch adversarial loss: 0.693267\n",
      "epoch 4; iter: 200; batch classifier loss: 0.605811; batch adversarial loss: 0.649096\n",
      "epoch 5; iter: 0; batch classifier loss: 0.630594; batch adversarial loss: 0.674121\n",
      "epoch 5; iter: 200; batch classifier loss: 0.644363; batch adversarial loss: 0.677040\n",
      "epoch 6; iter: 0; batch classifier loss: 0.666401; batch adversarial loss: 0.639265\n",
      "epoch 6; iter: 200; batch classifier loss: 0.651007; batch adversarial loss: 0.664039\n",
      "epoch 7; iter: 0; batch classifier loss: 0.641841; batch adversarial loss: 0.686136\n",
      "epoch 7; iter: 200; batch classifier loss: 0.670741; batch adversarial loss: 0.680589\n",
      "epoch 8; iter: 0; batch classifier loss: 0.640536; batch adversarial loss: 0.677299\n",
      "epoch 8; iter: 200; batch classifier loss: 0.622656; batch adversarial loss: 0.701796\n",
      "epoch 9; iter: 0; batch classifier loss: 0.651089; batch adversarial loss: 0.653667\n",
      "epoch 9; iter: 200; batch classifier loss: 0.624953; batch adversarial loss: 0.665943\n",
      "epoch 10; iter: 0; batch classifier loss: 0.640437; batch adversarial loss: 0.661102\n",
      "epoch 10; iter: 200; batch classifier loss: 0.622432; batch adversarial loss: 0.675832\n",
      "epoch 11; iter: 0; batch classifier loss: 0.593055; batch adversarial loss: 0.655908\n",
      "epoch 11; iter: 200; batch classifier loss: 0.624914; batch adversarial loss: 0.689170\n",
      "epoch 12; iter: 0; batch classifier loss: 0.611147; batch adversarial loss: 0.666173\n",
      "epoch 12; iter: 200; batch classifier loss: 0.651957; batch adversarial loss: 0.687314\n",
      "epoch 13; iter: 0; batch classifier loss: 0.571021; batch adversarial loss: 0.706675\n",
      "epoch 13; iter: 200; batch classifier loss: 0.634263; batch adversarial loss: 0.670580\n",
      "epoch 14; iter: 0; batch classifier loss: 0.673648; batch adversarial loss: 0.693346\n",
      "epoch 14; iter: 200; batch classifier loss: 0.634324; batch adversarial loss: 0.685138\n",
      "epoch 15; iter: 0; batch classifier loss: 0.654537; batch adversarial loss: 0.686384\n",
      "epoch 15; iter: 200; batch classifier loss: 0.654564; batch adversarial loss: 0.702713\n",
      "epoch 16; iter: 0; batch classifier loss: 0.620786; batch adversarial loss: 0.669849\n",
      "epoch 16; iter: 200; batch classifier loss: 0.634813; batch adversarial loss: 0.643694\n",
      "epoch 17; iter: 0; batch classifier loss: 0.612029; batch adversarial loss: 0.663455\n",
      "epoch 17; iter: 200; batch classifier loss: 0.618299; batch adversarial loss: 0.659780\n",
      "epoch 18; iter: 0; batch classifier loss: 0.600340; batch adversarial loss: 0.699547\n",
      "epoch 18; iter: 200; batch classifier loss: 0.673895; batch adversarial loss: 0.665129\n",
      "epoch 19; iter: 0; batch classifier loss: 0.603900; batch adversarial loss: 0.678708\n",
      "epoch 19; iter: 200; batch classifier loss: 0.639926; batch adversarial loss: 0.676354\n",
      "epoch 20; iter: 0; batch classifier loss: 0.647155; batch adversarial loss: 0.655949\n",
      "epoch 20; iter: 200; batch classifier loss: 0.618840; batch adversarial loss: 0.657893\n",
      "epoch 21; iter: 0; batch classifier loss: 0.583968; batch adversarial loss: 0.700269\n",
      "epoch 21; iter: 200; batch classifier loss: 0.625760; batch adversarial loss: 0.702500\n",
      "epoch 22; iter: 0; batch classifier loss: 0.600878; batch adversarial loss: 0.677523\n",
      "epoch 22; iter: 200; batch classifier loss: 0.662043; batch adversarial loss: 0.650683\n",
      "epoch 23; iter: 0; batch classifier loss: 0.612243; batch adversarial loss: 0.685911\n",
      "epoch 23; iter: 200; batch classifier loss: 0.603843; batch adversarial loss: 0.670760\n",
      "epoch 24; iter: 0; batch classifier loss: 0.598806; batch adversarial loss: 0.688979\n",
      "epoch 24; iter: 200; batch classifier loss: 0.648835; batch adversarial loss: 0.678119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25; iter: 0; batch classifier loss: 0.629506; batch adversarial loss: 0.675567\n",
      "epoch 25; iter: 200; batch classifier loss: 0.589801; batch adversarial loss: 0.669937\n",
      "epoch 26; iter: 0; batch classifier loss: 0.657331; batch adversarial loss: 0.701242\n",
      "epoch 26; iter: 200; batch classifier loss: 0.594253; batch adversarial loss: 0.687537\n",
      "epoch 27; iter: 0; batch classifier loss: 0.635627; batch adversarial loss: 0.667326\n",
      "epoch 27; iter: 200; batch classifier loss: 0.599011; batch adversarial loss: 0.700772\n",
      "epoch 28; iter: 0; batch classifier loss: 0.641175; batch adversarial loss: 0.673098\n",
      "epoch 28; iter: 200; batch classifier loss: 0.598031; batch adversarial loss: 0.658722\n",
      "epoch 29; iter: 0; batch classifier loss: 0.605377; batch adversarial loss: 0.678661\n",
      "epoch 29; iter: 200; batch classifier loss: 0.580204; batch adversarial loss: 0.687107\n",
      "epoch 30; iter: 0; batch classifier loss: 0.665078; batch adversarial loss: 0.675284\n",
      "epoch 30; iter: 200; batch classifier loss: 0.643316; batch adversarial loss: 0.672804\n",
      "epoch 31; iter: 0; batch classifier loss: 0.656170; batch adversarial loss: 0.678535\n",
      "epoch 31; iter: 200; batch classifier loss: 0.624868; batch adversarial loss: 0.670495\n",
      "epoch 32; iter: 0; batch classifier loss: 0.625108; batch adversarial loss: 0.672286\n",
      "epoch 32; iter: 200; batch classifier loss: 0.650392; batch adversarial loss: 0.672515\n",
      "epoch 33; iter: 0; batch classifier loss: 0.614015; batch adversarial loss: 0.655383\n",
      "epoch 33; iter: 200; batch classifier loss: 0.625503; batch adversarial loss: 0.659041\n",
      "epoch 34; iter: 0; batch classifier loss: 0.699114; batch adversarial loss: 0.669050\n",
      "epoch 34; iter: 200; batch classifier loss: 0.625277; batch adversarial loss: 0.675628\n",
      "epoch 35; iter: 0; batch classifier loss: 0.652322; batch adversarial loss: 0.660437\n",
      "epoch 35; iter: 200; batch classifier loss: 0.616241; batch adversarial loss: 0.698833\n",
      "epoch 36; iter: 0; batch classifier loss: 0.585300; batch adversarial loss: 0.679408\n",
      "epoch 36; iter: 200; batch classifier loss: 0.600220; batch adversarial loss: 0.717907\n",
      "epoch 37; iter: 0; batch classifier loss: 0.630888; batch adversarial loss: 0.664018\n",
      "epoch 37; iter: 200; batch classifier loss: 0.638999; batch adversarial loss: 0.692895\n",
      "epoch 38; iter: 0; batch classifier loss: 0.640981; batch adversarial loss: 0.678377\n",
      "epoch 38; iter: 200; batch classifier loss: 0.626006; batch adversarial loss: 0.692480\n",
      "epoch 39; iter: 0; batch classifier loss: 0.597643; batch adversarial loss: 0.709038\n",
      "epoch 39; iter: 200; batch classifier loss: 0.647980; batch adversarial loss: 0.665755\n",
      "epoch 40; iter: 0; batch classifier loss: 0.572680; batch adversarial loss: 0.643947\n",
      "epoch 40; iter: 200; batch classifier loss: 0.630587; batch adversarial loss: 0.700621\n",
      "epoch 41; iter: 0; batch classifier loss: 0.603480; batch adversarial loss: 0.666800\n",
      "epoch 41; iter: 200; batch classifier loss: 0.619715; batch adversarial loss: 0.671865\n",
      "epoch 42; iter: 0; batch classifier loss: 0.592981; batch adversarial loss: 0.681286\n",
      "epoch 42; iter: 200; batch classifier loss: 0.613119; batch adversarial loss: 0.671443\n",
      "epoch 43; iter: 0; batch classifier loss: 0.654741; batch adversarial loss: 0.673657\n",
      "epoch 43; iter: 200; batch classifier loss: 0.634800; batch adversarial loss: 0.695502\n",
      "epoch 44; iter: 0; batch classifier loss: 0.638364; batch adversarial loss: 0.662980\n",
      "epoch 44; iter: 200; batch classifier loss: 0.617168; batch adversarial loss: 0.658613\n",
      "epoch 45; iter: 0; batch classifier loss: 0.672317; batch adversarial loss: 0.703386\n",
      "epoch 45; iter: 200; batch classifier loss: 0.598482; batch adversarial loss: 0.667518\n",
      "epoch 46; iter: 0; batch classifier loss: 0.606504; batch adversarial loss: 0.650970\n",
      "epoch 46; iter: 200; batch classifier loss: 0.544267; batch adversarial loss: 0.699088\n",
      "epoch 47; iter: 0; batch classifier loss: 0.628664; batch adversarial loss: 0.684700\n",
      "epoch 47; iter: 200; batch classifier loss: 0.601036; batch adversarial loss: 0.670051\n",
      "epoch 48; iter: 0; batch classifier loss: 0.622420; batch adversarial loss: 0.696312\n",
      "epoch 48; iter: 200; batch classifier loss: 0.666906; batch adversarial loss: 0.658599\n",
      "epoch 49; iter: 0; batch classifier loss: 0.594149; batch adversarial loss: 0.679433\n",
      "epoch 49; iter: 200; batch classifier loss: 0.696992; batch adversarial loss: 0.677321\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689626\n",
      "epoch 0; iter: 200; batch classifier loss: 0.622877\n",
      "epoch 1; iter: 0; batch classifier loss: 0.619803\n",
      "epoch 1; iter: 200; batch classifier loss: 0.643741\n",
      "epoch 2; iter: 0; batch classifier loss: 0.649023\n",
      "epoch 2; iter: 200; batch classifier loss: 0.628686\n",
      "epoch 3; iter: 0; batch classifier loss: 0.594753\n",
      "epoch 3; iter: 200; batch classifier loss: 0.625608\n",
      "epoch 4; iter: 0; batch classifier loss: 0.573724\n",
      "epoch 4; iter: 200; batch classifier loss: 0.585630\n",
      "epoch 5; iter: 0; batch classifier loss: 0.601361\n",
      "epoch 5; iter: 200; batch classifier loss: 0.625874\n",
      "epoch 6; iter: 0; batch classifier loss: 0.621405\n",
      "epoch 6; iter: 200; batch classifier loss: 0.633011\n",
      "epoch 7; iter: 0; batch classifier loss: 0.615548\n",
      "epoch 7; iter: 200; batch classifier loss: 0.646020\n",
      "epoch 8; iter: 0; batch classifier loss: 0.641826\n",
      "epoch 8; iter: 200; batch classifier loss: 0.649943\n",
      "epoch 9; iter: 0; batch classifier loss: 0.590816\n",
      "epoch 9; iter: 200; batch classifier loss: 0.652635\n",
      "epoch 10; iter: 0; batch classifier loss: 0.589445\n",
      "epoch 10; iter: 200; batch classifier loss: 0.635940\n",
      "epoch 11; iter: 0; batch classifier loss: 0.613436\n",
      "epoch 11; iter: 200; batch classifier loss: 0.587351\n",
      "epoch 12; iter: 0; batch classifier loss: 0.658751\n",
      "epoch 12; iter: 200; batch classifier loss: 0.617256\n",
      "epoch 13; iter: 0; batch classifier loss: 0.616419\n",
      "epoch 13; iter: 200; batch classifier loss: 0.626853\n",
      "epoch 14; iter: 0; batch classifier loss: 0.608818\n",
      "epoch 14; iter: 200; batch classifier loss: 0.624771\n",
      "epoch 15; iter: 0; batch classifier loss: 0.620744\n",
      "epoch 15; iter: 200; batch classifier loss: 0.604436\n",
      "epoch 16; iter: 0; batch classifier loss: 0.611680\n",
      "epoch 16; iter: 200; batch classifier loss: 0.612548\n",
      "epoch 17; iter: 0; batch classifier loss: 0.633640\n",
      "epoch 17; iter: 200; batch classifier loss: 0.649394\n",
      "epoch 18; iter: 0; batch classifier loss: 0.574484\n",
      "epoch 18; iter: 200; batch classifier loss: 0.607436\n",
      "epoch 19; iter: 0; batch classifier loss: 0.578290\n",
      "epoch 19; iter: 200; batch classifier loss: 0.622913\n",
      "epoch 20; iter: 0; batch classifier loss: 0.658821\n",
      "epoch 20; iter: 200; batch classifier loss: 0.624774\n",
      "epoch 21; iter: 0; batch classifier loss: 0.625250\n",
      "epoch 21; iter: 200; batch classifier loss: 0.655672\n",
      "epoch 22; iter: 0; batch classifier loss: 0.566208\n",
      "epoch 22; iter: 200; batch classifier loss: 0.573009\n",
      "epoch 23; iter: 0; batch classifier loss: 0.626396\n",
      "epoch 23; iter: 200; batch classifier loss: 0.632228\n",
      "epoch 24; iter: 0; batch classifier loss: 0.613389\n",
      "epoch 24; iter: 200; batch classifier loss: 0.637297\n",
      "epoch 25; iter: 0; batch classifier loss: 0.605759\n",
      "epoch 25; iter: 200; batch classifier loss: 0.602537\n",
      "epoch 26; iter: 0; batch classifier loss: 0.670857\n",
      "epoch 26; iter: 200; batch classifier loss: 0.583582\n",
      "epoch 27; iter: 0; batch classifier loss: 0.539900\n",
      "epoch 27; iter: 200; batch classifier loss: 0.611426\n",
      "epoch 28; iter: 0; batch classifier loss: 0.637984\n",
      "epoch 28; iter: 200; batch classifier loss: 0.626415\n",
      "epoch 29; iter: 0; batch classifier loss: 0.606673\n",
      "epoch 29; iter: 200; batch classifier loss: 0.622851\n",
      "epoch 30; iter: 0; batch classifier loss: 0.680889\n",
      "epoch 30; iter: 200; batch classifier loss: 0.606865\n",
      "epoch 31; iter: 0; batch classifier loss: 0.638055\n",
      "epoch 31; iter: 200; batch classifier loss: 0.653527\n",
      "epoch 32; iter: 0; batch classifier loss: 0.568048\n",
      "epoch 32; iter: 200; batch classifier loss: 0.650220\n",
      "epoch 33; iter: 0; batch classifier loss: 0.594228\n",
      "epoch 33; iter: 200; batch classifier loss: 0.558330\n",
      "epoch 34; iter: 0; batch classifier loss: 0.602563\n",
      "epoch 34; iter: 200; batch classifier loss: 0.607410\n",
      "epoch 35; iter: 0; batch classifier loss: 0.617868\n",
      "epoch 35; iter: 200; batch classifier loss: 0.553003\n",
      "epoch 36; iter: 0; batch classifier loss: 0.632874\n",
      "epoch 36; iter: 200; batch classifier loss: 0.620927\n",
      "epoch 37; iter: 0; batch classifier loss: 0.611840\n",
      "epoch 37; iter: 200; batch classifier loss: 0.567551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 0; batch classifier loss: 0.592296\n",
      "epoch 38; iter: 200; batch classifier loss: 0.631842\n",
      "epoch 39; iter: 0; batch classifier loss: 0.614906\n",
      "epoch 39; iter: 200; batch classifier loss: 0.593236\n",
      "epoch 40; iter: 0; batch classifier loss: 0.621893\n",
      "epoch 40; iter: 200; batch classifier loss: 0.618157\n",
      "epoch 41; iter: 0; batch classifier loss: 0.593308\n",
      "epoch 41; iter: 200; batch classifier loss: 0.649730\n",
      "epoch 42; iter: 0; batch classifier loss: 0.620105\n",
      "epoch 42; iter: 200; batch classifier loss: 0.586929\n",
      "epoch 43; iter: 0; batch classifier loss: 0.570927\n",
      "epoch 43; iter: 200; batch classifier loss: 0.661625\n",
      "epoch 44; iter: 0; batch classifier loss: 0.654550\n",
      "epoch 44; iter: 200; batch classifier loss: 0.663090\n",
      "epoch 45; iter: 0; batch classifier loss: 0.598821\n",
      "epoch 45; iter: 200; batch classifier loss: 0.625604\n",
      "epoch 46; iter: 0; batch classifier loss: 0.597847\n",
      "epoch 46; iter: 200; batch classifier loss: 0.630554\n",
      "epoch 47; iter: 0; batch classifier loss: 0.577587\n",
      "epoch 47; iter: 200; batch classifier loss: 0.633688\n",
      "epoch 48; iter: 0; batch classifier loss: 0.679374\n",
      "epoch 48; iter: 200; batch classifier loss: 0.642440\n",
      "epoch 49; iter: 0; batch classifier loss: 0.558331\n",
      "epoch 49; iter: 200; batch classifier loss: 0.619715\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704313; batch adversarial loss: 0.701470\n",
      "epoch 1; iter: 0; batch classifier loss: 0.655156; batch adversarial loss: 0.701302\n",
      "epoch 2; iter: 0; batch classifier loss: 0.662901; batch adversarial loss: 0.761362\n",
      "epoch 3; iter: 0; batch classifier loss: 0.590569; batch adversarial loss: 0.730528\n",
      "epoch 4; iter: 0; batch classifier loss: 0.627132; batch adversarial loss: 0.714818\n",
      "epoch 5; iter: 0; batch classifier loss: 0.614889; batch adversarial loss: 0.739098\n",
      "epoch 6; iter: 0; batch classifier loss: 0.604005; batch adversarial loss: 0.709610\n",
      "epoch 7; iter: 0; batch classifier loss: 0.626250; batch adversarial loss: 0.722646\n",
      "epoch 8; iter: 0; batch classifier loss: 0.587776; batch adversarial loss: 0.715004\n",
      "epoch 9; iter: 0; batch classifier loss: 0.643772; batch adversarial loss: 0.704342\n",
      "epoch 10; iter: 0; batch classifier loss: 0.563748; batch adversarial loss: 0.706020\n",
      "epoch 11; iter: 0; batch classifier loss: 0.604720; batch adversarial loss: 0.726820\n",
      "epoch 12; iter: 0; batch classifier loss: 0.637501; batch adversarial loss: 0.700645\n",
      "epoch 13; iter: 0; batch classifier loss: 0.623452; batch adversarial loss: 0.692678\n",
      "epoch 14; iter: 0; batch classifier loss: 0.604574; batch adversarial loss: 0.710601\n",
      "epoch 15; iter: 0; batch classifier loss: 0.580146; batch adversarial loss: 0.676943\n",
      "epoch 16; iter: 0; batch classifier loss: 0.625874; batch adversarial loss: 0.687605\n",
      "epoch 17; iter: 0; batch classifier loss: 0.631597; batch adversarial loss: 0.666842\n",
      "epoch 18; iter: 0; batch classifier loss: 0.615443; batch adversarial loss: 0.694950\n",
      "epoch 19; iter: 0; batch classifier loss: 0.640056; batch adversarial loss: 0.681709\n",
      "epoch 20; iter: 0; batch classifier loss: 0.639317; batch adversarial loss: 0.669433\n",
      "epoch 21; iter: 0; batch classifier loss: 0.649991; batch adversarial loss: 0.677388\n",
      "epoch 22; iter: 0; batch classifier loss: 0.651027; batch adversarial loss: 0.665685\n",
      "epoch 23; iter: 0; batch classifier loss: 0.625701; batch adversarial loss: 0.673480\n",
      "epoch 24; iter: 0; batch classifier loss: 0.618314; batch adversarial loss: 0.660087\n",
      "epoch 25; iter: 0; batch classifier loss: 0.586336; batch adversarial loss: 0.675617\n",
      "epoch 26; iter: 0; batch classifier loss: 0.615773; batch adversarial loss: 0.670648\n",
      "epoch 27; iter: 0; batch classifier loss: 0.634661; batch adversarial loss: 0.657795\n",
      "epoch 28; iter: 0; batch classifier loss: 0.567741; batch adversarial loss: 0.668328\n",
      "epoch 29; iter: 0; batch classifier loss: 0.598752; batch adversarial loss: 0.647753\n",
      "epoch 30; iter: 0; batch classifier loss: 0.630207; batch adversarial loss: 0.671754\n",
      "epoch 31; iter: 0; batch classifier loss: 0.585111; batch adversarial loss: 0.669248\n",
      "epoch 32; iter: 0; batch classifier loss: 0.596313; batch adversarial loss: 0.681805\n",
      "epoch 33; iter: 0; batch classifier loss: 0.573879; batch adversarial loss: 0.665480\n",
      "epoch 34; iter: 0; batch classifier loss: 0.650816; batch adversarial loss: 0.653311\n",
      "epoch 35; iter: 0; batch classifier loss: 0.562383; batch adversarial loss: 0.683155\n",
      "epoch 36; iter: 0; batch classifier loss: 0.606926; batch adversarial loss: 0.687843\n",
      "epoch 37; iter: 0; batch classifier loss: 0.613611; batch adversarial loss: 0.673245\n",
      "epoch 38; iter: 0; batch classifier loss: 0.633639; batch adversarial loss: 0.677028\n",
      "epoch 39; iter: 0; batch classifier loss: 0.611021; batch adversarial loss: 0.665499\n",
      "epoch 40; iter: 0; batch classifier loss: 0.603392; batch adversarial loss: 0.659424\n",
      "epoch 41; iter: 0; batch classifier loss: 0.639377; batch adversarial loss: 0.658277\n",
      "epoch 42; iter: 0; batch classifier loss: 0.629816; batch adversarial loss: 0.690184\n",
      "epoch 43; iter: 0; batch classifier loss: 0.614004; batch adversarial loss: 0.688879\n",
      "epoch 44; iter: 0; batch classifier loss: 0.602568; batch adversarial loss: 0.687240\n",
      "epoch 45; iter: 0; batch classifier loss: 0.616502; batch adversarial loss: 0.670170\n",
      "epoch 46; iter: 0; batch classifier loss: 0.684642; batch adversarial loss: 0.682521\n",
      "epoch 47; iter: 0; batch classifier loss: 0.710686; batch adversarial loss: 0.669744\n",
      "epoch 48; iter: 0; batch classifier loss: 0.543550; batch adversarial loss: 0.651196\n",
      "epoch 49; iter: 0; batch classifier loss: 0.585462; batch adversarial loss: 0.669649\n",
      "epoch 0; iter: 0; batch classifier loss: 0.706514\n",
      "epoch 1; iter: 0; batch classifier loss: 0.666722\n",
      "epoch 2; iter: 0; batch classifier loss: 0.615854\n",
      "epoch 3; iter: 0; batch classifier loss: 0.585908\n",
      "epoch 4; iter: 0; batch classifier loss: 0.638929\n",
      "epoch 5; iter: 0; batch classifier loss: 0.617833\n",
      "epoch 6; iter: 0; batch classifier loss: 0.602025\n",
      "epoch 7; iter: 0; batch classifier loss: 0.627868\n",
      "epoch 8; iter: 0; batch classifier loss: 0.666989\n",
      "epoch 9; iter: 0; batch classifier loss: 0.669240\n",
      "epoch 10; iter: 0; batch classifier loss: 0.649071\n",
      "epoch 11; iter: 0; batch classifier loss: 0.607865\n",
      "epoch 12; iter: 0; batch classifier loss: 0.646400\n",
      "epoch 13; iter: 0; batch classifier loss: 0.621993\n",
      "epoch 14; iter: 0; batch classifier loss: 0.667815\n",
      "epoch 15; iter: 0; batch classifier loss: 0.589352\n",
      "epoch 16; iter: 0; batch classifier loss: 0.627697\n",
      "epoch 17; iter: 0; batch classifier loss: 0.596977\n",
      "epoch 18; iter: 0; batch classifier loss: 0.622988\n",
      "epoch 19; iter: 0; batch classifier loss: 0.619983\n",
      "epoch 20; iter: 0; batch classifier loss: 0.599050\n",
      "epoch 21; iter: 0; batch classifier loss: 0.546888\n",
      "epoch 22; iter: 0; batch classifier loss: 0.671842\n",
      "epoch 23; iter: 0; batch classifier loss: 0.646864\n",
      "epoch 24; iter: 0; batch classifier loss: 0.565512\n",
      "epoch 25; iter: 0; batch classifier loss: 0.638001\n",
      "epoch 26; iter: 0; batch classifier loss: 0.615252\n",
      "epoch 27; iter: 0; batch classifier loss: 0.631581\n",
      "epoch 28; iter: 0; batch classifier loss: 0.625771\n",
      "epoch 29; iter: 0; batch classifier loss: 0.560699\n",
      "epoch 30; iter: 0; batch classifier loss: 0.590407\n",
      "epoch 31; iter: 0; batch classifier loss: 0.612986\n",
      "epoch 32; iter: 0; batch classifier loss: 0.625784\n",
      "epoch 33; iter: 0; batch classifier loss: 0.667269\n",
      "epoch 34; iter: 0; batch classifier loss: 0.565809\n",
      "epoch 35; iter: 0; batch classifier loss: 0.588514\n",
      "epoch 36; iter: 0; batch classifier loss: 0.614274\n",
      "epoch 37; iter: 0; batch classifier loss: 0.600249\n",
      "epoch 38; iter: 0; batch classifier loss: 0.663733\n",
      "epoch 39; iter: 0; batch classifier loss: 0.656744\n",
      "epoch 40; iter: 0; batch classifier loss: 0.602596\n",
      "epoch 41; iter: 0; batch classifier loss: 0.586569\n",
      "epoch 42; iter: 0; batch classifier loss: 0.632745\n",
      "epoch 43; iter: 0; batch classifier loss: 0.647650\n",
      "epoch 44; iter: 0; batch classifier loss: 0.594754\n",
      "epoch 45; iter: 0; batch classifier loss: 0.648516\n",
      "epoch 46; iter: 0; batch classifier loss: 0.609035\n",
      "epoch 47; iter: 0; batch classifier loss: 0.583613\n",
      "epoch 48; iter: 0; batch classifier loss: 0.603130\n",
      "epoch 49; iter: 0; batch classifier loss: 0.644675\n",
      "run = 3\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680655; batch adversarial loss: 0.697082\n",
      "epoch 0; iter: 200; batch classifier loss: 0.613885; batch adversarial loss: 0.684891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1; iter: 0; batch classifier loss: 0.673278; batch adversarial loss: 0.675939\n",
      "epoch 1; iter: 200; batch classifier loss: 0.591143; batch adversarial loss: 0.650296\n",
      "epoch 2; iter: 0; batch classifier loss: 0.630530; batch adversarial loss: 0.668000\n",
      "epoch 2; iter: 200; batch classifier loss: 0.630313; batch adversarial loss: 0.680308\n",
      "epoch 3; iter: 0; batch classifier loss: 0.593999; batch adversarial loss: 0.654557\n",
      "epoch 3; iter: 200; batch classifier loss: 0.578455; batch adversarial loss: 0.677655\n",
      "epoch 4; iter: 0; batch classifier loss: 0.645367; batch adversarial loss: 0.663398\n",
      "epoch 4; iter: 200; batch classifier loss: 0.600574; batch adversarial loss: 0.682716\n",
      "epoch 5; iter: 0; batch classifier loss: 0.647676; batch adversarial loss: 0.651593\n",
      "epoch 5; iter: 200; batch classifier loss: 0.657470; batch adversarial loss: 0.684814\n",
      "epoch 6; iter: 0; batch classifier loss: 0.563700; batch adversarial loss: 0.667073\n",
      "epoch 6; iter: 200; batch classifier loss: 0.639180; batch adversarial loss: 0.676603\n",
      "epoch 7; iter: 0; batch classifier loss: 0.598263; batch adversarial loss: 0.673636\n",
      "epoch 7; iter: 200; batch classifier loss: 0.601519; batch adversarial loss: 0.679997\n",
      "epoch 8; iter: 0; batch classifier loss: 0.652574; batch adversarial loss: 0.686167\n",
      "epoch 8; iter: 200; batch classifier loss: 0.615705; batch adversarial loss: 0.645516\n",
      "epoch 9; iter: 0; batch classifier loss: 0.660996; batch adversarial loss: 0.685555\n",
      "epoch 9; iter: 200; batch classifier loss: 0.627099; batch adversarial loss: 0.680283\n",
      "epoch 10; iter: 0; batch classifier loss: 0.650562; batch adversarial loss: 0.653532\n",
      "epoch 10; iter: 200; batch classifier loss: 0.562936; batch adversarial loss: 0.666603\n",
      "epoch 11; iter: 0; batch classifier loss: 0.634746; batch adversarial loss: 0.650210\n",
      "epoch 11; iter: 200; batch classifier loss: 0.648067; batch adversarial loss: 0.688071\n",
      "epoch 12; iter: 0; batch classifier loss: 0.599404; batch adversarial loss: 0.674693\n",
      "epoch 12; iter: 200; batch classifier loss: 0.615755; batch adversarial loss: 0.665892\n",
      "epoch 13; iter: 0; batch classifier loss: 0.595231; batch adversarial loss: 0.655284\n",
      "epoch 13; iter: 200; batch classifier loss: 0.682218; batch adversarial loss: 0.672918\n",
      "epoch 14; iter: 0; batch classifier loss: 0.626187; batch adversarial loss: 0.651174\n",
      "epoch 14; iter: 200; batch classifier loss: 0.667044; batch adversarial loss: 0.665519\n",
      "epoch 15; iter: 0; batch classifier loss: 0.626241; batch adversarial loss: 0.679681\n",
      "epoch 15; iter: 200; batch classifier loss: 0.643552; batch adversarial loss: 0.693546\n",
      "epoch 16; iter: 0; batch classifier loss: 0.605273; batch adversarial loss: 0.682388\n",
      "epoch 16; iter: 200; batch classifier loss: 0.606064; batch adversarial loss: 0.697402\n",
      "epoch 17; iter: 0; batch classifier loss: 0.634404; batch adversarial loss: 0.678431\n",
      "epoch 17; iter: 200; batch classifier loss: 0.573347; batch adversarial loss: 0.657868\n",
      "epoch 18; iter: 0; batch classifier loss: 0.557528; batch adversarial loss: 0.678782\n",
      "epoch 18; iter: 200; batch classifier loss: 0.588456; batch adversarial loss: 0.671682\n",
      "epoch 19; iter: 0; batch classifier loss: 0.652394; batch adversarial loss: 0.666448\n",
      "epoch 19; iter: 200; batch classifier loss: 0.620560; batch adversarial loss: 0.678775\n",
      "epoch 20; iter: 0; batch classifier loss: 0.647038; batch adversarial loss: 0.644061\n",
      "epoch 20; iter: 200; batch classifier loss: 0.640684; batch adversarial loss: 0.647979\n",
      "epoch 21; iter: 0; batch classifier loss: 0.583138; batch adversarial loss: 0.661487\n",
      "epoch 21; iter: 200; batch classifier loss: 0.623000; batch adversarial loss: 0.690664\n",
      "epoch 22; iter: 0; batch classifier loss: 0.565507; batch adversarial loss: 0.688004\n",
      "epoch 22; iter: 200; batch classifier loss: 0.593421; batch adversarial loss: 0.663696\n",
      "epoch 23; iter: 0; batch classifier loss: 0.590511; batch adversarial loss: 0.693346\n",
      "epoch 23; iter: 200; batch classifier loss: 0.625575; batch adversarial loss: 0.684849\n",
      "epoch 24; iter: 0; batch classifier loss: 0.553443; batch adversarial loss: 0.662965\n",
      "epoch 24; iter: 200; batch classifier loss: 0.577243; batch adversarial loss: 0.685230\n",
      "epoch 25; iter: 0; batch classifier loss: 0.600071; batch adversarial loss: 0.686963\n",
      "epoch 25; iter: 200; batch classifier loss: 0.635653; batch adversarial loss: 0.678921\n",
      "epoch 26; iter: 0; batch classifier loss: 0.669564; batch adversarial loss: 0.695697\n",
      "epoch 26; iter: 200; batch classifier loss: 0.685664; batch adversarial loss: 0.687527\n",
      "epoch 27; iter: 0; batch classifier loss: 0.626768; batch adversarial loss: 0.652527\n",
      "epoch 27; iter: 200; batch classifier loss: 0.679349; batch adversarial loss: 0.662402\n",
      "epoch 28; iter: 0; batch classifier loss: 0.583983; batch adversarial loss: 0.677235\n",
      "epoch 28; iter: 200; batch classifier loss: 0.638183; batch adversarial loss: 0.688058\n",
      "epoch 29; iter: 0; batch classifier loss: 0.575159; batch adversarial loss: 0.701304\n",
      "epoch 29; iter: 200; batch classifier loss: 0.690273; batch adversarial loss: 0.685274\n",
      "epoch 30; iter: 0; batch classifier loss: 0.595241; batch adversarial loss: 0.674340\n",
      "epoch 30; iter: 200; batch classifier loss: 0.609395; batch adversarial loss: 0.677941\n",
      "epoch 31; iter: 0; batch classifier loss: 0.605655; batch adversarial loss: 0.700414\n",
      "epoch 31; iter: 200; batch classifier loss: 0.610184; batch adversarial loss: 0.697119\n",
      "epoch 32; iter: 0; batch classifier loss: 0.627520; batch adversarial loss: 0.643389\n",
      "epoch 32; iter: 200; batch classifier loss: 0.597095; batch adversarial loss: 0.670152\n",
      "epoch 33; iter: 0; batch classifier loss: 0.581346; batch adversarial loss: 0.669417\n",
      "epoch 33; iter: 200; batch classifier loss: 0.563272; batch adversarial loss: 0.696531\n",
      "epoch 34; iter: 0; batch classifier loss: 0.634225; batch adversarial loss: 0.661236\n",
      "epoch 34; iter: 200; batch classifier loss: 0.645539; batch adversarial loss: 0.631901\n",
      "epoch 35; iter: 0; batch classifier loss: 0.574324; batch adversarial loss: 0.690981\n",
      "epoch 35; iter: 200; batch classifier loss: 0.582307; batch adversarial loss: 0.666955\n",
      "epoch 36; iter: 0; batch classifier loss: 0.569968; batch adversarial loss: 0.684670\n",
      "epoch 36; iter: 200; batch classifier loss: 0.646572; batch adversarial loss: 0.640496\n",
      "epoch 37; iter: 0; batch classifier loss: 0.620117; batch adversarial loss: 0.676764\n",
      "epoch 37; iter: 200; batch classifier loss: 0.573608; batch adversarial loss: 0.693578\n",
      "epoch 38; iter: 0; batch classifier loss: 0.662703; batch adversarial loss: 0.687238\n",
      "epoch 38; iter: 200; batch classifier loss: 0.592903; batch adversarial loss: 0.688017\n",
      "epoch 39; iter: 0; batch classifier loss: 0.608693; batch adversarial loss: 0.668642\n",
      "epoch 39; iter: 200; batch classifier loss: 0.650426; batch adversarial loss: 0.676292\n",
      "epoch 40; iter: 0; batch classifier loss: 0.607538; batch adversarial loss: 0.676615\n",
      "epoch 40; iter: 200; batch classifier loss: 0.621080; batch adversarial loss: 0.651819\n",
      "epoch 41; iter: 0; batch classifier loss: 0.578809; batch adversarial loss: 0.713148\n",
      "epoch 41; iter: 200; batch classifier loss: 0.542869; batch adversarial loss: 0.697980\n",
      "epoch 42; iter: 0; batch classifier loss: 0.608624; batch adversarial loss: 0.710607\n",
      "epoch 42; iter: 200; batch classifier loss: 0.627958; batch adversarial loss: 0.687338\n",
      "epoch 43; iter: 0; batch classifier loss: 0.660136; batch adversarial loss: 0.679827\n",
      "epoch 43; iter: 200; batch classifier loss: 0.592630; batch adversarial loss: 0.666991\n",
      "epoch 44; iter: 0; batch classifier loss: 0.613235; batch adversarial loss: 0.675233\n",
      "epoch 44; iter: 200; batch classifier loss: 0.651607; batch adversarial loss: 0.675422\n",
      "epoch 45; iter: 0; batch classifier loss: 0.669570; batch adversarial loss: 0.664746\n",
      "epoch 45; iter: 200; batch classifier loss: 0.711075; batch adversarial loss: 0.663302\n",
      "epoch 46; iter: 0; batch classifier loss: 0.586408; batch adversarial loss: 0.663665\n",
      "epoch 46; iter: 200; batch classifier loss: 0.606853; batch adversarial loss: 0.634578\n",
      "epoch 47; iter: 0; batch classifier loss: 0.597175; batch adversarial loss: 0.662610\n",
      "epoch 47; iter: 200; batch classifier loss: 0.613032; batch adversarial loss: 0.671199\n",
      "epoch 48; iter: 0; batch classifier loss: 0.631317; batch adversarial loss: 0.669487\n",
      "epoch 48; iter: 200; batch classifier loss: 0.663170; batch adversarial loss: 0.677029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49; iter: 0; batch classifier loss: 0.660743; batch adversarial loss: 0.652651\n",
      "epoch 49; iter: 200; batch classifier loss: 0.620412; batch adversarial loss: 0.663258\n",
      "epoch 0; iter: 0; batch classifier loss: 0.704856\n",
      "epoch 0; iter: 200; batch classifier loss: 0.675550\n",
      "epoch 1; iter: 0; batch classifier loss: 0.616541\n",
      "epoch 1; iter: 200; batch classifier loss: 0.626762\n",
      "epoch 2; iter: 0; batch classifier loss: 0.679313\n",
      "epoch 2; iter: 200; batch classifier loss: 0.638878\n",
      "epoch 3; iter: 0; batch classifier loss: 0.623636\n",
      "epoch 3; iter: 200; batch classifier loss: 0.599152\n",
      "epoch 4; iter: 0; batch classifier loss: 0.582748\n",
      "epoch 4; iter: 200; batch classifier loss: 0.578870\n",
      "epoch 5; iter: 0; batch classifier loss: 0.612692\n",
      "epoch 5; iter: 200; batch classifier loss: 0.651717\n",
      "epoch 6; iter: 0; batch classifier loss: 0.663585\n",
      "epoch 6; iter: 200; batch classifier loss: 0.581674\n",
      "epoch 7; iter: 0; batch classifier loss: 0.693032\n",
      "epoch 7; iter: 200; batch classifier loss: 0.671521\n",
      "epoch 8; iter: 0; batch classifier loss: 0.615192\n",
      "epoch 8; iter: 200; batch classifier loss: 0.653169\n",
      "epoch 9; iter: 0; batch classifier loss: 0.587319\n",
      "epoch 9; iter: 200; batch classifier loss: 0.609877\n",
      "epoch 10; iter: 0; batch classifier loss: 0.601993\n",
      "epoch 10; iter: 200; batch classifier loss: 0.666308\n",
      "epoch 11; iter: 0; batch classifier loss: 0.589653\n",
      "epoch 11; iter: 200; batch classifier loss: 0.548799\n",
      "epoch 12; iter: 0; batch classifier loss: 0.599657\n",
      "epoch 12; iter: 200; batch classifier loss: 0.645383\n",
      "epoch 13; iter: 0; batch classifier loss: 0.584183\n",
      "epoch 13; iter: 200; batch classifier loss: 0.627948\n",
      "epoch 14; iter: 0; batch classifier loss: 0.657030\n",
      "epoch 14; iter: 200; batch classifier loss: 0.661240\n",
      "epoch 15; iter: 0; batch classifier loss: 0.598176\n",
      "epoch 15; iter: 200; batch classifier loss: 0.579931\n",
      "epoch 16; iter: 0; batch classifier loss: 0.614701\n",
      "epoch 16; iter: 200; batch classifier loss: 0.650350\n",
      "epoch 17; iter: 0; batch classifier loss: 0.600822\n",
      "epoch 17; iter: 200; batch classifier loss: 0.605240\n",
      "epoch 18; iter: 0; batch classifier loss: 0.626956\n",
      "epoch 18; iter: 200; batch classifier loss: 0.625709\n",
      "epoch 19; iter: 0; batch classifier loss: 0.610513\n",
      "epoch 19; iter: 200; batch classifier loss: 0.639306\n",
      "epoch 20; iter: 0; batch classifier loss: 0.645906\n",
      "epoch 20; iter: 200; batch classifier loss: 0.654179\n",
      "epoch 21; iter: 0; batch classifier loss: 0.618121\n",
      "epoch 21; iter: 200; batch classifier loss: 0.668023\n",
      "epoch 22; iter: 0; batch classifier loss: 0.610755\n",
      "epoch 22; iter: 200; batch classifier loss: 0.650610\n",
      "epoch 23; iter: 0; batch classifier loss: 0.590658\n",
      "epoch 23; iter: 200; batch classifier loss: 0.643527\n",
      "epoch 24; iter: 0; batch classifier loss: 0.600289\n",
      "epoch 24; iter: 200; batch classifier loss: 0.566364\n",
      "epoch 25; iter: 0; batch classifier loss: 0.545342\n",
      "epoch 25; iter: 200; batch classifier loss: 0.602492\n",
      "epoch 26; iter: 0; batch classifier loss: 0.637619\n",
      "epoch 26; iter: 200; batch classifier loss: 0.569641\n",
      "epoch 27; iter: 0; batch classifier loss: 0.583103\n",
      "epoch 27; iter: 200; batch classifier loss: 0.642023\n",
      "epoch 28; iter: 0; batch classifier loss: 0.645521\n",
      "epoch 28; iter: 200; batch classifier loss: 0.602280\n",
      "epoch 29; iter: 0; batch classifier loss: 0.634201\n",
      "epoch 29; iter: 200; batch classifier loss: 0.586271\n",
      "epoch 30; iter: 0; batch classifier loss: 0.589051\n",
      "epoch 30; iter: 200; batch classifier loss: 0.613410\n",
      "epoch 31; iter: 0; batch classifier loss: 0.577248\n",
      "epoch 31; iter: 200; batch classifier loss: 0.597956\n",
      "epoch 32; iter: 0; batch classifier loss: 0.675605\n",
      "epoch 32; iter: 200; batch classifier loss: 0.637134\n",
      "epoch 33; iter: 0; batch classifier loss: 0.652360\n",
      "epoch 33; iter: 200; batch classifier loss: 0.667458\n",
      "epoch 34; iter: 0; batch classifier loss: 0.676399\n",
      "epoch 34; iter: 200; batch classifier loss: 0.617291\n",
      "epoch 35; iter: 0; batch classifier loss: 0.664878\n",
      "epoch 35; iter: 200; batch classifier loss: 0.612408\n",
      "epoch 36; iter: 0; batch classifier loss: 0.618675\n",
      "epoch 36; iter: 200; batch classifier loss: 0.655059\n",
      "epoch 37; iter: 0; batch classifier loss: 0.569987\n",
      "epoch 37; iter: 200; batch classifier loss: 0.558538\n",
      "epoch 38; iter: 0; batch classifier loss: 0.675402\n",
      "epoch 38; iter: 200; batch classifier loss: 0.676608\n",
      "epoch 39; iter: 0; batch classifier loss: 0.615474\n",
      "epoch 39; iter: 200; batch classifier loss: 0.609499\n",
      "epoch 40; iter: 0; batch classifier loss: 0.607904\n",
      "epoch 40; iter: 200; batch classifier loss: 0.647206\n",
      "epoch 41; iter: 0; batch classifier loss: 0.584671\n",
      "epoch 41; iter: 200; batch classifier loss: 0.639194\n",
      "epoch 42; iter: 0; batch classifier loss: 0.607122\n",
      "epoch 42; iter: 200; batch classifier loss: 0.615053\n",
      "epoch 43; iter: 0; batch classifier loss: 0.597296\n",
      "epoch 43; iter: 200; batch classifier loss: 0.575994\n",
      "epoch 44; iter: 0; batch classifier loss: 0.658926\n",
      "epoch 44; iter: 200; batch classifier loss: 0.582270\n",
      "epoch 45; iter: 0; batch classifier loss: 0.618100\n",
      "epoch 45; iter: 200; batch classifier loss: 0.631741\n",
      "epoch 46; iter: 0; batch classifier loss: 0.624488\n",
      "epoch 46; iter: 200; batch classifier loss: 0.606234\n",
      "epoch 47; iter: 0; batch classifier loss: 0.578641\n",
      "epoch 47; iter: 200; batch classifier loss: 0.616995\n",
      "epoch 48; iter: 0; batch classifier loss: 0.595646\n",
      "epoch 48; iter: 200; batch classifier loss: 0.616526\n",
      "epoch 49; iter: 0; batch classifier loss: 0.623250\n",
      "epoch 49; iter: 200; batch classifier loss: 0.565122\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711197; batch adversarial loss: 0.776560\n",
      "epoch 1; iter: 0; batch classifier loss: 0.616565; batch adversarial loss: 0.707111\n",
      "epoch 2; iter: 0; batch classifier loss: 0.671215; batch adversarial loss: 0.748027\n",
      "epoch 3; iter: 0; batch classifier loss: 0.732977; batch adversarial loss: 0.747751\n",
      "epoch 4; iter: 0; batch classifier loss: 0.680079; batch adversarial loss: 0.732044\n",
      "epoch 5; iter: 0; batch classifier loss: 0.646947; batch adversarial loss: 0.738309\n",
      "epoch 6; iter: 0; batch classifier loss: 0.633180; batch adversarial loss: 0.688695\n",
      "epoch 7; iter: 0; batch classifier loss: 0.673549; batch adversarial loss: 0.753108\n",
      "epoch 8; iter: 0; batch classifier loss: 0.656465; batch adversarial loss: 0.698548\n",
      "epoch 9; iter: 0; batch classifier loss: 0.612454; batch adversarial loss: 0.731832\n",
      "epoch 10; iter: 0; batch classifier loss: 0.581534; batch adversarial loss: 0.684214\n",
      "epoch 11; iter: 0; batch classifier loss: 0.587140; batch adversarial loss: 0.706752\n",
      "epoch 12; iter: 0; batch classifier loss: 0.643762; batch adversarial loss: 0.713552\n",
      "epoch 13; iter: 0; batch classifier loss: 0.628128; batch adversarial loss: 0.698740\n",
      "epoch 14; iter: 0; batch classifier loss: 0.604443; batch adversarial loss: 0.716429\n",
      "epoch 15; iter: 0; batch classifier loss: 0.600641; batch adversarial loss: 0.700565\n",
      "epoch 16; iter: 0; batch classifier loss: 0.703633; batch adversarial loss: 0.696698\n",
      "epoch 17; iter: 0; batch classifier loss: 0.607702; batch adversarial loss: 0.685842\n",
      "epoch 18; iter: 0; batch classifier loss: 0.638338; batch adversarial loss: 0.695527\n",
      "epoch 19; iter: 0; batch classifier loss: 0.605179; batch adversarial loss: 0.678179\n",
      "epoch 20; iter: 0; batch classifier loss: 0.642255; batch adversarial loss: 0.690445\n",
      "epoch 21; iter: 0; batch classifier loss: 0.593159; batch adversarial loss: 0.695753\n",
      "epoch 22; iter: 0; batch classifier loss: 0.618190; batch adversarial loss: 0.683564\n",
      "epoch 23; iter: 0; batch classifier loss: 0.608750; batch adversarial loss: 0.683187\n",
      "epoch 24; iter: 0; batch classifier loss: 0.676521; batch adversarial loss: 0.675724\n",
      "epoch 25; iter: 0; batch classifier loss: 0.645178; batch adversarial loss: 0.660440\n",
      "epoch 26; iter: 0; batch classifier loss: 0.619026; batch adversarial loss: 0.670395\n",
      "epoch 27; iter: 0; batch classifier loss: 0.648645; batch adversarial loss: 0.697229\n",
      "epoch 28; iter: 0; batch classifier loss: 0.627016; batch adversarial loss: 0.667489\n",
      "epoch 29; iter: 0; batch classifier loss: 0.713053; batch adversarial loss: 0.672504\n",
      "epoch 30; iter: 0; batch classifier loss: 0.609581; batch adversarial loss: 0.665290\n",
      "epoch 31; iter: 0; batch classifier loss: 0.619328; batch adversarial loss: 0.681291\n",
      "epoch 32; iter: 0; batch classifier loss: 0.620777; batch adversarial loss: 0.668557\n",
      "epoch 33; iter: 0; batch classifier loss: 0.633734; batch adversarial loss: 0.662605\n",
      "epoch 34; iter: 0; batch classifier loss: 0.640174; batch adversarial loss: 0.673832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 0; batch classifier loss: 0.639736; batch adversarial loss: 0.697282\n",
      "epoch 36; iter: 0; batch classifier loss: 0.642848; batch adversarial loss: 0.678496\n",
      "epoch 37; iter: 0; batch classifier loss: 0.587300; batch adversarial loss: 0.685610\n",
      "epoch 38; iter: 0; batch classifier loss: 0.624689; batch adversarial loss: 0.666098\n",
      "epoch 39; iter: 0; batch classifier loss: 0.573634; batch adversarial loss: 0.683075\n",
      "epoch 40; iter: 0; batch classifier loss: 0.609906; batch adversarial loss: 0.659589\n",
      "epoch 41; iter: 0; batch classifier loss: 0.615730; batch adversarial loss: 0.650868\n",
      "epoch 42; iter: 0; batch classifier loss: 0.634778; batch adversarial loss: 0.659061\n",
      "epoch 43; iter: 0; batch classifier loss: 0.729595; batch adversarial loss: 0.674959\n",
      "epoch 44; iter: 0; batch classifier loss: 0.657426; batch adversarial loss: 0.637212\n",
      "epoch 45; iter: 0; batch classifier loss: 0.604880; batch adversarial loss: 0.697987\n",
      "epoch 46; iter: 0; batch classifier loss: 0.609811; batch adversarial loss: 0.651242\n",
      "epoch 47; iter: 0; batch classifier loss: 0.629990; batch adversarial loss: 0.685008\n",
      "epoch 48; iter: 0; batch classifier loss: 0.635861; batch adversarial loss: 0.662798\n",
      "epoch 49; iter: 0; batch classifier loss: 0.616033; batch adversarial loss: 0.666851\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690065\n",
      "epoch 1; iter: 0; batch classifier loss: 0.653779\n",
      "epoch 2; iter: 0; batch classifier loss: 0.613166\n",
      "epoch 3; iter: 0; batch classifier loss: 0.673965\n",
      "epoch 4; iter: 0; batch classifier loss: 0.625743\n",
      "epoch 5; iter: 0; batch classifier loss: 0.593806\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582126\n",
      "epoch 7; iter: 0; batch classifier loss: 0.628530\n",
      "epoch 8; iter: 0; batch classifier loss: 0.686418\n",
      "epoch 9; iter: 0; batch classifier loss: 0.614556\n",
      "epoch 10; iter: 0; batch classifier loss: 0.572387\n",
      "epoch 11; iter: 0; batch classifier loss: 0.708397\n",
      "epoch 12; iter: 0; batch classifier loss: 0.566078\n",
      "epoch 13; iter: 0; batch classifier loss: 0.650475\n",
      "epoch 14; iter: 0; batch classifier loss: 0.623562\n",
      "epoch 15; iter: 0; batch classifier loss: 0.608436\n",
      "epoch 16; iter: 0; batch classifier loss: 0.640611\n",
      "epoch 17; iter: 0; batch classifier loss: 0.709076\n",
      "epoch 18; iter: 0; batch classifier loss: 0.560176\n",
      "epoch 19; iter: 0; batch classifier loss: 0.580215\n",
      "epoch 20; iter: 0; batch classifier loss: 0.603097\n",
      "epoch 21; iter: 0; batch classifier loss: 0.549546\n",
      "epoch 22; iter: 0; batch classifier loss: 0.573980\n",
      "epoch 23; iter: 0; batch classifier loss: 0.611997\n",
      "epoch 24; iter: 0; batch classifier loss: 0.608968\n",
      "epoch 25; iter: 0; batch classifier loss: 0.544998\n",
      "epoch 26; iter: 0; batch classifier loss: 0.574251\n",
      "epoch 27; iter: 0; batch classifier loss: 0.600404\n",
      "epoch 28; iter: 0; batch classifier loss: 0.642575\n",
      "epoch 29; iter: 0; batch classifier loss: 0.605717\n",
      "epoch 30; iter: 0; batch classifier loss: 0.680762\n",
      "epoch 31; iter: 0; batch classifier loss: 0.653815\n",
      "epoch 32; iter: 0; batch classifier loss: 0.630391\n",
      "epoch 33; iter: 0; batch classifier loss: 0.604137\n",
      "epoch 34; iter: 0; batch classifier loss: 0.592488\n",
      "epoch 35; iter: 0; batch classifier loss: 0.634929\n",
      "epoch 36; iter: 0; batch classifier loss: 0.640339\n",
      "epoch 37; iter: 0; batch classifier loss: 0.583992\n",
      "epoch 38; iter: 0; batch classifier loss: 0.577127\n",
      "epoch 39; iter: 0; batch classifier loss: 0.647791\n",
      "epoch 40; iter: 0; batch classifier loss: 0.614749\n",
      "epoch 41; iter: 0; batch classifier loss: 0.644156\n",
      "epoch 42; iter: 0; batch classifier loss: 0.585574\n",
      "epoch 43; iter: 0; batch classifier loss: 0.601700\n",
      "epoch 44; iter: 0; batch classifier loss: 0.642410\n",
      "epoch 45; iter: 0; batch classifier loss: 0.629163\n",
      "epoch 46; iter: 0; batch classifier loss: 0.623475\n",
      "epoch 47; iter: 0; batch classifier loss: 0.600585\n",
      "epoch 48; iter: 0; batch classifier loss: 0.591711\n",
      "epoch 49; iter: 0; batch classifier loss: 0.575986\n",
      "run = 4\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711426; batch adversarial loss: 0.690480\n",
      "epoch 0; iter: 200; batch classifier loss: 0.598164; batch adversarial loss: 0.703802\n",
      "epoch 1; iter: 0; batch classifier loss: 0.597253; batch adversarial loss: 0.701566\n",
      "epoch 1; iter: 200; batch classifier loss: 0.656885; batch adversarial loss: 0.664900\n",
      "epoch 2; iter: 0; batch classifier loss: 0.648977; batch adversarial loss: 0.675101\n",
      "epoch 2; iter: 200; batch classifier loss: 0.637241; batch adversarial loss: 0.659832\n",
      "epoch 3; iter: 0; batch classifier loss: 0.624378; batch adversarial loss: 0.659164\n",
      "epoch 3; iter: 200; batch classifier loss: 0.609510; batch adversarial loss: 0.665929\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579025; batch adversarial loss: 0.684489\n",
      "epoch 4; iter: 200; batch classifier loss: 0.613445; batch adversarial loss: 0.660747\n",
      "epoch 5; iter: 0; batch classifier loss: 0.626099; batch adversarial loss: 0.654932\n",
      "epoch 5; iter: 200; batch classifier loss: 0.601047; batch adversarial loss: 0.646953\n",
      "epoch 6; iter: 0; batch classifier loss: 0.631311; batch adversarial loss: 0.653352\n",
      "epoch 6; iter: 200; batch classifier loss: 0.645765; batch adversarial loss: 0.663095\n",
      "epoch 7; iter: 0; batch classifier loss: 0.614564; batch adversarial loss: 0.672835\n",
      "epoch 7; iter: 200; batch classifier loss: 0.609625; batch adversarial loss: 0.686798\n",
      "epoch 8; iter: 0; batch classifier loss: 0.585977; batch adversarial loss: 0.659978\n",
      "epoch 8; iter: 200; batch classifier loss: 0.624685; batch adversarial loss: 0.689681\n",
      "epoch 9; iter: 0; batch classifier loss: 0.597779; batch adversarial loss: 0.684381\n",
      "epoch 9; iter: 200; batch classifier loss: 0.623900; batch adversarial loss: 0.674659\n",
      "epoch 10; iter: 0; batch classifier loss: 0.588722; batch adversarial loss: 0.627370\n",
      "epoch 10; iter: 200; batch classifier loss: 0.661958; batch adversarial loss: 0.690330\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580516; batch adversarial loss: 0.652771\n",
      "epoch 11; iter: 200; batch classifier loss: 0.701169; batch adversarial loss: 0.684209\n",
      "epoch 12; iter: 0; batch classifier loss: 0.650644; batch adversarial loss: 0.689451\n",
      "epoch 12; iter: 200; batch classifier loss: 0.591769; batch adversarial loss: 0.675636\n",
      "epoch 13; iter: 0; batch classifier loss: 0.582451; batch adversarial loss: 0.658571\n",
      "epoch 13; iter: 200; batch classifier loss: 0.593043; batch adversarial loss: 0.697942\n",
      "epoch 14; iter: 0; batch classifier loss: 0.621329; batch adversarial loss: 0.658591\n",
      "epoch 14; iter: 200; batch classifier loss: 0.629499; batch adversarial loss: 0.686004\n",
      "epoch 15; iter: 0; batch classifier loss: 0.665186; batch adversarial loss: 0.665765\n",
      "epoch 15; iter: 200; batch classifier loss: 0.627341; batch adversarial loss: 0.690718\n",
      "epoch 16; iter: 0; batch classifier loss: 0.582322; batch adversarial loss: 0.684425\n",
      "epoch 16; iter: 200; batch classifier loss: 0.657589; batch adversarial loss: 0.667063\n",
      "epoch 17; iter: 0; batch classifier loss: 0.573585; batch adversarial loss: 0.669790\n",
      "epoch 17; iter: 200; batch classifier loss: 0.591123; batch adversarial loss: 0.655152\n",
      "epoch 18; iter: 0; batch classifier loss: 0.623444; batch adversarial loss: 0.652865\n",
      "epoch 18; iter: 200; batch classifier loss: 0.615010; batch adversarial loss: 0.692870\n",
      "epoch 19; iter: 0; batch classifier loss: 0.647956; batch adversarial loss: 0.675951\n",
      "epoch 19; iter: 200; batch classifier loss: 0.648886; batch adversarial loss: 0.681210\n",
      "epoch 20; iter: 0; batch classifier loss: 0.591675; batch adversarial loss: 0.682186\n",
      "epoch 20; iter: 200; batch classifier loss: 0.604860; batch adversarial loss: 0.666667\n",
      "epoch 21; iter: 0; batch classifier loss: 0.625413; batch adversarial loss: 0.686358\n",
      "epoch 21; iter: 200; batch classifier loss: 0.579413; batch adversarial loss: 0.699197\n",
      "epoch 22; iter: 0; batch classifier loss: 0.617930; batch adversarial loss: 0.684654\n",
      "epoch 22; iter: 200; batch classifier loss: 0.604416; batch adversarial loss: 0.686383\n",
      "epoch 23; iter: 0; batch classifier loss: 0.697514; batch adversarial loss: 0.691659\n",
      "epoch 23; iter: 200; batch classifier loss: 0.623175; batch adversarial loss: 0.668030\n",
      "epoch 24; iter: 0; batch classifier loss: 0.661874; batch adversarial loss: 0.672292\n",
      "epoch 24; iter: 200; batch classifier loss: 0.637658; batch adversarial loss: 0.708623\n",
      "epoch 25; iter: 0; batch classifier loss: 0.615697; batch adversarial loss: 0.697122\n",
      "epoch 25; iter: 200; batch classifier loss: 0.617364; batch adversarial loss: 0.685733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 0; batch classifier loss: 0.589928; batch adversarial loss: 0.661063\n",
      "epoch 26; iter: 200; batch classifier loss: 0.588207; batch adversarial loss: 0.680240\n",
      "epoch 27; iter: 0; batch classifier loss: 0.621158; batch adversarial loss: 0.668667\n",
      "epoch 27; iter: 200; batch classifier loss: 0.649159; batch adversarial loss: 0.705833\n",
      "epoch 28; iter: 0; batch classifier loss: 0.644080; batch adversarial loss: 0.669775\n",
      "epoch 28; iter: 200; batch classifier loss: 0.670727; batch adversarial loss: 0.654062\n",
      "epoch 29; iter: 0; batch classifier loss: 0.629344; batch adversarial loss: 0.685258\n",
      "epoch 29; iter: 200; batch classifier loss: 0.627718; batch adversarial loss: 0.679890\n",
      "epoch 30; iter: 0; batch classifier loss: 0.670686; batch adversarial loss: 0.667664\n",
      "epoch 30; iter: 200; batch classifier loss: 0.643836; batch adversarial loss: 0.697716\n",
      "epoch 31; iter: 0; batch classifier loss: 0.652378; batch adversarial loss: 0.671042\n",
      "epoch 31; iter: 200; batch classifier loss: 0.657201; batch adversarial loss: 0.657717\n",
      "epoch 32; iter: 0; batch classifier loss: 0.667136; batch adversarial loss: 0.680581\n",
      "epoch 32; iter: 200; batch classifier loss: 0.683614; batch adversarial loss: 0.652362\n",
      "epoch 33; iter: 0; batch classifier loss: 0.688842; batch adversarial loss: 0.678314\n",
      "epoch 33; iter: 200; batch classifier loss: 0.614994; batch adversarial loss: 0.682378\n",
      "epoch 34; iter: 0; batch classifier loss: 0.613467; batch adversarial loss: 0.661791\n",
      "epoch 34; iter: 200; batch classifier loss: 0.647713; batch adversarial loss: 0.693212\n",
      "epoch 35; iter: 0; batch classifier loss: 0.621097; batch adversarial loss: 0.670397\n",
      "epoch 35; iter: 200; batch classifier loss: 0.666469; batch adversarial loss: 0.699115\n",
      "epoch 36; iter: 0; batch classifier loss: 0.614179; batch adversarial loss: 0.647492\n",
      "epoch 36; iter: 200; batch classifier loss: 0.664566; batch adversarial loss: 0.663073\n",
      "epoch 37; iter: 0; batch classifier loss: 0.610632; batch adversarial loss: 0.697069\n",
      "epoch 37; iter: 200; batch classifier loss: 0.636513; batch adversarial loss: 0.668842\n",
      "epoch 38; iter: 0; batch classifier loss: 0.614141; batch adversarial loss: 0.693041\n",
      "epoch 38; iter: 200; batch classifier loss: 0.611099; batch adversarial loss: 0.668154\n",
      "epoch 39; iter: 0; batch classifier loss: 0.602155; batch adversarial loss: 0.663416\n",
      "epoch 39; iter: 200; batch classifier loss: 0.633960; batch adversarial loss: 0.653982\n",
      "epoch 40; iter: 0; batch classifier loss: 0.568494; batch adversarial loss: 0.658071\n",
      "epoch 40; iter: 200; batch classifier loss: 0.573087; batch adversarial loss: 0.669928\n",
      "epoch 41; iter: 0; batch classifier loss: 0.585261; batch adversarial loss: 0.639304\n",
      "epoch 41; iter: 200; batch classifier loss: 0.630928; batch adversarial loss: 0.642495\n",
      "epoch 42; iter: 0; batch classifier loss: 0.644603; batch adversarial loss: 0.640868\n",
      "epoch 42; iter: 200; batch classifier loss: 0.648370; batch adversarial loss: 0.674149\n",
      "epoch 43; iter: 0; batch classifier loss: 0.608970; batch adversarial loss: 0.654258\n",
      "epoch 43; iter: 200; batch classifier loss: 0.643932; batch adversarial loss: 0.664228\n",
      "epoch 44; iter: 0; batch classifier loss: 0.588683; batch adversarial loss: 0.667862\n",
      "epoch 44; iter: 200; batch classifier loss: 0.604558; batch adversarial loss: 0.675592\n",
      "epoch 45; iter: 0; batch classifier loss: 0.612244; batch adversarial loss: 0.666074\n",
      "epoch 45; iter: 200; batch classifier loss: 0.582735; batch adversarial loss: 0.687774\n",
      "epoch 46; iter: 0; batch classifier loss: 0.613839; batch adversarial loss: 0.685874\n",
      "epoch 46; iter: 200; batch classifier loss: 0.622740; batch adversarial loss: 0.675376\n",
      "epoch 47; iter: 0; batch classifier loss: 0.561453; batch adversarial loss: 0.650371\n",
      "epoch 47; iter: 200; batch classifier loss: 0.603014; batch adversarial loss: 0.679037\n",
      "epoch 48; iter: 0; batch classifier loss: 0.631897; batch adversarial loss: 0.678675\n",
      "epoch 48; iter: 200; batch classifier loss: 0.618137; batch adversarial loss: 0.669989\n",
      "epoch 49; iter: 0; batch classifier loss: 0.661157; batch adversarial loss: 0.636119\n",
      "epoch 49; iter: 200; batch classifier loss: 0.559789; batch adversarial loss: 0.669141\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692809\n",
      "epoch 0; iter: 200; batch classifier loss: 0.605381\n",
      "epoch 1; iter: 0; batch classifier loss: 0.630405\n",
      "epoch 1; iter: 200; batch classifier loss: 0.636683\n",
      "epoch 2; iter: 0; batch classifier loss: 0.607875\n",
      "epoch 2; iter: 200; batch classifier loss: 0.622231\n",
      "epoch 3; iter: 0; batch classifier loss: 0.663943\n",
      "epoch 3; iter: 200; batch classifier loss: 0.625928\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601141\n",
      "epoch 4; iter: 200; batch classifier loss: 0.569319\n",
      "epoch 5; iter: 0; batch classifier loss: 0.607371\n",
      "epoch 5; iter: 200; batch classifier loss: 0.642153\n",
      "epoch 6; iter: 0; batch classifier loss: 0.631404\n",
      "epoch 6; iter: 200; batch classifier loss: 0.630811\n",
      "epoch 7; iter: 0; batch classifier loss: 0.681845\n",
      "epoch 7; iter: 200; batch classifier loss: 0.606174\n",
      "epoch 8; iter: 0; batch classifier loss: 0.578364\n",
      "epoch 8; iter: 200; batch classifier loss: 0.637161\n",
      "epoch 9; iter: 0; batch classifier loss: 0.592588\n",
      "epoch 9; iter: 200; batch classifier loss: 0.745747\n",
      "epoch 10; iter: 0; batch classifier loss: 0.643464\n",
      "epoch 10; iter: 200; batch classifier loss: 0.581778\n",
      "epoch 11; iter: 0; batch classifier loss: 0.643124\n",
      "epoch 11; iter: 200; batch classifier loss: 0.602349\n",
      "epoch 12; iter: 0; batch classifier loss: 0.611689\n",
      "epoch 12; iter: 200; batch classifier loss: 0.620237\n",
      "epoch 13; iter: 0; batch classifier loss: 0.547578\n",
      "epoch 13; iter: 200; batch classifier loss: 0.606261\n",
      "epoch 14; iter: 0; batch classifier loss: 0.625651\n",
      "epoch 14; iter: 200; batch classifier loss: 0.613715\n",
      "epoch 15; iter: 0; batch classifier loss: 0.620762\n",
      "epoch 15; iter: 200; batch classifier loss: 0.596525\n",
      "epoch 16; iter: 0; batch classifier loss: 0.628599\n",
      "epoch 16; iter: 200; batch classifier loss: 0.618099\n",
      "epoch 17; iter: 0; batch classifier loss: 0.664291\n",
      "epoch 17; iter: 200; batch classifier loss: 0.637551\n",
      "epoch 18; iter: 0; batch classifier loss: 0.692888\n",
      "epoch 18; iter: 200; batch classifier loss: 0.611040\n",
      "epoch 19; iter: 0; batch classifier loss: 0.613244\n",
      "epoch 19; iter: 200; batch classifier loss: 0.510181\n",
      "epoch 20; iter: 0; batch classifier loss: 0.601875\n",
      "epoch 20; iter: 200; batch classifier loss: 0.696838\n",
      "epoch 21; iter: 0; batch classifier loss: 0.618435\n",
      "epoch 21; iter: 200; batch classifier loss: 0.677220\n",
      "epoch 22; iter: 0; batch classifier loss: 0.609048\n",
      "epoch 22; iter: 200; batch classifier loss: 0.626750\n",
      "epoch 23; iter: 0; batch classifier loss: 0.625686\n",
      "epoch 23; iter: 200; batch classifier loss: 0.617203\n",
      "epoch 24; iter: 0; batch classifier loss: 0.565183\n",
      "epoch 24; iter: 200; batch classifier loss: 0.602933\n",
      "epoch 25; iter: 0; batch classifier loss: 0.648254\n",
      "epoch 25; iter: 200; batch classifier loss: 0.648605\n",
      "epoch 26; iter: 0; batch classifier loss: 0.605006\n",
      "epoch 26; iter: 200; batch classifier loss: 0.649369\n",
      "epoch 27; iter: 0; batch classifier loss: 0.623039\n",
      "epoch 27; iter: 200; batch classifier loss: 0.623760\n",
      "epoch 28; iter: 0; batch classifier loss: 0.566282\n",
      "epoch 28; iter: 200; batch classifier loss: 0.614768\n",
      "epoch 29; iter: 0; batch classifier loss: 0.599471\n",
      "epoch 29; iter: 200; batch classifier loss: 0.601880\n",
      "epoch 30; iter: 0; batch classifier loss: 0.627264\n",
      "epoch 30; iter: 200; batch classifier loss: 0.611318\n",
      "epoch 31; iter: 0; batch classifier loss: 0.609879\n",
      "epoch 31; iter: 200; batch classifier loss: 0.581107\n",
      "epoch 32; iter: 0; batch classifier loss: 0.653114\n",
      "epoch 32; iter: 200; batch classifier loss: 0.628118\n",
      "epoch 33; iter: 0; batch classifier loss: 0.632302\n",
      "epoch 33; iter: 200; batch classifier loss: 0.597409\n",
      "epoch 34; iter: 0; batch classifier loss: 0.625970\n",
      "epoch 34; iter: 200; batch classifier loss: 0.611766\n",
      "epoch 35; iter: 0; batch classifier loss: 0.649413\n",
      "epoch 35; iter: 200; batch classifier loss: 0.619842\n",
      "epoch 36; iter: 0; batch classifier loss: 0.708161\n",
      "epoch 36; iter: 200; batch classifier loss: 0.653118\n",
      "epoch 37; iter: 0; batch classifier loss: 0.616121\n",
      "epoch 37; iter: 200; batch classifier loss: 0.596917\n",
      "epoch 38; iter: 0; batch classifier loss: 0.615594\n",
      "epoch 38; iter: 200; batch classifier loss: 0.629743\n",
      "epoch 39; iter: 0; batch classifier loss: 0.565950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 200; batch classifier loss: 0.605979\n",
      "epoch 40; iter: 0; batch classifier loss: 0.653269\n",
      "epoch 40; iter: 200; batch classifier loss: 0.629824\n",
      "epoch 41; iter: 0; batch classifier loss: 0.621276\n",
      "epoch 41; iter: 200; batch classifier loss: 0.579113\n",
      "epoch 42; iter: 0; batch classifier loss: 0.624168\n",
      "epoch 42; iter: 200; batch classifier loss: 0.596907\n",
      "epoch 43; iter: 0; batch classifier loss: 0.605559\n",
      "epoch 43; iter: 200; batch classifier loss: 0.640384\n",
      "epoch 44; iter: 0; batch classifier loss: 0.631445\n",
      "epoch 44; iter: 200; batch classifier loss: 0.621178\n",
      "epoch 45; iter: 0; batch classifier loss: 0.655105\n",
      "epoch 45; iter: 200; batch classifier loss: 0.642634\n",
      "epoch 46; iter: 0; batch classifier loss: 0.615058\n",
      "epoch 46; iter: 200; batch classifier loss: 0.606951\n",
      "epoch 47; iter: 0; batch classifier loss: 0.645969\n",
      "epoch 47; iter: 200; batch classifier loss: 0.572658\n",
      "epoch 48; iter: 0; batch classifier loss: 0.649001\n",
      "epoch 48; iter: 200; batch classifier loss: 0.669951\n",
      "epoch 49; iter: 0; batch classifier loss: 0.590920\n",
      "epoch 49; iter: 200; batch classifier loss: 0.642199\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689713; batch adversarial loss: 0.699937\n",
      "epoch 1; iter: 0; batch classifier loss: 0.656839; batch adversarial loss: 0.690951\n",
      "epoch 2; iter: 0; batch classifier loss: 0.621193; batch adversarial loss: 0.682226\n",
      "epoch 3; iter: 0; batch classifier loss: 0.658685; batch adversarial loss: 0.718244\n",
      "epoch 4; iter: 0; batch classifier loss: 0.644816; batch adversarial loss: 0.738752\n",
      "epoch 5; iter: 0; batch classifier loss: 0.563639; batch adversarial loss: 0.754654\n",
      "epoch 6; iter: 0; batch classifier loss: 0.642202; batch adversarial loss: 0.727490\n",
      "epoch 7; iter: 0; batch classifier loss: 0.611969; batch adversarial loss: 0.708513\n",
      "epoch 8; iter: 0; batch classifier loss: 0.651228; batch adversarial loss: 0.730846\n",
      "epoch 9; iter: 0; batch classifier loss: 0.612881; batch adversarial loss: 0.713405\n",
      "epoch 10; iter: 0; batch classifier loss: 0.618584; batch adversarial loss: 0.733382\n",
      "epoch 11; iter: 0; batch classifier loss: 0.601755; batch adversarial loss: 0.727016\n",
      "epoch 12; iter: 0; batch classifier loss: 0.578565; batch adversarial loss: 0.713297\n",
      "epoch 13; iter: 0; batch classifier loss: 0.598010; batch adversarial loss: 0.717917\n",
      "epoch 14; iter: 0; batch classifier loss: 0.689266; batch adversarial loss: 0.678945\n",
      "epoch 15; iter: 0; batch classifier loss: 0.653508; batch adversarial loss: 0.711332\n",
      "epoch 16; iter: 0; batch classifier loss: 0.609879; batch adversarial loss: 0.701448\n",
      "epoch 17; iter: 0; batch classifier loss: 0.628832; batch adversarial loss: 0.706178\n",
      "epoch 18; iter: 0; batch classifier loss: 0.588106; batch adversarial loss: 0.679758\n",
      "epoch 19; iter: 0; batch classifier loss: 0.583502; batch adversarial loss: 0.683731\n",
      "epoch 20; iter: 0; batch classifier loss: 0.639470; batch adversarial loss: 0.670730\n",
      "epoch 21; iter: 0; batch classifier loss: 0.653436; batch adversarial loss: 0.688197\n",
      "epoch 22; iter: 0; batch classifier loss: 0.593983; batch adversarial loss: 0.648691\n",
      "epoch 23; iter: 0; batch classifier loss: 0.583984; batch adversarial loss: 0.665581\n",
      "epoch 24; iter: 0; batch classifier loss: 0.658415; batch adversarial loss: 0.658697\n",
      "epoch 25; iter: 0; batch classifier loss: 0.648694; batch adversarial loss: 0.663002\n",
      "epoch 26; iter: 0; batch classifier loss: 0.606514; batch adversarial loss: 0.662367\n",
      "epoch 27; iter: 0; batch classifier loss: 0.622402; batch adversarial loss: 0.670998\n",
      "epoch 28; iter: 0; batch classifier loss: 0.621846; batch adversarial loss: 0.666371\n",
      "epoch 29; iter: 0; batch classifier loss: 0.601780; batch adversarial loss: 0.661832\n",
      "epoch 30; iter: 0; batch classifier loss: 0.632948; batch adversarial loss: 0.649798\n",
      "epoch 31; iter: 0; batch classifier loss: 0.605137; batch adversarial loss: 0.658077\n",
      "epoch 32; iter: 0; batch classifier loss: 0.612750; batch adversarial loss: 0.656010\n",
      "epoch 33; iter: 0; batch classifier loss: 0.632060; batch adversarial loss: 0.658885\n",
      "epoch 34; iter: 0; batch classifier loss: 0.582645; batch adversarial loss: 0.670287\n",
      "epoch 35; iter: 0; batch classifier loss: 0.637606; batch adversarial loss: 0.655729\n",
      "epoch 36; iter: 0; batch classifier loss: 0.592704; batch adversarial loss: 0.645469\n",
      "epoch 37; iter: 0; batch classifier loss: 0.623912; batch adversarial loss: 0.650149\n",
      "epoch 38; iter: 0; batch classifier loss: 0.619005; batch adversarial loss: 0.638308\n",
      "epoch 39; iter: 0; batch classifier loss: 0.587574; batch adversarial loss: 0.662454\n",
      "epoch 40; iter: 0; batch classifier loss: 0.569223; batch adversarial loss: 0.644333\n",
      "epoch 41; iter: 0; batch classifier loss: 0.610923; batch adversarial loss: 0.656484\n",
      "epoch 42; iter: 0; batch classifier loss: 0.596483; batch adversarial loss: 0.646698\n",
      "epoch 43; iter: 0; batch classifier loss: 0.584333; batch adversarial loss: 0.646084\n",
      "epoch 44; iter: 0; batch classifier loss: 0.592890; batch adversarial loss: 0.647064\n",
      "epoch 45; iter: 0; batch classifier loss: 0.639604; batch adversarial loss: 0.663889\n",
      "epoch 46; iter: 0; batch classifier loss: 0.584905; batch adversarial loss: 0.637413\n",
      "epoch 47; iter: 0; batch classifier loss: 0.590593; batch adversarial loss: 0.684196\n",
      "epoch 48; iter: 0; batch classifier loss: 0.639502; batch adversarial loss: 0.674441\n",
      "epoch 49; iter: 0; batch classifier loss: 0.625739; batch adversarial loss: 0.670256\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670615\n",
      "epoch 1; iter: 0; batch classifier loss: 0.662547\n",
      "epoch 2; iter: 0; batch classifier loss: 0.697405\n",
      "epoch 3; iter: 0; batch classifier loss: 0.652606\n",
      "epoch 4; iter: 0; batch classifier loss: 0.605145\n",
      "epoch 5; iter: 0; batch classifier loss: 0.646780\n",
      "epoch 6; iter: 0; batch classifier loss: 0.634839\n",
      "epoch 7; iter: 0; batch classifier loss: 0.653112\n",
      "epoch 8; iter: 0; batch classifier loss: 0.634146\n",
      "epoch 9; iter: 0; batch classifier loss: 0.602612\n",
      "epoch 10; iter: 0; batch classifier loss: 0.637873\n",
      "epoch 11; iter: 0; batch classifier loss: 0.645960\n",
      "epoch 12; iter: 0; batch classifier loss: 0.551320\n",
      "epoch 13; iter: 0; batch classifier loss: 0.599919\n",
      "epoch 14; iter: 0; batch classifier loss: 0.652003\n",
      "epoch 15; iter: 0; batch classifier loss: 0.608745\n",
      "epoch 16; iter: 0; batch classifier loss: 0.605906\n",
      "epoch 17; iter: 0; batch classifier loss: 0.635570\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539303\n",
      "epoch 19; iter: 0; batch classifier loss: 0.614480\n",
      "epoch 20; iter: 0; batch classifier loss: 0.598118\n",
      "epoch 21; iter: 0; batch classifier loss: 0.571513\n",
      "epoch 22; iter: 0; batch classifier loss: 0.614506\n",
      "epoch 23; iter: 0; batch classifier loss: 0.625507\n",
      "epoch 24; iter: 0; batch classifier loss: 0.597097\n",
      "epoch 25; iter: 0; batch classifier loss: 0.602250\n",
      "epoch 26; iter: 0; batch classifier loss: 0.590493\n",
      "epoch 27; iter: 0; batch classifier loss: 0.621381\n",
      "epoch 28; iter: 0; batch classifier loss: 0.606384\n",
      "epoch 29; iter: 0; batch classifier loss: 0.598467\n",
      "epoch 30; iter: 0; batch classifier loss: 0.613961\n",
      "epoch 31; iter: 0; batch classifier loss: 0.671691\n",
      "epoch 32; iter: 0; batch classifier loss: 0.571465\n",
      "epoch 33; iter: 0; batch classifier loss: 0.647331\n",
      "epoch 34; iter: 0; batch classifier loss: 0.624331\n",
      "epoch 35; iter: 0; batch classifier loss: 0.620542\n",
      "epoch 36; iter: 0; batch classifier loss: 0.591709\n",
      "epoch 37; iter: 0; batch classifier loss: 0.631101\n",
      "epoch 38; iter: 0; batch classifier loss: 0.621247\n",
      "epoch 39; iter: 0; batch classifier loss: 0.638967\n",
      "epoch 40; iter: 0; batch classifier loss: 0.622800\n",
      "epoch 41; iter: 0; batch classifier loss: 0.689854\n",
      "epoch 42; iter: 0; batch classifier loss: 0.655019\n",
      "epoch 43; iter: 0; batch classifier loss: 0.629369\n",
      "epoch 44; iter: 0; batch classifier loss: 0.644710\n",
      "epoch 45; iter: 0; batch classifier loss: 0.618111\n",
      "epoch 46; iter: 0; batch classifier loss: 0.625730\n",
      "epoch 47; iter: 0; batch classifier loss: 0.571754\n",
      "epoch 48; iter: 0; batch classifier loss: 0.602767\n",
      "epoch 49; iter: 0; batch classifier loss: 0.596024\n",
      "run = 5\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694261; batch adversarial loss: 0.688322\n",
      "epoch 0; iter: 200; batch classifier loss: 0.641752; batch adversarial loss: 0.661511\n",
      "epoch 1; iter: 0; batch classifier loss: 0.633053; batch adversarial loss: 0.676441\n",
      "epoch 1; iter: 200; batch classifier loss: 0.634257; batch adversarial loss: 0.675145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 0; batch classifier loss: 0.652378; batch adversarial loss: 0.727119\n",
      "epoch 2; iter: 200; batch classifier loss: 0.617811; batch adversarial loss: 0.651165\n",
      "epoch 3; iter: 0; batch classifier loss: 0.653831; batch adversarial loss: 0.682910\n",
      "epoch 3; iter: 200; batch classifier loss: 0.643464; batch adversarial loss: 0.653467\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558604; batch adversarial loss: 0.678273\n",
      "epoch 4; iter: 200; batch classifier loss: 0.600760; batch adversarial loss: 0.688582\n",
      "epoch 5; iter: 0; batch classifier loss: 0.661169; batch adversarial loss: 0.695445\n",
      "epoch 5; iter: 200; batch classifier loss: 0.677537; batch adversarial loss: 0.667200\n",
      "epoch 6; iter: 0; batch classifier loss: 0.663801; batch adversarial loss: 0.676949\n",
      "epoch 6; iter: 200; batch classifier loss: 0.612292; batch adversarial loss: 0.653084\n",
      "epoch 7; iter: 0; batch classifier loss: 0.638866; batch adversarial loss: 0.670620\n",
      "epoch 7; iter: 200; batch classifier loss: 0.624210; batch adversarial loss: 0.672691\n",
      "epoch 8; iter: 0; batch classifier loss: 0.617507; batch adversarial loss: 0.675901\n",
      "epoch 8; iter: 200; batch classifier loss: 0.647156; batch adversarial loss: 0.667237\n",
      "epoch 9; iter: 0; batch classifier loss: 0.610648; batch adversarial loss: 0.663603\n",
      "epoch 9; iter: 200; batch classifier loss: 0.653741; batch adversarial loss: 0.664200\n",
      "epoch 10; iter: 0; batch classifier loss: 0.630314; batch adversarial loss: 0.660728\n",
      "epoch 10; iter: 200; batch classifier loss: 0.612764; batch adversarial loss: 0.644479\n",
      "epoch 11; iter: 0; batch classifier loss: 0.704830; batch adversarial loss: 0.674936\n",
      "epoch 11; iter: 200; batch classifier loss: 0.581364; batch adversarial loss: 0.692612\n",
      "epoch 12; iter: 0; batch classifier loss: 0.663908; batch adversarial loss: 0.701124\n",
      "epoch 12; iter: 200; batch classifier loss: 0.613723; batch adversarial loss: 0.689396\n",
      "epoch 13; iter: 0; batch classifier loss: 0.621949; batch adversarial loss: 0.704365\n",
      "epoch 13; iter: 200; batch classifier loss: 0.645750; batch adversarial loss: 0.704664\n",
      "epoch 14; iter: 0; batch classifier loss: 0.639011; batch adversarial loss: 0.671245\n",
      "epoch 14; iter: 200; batch classifier loss: 0.620521; batch adversarial loss: 0.658422\n",
      "epoch 15; iter: 0; batch classifier loss: 0.627888; batch adversarial loss: 0.679167\n",
      "epoch 15; iter: 200; batch classifier loss: 0.617301; batch adversarial loss: 0.664010\n",
      "epoch 16; iter: 0; batch classifier loss: 0.650476; batch adversarial loss: 0.650353\n",
      "epoch 16; iter: 200; batch classifier loss: 0.606611; batch adversarial loss: 0.684497\n",
      "epoch 17; iter: 0; batch classifier loss: 0.643007; batch adversarial loss: 0.696416\n",
      "epoch 17; iter: 200; batch classifier loss: 0.613407; batch adversarial loss: 0.657100\n",
      "epoch 18; iter: 0; batch classifier loss: 0.630519; batch adversarial loss: 0.689492\n",
      "epoch 18; iter: 200; batch classifier loss: 0.691322; batch adversarial loss: 0.690593\n",
      "epoch 19; iter: 0; batch classifier loss: 0.609354; batch adversarial loss: 0.690301\n",
      "epoch 19; iter: 200; batch classifier loss: 0.660260; batch adversarial loss: 0.688537\n",
      "epoch 20; iter: 0; batch classifier loss: 0.603038; batch adversarial loss: 0.679151\n",
      "epoch 20; iter: 200; batch classifier loss: 0.597997; batch adversarial loss: 0.679212\n",
      "epoch 21; iter: 0; batch classifier loss: 0.612743; batch adversarial loss: 0.681156\n",
      "epoch 21; iter: 200; batch classifier loss: 0.638672; batch adversarial loss: 0.692948\n",
      "epoch 22; iter: 0; batch classifier loss: 0.631600; batch adversarial loss: 0.664393\n",
      "epoch 22; iter: 200; batch classifier loss: 0.569257; batch adversarial loss: 0.683695\n",
      "epoch 23; iter: 0; batch classifier loss: 0.682148; batch adversarial loss: 0.690768\n",
      "epoch 23; iter: 200; batch classifier loss: 0.581445; batch adversarial loss: 0.700484\n",
      "epoch 24; iter: 0; batch classifier loss: 0.583809; batch adversarial loss: 0.668579\n",
      "epoch 24; iter: 200; batch classifier loss: 0.597306; batch adversarial loss: 0.667425\n",
      "epoch 25; iter: 0; batch classifier loss: 0.563287; batch adversarial loss: 0.677447\n",
      "epoch 25; iter: 200; batch classifier loss: 0.636841; batch adversarial loss: 0.672302\n",
      "epoch 26; iter: 0; batch classifier loss: 0.582414; batch adversarial loss: 0.683311\n",
      "epoch 26; iter: 200; batch classifier loss: 0.664647; batch adversarial loss: 0.680468\n",
      "epoch 27; iter: 0; batch classifier loss: 0.680202; batch adversarial loss: 0.685006\n",
      "epoch 27; iter: 200; batch classifier loss: 0.627549; batch adversarial loss: 0.672812\n",
      "epoch 28; iter: 0; batch classifier loss: 0.601155; batch adversarial loss: 0.697531\n",
      "epoch 28; iter: 200; batch classifier loss: 0.623044; batch adversarial loss: 0.673890\n",
      "epoch 29; iter: 0; batch classifier loss: 0.640024; batch adversarial loss: 0.664724\n",
      "epoch 29; iter: 200; batch classifier loss: 0.595157; batch adversarial loss: 0.675433\n",
      "epoch 30; iter: 0; batch classifier loss: 0.613198; batch adversarial loss: 0.699615\n",
      "epoch 30; iter: 200; batch classifier loss: 0.622180; batch adversarial loss: 0.684333\n",
      "epoch 31; iter: 0; batch classifier loss: 0.626767; batch adversarial loss: 0.709830\n",
      "epoch 31; iter: 200; batch classifier loss: 0.598027; batch adversarial loss: 0.704190\n",
      "epoch 32; iter: 0; batch classifier loss: 0.592808; batch adversarial loss: 0.697103\n",
      "epoch 32; iter: 200; batch classifier loss: 0.619508; batch adversarial loss: 0.697578\n",
      "epoch 33; iter: 0; batch classifier loss: 0.631152; batch adversarial loss: 0.666601\n",
      "epoch 33; iter: 200; batch classifier loss: 0.642223; batch adversarial loss: 0.686827\n",
      "epoch 34; iter: 0; batch classifier loss: 0.600343; batch adversarial loss: 0.689291\n",
      "epoch 34; iter: 200; batch classifier loss: 0.581298; batch adversarial loss: 0.668453\n",
      "epoch 35; iter: 0; batch classifier loss: 0.626732; batch adversarial loss: 0.679360\n",
      "epoch 35; iter: 200; batch classifier loss: 0.642137; batch adversarial loss: 0.671504\n",
      "epoch 36; iter: 0; batch classifier loss: 0.586041; batch adversarial loss: 0.677890\n",
      "epoch 36; iter: 200; batch classifier loss: 0.607790; batch adversarial loss: 0.654712\n",
      "epoch 37; iter: 0; batch classifier loss: 0.615923; batch adversarial loss: 0.657954\n",
      "epoch 37; iter: 200; batch classifier loss: 0.605834; batch adversarial loss: 0.679770\n",
      "epoch 38; iter: 0; batch classifier loss: 0.664303; batch adversarial loss: 0.679822\n",
      "epoch 38; iter: 200; batch classifier loss: 0.612837; batch adversarial loss: 0.674546\n",
      "epoch 39; iter: 0; batch classifier loss: 0.670094; batch adversarial loss: 0.685829\n",
      "epoch 39; iter: 200; batch classifier loss: 0.606653; batch adversarial loss: 0.669903\n",
      "epoch 40; iter: 0; batch classifier loss: 0.698384; batch adversarial loss: 0.678682\n",
      "epoch 40; iter: 200; batch classifier loss: 0.624118; batch adversarial loss: 0.698338\n",
      "epoch 41; iter: 0; batch classifier loss: 0.607791; batch adversarial loss: 0.677355\n",
      "epoch 41; iter: 200; batch classifier loss: 0.651015; batch adversarial loss: 0.673453\n",
      "epoch 42; iter: 0; batch classifier loss: 0.634337; batch adversarial loss: 0.690188\n",
      "epoch 42; iter: 200; batch classifier loss: 0.638226; batch adversarial loss: 0.666395\n",
      "epoch 43; iter: 0; batch classifier loss: 0.679674; batch adversarial loss: 0.655997\n",
      "epoch 43; iter: 200; batch classifier loss: 0.633185; batch adversarial loss: 0.689562\n",
      "epoch 44; iter: 0; batch classifier loss: 0.643989; batch adversarial loss: 0.664581\n",
      "epoch 44; iter: 200; batch classifier loss: 0.637009; batch adversarial loss: 0.676865\n",
      "epoch 45; iter: 0; batch classifier loss: 0.582438; batch adversarial loss: 0.682180\n",
      "epoch 45; iter: 200; batch classifier loss: 0.659421; batch adversarial loss: 0.676684\n",
      "epoch 46; iter: 0; batch classifier loss: 0.659285; batch adversarial loss: 0.668662\n",
      "epoch 46; iter: 200; batch classifier loss: 0.652336; batch adversarial loss: 0.659134\n",
      "epoch 47; iter: 0; batch classifier loss: 0.594050; batch adversarial loss: 0.682885\n",
      "epoch 47; iter: 200; batch classifier loss: 0.644129; batch adversarial loss: 0.656393\n",
      "epoch 48; iter: 0; batch classifier loss: 0.607591; batch adversarial loss: 0.700901\n",
      "epoch 48; iter: 200; batch classifier loss: 0.598480; batch adversarial loss: 0.660072\n",
      "epoch 49; iter: 0; batch classifier loss: 0.643621; batch adversarial loss: 0.691279\n",
      "epoch 49; iter: 200; batch classifier loss: 0.627516; batch adversarial loss: 0.669652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.702677\n",
      "epoch 0; iter: 200; batch classifier loss: 0.593896\n",
      "epoch 1; iter: 0; batch classifier loss: 0.601699\n",
      "epoch 1; iter: 200; batch classifier loss: 0.545972\n",
      "epoch 2; iter: 0; batch classifier loss: 0.662163\n",
      "epoch 2; iter: 200; batch classifier loss: 0.593465\n",
      "epoch 3; iter: 0; batch classifier loss: 0.641511\n",
      "epoch 3; iter: 200; batch classifier loss: 0.631256\n",
      "epoch 4; iter: 0; batch classifier loss: 0.676513\n",
      "epoch 4; iter: 200; batch classifier loss: 0.629453\n",
      "epoch 5; iter: 0; batch classifier loss: 0.618883\n",
      "epoch 5; iter: 200; batch classifier loss: 0.612358\n",
      "epoch 6; iter: 0; batch classifier loss: 0.640741\n",
      "epoch 6; iter: 200; batch classifier loss: 0.605339\n",
      "epoch 7; iter: 0; batch classifier loss: 0.612170\n",
      "epoch 7; iter: 200; batch classifier loss: 0.621641\n",
      "epoch 8; iter: 0; batch classifier loss: 0.633675\n",
      "epoch 8; iter: 200; batch classifier loss: 0.602919\n",
      "epoch 9; iter: 0; batch classifier loss: 0.635838\n",
      "epoch 9; iter: 200; batch classifier loss: 0.619724\n",
      "epoch 10; iter: 0; batch classifier loss: 0.602479\n",
      "epoch 10; iter: 200; batch classifier loss: 0.644414\n",
      "epoch 11; iter: 0; batch classifier loss: 0.654456\n",
      "epoch 11; iter: 200; batch classifier loss: 0.577269\n",
      "epoch 12; iter: 0; batch classifier loss: 0.646871\n",
      "epoch 12; iter: 200; batch classifier loss: 0.599511\n",
      "epoch 13; iter: 0; batch classifier loss: 0.632324\n",
      "epoch 13; iter: 200; batch classifier loss: 0.607179\n",
      "epoch 14; iter: 0; batch classifier loss: 0.588378\n",
      "epoch 14; iter: 200; batch classifier loss: 0.624089\n",
      "epoch 15; iter: 0; batch classifier loss: 0.576826\n",
      "epoch 15; iter: 200; batch classifier loss: 0.646818\n",
      "epoch 16; iter: 0; batch classifier loss: 0.646715\n",
      "epoch 16; iter: 200; batch classifier loss: 0.667841\n",
      "epoch 17; iter: 0; batch classifier loss: 0.652143\n",
      "epoch 17; iter: 200; batch classifier loss: 0.591834\n",
      "epoch 18; iter: 0; batch classifier loss: 0.604184\n",
      "epoch 18; iter: 200; batch classifier loss: 0.636557\n",
      "epoch 19; iter: 0; batch classifier loss: 0.652507\n",
      "epoch 19; iter: 200; batch classifier loss: 0.625078\n",
      "epoch 20; iter: 0; batch classifier loss: 0.631745\n",
      "epoch 20; iter: 200; batch classifier loss: 0.583700\n",
      "epoch 21; iter: 0; batch classifier loss: 0.673583\n",
      "epoch 21; iter: 200; batch classifier loss: 0.620185\n",
      "epoch 22; iter: 0; batch classifier loss: 0.586880\n",
      "epoch 22; iter: 200; batch classifier loss: 0.673218\n",
      "epoch 23; iter: 0; batch classifier loss: 0.624303\n",
      "epoch 23; iter: 200; batch classifier loss: 0.595310\n",
      "epoch 24; iter: 0; batch classifier loss: 0.660595\n",
      "epoch 24; iter: 200; batch classifier loss: 0.627331\n",
      "epoch 25; iter: 0; batch classifier loss: 0.616988\n",
      "epoch 25; iter: 200; batch classifier loss: 0.616993\n",
      "epoch 26; iter: 0; batch classifier loss: 0.636694\n",
      "epoch 26; iter: 200; batch classifier loss: 0.639991\n",
      "epoch 27; iter: 0; batch classifier loss: 0.657471\n",
      "epoch 27; iter: 200; batch classifier loss: 0.620453\n",
      "epoch 28; iter: 0; batch classifier loss: 0.635680\n",
      "epoch 28; iter: 200; batch classifier loss: 0.598316\n",
      "epoch 29; iter: 0; batch classifier loss: 0.652237\n",
      "epoch 29; iter: 200; batch classifier loss: 0.591411\n",
      "epoch 30; iter: 0; batch classifier loss: 0.650204\n",
      "epoch 30; iter: 200; batch classifier loss: 0.669209\n",
      "epoch 31; iter: 0; batch classifier loss: 0.642097\n",
      "epoch 31; iter: 200; batch classifier loss: 0.632257\n",
      "epoch 32; iter: 0; batch classifier loss: 0.699307\n",
      "epoch 32; iter: 200; batch classifier loss: 0.603613\n",
      "epoch 33; iter: 0; batch classifier loss: 0.632722\n",
      "epoch 33; iter: 200; batch classifier loss: 0.581996\n",
      "epoch 34; iter: 0; batch classifier loss: 0.591881\n",
      "epoch 34; iter: 200; batch classifier loss: 0.612930\n",
      "epoch 35; iter: 0; batch classifier loss: 0.636369\n",
      "epoch 35; iter: 200; batch classifier loss: 0.608041\n",
      "epoch 36; iter: 0; batch classifier loss: 0.596801\n",
      "epoch 36; iter: 200; batch classifier loss: 0.625174\n",
      "epoch 37; iter: 0; batch classifier loss: 0.648545\n",
      "epoch 37; iter: 200; batch classifier loss: 0.675492\n",
      "epoch 38; iter: 0; batch classifier loss: 0.577990\n",
      "epoch 38; iter: 200; batch classifier loss: 0.580803\n",
      "epoch 39; iter: 0; batch classifier loss: 0.599397\n",
      "epoch 39; iter: 200; batch classifier loss: 0.655840\n",
      "epoch 40; iter: 0; batch classifier loss: 0.623847\n",
      "epoch 40; iter: 200; batch classifier loss: 0.651378\n",
      "epoch 41; iter: 0; batch classifier loss: 0.578271\n",
      "epoch 41; iter: 200; batch classifier loss: 0.610047\n",
      "epoch 42; iter: 0; batch classifier loss: 0.617338\n",
      "epoch 42; iter: 200; batch classifier loss: 0.589319\n",
      "epoch 43; iter: 0; batch classifier loss: 0.624893\n",
      "epoch 43; iter: 200; batch classifier loss: 0.602239\n",
      "epoch 44; iter: 0; batch classifier loss: 0.606314\n",
      "epoch 44; iter: 200; batch classifier loss: 0.629849\n",
      "epoch 45; iter: 0; batch classifier loss: 0.589915\n",
      "epoch 45; iter: 200; batch classifier loss: 0.559558\n",
      "epoch 46; iter: 0; batch classifier loss: 0.641347\n",
      "epoch 46; iter: 200; batch classifier loss: 0.620626\n",
      "epoch 47; iter: 0; batch classifier loss: 0.575103\n",
      "epoch 47; iter: 200; batch classifier loss: 0.598151\n",
      "epoch 48; iter: 0; batch classifier loss: 0.613462\n",
      "epoch 48; iter: 200; batch classifier loss: 0.607995\n",
      "epoch 49; iter: 0; batch classifier loss: 0.667882\n",
      "epoch 49; iter: 200; batch classifier loss: 0.615754\n",
      "epoch 0; iter: 0; batch classifier loss: 0.734448; batch adversarial loss: 0.694302\n",
      "epoch 1; iter: 0; batch classifier loss: 0.659129; batch adversarial loss: 0.692128\n",
      "epoch 2; iter: 0; batch classifier loss: 0.623078; batch adversarial loss: 0.681524\n",
      "epoch 3; iter: 0; batch classifier loss: 0.650588; batch adversarial loss: 0.676743\n",
      "epoch 4; iter: 0; batch classifier loss: 0.689053; batch adversarial loss: 0.679984\n",
      "epoch 5; iter: 0; batch classifier loss: 0.598228; batch adversarial loss: 0.667906\n",
      "epoch 6; iter: 0; batch classifier loss: 0.615077; batch adversarial loss: 0.678866\n",
      "epoch 7; iter: 0; batch classifier loss: 0.626343; batch adversarial loss: 0.692902\n",
      "epoch 8; iter: 0; batch classifier loss: 0.642058; batch adversarial loss: 0.685731\n",
      "epoch 9; iter: 0; batch classifier loss: 0.639807; batch adversarial loss: 0.669821\n",
      "epoch 10; iter: 0; batch classifier loss: 0.665727; batch adversarial loss: 0.676171\n",
      "epoch 11; iter: 0; batch classifier loss: 0.658638; batch adversarial loss: 0.672461\n",
      "epoch 12; iter: 0; batch classifier loss: 0.664630; batch adversarial loss: 0.676827\n",
      "epoch 13; iter: 0; batch classifier loss: 0.624531; batch adversarial loss: 0.665188\n",
      "epoch 14; iter: 0; batch classifier loss: 0.605892; batch adversarial loss: 0.682960\n",
      "epoch 15; iter: 0; batch classifier loss: 0.651822; batch adversarial loss: 0.654131\n",
      "epoch 16; iter: 0; batch classifier loss: 0.607541; batch adversarial loss: 0.681743\n",
      "epoch 17; iter: 0; batch classifier loss: 0.610527; batch adversarial loss: 0.676430\n",
      "epoch 18; iter: 0; batch classifier loss: 0.652933; batch adversarial loss: 0.670381\n",
      "epoch 19; iter: 0; batch classifier loss: 0.638952; batch adversarial loss: 0.679643\n",
      "epoch 20; iter: 0; batch classifier loss: 0.652627; batch adversarial loss: 0.651932\n",
      "epoch 21; iter: 0; batch classifier loss: 0.642589; batch adversarial loss: 0.672445\n",
      "epoch 22; iter: 0; batch classifier loss: 0.632780; batch adversarial loss: 0.668694\n",
      "epoch 23; iter: 0; batch classifier loss: 0.590372; batch adversarial loss: 0.683846\n",
      "epoch 24; iter: 0; batch classifier loss: 0.617868; batch adversarial loss: 0.653163\n",
      "epoch 25; iter: 0; batch classifier loss: 0.588239; batch adversarial loss: 0.648877\n",
      "epoch 26; iter: 0; batch classifier loss: 0.604860; batch adversarial loss: 0.655772\n",
      "epoch 27; iter: 0; batch classifier loss: 0.576565; batch adversarial loss: 0.672270\n",
      "epoch 28; iter: 0; batch classifier loss: 0.637392; batch adversarial loss: 0.668914\n",
      "epoch 29; iter: 0; batch classifier loss: 0.630759; batch adversarial loss: 0.682626\n",
      "epoch 30; iter: 0; batch classifier loss: 0.607529; batch adversarial loss: 0.649715\n",
      "epoch 31; iter: 0; batch classifier loss: 0.550378; batch adversarial loss: 0.658786\n",
      "epoch 32; iter: 0; batch classifier loss: 0.659023; batch adversarial loss: 0.680122\n",
      "epoch 33; iter: 0; batch classifier loss: 0.670003; batch adversarial loss: 0.655734\n",
      "epoch 34; iter: 0; batch classifier loss: 0.647072; batch adversarial loss: 0.654977\n",
      "epoch 35; iter: 0; batch classifier loss: 0.593718; batch adversarial loss: 0.664796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 0; batch classifier loss: 0.609606; batch adversarial loss: 0.667697\n",
      "epoch 37; iter: 0; batch classifier loss: 0.631707; batch adversarial loss: 0.685767\n",
      "epoch 38; iter: 0; batch classifier loss: 0.624837; batch adversarial loss: 0.667876\n",
      "epoch 39; iter: 0; batch classifier loss: 0.633819; batch adversarial loss: 0.669972\n",
      "epoch 40; iter: 0; batch classifier loss: 0.609276; batch adversarial loss: 0.665933\n",
      "epoch 41; iter: 0; batch classifier loss: 0.601995; batch adversarial loss: 0.679240\n",
      "epoch 42; iter: 0; batch classifier loss: 0.590123; batch adversarial loss: 0.679501\n",
      "epoch 43; iter: 0; batch classifier loss: 0.621264; batch adversarial loss: 0.694171\n",
      "epoch 44; iter: 0; batch classifier loss: 0.628840; batch adversarial loss: 0.692685\n",
      "epoch 45; iter: 0; batch classifier loss: 0.625455; batch adversarial loss: 0.644007\n",
      "epoch 46; iter: 0; batch classifier loss: 0.610890; batch adversarial loss: 0.681253\n",
      "epoch 47; iter: 0; batch classifier loss: 0.686385; batch adversarial loss: 0.643318\n",
      "epoch 48; iter: 0; batch classifier loss: 0.636516; batch adversarial loss: 0.650474\n",
      "epoch 49; iter: 0; batch classifier loss: 0.690715; batch adversarial loss: 0.701246\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685897\n",
      "epoch 1; iter: 0; batch classifier loss: 0.647942\n",
      "epoch 2; iter: 0; batch classifier loss: 0.579204\n",
      "epoch 3; iter: 0; batch classifier loss: 0.612982\n",
      "epoch 4; iter: 0; batch classifier loss: 0.618954\n",
      "epoch 5; iter: 0; batch classifier loss: 0.651027\n",
      "epoch 6; iter: 0; batch classifier loss: 0.557045\n",
      "epoch 7; iter: 0; batch classifier loss: 0.620310\n",
      "epoch 8; iter: 0; batch classifier loss: 0.634859\n",
      "epoch 9; iter: 0; batch classifier loss: 0.587721\n",
      "epoch 10; iter: 0; batch classifier loss: 0.635741\n",
      "epoch 11; iter: 0; batch classifier loss: 0.666822\n",
      "epoch 12; iter: 0; batch classifier loss: 0.662529\n",
      "epoch 13; iter: 0; batch classifier loss: 0.693727\n",
      "epoch 14; iter: 0; batch classifier loss: 0.606684\n",
      "epoch 15; iter: 0; batch classifier loss: 0.589810\n",
      "epoch 16; iter: 0; batch classifier loss: 0.634136\n",
      "epoch 17; iter: 0; batch classifier loss: 0.601197\n",
      "epoch 18; iter: 0; batch classifier loss: 0.626724\n",
      "epoch 19; iter: 0; batch classifier loss: 0.656252\n",
      "epoch 20; iter: 0; batch classifier loss: 0.679672\n",
      "epoch 21; iter: 0; batch classifier loss: 0.638615\n",
      "epoch 22; iter: 0; batch classifier loss: 0.632591\n",
      "epoch 23; iter: 0; batch classifier loss: 0.593937\n",
      "epoch 24; iter: 0; batch classifier loss: 0.610140\n",
      "epoch 25; iter: 0; batch classifier loss: 0.558728\n",
      "epoch 26; iter: 0; batch classifier loss: 0.635388\n",
      "epoch 27; iter: 0; batch classifier loss: 0.611717\n",
      "epoch 28; iter: 0; batch classifier loss: 0.644842\n",
      "epoch 29; iter: 0; batch classifier loss: 0.629373\n",
      "epoch 30; iter: 0; batch classifier loss: 0.693435\n",
      "epoch 31; iter: 0; batch classifier loss: 0.605805\n",
      "epoch 32; iter: 0; batch classifier loss: 0.629249\n",
      "epoch 33; iter: 0; batch classifier loss: 0.562371\n",
      "epoch 34; iter: 0; batch classifier loss: 0.610578\n",
      "epoch 35; iter: 0; batch classifier loss: 0.610173\n",
      "epoch 36; iter: 0; batch classifier loss: 0.602931\n",
      "epoch 37; iter: 0; batch classifier loss: 0.658786\n",
      "epoch 38; iter: 0; batch classifier loss: 0.653746\n",
      "epoch 39; iter: 0; batch classifier loss: 0.620032\n",
      "epoch 40; iter: 0; batch classifier loss: 0.584677\n",
      "epoch 41; iter: 0; batch classifier loss: 0.626324\n",
      "epoch 42; iter: 0; batch classifier loss: 0.601849\n",
      "epoch 43; iter: 0; batch classifier loss: 0.635579\n",
      "epoch 44; iter: 0; batch classifier loss: 0.566086\n",
      "epoch 45; iter: 0; batch classifier loss: 0.573525\n",
      "epoch 46; iter: 0; batch classifier loss: 0.601149\n",
      "epoch 47; iter: 0; batch classifier loss: 0.630555\n",
      "epoch 48; iter: 0; batch classifier loss: 0.647737\n",
      "epoch 49; iter: 0; batch classifier loss: 0.608604\n",
      "run = 6\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691315; batch adversarial loss: 0.892985\n",
      "epoch 0; iter: 200; batch classifier loss: 0.708637; batch adversarial loss: 0.932149\n",
      "epoch 1; iter: 0; batch classifier loss: 0.733338; batch adversarial loss: 0.834985\n",
      "epoch 1; iter: 200; batch classifier loss: 0.739263; batch adversarial loss: 0.753297\n",
      "epoch 2; iter: 0; batch classifier loss: 0.646223; batch adversarial loss: 0.709122\n",
      "epoch 2; iter: 200; batch classifier loss: 0.640988; batch adversarial loss: 0.695263\n",
      "epoch 3; iter: 0; batch classifier loss: 0.630012; batch adversarial loss: 0.700992\n",
      "epoch 3; iter: 200; batch classifier loss: 0.613206; batch adversarial loss: 0.680351\n",
      "epoch 4; iter: 0; batch classifier loss: 0.639997; batch adversarial loss: 0.645198\n",
      "epoch 4; iter: 200; batch classifier loss: 0.578590; batch adversarial loss: 0.701960\n",
      "epoch 5; iter: 0; batch classifier loss: 0.645525; batch adversarial loss: 0.677149\n",
      "epoch 5; iter: 200; batch classifier loss: 0.621314; batch adversarial loss: 0.699378\n",
      "epoch 6; iter: 0; batch classifier loss: 0.643930; batch adversarial loss: 0.695150\n",
      "epoch 6; iter: 200; batch classifier loss: 0.601783; batch adversarial loss: 0.656709\n",
      "epoch 7; iter: 0; batch classifier loss: 0.663914; batch adversarial loss: 0.672099\n",
      "epoch 7; iter: 200; batch classifier loss: 0.641444; batch adversarial loss: 0.688655\n",
      "epoch 8; iter: 0; batch classifier loss: 0.604539; batch adversarial loss: 0.684392\n",
      "epoch 8; iter: 200; batch classifier loss: 0.591004; batch adversarial loss: 0.694529\n",
      "epoch 9; iter: 0; batch classifier loss: 0.613841; batch adversarial loss: 0.643033\n",
      "epoch 9; iter: 200; batch classifier loss: 0.610233; batch adversarial loss: 0.687005\n",
      "epoch 10; iter: 0; batch classifier loss: 0.605207; batch adversarial loss: 0.665454\n",
      "epoch 10; iter: 200; batch classifier loss: 0.650078; batch adversarial loss: 0.686387\n",
      "epoch 11; iter: 0; batch classifier loss: 0.624414; batch adversarial loss: 0.685439\n",
      "epoch 11; iter: 200; batch classifier loss: 0.605086; batch adversarial loss: 0.665786\n",
      "epoch 12; iter: 0; batch classifier loss: 0.644779; batch adversarial loss: 0.670686\n",
      "epoch 12; iter: 200; batch classifier loss: 0.632444; batch adversarial loss: 0.678339\n",
      "epoch 13; iter: 0; batch classifier loss: 0.579321; batch adversarial loss: 0.652912\n",
      "epoch 13; iter: 200; batch classifier loss: 0.674130; batch adversarial loss: 0.658884\n",
      "epoch 14; iter: 0; batch classifier loss: 0.638680; batch adversarial loss: 0.677378\n",
      "epoch 14; iter: 200; batch classifier loss: 0.627963; batch adversarial loss: 0.676742\n",
      "epoch 15; iter: 0; batch classifier loss: 0.587641; batch adversarial loss: 0.657079\n",
      "epoch 15; iter: 200; batch classifier loss: 0.608273; batch adversarial loss: 0.697303\n",
      "epoch 16; iter: 0; batch classifier loss: 0.669093; batch adversarial loss: 0.670083\n",
      "epoch 16; iter: 200; batch classifier loss: 0.611986; batch adversarial loss: 0.703713\n",
      "epoch 17; iter: 0; batch classifier loss: 0.592192; batch adversarial loss: 0.676190\n",
      "epoch 17; iter: 200; batch classifier loss: 0.649723; batch adversarial loss: 0.689321\n",
      "epoch 18; iter: 0; batch classifier loss: 0.624071; batch adversarial loss: 0.672444\n",
      "epoch 18; iter: 200; batch classifier loss: 0.608310; batch adversarial loss: 0.669942\n",
      "epoch 19; iter: 0; batch classifier loss: 0.547284; batch adversarial loss: 0.671493\n",
      "epoch 19; iter: 200; batch classifier loss: 0.607576; batch adversarial loss: 0.680173\n",
      "epoch 20; iter: 0; batch classifier loss: 0.625411; batch adversarial loss: 0.661038\n",
      "epoch 20; iter: 200; batch classifier loss: 0.564975; batch adversarial loss: 0.673184\n",
      "epoch 21; iter: 0; batch classifier loss: 0.602758; batch adversarial loss: 0.699409\n",
      "epoch 21; iter: 200; batch classifier loss: 0.659423; batch adversarial loss: 0.645577\n",
      "epoch 22; iter: 0; batch classifier loss: 0.560218; batch adversarial loss: 0.674196\n",
      "epoch 22; iter: 200; batch classifier loss: 0.657067; batch adversarial loss: 0.690308\n",
      "epoch 23; iter: 0; batch classifier loss: 0.617872; batch adversarial loss: 0.679650\n",
      "epoch 23; iter: 200; batch classifier loss: 0.594124; batch adversarial loss: 0.662114\n",
      "epoch 24; iter: 0; batch classifier loss: 0.638505; batch adversarial loss: 0.688506\n",
      "epoch 24; iter: 200; batch classifier loss: 0.629990; batch adversarial loss: 0.684219\n",
      "epoch 25; iter: 0; batch classifier loss: 0.610469; batch adversarial loss: 0.687115\n",
      "epoch 25; iter: 200; batch classifier loss: 0.640765; batch adversarial loss: 0.680459\n",
      "epoch 26; iter: 0; batch classifier loss: 0.589295; batch adversarial loss: 0.682621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 200; batch classifier loss: 0.618612; batch adversarial loss: 0.644712\n",
      "epoch 27; iter: 0; batch classifier loss: 0.592206; batch adversarial loss: 0.655698\n",
      "epoch 27; iter: 200; batch classifier loss: 0.605586; batch adversarial loss: 0.681692\n",
      "epoch 28; iter: 0; batch classifier loss: 0.646096; batch adversarial loss: 0.640799\n",
      "epoch 28; iter: 200; batch classifier loss: 0.609679; batch adversarial loss: 0.688534\n",
      "epoch 29; iter: 0; batch classifier loss: 0.603111; batch adversarial loss: 0.684021\n",
      "epoch 29; iter: 200; batch classifier loss: 0.656647; batch adversarial loss: 0.668209\n",
      "epoch 30; iter: 0; batch classifier loss: 0.620366; batch adversarial loss: 0.673125\n",
      "epoch 30; iter: 200; batch classifier loss: 0.571873; batch adversarial loss: 0.632061\n",
      "epoch 31; iter: 0; batch classifier loss: 0.637987; batch adversarial loss: 0.672315\n",
      "epoch 31; iter: 200; batch classifier loss: 0.637860; batch adversarial loss: 0.664343\n",
      "epoch 32; iter: 0; batch classifier loss: 0.662261; batch adversarial loss: 0.690627\n",
      "epoch 32; iter: 200; batch classifier loss: 0.606685; batch adversarial loss: 0.695213\n",
      "epoch 33; iter: 0; batch classifier loss: 0.597314; batch adversarial loss: 0.691675\n",
      "epoch 33; iter: 200; batch classifier loss: 0.605125; batch adversarial loss: 0.650216\n",
      "epoch 34; iter: 0; batch classifier loss: 0.588462; batch adversarial loss: 0.675763\n",
      "epoch 34; iter: 200; batch classifier loss: 0.606867; batch adversarial loss: 0.659726\n",
      "epoch 35; iter: 0; batch classifier loss: 0.604376; batch adversarial loss: 0.669548\n",
      "epoch 35; iter: 200; batch classifier loss: 0.698649; batch adversarial loss: 0.648081\n",
      "epoch 36; iter: 0; batch classifier loss: 0.674948; batch adversarial loss: 0.689705\n",
      "epoch 36; iter: 200; batch classifier loss: 0.578412; batch adversarial loss: 0.661339\n",
      "epoch 37; iter: 0; batch classifier loss: 0.573536; batch adversarial loss: 0.658774\n",
      "epoch 37; iter: 200; batch classifier loss: 0.634394; batch adversarial loss: 0.673396\n",
      "epoch 38; iter: 0; batch classifier loss: 0.622775; batch adversarial loss: 0.669180\n",
      "epoch 38; iter: 200; batch classifier loss: 0.601360; batch adversarial loss: 0.671039\n",
      "epoch 39; iter: 0; batch classifier loss: 0.581078; batch adversarial loss: 0.681937\n",
      "epoch 39; iter: 200; batch classifier loss: 0.647144; batch adversarial loss: 0.687084\n",
      "epoch 40; iter: 0; batch classifier loss: 0.592011; batch adversarial loss: 0.686277\n",
      "epoch 40; iter: 200; batch classifier loss: 0.626453; batch adversarial loss: 0.685294\n",
      "epoch 41; iter: 0; batch classifier loss: 0.661444; batch adversarial loss: 0.637268\n",
      "epoch 41; iter: 200; batch classifier loss: 0.722822; batch adversarial loss: 0.688763\n",
      "epoch 42; iter: 0; batch classifier loss: 0.582809; batch adversarial loss: 0.663135\n",
      "epoch 42; iter: 200; batch classifier loss: 0.632184; batch adversarial loss: 0.685316\n",
      "epoch 43; iter: 0; batch classifier loss: 0.623381; batch adversarial loss: 0.631619\n",
      "epoch 43; iter: 200; batch classifier loss: 0.641720; batch adversarial loss: 0.688004\n",
      "epoch 44; iter: 0; batch classifier loss: 0.617121; batch adversarial loss: 0.677922\n",
      "epoch 44; iter: 200; batch classifier loss: 0.635207; batch adversarial loss: 0.704120\n",
      "epoch 45; iter: 0; batch classifier loss: 0.598035; batch adversarial loss: 0.668452\n",
      "epoch 45; iter: 200; batch classifier loss: 0.637378; batch adversarial loss: 0.645440\n",
      "epoch 46; iter: 0; batch classifier loss: 0.621490; batch adversarial loss: 0.649017\n",
      "epoch 46; iter: 200; batch classifier loss: 0.628437; batch adversarial loss: 0.670648\n",
      "epoch 47; iter: 0; batch classifier loss: 0.658941; batch adversarial loss: 0.671503\n",
      "epoch 47; iter: 200; batch classifier loss: 0.586874; batch adversarial loss: 0.663836\n",
      "epoch 48; iter: 0; batch classifier loss: 0.565352; batch adversarial loss: 0.663750\n",
      "epoch 48; iter: 200; batch classifier loss: 0.705307; batch adversarial loss: 0.696377\n",
      "epoch 49; iter: 0; batch classifier loss: 0.688541; batch adversarial loss: 0.693456\n",
      "epoch 49; iter: 200; batch classifier loss: 0.632326; batch adversarial loss: 0.685657\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696639\n",
      "epoch 0; iter: 200; batch classifier loss: 0.658165\n",
      "epoch 1; iter: 0; batch classifier loss: 0.625887\n",
      "epoch 1; iter: 200; batch classifier loss: 0.664663\n",
      "epoch 2; iter: 0; batch classifier loss: 0.617981\n",
      "epoch 2; iter: 200; batch classifier loss: 0.637335\n",
      "epoch 3; iter: 0; batch classifier loss: 0.589002\n",
      "epoch 3; iter: 200; batch classifier loss: 0.632777\n",
      "epoch 4; iter: 0; batch classifier loss: 0.635300\n",
      "epoch 4; iter: 200; batch classifier loss: 0.651921\n",
      "epoch 5; iter: 0; batch classifier loss: 0.597294\n",
      "epoch 5; iter: 200; batch classifier loss: 0.656314\n",
      "epoch 6; iter: 0; batch classifier loss: 0.660793\n",
      "epoch 6; iter: 200; batch classifier loss: 0.590392\n",
      "epoch 7; iter: 0; batch classifier loss: 0.557173\n",
      "epoch 7; iter: 200; batch classifier loss: 0.629989\n",
      "epoch 8; iter: 0; batch classifier loss: 0.586879\n",
      "epoch 8; iter: 200; batch classifier loss: 0.642573\n",
      "epoch 9; iter: 0; batch classifier loss: 0.630589\n",
      "epoch 9; iter: 200; batch classifier loss: 0.622910\n",
      "epoch 10; iter: 0; batch classifier loss: 0.614048\n",
      "epoch 10; iter: 200; batch classifier loss: 0.630590\n",
      "epoch 11; iter: 0; batch classifier loss: 0.693419\n",
      "epoch 11; iter: 200; batch classifier loss: 0.603275\n",
      "epoch 12; iter: 0; batch classifier loss: 0.625561\n",
      "epoch 12; iter: 200; batch classifier loss: 0.640452\n",
      "epoch 13; iter: 0; batch classifier loss: 0.630312\n",
      "epoch 13; iter: 200; batch classifier loss: 0.614595\n",
      "epoch 14; iter: 0; batch classifier loss: 0.637758\n",
      "epoch 14; iter: 200; batch classifier loss: 0.650257\n",
      "epoch 15; iter: 0; batch classifier loss: 0.652354\n",
      "epoch 15; iter: 200; batch classifier loss: 0.641784\n",
      "epoch 16; iter: 0; batch classifier loss: 0.573742\n",
      "epoch 16; iter: 200; batch classifier loss: 0.578216\n",
      "epoch 17; iter: 0; batch classifier loss: 0.578161\n",
      "epoch 17; iter: 200; batch classifier loss: 0.639813\n",
      "epoch 18; iter: 0; batch classifier loss: 0.613508\n",
      "epoch 18; iter: 200; batch classifier loss: 0.593270\n",
      "epoch 19; iter: 0; batch classifier loss: 0.564328\n",
      "epoch 19; iter: 200; batch classifier loss: 0.624411\n",
      "epoch 20; iter: 0; batch classifier loss: 0.585812\n",
      "epoch 20; iter: 200; batch classifier loss: 0.651884\n",
      "epoch 21; iter: 0; batch classifier loss: 0.652138\n",
      "epoch 21; iter: 200; batch classifier loss: 0.610159\n",
      "epoch 22; iter: 0; batch classifier loss: 0.647426\n",
      "epoch 22; iter: 200; batch classifier loss: 0.584676\n",
      "epoch 23; iter: 0; batch classifier loss: 0.630147\n",
      "epoch 23; iter: 200; batch classifier loss: 0.611713\n",
      "epoch 24; iter: 0; batch classifier loss: 0.609104\n",
      "epoch 24; iter: 200; batch classifier loss: 0.618700\n",
      "epoch 25; iter: 0; batch classifier loss: 0.582162\n",
      "epoch 25; iter: 200; batch classifier loss: 0.596409\n",
      "epoch 26; iter: 0; batch classifier loss: 0.613791\n",
      "epoch 26; iter: 200; batch classifier loss: 0.628074\n",
      "epoch 27; iter: 0; batch classifier loss: 0.614693\n",
      "epoch 27; iter: 200; batch classifier loss: 0.640863\n",
      "epoch 28; iter: 0; batch classifier loss: 0.636140\n",
      "epoch 28; iter: 200; batch classifier loss: 0.625123\n",
      "epoch 29; iter: 0; batch classifier loss: 0.559134\n",
      "epoch 29; iter: 200; batch classifier loss: 0.616076\n",
      "epoch 30; iter: 0; batch classifier loss: 0.620648\n",
      "epoch 30; iter: 200; batch classifier loss: 0.678203\n",
      "epoch 31; iter: 0; batch classifier loss: 0.664915\n",
      "epoch 31; iter: 200; batch classifier loss: 0.593738\n",
      "epoch 32; iter: 0; batch classifier loss: 0.567199\n",
      "epoch 32; iter: 200; batch classifier loss: 0.618151\n",
      "epoch 33; iter: 0; batch classifier loss: 0.598428\n",
      "epoch 33; iter: 200; batch classifier loss: 0.606115\n",
      "epoch 34; iter: 0; batch classifier loss: 0.648345\n",
      "epoch 34; iter: 200; batch classifier loss: 0.622644\n",
      "epoch 35; iter: 0; batch classifier loss: 0.595790\n",
      "epoch 35; iter: 200; batch classifier loss: 0.685972\n",
      "epoch 36; iter: 0; batch classifier loss: 0.615184\n",
      "epoch 36; iter: 200; batch classifier loss: 0.601917\n",
      "epoch 37; iter: 0; batch classifier loss: 0.602065\n",
      "epoch 37; iter: 200; batch classifier loss: 0.622510\n",
      "epoch 38; iter: 0; batch classifier loss: 0.630694\n",
      "epoch 38; iter: 200; batch classifier loss: 0.639831\n",
      "epoch 39; iter: 0; batch classifier loss: 0.629940\n",
      "epoch 39; iter: 200; batch classifier loss: 0.652039\n",
      "epoch 40; iter: 0; batch classifier loss: 0.629008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 200; batch classifier loss: 0.598431\n",
      "epoch 41; iter: 0; batch classifier loss: 0.575178\n",
      "epoch 41; iter: 200; batch classifier loss: 0.645372\n",
      "epoch 42; iter: 0; batch classifier loss: 0.611073\n",
      "epoch 42; iter: 200; batch classifier loss: 0.622204\n",
      "epoch 43; iter: 0; batch classifier loss: 0.601855\n",
      "epoch 43; iter: 200; batch classifier loss: 0.624032\n",
      "epoch 44; iter: 0; batch classifier loss: 0.599738\n",
      "epoch 44; iter: 200; batch classifier loss: 0.623978\n",
      "epoch 45; iter: 0; batch classifier loss: 0.627194\n",
      "epoch 45; iter: 200; batch classifier loss: 0.666682\n",
      "epoch 46; iter: 0; batch classifier loss: 0.653638\n",
      "epoch 46; iter: 200; batch classifier loss: 0.638638\n",
      "epoch 47; iter: 0; batch classifier loss: 0.616682\n",
      "epoch 47; iter: 200; batch classifier loss: 0.572598\n",
      "epoch 48; iter: 0; batch classifier loss: 0.625759\n",
      "epoch 48; iter: 200; batch classifier loss: 0.620713\n",
      "epoch 49; iter: 0; batch classifier loss: 0.615588\n",
      "epoch 49; iter: 200; batch classifier loss: 0.621648\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694330; batch adversarial loss: 0.666639\n",
      "epoch 1; iter: 0; batch classifier loss: 0.634214; batch adversarial loss: 0.689343\n",
      "epoch 2; iter: 0; batch classifier loss: 0.609994; batch adversarial loss: 0.665458\n",
      "epoch 3; iter: 0; batch classifier loss: 0.616051; batch adversarial loss: 0.724398\n",
      "epoch 4; iter: 0; batch classifier loss: 0.682754; batch adversarial loss: 0.687019\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580927; batch adversarial loss: 0.702546\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561222; batch adversarial loss: 0.688800\n",
      "epoch 7; iter: 0; batch classifier loss: 0.667174; batch adversarial loss: 0.689094\n",
      "epoch 8; iter: 0; batch classifier loss: 0.586179; batch adversarial loss: 0.694697\n",
      "epoch 9; iter: 0; batch classifier loss: 0.613942; batch adversarial loss: 0.685288\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549408; batch adversarial loss: 0.660164\n",
      "epoch 11; iter: 0; batch classifier loss: 0.627669; batch adversarial loss: 0.682936\n",
      "epoch 12; iter: 0; batch classifier loss: 0.631579; batch adversarial loss: 0.645860\n",
      "epoch 13; iter: 0; batch classifier loss: 0.576393; batch adversarial loss: 0.650897\n",
      "epoch 14; iter: 0; batch classifier loss: 0.625896; batch adversarial loss: 0.677549\n",
      "epoch 15; iter: 0; batch classifier loss: 0.647000; batch adversarial loss: 0.685642\n",
      "epoch 16; iter: 0; batch classifier loss: 0.599325; batch adversarial loss: 0.674786\n",
      "epoch 17; iter: 0; batch classifier loss: 0.629259; batch adversarial loss: 0.676971\n",
      "epoch 18; iter: 0; batch classifier loss: 0.636716; batch adversarial loss: 0.694306\n",
      "epoch 19; iter: 0; batch classifier loss: 0.646639; batch adversarial loss: 0.670496\n",
      "epoch 20; iter: 0; batch classifier loss: 0.663714; batch adversarial loss: 0.669580\n",
      "epoch 21; iter: 0; batch classifier loss: 0.618557; batch adversarial loss: 0.678255\n",
      "epoch 22; iter: 0; batch classifier loss: 0.605663; batch adversarial loss: 0.667215\n",
      "epoch 23; iter: 0; batch classifier loss: 0.615631; batch adversarial loss: 0.658608\n",
      "epoch 24; iter: 0; batch classifier loss: 0.696593; batch adversarial loss: 0.646185\n",
      "epoch 25; iter: 0; batch classifier loss: 0.578399; batch adversarial loss: 0.684448\n",
      "epoch 26; iter: 0; batch classifier loss: 0.626533; batch adversarial loss: 0.651093\n",
      "epoch 27; iter: 0; batch classifier loss: 0.593535; batch adversarial loss: 0.647187\n",
      "epoch 28; iter: 0; batch classifier loss: 0.635128; batch adversarial loss: 0.665754\n",
      "epoch 29; iter: 0; batch classifier loss: 0.605007; batch adversarial loss: 0.652551\n",
      "epoch 30; iter: 0; batch classifier loss: 0.644349; batch adversarial loss: 0.639202\n",
      "epoch 31; iter: 0; batch classifier loss: 0.605135; batch adversarial loss: 0.685026\n",
      "epoch 32; iter: 0; batch classifier loss: 0.574351; batch adversarial loss: 0.655644\n",
      "epoch 33; iter: 0; batch classifier loss: 0.621890; batch adversarial loss: 0.657819\n",
      "epoch 34; iter: 0; batch classifier loss: 0.598789; batch adversarial loss: 0.659303\n",
      "epoch 35; iter: 0; batch classifier loss: 0.572141; batch adversarial loss: 0.642172\n",
      "epoch 36; iter: 0; batch classifier loss: 0.641258; batch adversarial loss: 0.632577\n",
      "epoch 37; iter: 0; batch classifier loss: 0.637531; batch adversarial loss: 0.669019\n",
      "epoch 38; iter: 0; batch classifier loss: 0.613264; batch adversarial loss: 0.654894\n",
      "epoch 39; iter: 0; batch classifier loss: 0.572295; batch adversarial loss: 0.673051\n",
      "epoch 40; iter: 0; batch classifier loss: 0.626679; batch adversarial loss: 0.674468\n",
      "epoch 41; iter: 0; batch classifier loss: 0.601864; batch adversarial loss: 0.664031\n",
      "epoch 42; iter: 0; batch classifier loss: 0.560588; batch adversarial loss: 0.640155\n",
      "epoch 43; iter: 0; batch classifier loss: 0.607748; batch adversarial loss: 0.663586\n",
      "epoch 44; iter: 0; batch classifier loss: 0.642793; batch adversarial loss: 0.653979\n",
      "epoch 45; iter: 0; batch classifier loss: 0.624357; batch adversarial loss: 0.648413\n",
      "epoch 46; iter: 0; batch classifier loss: 0.633585; batch adversarial loss: 0.668382\n",
      "epoch 47; iter: 0; batch classifier loss: 0.605593; batch adversarial loss: 0.654461\n",
      "epoch 48; iter: 0; batch classifier loss: 0.627240; batch adversarial loss: 0.642341\n",
      "epoch 49; iter: 0; batch classifier loss: 0.640962; batch adversarial loss: 0.673257\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676935\n",
      "epoch 1; iter: 0; batch classifier loss: 0.630954\n",
      "epoch 2; iter: 0; batch classifier loss: 0.570015\n",
      "epoch 3; iter: 0; batch classifier loss: 0.652237\n",
      "epoch 4; iter: 0; batch classifier loss: 0.588432\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594090\n",
      "epoch 6; iter: 0; batch classifier loss: 0.580187\n",
      "epoch 7; iter: 0; batch classifier loss: 0.555191\n",
      "epoch 8; iter: 0; batch classifier loss: 0.622333\n",
      "epoch 9; iter: 0; batch classifier loss: 0.668155\n",
      "epoch 10; iter: 0; batch classifier loss: 0.598913\n",
      "epoch 11; iter: 0; batch classifier loss: 0.584779\n",
      "epoch 12; iter: 0; batch classifier loss: 0.579687\n",
      "epoch 13; iter: 0; batch classifier loss: 0.625956\n",
      "epoch 14; iter: 0; batch classifier loss: 0.597019\n",
      "epoch 15; iter: 0; batch classifier loss: 0.637545\n",
      "epoch 16; iter: 0; batch classifier loss: 0.590917\n",
      "epoch 17; iter: 0; batch classifier loss: 0.557811\n",
      "epoch 18; iter: 0; batch classifier loss: 0.632464\n",
      "epoch 19; iter: 0; batch classifier loss: 0.590732\n",
      "epoch 20; iter: 0; batch classifier loss: 0.612425\n",
      "epoch 21; iter: 0; batch classifier loss: 0.629414\n",
      "epoch 22; iter: 0; batch classifier loss: 0.660026\n",
      "epoch 23; iter: 0; batch classifier loss: 0.584049\n",
      "epoch 24; iter: 0; batch classifier loss: 0.585291\n",
      "epoch 25; iter: 0; batch classifier loss: 0.578800\n",
      "epoch 26; iter: 0; batch classifier loss: 0.575110\n",
      "epoch 27; iter: 0; batch classifier loss: 0.674197\n",
      "epoch 28; iter: 0; batch classifier loss: 0.555282\n",
      "epoch 29; iter: 0; batch classifier loss: 0.580613\n",
      "epoch 30; iter: 0; batch classifier loss: 0.670654\n",
      "epoch 31; iter: 0; batch classifier loss: 0.582523\n",
      "epoch 32; iter: 0; batch classifier loss: 0.657391\n",
      "epoch 33; iter: 0; batch classifier loss: 0.608828\n",
      "epoch 34; iter: 0; batch classifier loss: 0.576778\n",
      "epoch 35; iter: 0; batch classifier loss: 0.590746\n",
      "epoch 36; iter: 0; batch classifier loss: 0.687610\n",
      "epoch 37; iter: 0; batch classifier loss: 0.619164\n",
      "epoch 38; iter: 0; batch classifier loss: 0.635687\n",
      "epoch 39; iter: 0; batch classifier loss: 0.571555\n",
      "epoch 40; iter: 0; batch classifier loss: 0.620383\n",
      "epoch 41; iter: 0; batch classifier loss: 0.661608\n",
      "epoch 42; iter: 0; batch classifier loss: 0.648730\n",
      "epoch 43; iter: 0; batch classifier loss: 0.680388\n",
      "epoch 44; iter: 0; batch classifier loss: 0.586119\n",
      "epoch 45; iter: 0; batch classifier loss: 0.614904\n",
      "epoch 46; iter: 0; batch classifier loss: 0.620040\n",
      "epoch 47; iter: 0; batch classifier loss: 0.609891\n",
      "epoch 48; iter: 0; batch classifier loss: 0.609836\n",
      "epoch 49; iter: 0; batch classifier loss: 0.625276\n",
      "run = 7\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688865; batch adversarial loss: 0.690211\n",
      "epoch 0; iter: 200; batch classifier loss: 0.778974; batch adversarial loss: 0.803823\n",
      "epoch 1; iter: 0; batch classifier loss: 0.681772; batch adversarial loss: 0.802365\n",
      "epoch 1; iter: 200; batch classifier loss: 0.777446; batch adversarial loss: 0.735416\n",
      "epoch 2; iter: 0; batch classifier loss: 0.734698; batch adversarial loss: 0.720848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 200; batch classifier loss: 0.626067; batch adversarial loss: 0.681070\n",
      "epoch 3; iter: 0; batch classifier loss: 0.618398; batch adversarial loss: 0.676994\n",
      "epoch 3; iter: 200; batch classifier loss: 0.606694; batch adversarial loss: 0.694789\n",
      "epoch 4; iter: 0; batch classifier loss: 0.650609; batch adversarial loss: 0.690087\n",
      "epoch 4; iter: 200; batch classifier loss: 0.625787; batch adversarial loss: 0.680686\n",
      "epoch 5; iter: 0; batch classifier loss: 0.637263; batch adversarial loss: 0.641457\n",
      "epoch 5; iter: 200; batch classifier loss: 0.598409; batch adversarial loss: 0.659858\n",
      "epoch 6; iter: 0; batch classifier loss: 0.575171; batch adversarial loss: 0.659102\n",
      "epoch 6; iter: 200; batch classifier loss: 0.634999; batch adversarial loss: 0.641333\n",
      "epoch 7; iter: 0; batch classifier loss: 0.615740; batch adversarial loss: 0.659762\n",
      "epoch 7; iter: 200; batch classifier loss: 0.567249; batch adversarial loss: 0.681919\n",
      "epoch 8; iter: 0; batch classifier loss: 0.641879; batch adversarial loss: 0.654500\n",
      "epoch 8; iter: 200; batch classifier loss: 0.625840; batch adversarial loss: 0.689002\n",
      "epoch 9; iter: 0; batch classifier loss: 0.555631; batch adversarial loss: 0.669410\n",
      "epoch 9; iter: 200; batch classifier loss: 0.538091; batch adversarial loss: 0.688443\n",
      "epoch 10; iter: 0; batch classifier loss: 0.614141; batch adversarial loss: 0.668928\n",
      "epoch 10; iter: 200; batch classifier loss: 0.599784; batch adversarial loss: 0.691171\n",
      "epoch 11; iter: 0; batch classifier loss: 0.622527; batch adversarial loss: 0.671851\n",
      "epoch 11; iter: 200; batch classifier loss: 0.593486; batch adversarial loss: 0.699221\n",
      "epoch 12; iter: 0; batch classifier loss: 0.649698; batch adversarial loss: 0.673278\n",
      "epoch 12; iter: 200; batch classifier loss: 0.595703; batch adversarial loss: 0.670382\n",
      "epoch 13; iter: 0; batch classifier loss: 0.600121; batch adversarial loss: 0.660751\n",
      "epoch 13; iter: 200; batch classifier loss: 0.582585; batch adversarial loss: 0.684740\n",
      "epoch 14; iter: 0; batch classifier loss: 0.596114; batch adversarial loss: 0.649676\n",
      "epoch 14; iter: 200; batch classifier loss: 0.635001; batch adversarial loss: 0.669762\n",
      "epoch 15; iter: 0; batch classifier loss: 0.616198; batch adversarial loss: 0.702849\n",
      "epoch 15; iter: 200; batch classifier loss: 0.681913; batch adversarial loss: 0.698984\n",
      "epoch 16; iter: 0; batch classifier loss: 0.662506; batch adversarial loss: 0.659549\n",
      "epoch 16; iter: 200; batch classifier loss: 0.646338; batch adversarial loss: 0.694174\n",
      "epoch 17; iter: 0; batch classifier loss: 0.562463; batch adversarial loss: 0.665132\n",
      "epoch 17; iter: 200; batch classifier loss: 0.600106; batch adversarial loss: 0.663267\n",
      "epoch 18; iter: 0; batch classifier loss: 0.701692; batch adversarial loss: 0.649872\n",
      "epoch 18; iter: 200; batch classifier loss: 0.685642; batch adversarial loss: 0.696146\n",
      "epoch 19; iter: 0; batch classifier loss: 0.553007; batch adversarial loss: 0.665268\n",
      "epoch 19; iter: 200; batch classifier loss: 0.601971; batch adversarial loss: 0.656770\n",
      "epoch 20; iter: 0; batch classifier loss: 0.617840; batch adversarial loss: 0.649937\n",
      "epoch 20; iter: 200; batch classifier loss: 0.591579; batch adversarial loss: 0.648464\n",
      "epoch 21; iter: 0; batch classifier loss: 0.581840; batch adversarial loss: 0.677260\n",
      "epoch 21; iter: 200; batch classifier loss: 0.608159; batch adversarial loss: 0.682946\n",
      "epoch 22; iter: 0; batch classifier loss: 0.631533; batch adversarial loss: 0.693452\n",
      "epoch 22; iter: 200; batch classifier loss: 0.608965; batch adversarial loss: 0.681216\n",
      "epoch 23; iter: 0; batch classifier loss: 0.612602; batch adversarial loss: 0.659291\n",
      "epoch 23; iter: 200; batch classifier loss: 0.581916; batch adversarial loss: 0.662645\n",
      "epoch 24; iter: 0; batch classifier loss: 0.648121; batch adversarial loss: 0.663144\n",
      "epoch 24; iter: 200; batch classifier loss: 0.596514; batch adversarial loss: 0.671487\n",
      "epoch 25; iter: 0; batch classifier loss: 0.638927; batch adversarial loss: 0.679188\n",
      "epoch 25; iter: 200; batch classifier loss: 0.660068; batch adversarial loss: 0.658227\n",
      "epoch 26; iter: 0; batch classifier loss: 0.606748; batch adversarial loss: 0.693478\n",
      "epoch 26; iter: 200; batch classifier loss: 0.605281; batch adversarial loss: 0.663255\n",
      "epoch 27; iter: 0; batch classifier loss: 0.681503; batch adversarial loss: 0.669448\n",
      "epoch 27; iter: 200; batch classifier loss: 0.608823; batch adversarial loss: 0.670715\n",
      "epoch 28; iter: 0; batch classifier loss: 0.554919; batch adversarial loss: 0.703254\n",
      "epoch 28; iter: 200; batch classifier loss: 0.612435; batch adversarial loss: 0.663252\n",
      "epoch 29; iter: 0; batch classifier loss: 0.642220; batch adversarial loss: 0.685659\n",
      "epoch 29; iter: 200; batch classifier loss: 0.591019; batch adversarial loss: 0.702990\n",
      "epoch 30; iter: 0; batch classifier loss: 0.571601; batch adversarial loss: 0.675408\n",
      "epoch 30; iter: 200; batch classifier loss: 0.595932; batch adversarial loss: 0.711757\n",
      "epoch 31; iter: 0; batch classifier loss: 0.618274; batch adversarial loss: 0.667362\n",
      "epoch 31; iter: 200; batch classifier loss: 0.585619; batch adversarial loss: 0.677214\n",
      "epoch 32; iter: 0; batch classifier loss: 0.650895; batch adversarial loss: 0.691000\n",
      "epoch 32; iter: 200; batch classifier loss: 0.558519; batch adversarial loss: 0.645318\n",
      "epoch 33; iter: 0; batch classifier loss: 0.617610; batch adversarial loss: 0.672639\n",
      "epoch 33; iter: 200; batch classifier loss: 0.647684; batch adversarial loss: 0.679428\n",
      "epoch 34; iter: 0; batch classifier loss: 0.720899; batch adversarial loss: 0.691520\n",
      "epoch 34; iter: 200; batch classifier loss: 0.601799; batch adversarial loss: 0.679080\n",
      "epoch 35; iter: 0; batch classifier loss: 0.615273; batch adversarial loss: 0.675626\n",
      "epoch 35; iter: 200; batch classifier loss: 0.615734; batch adversarial loss: 0.684264\n",
      "epoch 36; iter: 0; batch classifier loss: 0.645904; batch adversarial loss: 0.660439\n",
      "epoch 36; iter: 200; batch classifier loss: 0.651276; batch adversarial loss: 0.659352\n",
      "epoch 37; iter: 0; batch classifier loss: 0.628114; batch adversarial loss: 0.680352\n",
      "epoch 37; iter: 200; batch classifier loss: 0.644382; batch adversarial loss: 0.654494\n",
      "epoch 38; iter: 0; batch classifier loss: 0.668996; batch adversarial loss: 0.642228\n",
      "epoch 38; iter: 200; batch classifier loss: 0.574310; batch adversarial loss: 0.729116\n",
      "epoch 39; iter: 0; batch classifier loss: 0.614400; batch adversarial loss: 0.687219\n",
      "epoch 39; iter: 200; batch classifier loss: 0.633303; batch adversarial loss: 0.670768\n",
      "epoch 40; iter: 0; batch classifier loss: 0.627287; batch adversarial loss: 0.694456\n",
      "epoch 40; iter: 200; batch classifier loss: 0.667836; batch adversarial loss: 0.698237\n",
      "epoch 41; iter: 0; batch classifier loss: 0.667071; batch adversarial loss: 0.671709\n",
      "epoch 41; iter: 200; batch classifier loss: 0.624091; batch adversarial loss: 0.700039\n",
      "epoch 42; iter: 0; batch classifier loss: 0.583041; batch adversarial loss: 0.672696\n",
      "epoch 42; iter: 200; batch classifier loss: 0.570701; batch adversarial loss: 0.658804\n",
      "epoch 43; iter: 0; batch classifier loss: 0.583403; batch adversarial loss: 0.660669\n",
      "epoch 43; iter: 200; batch classifier loss: 0.638453; batch adversarial loss: 0.681937\n",
      "epoch 44; iter: 0; batch classifier loss: 0.610709; batch adversarial loss: 0.668539\n",
      "epoch 44; iter: 200; batch classifier loss: 0.616716; batch adversarial loss: 0.683551\n",
      "epoch 45; iter: 0; batch classifier loss: 0.591998; batch adversarial loss: 0.645680\n",
      "epoch 45; iter: 200; batch classifier loss: 0.587992; batch adversarial loss: 0.677289\n",
      "epoch 46; iter: 0; batch classifier loss: 0.566489; batch adversarial loss: 0.684543\n",
      "epoch 46; iter: 200; batch classifier loss: 0.608089; batch adversarial loss: 0.620337\n",
      "epoch 47; iter: 0; batch classifier loss: 0.662774; batch adversarial loss: 0.676271\n",
      "epoch 47; iter: 200; batch classifier loss: 0.585012; batch adversarial loss: 0.682555\n",
      "epoch 48; iter: 0; batch classifier loss: 0.552600; batch adversarial loss: 0.689100\n",
      "epoch 48; iter: 200; batch classifier loss: 0.597108; batch adversarial loss: 0.654849\n",
      "epoch 49; iter: 0; batch classifier loss: 0.621015; batch adversarial loss: 0.690165\n",
      "epoch 49; iter: 200; batch classifier loss: 0.642391; batch adversarial loss: 0.688992\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 200; batch classifier loss: 0.584256\n",
      "epoch 1; iter: 0; batch classifier loss: 0.624818\n",
      "epoch 1; iter: 200; batch classifier loss: 0.641800\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580934\n",
      "epoch 2; iter: 200; batch classifier loss: 0.645326\n",
      "epoch 3; iter: 0; batch classifier loss: 0.547598\n",
      "epoch 3; iter: 200; batch classifier loss: 0.589248\n",
      "epoch 4; iter: 0; batch classifier loss: 0.626272\n",
      "epoch 4; iter: 200; batch classifier loss: 0.605799\n",
      "epoch 5; iter: 0; batch classifier loss: 0.647423\n",
      "epoch 5; iter: 200; batch classifier loss: 0.590097\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577918\n",
      "epoch 6; iter: 200; batch classifier loss: 0.604583\n",
      "epoch 7; iter: 0; batch classifier loss: 0.634492\n",
      "epoch 7; iter: 200; batch classifier loss: 0.615799\n",
      "epoch 8; iter: 0; batch classifier loss: 0.570442\n",
      "epoch 8; iter: 200; batch classifier loss: 0.558002\n",
      "epoch 9; iter: 0; batch classifier loss: 0.595921\n",
      "epoch 9; iter: 200; batch classifier loss: 0.617922\n",
      "epoch 10; iter: 0; batch classifier loss: 0.617012\n",
      "epoch 10; iter: 200; batch classifier loss: 0.611275\n",
      "epoch 11; iter: 0; batch classifier loss: 0.597224\n",
      "epoch 11; iter: 200; batch classifier loss: 0.650852\n",
      "epoch 12; iter: 0; batch classifier loss: 0.618168\n",
      "epoch 12; iter: 200; batch classifier loss: 0.612646\n",
      "epoch 13; iter: 0; batch classifier loss: 0.638894\n",
      "epoch 13; iter: 200; batch classifier loss: 0.634634\n",
      "epoch 14; iter: 0; batch classifier loss: 0.601455\n",
      "epoch 14; iter: 200; batch classifier loss: 0.594310\n",
      "epoch 15; iter: 0; batch classifier loss: 0.605506\n",
      "epoch 15; iter: 200; batch classifier loss: 0.592624\n",
      "epoch 16; iter: 0; batch classifier loss: 0.583367\n",
      "epoch 16; iter: 200; batch classifier loss: 0.630759\n",
      "epoch 17; iter: 0; batch classifier loss: 0.627640\n",
      "epoch 17; iter: 200; batch classifier loss: 0.612889\n",
      "epoch 18; iter: 0; batch classifier loss: 0.667831\n",
      "epoch 18; iter: 200; batch classifier loss: 0.614502\n",
      "epoch 19; iter: 0; batch classifier loss: 0.672913\n",
      "epoch 19; iter: 200; batch classifier loss: 0.624554\n",
      "epoch 20; iter: 0; batch classifier loss: 0.550887\n",
      "epoch 20; iter: 200; batch classifier loss: 0.593679\n",
      "epoch 21; iter: 0; batch classifier loss: 0.617116\n",
      "epoch 21; iter: 200; batch classifier loss: 0.607979\n",
      "epoch 22; iter: 0; batch classifier loss: 0.565901\n",
      "epoch 22; iter: 200; batch classifier loss: 0.607055\n",
      "epoch 23; iter: 0; batch classifier loss: 0.592067\n",
      "epoch 23; iter: 200; batch classifier loss: 0.608400\n",
      "epoch 24; iter: 0; batch classifier loss: 0.613050\n",
      "epoch 24; iter: 200; batch classifier loss: 0.600664\n",
      "epoch 25; iter: 0; batch classifier loss: 0.562771\n",
      "epoch 25; iter: 200; batch classifier loss: 0.631389\n",
      "epoch 26; iter: 0; batch classifier loss: 0.600407\n",
      "epoch 26; iter: 200; batch classifier loss: 0.591593\n",
      "epoch 27; iter: 0; batch classifier loss: 0.588618\n",
      "epoch 27; iter: 200; batch classifier loss: 0.675088\n",
      "epoch 28; iter: 0; batch classifier loss: 0.552606\n",
      "epoch 28; iter: 200; batch classifier loss: 0.618481\n",
      "epoch 29; iter: 0; batch classifier loss: 0.573975\n",
      "epoch 29; iter: 200; batch classifier loss: 0.641355\n",
      "epoch 30; iter: 0; batch classifier loss: 0.598484\n",
      "epoch 30; iter: 200; batch classifier loss: 0.565551\n",
      "epoch 31; iter: 0; batch classifier loss: 0.597023\n",
      "epoch 31; iter: 200; batch classifier loss: 0.634440\n",
      "epoch 32; iter: 0; batch classifier loss: 0.571948\n",
      "epoch 32; iter: 200; batch classifier loss: 0.614010\n",
      "epoch 33; iter: 0; batch classifier loss: 0.647502\n",
      "epoch 33; iter: 200; batch classifier loss: 0.656105\n",
      "epoch 34; iter: 0; batch classifier loss: 0.642992\n",
      "epoch 34; iter: 200; batch classifier loss: 0.548810\n",
      "epoch 35; iter: 0; batch classifier loss: 0.651669\n",
      "epoch 35; iter: 200; batch classifier loss: 0.612340\n",
      "epoch 36; iter: 0; batch classifier loss: 0.616562\n",
      "epoch 36; iter: 200; batch classifier loss: 0.569456\n",
      "epoch 37; iter: 0; batch classifier loss: 0.629128\n",
      "epoch 37; iter: 200; batch classifier loss: 0.580457\n",
      "epoch 38; iter: 0; batch classifier loss: 0.651003\n",
      "epoch 38; iter: 200; batch classifier loss: 0.589994\n",
      "epoch 39; iter: 0; batch classifier loss: 0.580169\n",
      "epoch 39; iter: 200; batch classifier loss: 0.644596\n",
      "epoch 40; iter: 0; batch classifier loss: 0.659327\n",
      "epoch 40; iter: 200; batch classifier loss: 0.604468\n",
      "epoch 41; iter: 0; batch classifier loss: 0.660272\n",
      "epoch 41; iter: 200; batch classifier loss: 0.584040\n",
      "epoch 42; iter: 0; batch classifier loss: 0.628429\n",
      "epoch 42; iter: 200; batch classifier loss: 0.651213\n",
      "epoch 43; iter: 0; batch classifier loss: 0.586004\n",
      "epoch 43; iter: 200; batch classifier loss: 0.608418\n",
      "epoch 44; iter: 0; batch classifier loss: 0.609030\n",
      "epoch 44; iter: 200; batch classifier loss: 0.585839\n",
      "epoch 45; iter: 0; batch classifier loss: 0.636959\n",
      "epoch 45; iter: 200; batch classifier loss: 0.573791\n",
      "epoch 46; iter: 0; batch classifier loss: 0.582471\n",
      "epoch 46; iter: 200; batch classifier loss: 0.611196\n",
      "epoch 47; iter: 0; batch classifier loss: 0.654173\n",
      "epoch 47; iter: 200; batch classifier loss: 0.623006\n",
      "epoch 48; iter: 0; batch classifier loss: 0.665006\n",
      "epoch 48; iter: 200; batch classifier loss: 0.610465\n",
      "epoch 49; iter: 0; batch classifier loss: 0.588009\n",
      "epoch 49; iter: 200; batch classifier loss: 0.615894\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680288; batch adversarial loss: 0.709050\n",
      "epoch 1; iter: 0; batch classifier loss: 0.635234; batch adversarial loss: 0.720858\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580969; batch adversarial loss: 0.680905\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582049; batch adversarial loss: 0.669753\n",
      "epoch 4; iter: 0; batch classifier loss: 0.616160; batch adversarial loss: 0.678951\n",
      "epoch 5; iter: 0; batch classifier loss: 0.663295; batch adversarial loss: 0.688816\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592306; batch adversarial loss: 0.678078\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537594; batch adversarial loss: 0.669946\n",
      "epoch 8; iter: 0; batch classifier loss: 0.655019; batch adversarial loss: 0.684167\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586120; batch adversarial loss: 0.657554\n",
      "epoch 10; iter: 0; batch classifier loss: 0.588137; batch adversarial loss: 0.679758\n",
      "epoch 11; iter: 0; batch classifier loss: 0.615292; batch adversarial loss: 0.678649\n",
      "epoch 12; iter: 0; batch classifier loss: 0.594879; batch adversarial loss: 0.663359\n",
      "epoch 13; iter: 0; batch classifier loss: 0.570804; batch adversarial loss: 0.660058\n",
      "epoch 14; iter: 0; batch classifier loss: 0.576960; batch adversarial loss: 0.646356\n",
      "epoch 15; iter: 0; batch classifier loss: 0.597999; batch adversarial loss: 0.670624\n",
      "epoch 16; iter: 0; batch classifier loss: 0.624183; batch adversarial loss: 0.654724\n",
      "epoch 17; iter: 0; batch classifier loss: 0.666471; batch adversarial loss: 0.668887\n",
      "epoch 18; iter: 0; batch classifier loss: 0.587310; batch adversarial loss: 0.659480\n",
      "epoch 19; iter: 0; batch classifier loss: 0.594661; batch adversarial loss: 0.655326\n",
      "epoch 20; iter: 0; batch classifier loss: 0.592040; batch adversarial loss: 0.654180\n",
      "epoch 21; iter: 0; batch classifier loss: 0.635796; batch adversarial loss: 0.658532\n",
      "epoch 22; iter: 0; batch classifier loss: 0.678857; batch adversarial loss: 0.664182\n",
      "epoch 23; iter: 0; batch classifier loss: 0.605179; batch adversarial loss: 0.642398\n",
      "epoch 24; iter: 0; batch classifier loss: 0.615646; batch adversarial loss: 0.646446\n",
      "epoch 25; iter: 0; batch classifier loss: 0.608530; batch adversarial loss: 0.656138\n",
      "epoch 26; iter: 0; batch classifier loss: 0.566983; batch adversarial loss: 0.650869\n",
      "epoch 27; iter: 0; batch classifier loss: 0.610231; batch adversarial loss: 0.638968\n",
      "epoch 28; iter: 0; batch classifier loss: 0.573855; batch adversarial loss: 0.644118\n",
      "epoch 29; iter: 0; batch classifier loss: 0.565850; batch adversarial loss: 0.653319\n",
      "epoch 30; iter: 0; batch classifier loss: 0.583361; batch adversarial loss: 0.669341\n",
      "epoch 31; iter: 0; batch classifier loss: 0.625130; batch adversarial loss: 0.647348\n",
      "epoch 32; iter: 0; batch classifier loss: 0.598104; batch adversarial loss: 0.631369\n",
      "epoch 33; iter: 0; batch classifier loss: 0.615931; batch adversarial loss: 0.645010\n",
      "epoch 34; iter: 0; batch classifier loss: 0.677058; batch adversarial loss: 0.627994\n",
      "epoch 35; iter: 0; batch classifier loss: 0.623296; batch adversarial loss: 0.675381\n",
      "epoch 36; iter: 0; batch classifier loss: 0.583977; batch adversarial loss: 0.662863\n",
      "epoch 37; iter: 0; batch classifier loss: 0.612916; batch adversarial loss: 0.662181\n",
      "epoch 38; iter: 0; batch classifier loss: 0.625767; batch adversarial loss: 0.669972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 0; batch classifier loss: 0.591538; batch adversarial loss: 0.642660\n",
      "epoch 40; iter: 0; batch classifier loss: 0.640709; batch adversarial loss: 0.637462\n",
      "epoch 41; iter: 0; batch classifier loss: 0.635178; batch adversarial loss: 0.668328\n",
      "epoch 42; iter: 0; batch classifier loss: 0.597962; batch adversarial loss: 0.653744\n",
      "epoch 43; iter: 0; batch classifier loss: 0.615356; batch adversarial loss: 0.653748\n",
      "epoch 44; iter: 0; batch classifier loss: 0.630565; batch adversarial loss: 0.667916\n",
      "epoch 45; iter: 0; batch classifier loss: 0.659342; batch adversarial loss: 0.646543\n",
      "epoch 46; iter: 0; batch classifier loss: 0.560889; batch adversarial loss: 0.681121\n",
      "epoch 47; iter: 0; batch classifier loss: 0.619892; batch adversarial loss: 0.665266\n",
      "epoch 48; iter: 0; batch classifier loss: 0.557569; batch adversarial loss: 0.659531\n",
      "epoch 49; iter: 0; batch classifier loss: 0.555787; batch adversarial loss: 0.721008\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699493\n",
      "epoch 1; iter: 0; batch classifier loss: 0.624382\n",
      "epoch 2; iter: 0; batch classifier loss: 0.650899\n",
      "epoch 3; iter: 0; batch classifier loss: 0.627039\n",
      "epoch 4; iter: 0; batch classifier loss: 0.633471\n",
      "epoch 5; iter: 0; batch classifier loss: 0.616441\n",
      "epoch 6; iter: 0; batch classifier loss: 0.595719\n",
      "epoch 7; iter: 0; batch classifier loss: 0.606640\n",
      "epoch 8; iter: 0; batch classifier loss: 0.661939\n",
      "epoch 9; iter: 0; batch classifier loss: 0.604640\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578406\n",
      "epoch 11; iter: 0; batch classifier loss: 0.583129\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555697\n",
      "epoch 13; iter: 0; batch classifier loss: 0.563958\n",
      "epoch 14; iter: 0; batch classifier loss: 0.671927\n",
      "epoch 15; iter: 0; batch classifier loss: 0.615433\n",
      "epoch 16; iter: 0; batch classifier loss: 0.613987\n",
      "epoch 17; iter: 0; batch classifier loss: 0.611084\n",
      "epoch 18; iter: 0; batch classifier loss: 0.687036\n",
      "epoch 19; iter: 0; batch classifier loss: 0.656804\n",
      "epoch 20; iter: 0; batch classifier loss: 0.615076\n",
      "epoch 21; iter: 0; batch classifier loss: 0.615016\n",
      "epoch 22; iter: 0; batch classifier loss: 0.652944\n",
      "epoch 23; iter: 0; batch classifier loss: 0.620169\n",
      "epoch 24; iter: 0; batch classifier loss: 0.598073\n",
      "epoch 25; iter: 0; batch classifier loss: 0.627803\n",
      "epoch 26; iter: 0; batch classifier loss: 0.535313\n",
      "epoch 27; iter: 0; batch classifier loss: 0.597277\n",
      "epoch 28; iter: 0; batch classifier loss: 0.556678\n",
      "epoch 29; iter: 0; batch classifier loss: 0.579735\n",
      "epoch 30; iter: 0; batch classifier loss: 0.616163\n",
      "epoch 31; iter: 0; batch classifier loss: 0.681455\n",
      "epoch 32; iter: 0; batch classifier loss: 0.602797\n",
      "epoch 33; iter: 0; batch classifier loss: 0.639186\n",
      "epoch 34; iter: 0; batch classifier loss: 0.615715\n",
      "epoch 35; iter: 0; batch classifier loss: 0.575231\n",
      "epoch 36; iter: 0; batch classifier loss: 0.633938\n",
      "epoch 37; iter: 0; batch classifier loss: 0.593926\n",
      "epoch 38; iter: 0; batch classifier loss: 0.641595\n",
      "epoch 39; iter: 0; batch classifier loss: 0.559090\n",
      "epoch 40; iter: 0; batch classifier loss: 0.600306\n",
      "epoch 41; iter: 0; batch classifier loss: 0.574432\n",
      "epoch 42; iter: 0; batch classifier loss: 0.551128\n",
      "epoch 43; iter: 0; batch classifier loss: 0.616064\n",
      "epoch 44; iter: 0; batch classifier loss: 0.557348\n",
      "epoch 45; iter: 0; batch classifier loss: 0.685162\n",
      "epoch 46; iter: 0; batch classifier loss: 0.676571\n",
      "epoch 47; iter: 0; batch classifier loss: 0.612640\n",
      "epoch 48; iter: 0; batch classifier loss: 0.627208\n",
      "epoch 49; iter: 0; batch classifier loss: 0.556436\n",
      "run = 8\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696160; batch adversarial loss: 0.681992\n",
      "epoch 0; iter: 200; batch classifier loss: 0.600741; batch adversarial loss: 0.676893\n",
      "epoch 1; iter: 0; batch classifier loss: 0.624968; batch adversarial loss: 0.688945\n",
      "epoch 1; iter: 200; batch classifier loss: 0.614411; batch adversarial loss: 0.669567\n",
      "epoch 2; iter: 0; batch classifier loss: 0.610473; batch adversarial loss: 0.684095\n",
      "epoch 2; iter: 200; batch classifier loss: 0.606856; batch adversarial loss: 0.689697\n",
      "epoch 3; iter: 0; batch classifier loss: 0.586355; batch adversarial loss: 0.706952\n",
      "epoch 3; iter: 200; batch classifier loss: 0.610727; batch adversarial loss: 0.671716\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607882; batch adversarial loss: 0.699830\n",
      "epoch 4; iter: 200; batch classifier loss: 0.684035; batch adversarial loss: 0.634490\n",
      "epoch 5; iter: 0; batch classifier loss: 0.568332; batch adversarial loss: 0.638800\n",
      "epoch 5; iter: 200; batch classifier loss: 0.608060; batch adversarial loss: 0.687452\n",
      "epoch 6; iter: 0; batch classifier loss: 0.612613; batch adversarial loss: 0.657434\n",
      "epoch 6; iter: 200; batch classifier loss: 0.599637; batch adversarial loss: 0.690218\n",
      "epoch 7; iter: 0; batch classifier loss: 0.598671; batch adversarial loss: 0.686759\n",
      "epoch 7; iter: 200; batch classifier loss: 0.589918; batch adversarial loss: 0.680804\n",
      "epoch 8; iter: 0; batch classifier loss: 0.650003; batch adversarial loss: 0.682438\n",
      "epoch 8; iter: 200; batch classifier loss: 0.663107; batch adversarial loss: 0.651722\n",
      "epoch 9; iter: 0; batch classifier loss: 0.645936; batch adversarial loss: 0.683077\n",
      "epoch 9; iter: 200; batch classifier loss: 0.640612; batch adversarial loss: 0.679298\n",
      "epoch 10; iter: 0; batch classifier loss: 0.621302; batch adversarial loss: 0.658637\n",
      "epoch 10; iter: 200; batch classifier loss: 0.674887; batch adversarial loss: 0.696656\n",
      "epoch 11; iter: 0; batch classifier loss: 0.641541; batch adversarial loss: 0.674817\n",
      "epoch 11; iter: 200; batch classifier loss: 0.561766; batch adversarial loss: 0.672343\n",
      "epoch 12; iter: 0; batch classifier loss: 0.599271; batch adversarial loss: 0.702842\n",
      "epoch 12; iter: 200; batch classifier loss: 0.621399; batch adversarial loss: 0.669677\n",
      "epoch 13; iter: 0; batch classifier loss: 0.672453; batch adversarial loss: 0.693766\n",
      "epoch 13; iter: 200; batch classifier loss: 0.588739; batch adversarial loss: 0.657676\n",
      "epoch 14; iter: 0; batch classifier loss: 0.662998; batch adversarial loss: 0.704550\n",
      "epoch 14; iter: 200; batch classifier loss: 0.639021; batch adversarial loss: 0.675606\n",
      "epoch 15; iter: 0; batch classifier loss: 0.605136; batch adversarial loss: 0.696236\n",
      "epoch 15; iter: 200; batch classifier loss: 0.651631; batch adversarial loss: 0.679317\n",
      "epoch 16; iter: 0; batch classifier loss: 0.687587; batch adversarial loss: 0.701855\n",
      "epoch 16; iter: 200; batch classifier loss: 0.647897; batch adversarial loss: 0.664891\n",
      "epoch 17; iter: 0; batch classifier loss: 0.666940; batch adversarial loss: 0.696221\n",
      "epoch 17; iter: 200; batch classifier loss: 0.563374; batch adversarial loss: 0.682710\n",
      "epoch 18; iter: 0; batch classifier loss: 0.585195; batch adversarial loss: 0.647665\n",
      "epoch 18; iter: 200; batch classifier loss: 0.597768; batch adversarial loss: 0.694129\n",
      "epoch 19; iter: 0; batch classifier loss: 0.597049; batch adversarial loss: 0.699367\n",
      "epoch 19; iter: 200; batch classifier loss: 0.649670; batch adversarial loss: 0.671586\n",
      "epoch 20; iter: 0; batch classifier loss: 0.618112; batch adversarial loss: 0.681470\n",
      "epoch 20; iter: 200; batch classifier loss: 0.635941; batch adversarial loss: 0.651568\n",
      "epoch 21; iter: 0; batch classifier loss: 0.617044; batch adversarial loss: 0.674257\n",
      "epoch 21; iter: 200; batch classifier loss: 0.606672; batch adversarial loss: 0.710663\n",
      "epoch 22; iter: 0; batch classifier loss: 0.661581; batch adversarial loss: 0.676702\n",
      "epoch 22; iter: 200; batch classifier loss: 0.640526; batch adversarial loss: 0.655982\n",
      "epoch 23; iter: 0; batch classifier loss: 0.581459; batch adversarial loss: 0.692329\n",
      "epoch 23; iter: 200; batch classifier loss: 0.604476; batch adversarial loss: 0.672132\n",
      "epoch 24; iter: 0; batch classifier loss: 0.649966; batch adversarial loss: 0.674254\n",
      "epoch 24; iter: 200; batch classifier loss: 0.571650; batch adversarial loss: 0.672654\n",
      "epoch 25; iter: 0; batch classifier loss: 0.633881; batch adversarial loss: 0.665569\n",
      "epoch 25; iter: 200; batch classifier loss: 0.651419; batch adversarial loss: 0.658917\n",
      "epoch 26; iter: 0; batch classifier loss: 0.618697; batch adversarial loss: 0.682652\n",
      "epoch 26; iter: 200; batch classifier loss: 0.574050; batch adversarial loss: 0.684868\n",
      "epoch 27; iter: 0; batch classifier loss: 0.606687; batch adversarial loss: 0.664553\n",
      "epoch 27; iter: 200; batch classifier loss: 0.630257; batch adversarial loss: 0.677049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.661437; batch adversarial loss: 0.685362\n",
      "epoch 28; iter: 200; batch classifier loss: 0.612148; batch adversarial loss: 0.675207\n",
      "epoch 29; iter: 0; batch classifier loss: 0.629320; batch adversarial loss: 0.691490\n",
      "epoch 29; iter: 200; batch classifier loss: 0.633493; batch adversarial loss: 0.674757\n",
      "epoch 30; iter: 0; batch classifier loss: 0.640307; batch adversarial loss: 0.679728\n",
      "epoch 30; iter: 200; batch classifier loss: 0.609725; batch adversarial loss: 0.710556\n",
      "epoch 31; iter: 0; batch classifier loss: 0.618418; batch adversarial loss: 0.695765\n",
      "epoch 31; iter: 200; batch classifier loss: 0.578017; batch adversarial loss: 0.694857\n",
      "epoch 32; iter: 0; batch classifier loss: 0.640780; batch adversarial loss: 0.669200\n",
      "epoch 32; iter: 200; batch classifier loss: 0.610790; batch adversarial loss: 0.672049\n",
      "epoch 33; iter: 0; batch classifier loss: 0.604458; batch adversarial loss: 0.677306\n",
      "epoch 33; iter: 200; batch classifier loss: 0.647421; batch adversarial loss: 0.683570\n",
      "epoch 34; iter: 0; batch classifier loss: 0.605695; batch adversarial loss: 0.667202\n",
      "epoch 34; iter: 200; batch classifier loss: 0.571032; batch adversarial loss: 0.703532\n",
      "epoch 35; iter: 0; batch classifier loss: 0.585094; batch adversarial loss: 0.681143\n",
      "epoch 35; iter: 200; batch classifier loss: 0.649131; batch adversarial loss: 0.673024\n",
      "epoch 36; iter: 0; batch classifier loss: 0.567758; batch adversarial loss: 0.698847\n",
      "epoch 36; iter: 200; batch classifier loss: 0.646605; batch adversarial loss: 0.665733\n",
      "epoch 37; iter: 0; batch classifier loss: 0.616297; batch adversarial loss: 0.672039\n",
      "epoch 37; iter: 200; batch classifier loss: 0.623732; batch adversarial loss: 0.662116\n",
      "epoch 38; iter: 0; batch classifier loss: 0.619119; batch adversarial loss: 0.683871\n",
      "epoch 38; iter: 200; batch classifier loss: 0.613283; batch adversarial loss: 0.675444\n",
      "epoch 39; iter: 0; batch classifier loss: 0.642225; batch adversarial loss: 0.680425\n",
      "epoch 39; iter: 200; batch classifier loss: 0.643656; batch adversarial loss: 0.680026\n",
      "epoch 40; iter: 0; batch classifier loss: 0.576637; batch adversarial loss: 0.673589\n",
      "epoch 40; iter: 200; batch classifier loss: 0.635519; batch adversarial loss: 0.676011\n",
      "epoch 41; iter: 0; batch classifier loss: 0.635040; batch adversarial loss: 0.662896\n",
      "epoch 41; iter: 200; batch classifier loss: 0.614544; batch adversarial loss: 0.627032\n",
      "epoch 42; iter: 0; batch classifier loss: 0.646432; batch adversarial loss: 0.667371\n",
      "epoch 42; iter: 200; batch classifier loss: 0.615217; batch adversarial loss: 0.695748\n",
      "epoch 43; iter: 0; batch classifier loss: 0.611883; batch adversarial loss: 0.671990\n",
      "epoch 43; iter: 200; batch classifier loss: 0.678960; batch adversarial loss: 0.669469\n",
      "epoch 44; iter: 0; batch classifier loss: 0.625897; batch adversarial loss: 0.683020\n",
      "epoch 44; iter: 200; batch classifier loss: 0.650226; batch adversarial loss: 0.686183\n",
      "epoch 45; iter: 0; batch classifier loss: 0.652613; batch adversarial loss: 0.682395\n",
      "epoch 45; iter: 200; batch classifier loss: 0.598582; batch adversarial loss: 0.662581\n",
      "epoch 46; iter: 0; batch classifier loss: 0.609171; batch adversarial loss: 0.695886\n",
      "epoch 46; iter: 200; batch classifier loss: 0.594309; batch adversarial loss: 0.674037\n",
      "epoch 47; iter: 0; batch classifier loss: 0.614881; batch adversarial loss: 0.697475\n",
      "epoch 47; iter: 200; batch classifier loss: 0.571823; batch adversarial loss: 0.679244\n",
      "epoch 48; iter: 0; batch classifier loss: 0.629898; batch adversarial loss: 0.646511\n",
      "epoch 48; iter: 200; batch classifier loss: 0.635686; batch adversarial loss: 0.682652\n",
      "epoch 49; iter: 0; batch classifier loss: 0.608425; batch adversarial loss: 0.677707\n",
      "epoch 49; iter: 200; batch classifier loss: 0.642923; batch adversarial loss: 0.699428\n",
      "epoch 0; iter: 0; batch classifier loss: 0.679977\n",
      "epoch 0; iter: 200; batch classifier loss: 0.632920\n",
      "epoch 1; iter: 0; batch classifier loss: 0.611586\n",
      "epoch 1; iter: 200; batch classifier loss: 0.689189\n",
      "epoch 2; iter: 0; batch classifier loss: 0.662580\n",
      "epoch 2; iter: 200; batch classifier loss: 0.624824\n",
      "epoch 3; iter: 0; batch classifier loss: 0.583955\n",
      "epoch 3; iter: 200; batch classifier loss: 0.662278\n",
      "epoch 4; iter: 0; batch classifier loss: 0.606670\n",
      "epoch 4; iter: 200; batch classifier loss: 0.594478\n",
      "epoch 5; iter: 0; batch classifier loss: 0.600781\n",
      "epoch 5; iter: 200; batch classifier loss: 0.595194\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562873\n",
      "epoch 6; iter: 200; batch classifier loss: 0.605476\n",
      "epoch 7; iter: 0; batch classifier loss: 0.655349\n",
      "epoch 7; iter: 200; batch classifier loss: 0.647368\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573065\n",
      "epoch 8; iter: 200; batch classifier loss: 0.573249\n",
      "epoch 9; iter: 0; batch classifier loss: 0.574849\n",
      "epoch 9; iter: 200; batch classifier loss: 0.635992\n",
      "epoch 10; iter: 0; batch classifier loss: 0.651973\n",
      "epoch 10; iter: 200; batch classifier loss: 0.608091\n",
      "epoch 11; iter: 0; batch classifier loss: 0.649164\n",
      "epoch 11; iter: 200; batch classifier loss: 0.595049\n",
      "epoch 12; iter: 0; batch classifier loss: 0.644152\n",
      "epoch 12; iter: 200; batch classifier loss: 0.622964\n",
      "epoch 13; iter: 0; batch classifier loss: 0.598409\n",
      "epoch 13; iter: 200; batch classifier loss: 0.625591\n",
      "epoch 14; iter: 0; batch classifier loss: 0.593963\n",
      "epoch 14; iter: 200; batch classifier loss: 0.592494\n",
      "epoch 15; iter: 0; batch classifier loss: 0.530711\n",
      "epoch 15; iter: 200; batch classifier loss: 0.666977\n",
      "epoch 16; iter: 0; batch classifier loss: 0.672682\n",
      "epoch 16; iter: 200; batch classifier loss: 0.640916\n",
      "epoch 17; iter: 0; batch classifier loss: 0.623313\n",
      "epoch 17; iter: 200; batch classifier loss: 0.658201\n",
      "epoch 18; iter: 0; batch classifier loss: 0.589797\n",
      "epoch 18; iter: 200; batch classifier loss: 0.608271\n",
      "epoch 19; iter: 0; batch classifier loss: 0.658018\n",
      "epoch 19; iter: 200; batch classifier loss: 0.666961\n",
      "epoch 20; iter: 0; batch classifier loss: 0.598709\n",
      "epoch 20; iter: 200; batch classifier loss: 0.643413\n",
      "epoch 21; iter: 0; batch classifier loss: 0.601260\n",
      "epoch 21; iter: 200; batch classifier loss: 0.638509\n",
      "epoch 22; iter: 0; batch classifier loss: 0.626850\n",
      "epoch 22; iter: 200; batch classifier loss: 0.659110\n",
      "epoch 23; iter: 0; batch classifier loss: 0.639869\n",
      "epoch 23; iter: 200; batch classifier loss: 0.635613\n",
      "epoch 24; iter: 0; batch classifier loss: 0.630091\n",
      "epoch 24; iter: 200; batch classifier loss: 0.574146\n",
      "epoch 25; iter: 0; batch classifier loss: 0.633648\n",
      "epoch 25; iter: 200; batch classifier loss: 0.576720\n",
      "epoch 26; iter: 0; batch classifier loss: 0.651240\n",
      "epoch 26; iter: 200; batch classifier loss: 0.636300\n",
      "epoch 27; iter: 0; batch classifier loss: 0.609081\n",
      "epoch 27; iter: 200; batch classifier loss: 0.627296\n",
      "epoch 28; iter: 0; batch classifier loss: 0.692802\n",
      "epoch 28; iter: 200; batch classifier loss: 0.597229\n",
      "epoch 29; iter: 0; batch classifier loss: 0.568814\n",
      "epoch 29; iter: 200; batch classifier loss: 0.621687\n",
      "epoch 30; iter: 0; batch classifier loss: 0.591030\n",
      "epoch 30; iter: 200; batch classifier loss: 0.625492\n",
      "epoch 31; iter: 0; batch classifier loss: 0.628150\n",
      "epoch 31; iter: 200; batch classifier loss: 0.606047\n",
      "epoch 32; iter: 0; batch classifier loss: 0.668240\n",
      "epoch 32; iter: 200; batch classifier loss: 0.641336\n",
      "epoch 33; iter: 0; batch classifier loss: 0.586142\n",
      "epoch 33; iter: 200; batch classifier loss: 0.601868\n",
      "epoch 34; iter: 0; batch classifier loss: 0.671781\n",
      "epoch 34; iter: 200; batch classifier loss: 0.611221\n",
      "epoch 35; iter: 0; batch classifier loss: 0.627731\n",
      "epoch 35; iter: 200; batch classifier loss: 0.619353\n",
      "epoch 36; iter: 0; batch classifier loss: 0.580179\n",
      "epoch 36; iter: 200; batch classifier loss: 0.621136\n",
      "epoch 37; iter: 0; batch classifier loss: 0.647016\n",
      "epoch 37; iter: 200; batch classifier loss: 0.621945\n",
      "epoch 38; iter: 0; batch classifier loss: 0.631244\n",
      "epoch 38; iter: 200; batch classifier loss: 0.607857\n",
      "epoch 39; iter: 0; batch classifier loss: 0.646141\n",
      "epoch 39; iter: 200; batch classifier loss: 0.567952\n",
      "epoch 40; iter: 0; batch classifier loss: 0.663067\n",
      "epoch 40; iter: 200; batch classifier loss: 0.698998\n",
      "epoch 41; iter: 0; batch classifier loss: 0.629918\n",
      "epoch 41; iter: 200; batch classifier loss: 0.564119\n",
      "epoch 42; iter: 0; batch classifier loss: 0.605230\n",
      "epoch 42; iter: 200; batch classifier loss: 0.656268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43; iter: 0; batch classifier loss: 0.681322\n",
      "epoch 43; iter: 200; batch classifier loss: 0.609710\n",
      "epoch 44; iter: 0; batch classifier loss: 0.608249\n",
      "epoch 44; iter: 200; batch classifier loss: 0.713804\n",
      "epoch 45; iter: 0; batch classifier loss: 0.597390\n",
      "epoch 45; iter: 200; batch classifier loss: 0.605264\n",
      "epoch 46; iter: 0; batch classifier loss: 0.656860\n",
      "epoch 46; iter: 200; batch classifier loss: 0.604975\n",
      "epoch 47; iter: 0; batch classifier loss: 0.561422\n",
      "epoch 47; iter: 200; batch classifier loss: 0.664736\n",
      "epoch 48; iter: 0; batch classifier loss: 0.583999\n",
      "epoch 48; iter: 200; batch classifier loss: 0.627689\n",
      "epoch 49; iter: 0; batch classifier loss: 0.594550\n",
      "epoch 49; iter: 200; batch classifier loss: 0.580602\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722394; batch adversarial loss: 0.669355\n",
      "epoch 1; iter: 0; batch classifier loss: 0.638165; batch adversarial loss: 0.687715\n",
      "epoch 2; iter: 0; batch classifier loss: 0.652364; batch adversarial loss: 0.655097\n",
      "epoch 3; iter: 0; batch classifier loss: 0.592581; batch adversarial loss: 0.676588\n",
      "epoch 4; iter: 0; batch classifier loss: 0.551144; batch adversarial loss: 0.673136\n",
      "epoch 5; iter: 0; batch classifier loss: 0.615042; batch adversarial loss: 0.686386\n",
      "epoch 6; iter: 0; batch classifier loss: 0.730741; batch adversarial loss: 0.699252\n",
      "epoch 7; iter: 0; batch classifier loss: 0.596225; batch adversarial loss: 0.680035\n",
      "epoch 8; iter: 0; batch classifier loss: 0.652160; batch adversarial loss: 0.724051\n",
      "epoch 9; iter: 0; batch classifier loss: 0.616738; batch adversarial loss: 0.665982\n",
      "epoch 10; iter: 0; batch classifier loss: 0.583073; batch adversarial loss: 0.646505\n",
      "epoch 11; iter: 0; batch classifier loss: 0.628636; batch adversarial loss: 0.658869\n",
      "epoch 12; iter: 0; batch classifier loss: 0.599470; batch adversarial loss: 0.656163\n",
      "epoch 13; iter: 0; batch classifier loss: 0.622915; batch adversarial loss: 0.658238\n",
      "epoch 14; iter: 0; batch classifier loss: 0.559761; batch adversarial loss: 0.676300\n",
      "epoch 15; iter: 0; batch classifier loss: 0.627211; batch adversarial loss: 0.683826\n",
      "epoch 16; iter: 0; batch classifier loss: 0.668109; batch adversarial loss: 0.656440\n",
      "epoch 17; iter: 0; batch classifier loss: 0.609990; batch adversarial loss: 0.670161\n",
      "epoch 18; iter: 0; batch classifier loss: 0.643959; batch adversarial loss: 0.661589\n",
      "epoch 19; iter: 0; batch classifier loss: 0.645815; batch adversarial loss: 0.656279\n",
      "epoch 20; iter: 0; batch classifier loss: 0.615345; batch adversarial loss: 0.690219\n",
      "epoch 21; iter: 0; batch classifier loss: 0.605382; batch adversarial loss: 0.640619\n",
      "epoch 22; iter: 0; batch classifier loss: 0.586942; batch adversarial loss: 0.660880\n",
      "epoch 23; iter: 0; batch classifier loss: 0.589158; batch adversarial loss: 0.657762\n",
      "epoch 24; iter: 0; batch classifier loss: 0.594072; batch adversarial loss: 0.645704\n",
      "epoch 25; iter: 0; batch classifier loss: 0.619802; batch adversarial loss: 0.673792\n",
      "epoch 26; iter: 0; batch classifier loss: 0.685200; batch adversarial loss: 0.667747\n",
      "epoch 27; iter: 0; batch classifier loss: 0.570120; batch adversarial loss: 0.641231\n",
      "epoch 28; iter: 0; batch classifier loss: 0.586756; batch adversarial loss: 0.649444\n",
      "epoch 29; iter: 0; batch classifier loss: 0.621256; batch adversarial loss: 0.646444\n",
      "epoch 30; iter: 0; batch classifier loss: 0.626318; batch adversarial loss: 0.661370\n",
      "epoch 31; iter: 0; batch classifier loss: 0.658595; batch adversarial loss: 0.627185\n",
      "epoch 32; iter: 0; batch classifier loss: 0.585027; batch adversarial loss: 0.631574\n",
      "epoch 33; iter: 0; batch classifier loss: 0.614156; batch adversarial loss: 0.621041\n",
      "epoch 34; iter: 0; batch classifier loss: 0.601567; batch adversarial loss: 0.629184\n",
      "epoch 35; iter: 0; batch classifier loss: 0.598284; batch adversarial loss: 0.641350\n",
      "epoch 36; iter: 0; batch classifier loss: 0.602768; batch adversarial loss: 0.664332\n",
      "epoch 37; iter: 0; batch classifier loss: 0.634414; batch adversarial loss: 0.642925\n",
      "epoch 38; iter: 0; batch classifier loss: 0.612317; batch adversarial loss: 0.670391\n",
      "epoch 39; iter: 0; batch classifier loss: 0.570590; batch adversarial loss: 0.659955\n",
      "epoch 40; iter: 0; batch classifier loss: 0.644662; batch adversarial loss: 0.621659\n",
      "epoch 41; iter: 0; batch classifier loss: 0.526890; batch adversarial loss: 0.642010\n",
      "epoch 42; iter: 0; batch classifier loss: 0.564149; batch adversarial loss: 0.636031\n",
      "epoch 43; iter: 0; batch classifier loss: 0.540033; batch adversarial loss: 0.622616\n",
      "epoch 44; iter: 0; batch classifier loss: 0.561267; batch adversarial loss: 0.628523\n",
      "epoch 45; iter: 0; batch classifier loss: 0.611670; batch adversarial loss: 0.649886\n",
      "epoch 46; iter: 0; batch classifier loss: 0.609910; batch adversarial loss: 0.677436\n",
      "epoch 47; iter: 0; batch classifier loss: 0.575629; batch adversarial loss: 0.654231\n",
      "epoch 48; iter: 0; batch classifier loss: 0.625159; batch adversarial loss: 0.636913\n",
      "epoch 49; iter: 0; batch classifier loss: 0.655136; batch adversarial loss: 0.675201\n",
      "epoch 0; iter: 0; batch classifier loss: 0.723686\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628132\n",
      "epoch 2; iter: 0; batch classifier loss: 0.634518\n",
      "epoch 3; iter: 0; batch classifier loss: 0.607506\n",
      "epoch 4; iter: 0; batch classifier loss: 0.621916\n",
      "epoch 5; iter: 0; batch classifier loss: 0.611051\n",
      "epoch 6; iter: 0; batch classifier loss: 0.626454\n",
      "epoch 7; iter: 0; batch classifier loss: 0.591292\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602656\n",
      "epoch 9; iter: 0; batch classifier loss: 0.604653\n",
      "epoch 10; iter: 0; batch classifier loss: 0.682476\n",
      "epoch 11; iter: 0; batch classifier loss: 0.606157\n",
      "epoch 12; iter: 0; batch classifier loss: 0.624009\n",
      "epoch 13; iter: 0; batch classifier loss: 0.601172\n",
      "epoch 14; iter: 0; batch classifier loss: 0.586986\n",
      "epoch 15; iter: 0; batch classifier loss: 0.633858\n",
      "epoch 16; iter: 0; batch classifier loss: 0.574941\n",
      "epoch 17; iter: 0; batch classifier loss: 0.613959\n",
      "epoch 18; iter: 0; batch classifier loss: 0.580008\n",
      "epoch 19; iter: 0; batch classifier loss: 0.570678\n",
      "epoch 20; iter: 0; batch classifier loss: 0.622550\n",
      "epoch 21; iter: 0; batch classifier loss: 0.614345\n",
      "epoch 22; iter: 0; batch classifier loss: 0.635956\n",
      "epoch 23; iter: 0; batch classifier loss: 0.645253\n",
      "epoch 24; iter: 0; batch classifier loss: 0.633533\n",
      "epoch 25; iter: 0; batch classifier loss: 0.657642\n",
      "epoch 26; iter: 0; batch classifier loss: 0.566519\n",
      "epoch 27; iter: 0; batch classifier loss: 0.699065\n",
      "epoch 28; iter: 0; batch classifier loss: 0.597570\n",
      "epoch 29; iter: 0; batch classifier loss: 0.580828\n",
      "epoch 30; iter: 0; batch classifier loss: 0.603389\n",
      "epoch 31; iter: 0; batch classifier loss: 0.624906\n",
      "epoch 32; iter: 0; batch classifier loss: 0.634158\n",
      "epoch 33; iter: 0; batch classifier loss: 0.588604\n",
      "epoch 34; iter: 0; batch classifier loss: 0.530201\n",
      "epoch 35; iter: 0; batch classifier loss: 0.669342\n",
      "epoch 36; iter: 0; batch classifier loss: 0.553445\n",
      "epoch 37; iter: 0; batch classifier loss: 0.635760\n",
      "epoch 38; iter: 0; batch classifier loss: 0.617575\n",
      "epoch 39; iter: 0; batch classifier loss: 0.617251\n",
      "epoch 40; iter: 0; batch classifier loss: 0.624702\n",
      "epoch 41; iter: 0; batch classifier loss: 0.569546\n",
      "epoch 42; iter: 0; batch classifier loss: 0.635954\n",
      "epoch 43; iter: 0; batch classifier loss: 0.573996\n",
      "epoch 44; iter: 0; batch classifier loss: 0.655316\n",
      "epoch 45; iter: 0; batch classifier loss: 0.658688\n",
      "epoch 46; iter: 0; batch classifier loss: 0.656927\n",
      "epoch 47; iter: 0; batch classifier loss: 0.668529\n",
      "epoch 48; iter: 0; batch classifier loss: 0.580580\n",
      "epoch 49; iter: 0; batch classifier loss: 0.546799\n",
      "run = 9\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720972; batch adversarial loss: 0.746246\n",
      "epoch 0; iter: 200; batch classifier loss: 0.596420; batch adversarial loss: 0.741091\n",
      "epoch 1; iter: 0; batch classifier loss: 0.642652; batch adversarial loss: 0.728076\n",
      "epoch 1; iter: 200; batch classifier loss: 0.641388; batch adversarial loss: 0.716817\n",
      "epoch 2; iter: 0; batch classifier loss: 0.582014; batch adversarial loss: 0.675812\n",
      "epoch 2; iter: 200; batch classifier loss: 0.639043; batch adversarial loss: 0.684787\n",
      "epoch 3; iter: 0; batch classifier loss: 0.659165; batch adversarial loss: 0.685837\n",
      "epoch 3; iter: 200; batch classifier loss: 0.622975; batch adversarial loss: 0.666459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.631836; batch adversarial loss: 0.667754\n",
      "epoch 4; iter: 200; batch classifier loss: 0.674842; batch adversarial loss: 0.693835\n",
      "epoch 5; iter: 0; batch classifier loss: 0.657547; batch adversarial loss: 0.671234\n",
      "epoch 5; iter: 200; batch classifier loss: 0.667484; batch adversarial loss: 0.655314\n",
      "epoch 6; iter: 0; batch classifier loss: 0.645303; batch adversarial loss: 0.689906\n",
      "epoch 6; iter: 200; batch classifier loss: 0.618467; batch adversarial loss: 0.678802\n",
      "epoch 7; iter: 0; batch classifier loss: 0.696188; batch adversarial loss: 0.696612\n",
      "epoch 7; iter: 200; batch classifier loss: 0.597943; batch adversarial loss: 0.658388\n",
      "epoch 8; iter: 0; batch classifier loss: 0.710157; batch adversarial loss: 0.651732\n",
      "epoch 8; iter: 200; batch classifier loss: 0.585198; batch adversarial loss: 0.671327\n",
      "epoch 9; iter: 0; batch classifier loss: 0.674529; batch adversarial loss: 0.646420\n",
      "epoch 9; iter: 200; batch classifier loss: 0.598226; batch adversarial loss: 0.670035\n",
      "epoch 10; iter: 0; batch classifier loss: 0.635177; batch adversarial loss: 0.676899\n",
      "epoch 10; iter: 200; batch classifier loss: 0.574118; batch adversarial loss: 0.685002\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539082; batch adversarial loss: 0.688927\n",
      "epoch 11; iter: 200; batch classifier loss: 0.690849; batch adversarial loss: 0.667464\n",
      "epoch 12; iter: 0; batch classifier loss: 0.586618; batch adversarial loss: 0.689152\n",
      "epoch 12; iter: 200; batch classifier loss: 0.587124; batch adversarial loss: 0.694851\n",
      "epoch 13; iter: 0; batch classifier loss: 0.583483; batch adversarial loss: 0.653475\n",
      "epoch 13; iter: 200; batch classifier loss: 0.624125; batch adversarial loss: 0.664164\n",
      "epoch 14; iter: 0; batch classifier loss: 0.632798; batch adversarial loss: 0.651344\n",
      "epoch 14; iter: 200; batch classifier loss: 0.600525; batch adversarial loss: 0.681460\n",
      "epoch 15; iter: 0; batch classifier loss: 0.617180; batch adversarial loss: 0.679251\n",
      "epoch 15; iter: 200; batch classifier loss: 0.614887; batch adversarial loss: 0.666340\n",
      "epoch 16; iter: 0; batch classifier loss: 0.600303; batch adversarial loss: 0.643403\n",
      "epoch 16; iter: 200; batch classifier loss: 0.675541; batch adversarial loss: 0.681742\n",
      "epoch 17; iter: 0; batch classifier loss: 0.567699; batch adversarial loss: 0.658215\n",
      "epoch 17; iter: 200; batch classifier loss: 0.614559; batch adversarial loss: 0.689238\n",
      "epoch 18; iter: 0; batch classifier loss: 0.567857; batch adversarial loss: 0.657099\n",
      "epoch 18; iter: 200; batch classifier loss: 0.620406; batch adversarial loss: 0.665598\n",
      "epoch 19; iter: 0; batch classifier loss: 0.661539; batch adversarial loss: 0.700405\n",
      "epoch 19; iter: 200; batch classifier loss: 0.650506; batch adversarial loss: 0.644697\n",
      "epoch 20; iter: 0; batch classifier loss: 0.625660; batch adversarial loss: 0.692454\n",
      "epoch 20; iter: 200; batch classifier loss: 0.621673; batch adversarial loss: 0.701656\n",
      "epoch 21; iter: 0; batch classifier loss: 0.584034; batch adversarial loss: 0.675254\n",
      "epoch 21; iter: 200; batch classifier loss: 0.648683; batch adversarial loss: 0.690367\n",
      "epoch 22; iter: 0; batch classifier loss: 0.615650; batch adversarial loss: 0.672965\n",
      "epoch 22; iter: 200; batch classifier loss: 0.630235; batch adversarial loss: 0.693594\n",
      "epoch 23; iter: 0; batch classifier loss: 0.625089; batch adversarial loss: 0.682076\n",
      "epoch 23; iter: 200; batch classifier loss: 0.611667; batch adversarial loss: 0.640985\n",
      "epoch 24; iter: 0; batch classifier loss: 0.652745; batch adversarial loss: 0.670067\n",
      "epoch 24; iter: 200; batch classifier loss: 0.607468; batch adversarial loss: 0.681546\n",
      "epoch 25; iter: 0; batch classifier loss: 0.587314; batch adversarial loss: 0.675621\n",
      "epoch 25; iter: 200; batch classifier loss: 0.630878; batch adversarial loss: 0.684169\n",
      "epoch 26; iter: 0; batch classifier loss: 0.600953; batch adversarial loss: 0.690615\n",
      "epoch 26; iter: 200; batch classifier loss: 0.663054; batch adversarial loss: 0.666601\n",
      "epoch 27; iter: 0; batch classifier loss: 0.609152; batch adversarial loss: 0.686180\n",
      "epoch 27; iter: 200; batch classifier loss: 0.620596; batch adversarial loss: 0.699841\n",
      "epoch 28; iter: 0; batch classifier loss: 0.667348; batch adversarial loss: 0.697573\n",
      "epoch 28; iter: 200; batch classifier loss: 0.653562; batch adversarial loss: 0.661912\n",
      "epoch 29; iter: 0; batch classifier loss: 0.564699; batch adversarial loss: 0.698024\n",
      "epoch 29; iter: 200; batch classifier loss: 0.633789; batch adversarial loss: 0.677011\n",
      "epoch 30; iter: 0; batch classifier loss: 0.608512; batch adversarial loss: 0.664189\n",
      "epoch 30; iter: 200; batch classifier loss: 0.596743; batch adversarial loss: 0.663184\n",
      "epoch 31; iter: 0; batch classifier loss: 0.579051; batch adversarial loss: 0.680803\n",
      "epoch 31; iter: 200; batch classifier loss: 0.681266; batch adversarial loss: 0.666208\n",
      "epoch 32; iter: 0; batch classifier loss: 0.658432; batch adversarial loss: 0.665373\n",
      "epoch 32; iter: 200; batch classifier loss: 0.605995; batch adversarial loss: 0.689921\n",
      "epoch 33; iter: 0; batch classifier loss: 0.603157; batch adversarial loss: 0.690624\n",
      "epoch 33; iter: 200; batch classifier loss: 0.602449; batch adversarial loss: 0.674072\n",
      "epoch 34; iter: 0; batch classifier loss: 0.602452; batch adversarial loss: 0.666411\n",
      "epoch 34; iter: 200; batch classifier loss: 0.627606; batch adversarial loss: 0.693240\n",
      "epoch 35; iter: 0; batch classifier loss: 0.612480; batch adversarial loss: 0.654317\n",
      "epoch 35; iter: 200; batch classifier loss: 0.599517; batch adversarial loss: 0.663992\n",
      "epoch 36; iter: 0; batch classifier loss: 0.614162; batch adversarial loss: 0.701582\n",
      "epoch 36; iter: 200; batch classifier loss: 0.624482; batch adversarial loss: 0.667705\n",
      "epoch 37; iter: 0; batch classifier loss: 0.622867; batch adversarial loss: 0.681819\n",
      "epoch 37; iter: 200; batch classifier loss: 0.565825; batch adversarial loss: 0.696996\n",
      "epoch 38; iter: 0; batch classifier loss: 0.558015; batch adversarial loss: 0.684950\n",
      "epoch 38; iter: 200; batch classifier loss: 0.656993; batch adversarial loss: 0.688192\n",
      "epoch 39; iter: 0; batch classifier loss: 0.573065; batch adversarial loss: 0.688571\n",
      "epoch 39; iter: 200; batch classifier loss: 0.680397; batch adversarial loss: 0.666648\n",
      "epoch 40; iter: 0; batch classifier loss: 0.635765; batch adversarial loss: 0.684316\n",
      "epoch 40; iter: 200; batch classifier loss: 0.598165; batch adversarial loss: 0.703688\n",
      "epoch 41; iter: 0; batch classifier loss: 0.606320; batch adversarial loss: 0.675260\n",
      "epoch 41; iter: 200; batch classifier loss: 0.612399; batch adversarial loss: 0.678697\n",
      "epoch 42; iter: 0; batch classifier loss: 0.579001; batch adversarial loss: 0.675167\n",
      "epoch 42; iter: 200; batch classifier loss: 0.678941; batch adversarial loss: 0.666364\n",
      "epoch 43; iter: 0; batch classifier loss: 0.649396; batch adversarial loss: 0.669628\n",
      "epoch 43; iter: 200; batch classifier loss: 0.651497; batch adversarial loss: 0.638007\n",
      "epoch 44; iter: 0; batch classifier loss: 0.623628; batch adversarial loss: 0.669344\n",
      "epoch 44; iter: 200; batch classifier loss: 0.629389; batch adversarial loss: 0.664499\n",
      "epoch 45; iter: 0; batch classifier loss: 0.598181; batch adversarial loss: 0.677363\n",
      "epoch 45; iter: 200; batch classifier loss: 0.643945; batch adversarial loss: 0.688544\n",
      "epoch 46; iter: 0; batch classifier loss: 0.622051; batch adversarial loss: 0.669542\n",
      "epoch 46; iter: 200; batch classifier loss: 0.661919; batch adversarial loss: 0.678892\n",
      "epoch 47; iter: 0; batch classifier loss: 0.600266; batch adversarial loss: 0.666356\n",
      "epoch 47; iter: 200; batch classifier loss: 0.607569; batch adversarial loss: 0.665910\n",
      "epoch 48; iter: 0; batch classifier loss: 0.607285; batch adversarial loss: 0.675353\n",
      "epoch 48; iter: 200; batch classifier loss: 0.577116; batch adversarial loss: 0.647470\n",
      "epoch 49; iter: 0; batch classifier loss: 0.603991; batch adversarial loss: 0.691005\n",
      "epoch 49; iter: 200; batch classifier loss: 0.604579; batch adversarial loss: 0.672288\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685809\n",
      "epoch 0; iter: 200; batch classifier loss: 0.674370\n",
      "epoch 1; iter: 0; batch classifier loss: 0.682886\n",
      "epoch 1; iter: 200; batch classifier loss: 0.602346\n",
      "epoch 2; iter: 0; batch classifier loss: 0.610445\n",
      "epoch 2; iter: 200; batch classifier loss: 0.662933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.605763\n",
      "epoch 3; iter: 200; batch classifier loss: 0.611673\n",
      "epoch 4; iter: 0; batch classifier loss: 0.606327\n",
      "epoch 4; iter: 200; batch classifier loss: 0.665338\n",
      "epoch 5; iter: 0; batch classifier loss: 0.643140\n",
      "epoch 5; iter: 200; batch classifier loss: 0.665184\n",
      "epoch 6; iter: 0; batch classifier loss: 0.597487\n",
      "epoch 6; iter: 200; batch classifier loss: 0.652947\n",
      "epoch 7; iter: 0; batch classifier loss: 0.676465\n",
      "epoch 7; iter: 200; batch classifier loss: 0.578657\n",
      "epoch 8; iter: 0; batch classifier loss: 0.611475\n",
      "epoch 8; iter: 200; batch classifier loss: 0.698146\n",
      "epoch 9; iter: 0; batch classifier loss: 0.586708\n",
      "epoch 9; iter: 200; batch classifier loss: 0.610808\n",
      "epoch 10; iter: 0; batch classifier loss: 0.581947\n",
      "epoch 10; iter: 200; batch classifier loss: 0.636937\n",
      "epoch 11; iter: 0; batch classifier loss: 0.638622\n",
      "epoch 11; iter: 200; batch classifier loss: 0.628798\n",
      "epoch 12; iter: 0; batch classifier loss: 0.643044\n",
      "epoch 12; iter: 200; batch classifier loss: 0.558982\n",
      "epoch 13; iter: 0; batch classifier loss: 0.600266\n",
      "epoch 13; iter: 200; batch classifier loss: 0.639507\n",
      "epoch 14; iter: 0; batch classifier loss: 0.602784\n",
      "epoch 14; iter: 200; batch classifier loss: 0.630083\n",
      "epoch 15; iter: 0; batch classifier loss: 0.623703\n",
      "epoch 15; iter: 200; batch classifier loss: 0.610842\n",
      "epoch 16; iter: 0; batch classifier loss: 0.672203\n",
      "epoch 16; iter: 200; batch classifier loss: 0.624512\n",
      "epoch 17; iter: 0; batch classifier loss: 0.649713\n",
      "epoch 17; iter: 200; batch classifier loss: 0.620678\n",
      "epoch 18; iter: 0; batch classifier loss: 0.639083\n",
      "epoch 18; iter: 200; batch classifier loss: 0.646608\n",
      "epoch 19; iter: 0; batch classifier loss: 0.624547\n",
      "epoch 19; iter: 200; batch classifier loss: 0.638861\n",
      "epoch 20; iter: 0; batch classifier loss: 0.627344\n",
      "epoch 20; iter: 200; batch classifier loss: 0.561887\n",
      "epoch 21; iter: 0; batch classifier loss: 0.662905\n",
      "epoch 21; iter: 200; batch classifier loss: 0.635216\n",
      "epoch 22; iter: 0; batch classifier loss: 0.647424\n",
      "epoch 22; iter: 200; batch classifier loss: 0.603964\n",
      "epoch 23; iter: 0; batch classifier loss: 0.596805\n",
      "epoch 23; iter: 200; batch classifier loss: 0.636358\n",
      "epoch 24; iter: 0; batch classifier loss: 0.612684\n",
      "epoch 24; iter: 200; batch classifier loss: 0.672194\n",
      "epoch 25; iter: 0; batch classifier loss: 0.629660\n",
      "epoch 25; iter: 200; batch classifier loss: 0.639896\n",
      "epoch 26; iter: 0; batch classifier loss: 0.640574\n",
      "epoch 26; iter: 200; batch classifier loss: 0.611073\n",
      "epoch 27; iter: 0; batch classifier loss: 0.673861\n",
      "epoch 27; iter: 200; batch classifier loss: 0.633572\n",
      "epoch 28; iter: 0; batch classifier loss: 0.627944\n",
      "epoch 28; iter: 200; batch classifier loss: 0.575664\n",
      "epoch 29; iter: 0; batch classifier loss: 0.593678\n",
      "epoch 29; iter: 200; batch classifier loss: 0.675164\n",
      "epoch 30; iter: 0; batch classifier loss: 0.625921\n",
      "epoch 30; iter: 200; batch classifier loss: 0.626074\n",
      "epoch 31; iter: 0; batch classifier loss: 0.636789\n",
      "epoch 31; iter: 200; batch classifier loss: 0.623082\n",
      "epoch 32; iter: 0; batch classifier loss: 0.618009\n",
      "epoch 32; iter: 200; batch classifier loss: 0.582593\n",
      "epoch 33; iter: 0; batch classifier loss: 0.636405\n",
      "epoch 33; iter: 200; batch classifier loss: 0.563743\n",
      "epoch 34; iter: 0; batch classifier loss: 0.645450\n",
      "epoch 34; iter: 200; batch classifier loss: 0.623637\n",
      "epoch 35; iter: 0; batch classifier loss: 0.643795\n",
      "epoch 35; iter: 200; batch classifier loss: 0.641779\n",
      "epoch 36; iter: 0; batch classifier loss: 0.666787\n",
      "epoch 36; iter: 200; batch classifier loss: 0.572058\n",
      "epoch 37; iter: 0; batch classifier loss: 0.663119\n",
      "epoch 37; iter: 200; batch classifier loss: 0.620307\n",
      "epoch 38; iter: 0; batch classifier loss: 0.661688\n",
      "epoch 38; iter: 200; batch classifier loss: 0.609066\n",
      "epoch 39; iter: 0; batch classifier loss: 0.671204\n",
      "epoch 39; iter: 200; batch classifier loss: 0.595184\n",
      "epoch 40; iter: 0; batch classifier loss: 0.642710\n",
      "epoch 40; iter: 200; batch classifier loss: 0.629776\n",
      "epoch 41; iter: 0; batch classifier loss: 0.653519\n",
      "epoch 41; iter: 200; batch classifier loss: 0.665586\n",
      "epoch 42; iter: 0; batch classifier loss: 0.598325\n",
      "epoch 42; iter: 200; batch classifier loss: 0.600948\n",
      "epoch 43; iter: 0; batch classifier loss: 0.609734\n",
      "epoch 43; iter: 200; batch classifier loss: 0.581776\n",
      "epoch 44; iter: 0; batch classifier loss: 0.604356\n",
      "epoch 44; iter: 200; batch classifier loss: 0.667751\n",
      "epoch 45; iter: 0; batch classifier loss: 0.673389\n",
      "epoch 45; iter: 200; batch classifier loss: 0.630947\n",
      "epoch 46; iter: 0; batch classifier loss: 0.616773\n",
      "epoch 46; iter: 200; batch classifier loss: 0.617389\n",
      "epoch 47; iter: 0; batch classifier loss: 0.643059\n",
      "epoch 47; iter: 200; batch classifier loss: 0.663656\n",
      "epoch 48; iter: 0; batch classifier loss: 0.618567\n",
      "epoch 48; iter: 200; batch classifier loss: 0.652015\n",
      "epoch 49; iter: 0; batch classifier loss: 0.612048\n",
      "epoch 49; iter: 200; batch classifier loss: 0.608916\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697411; batch adversarial loss: 0.748832\n",
      "epoch 1; iter: 0; batch classifier loss: 0.647008; batch adversarial loss: 0.718521\n",
      "epoch 2; iter: 0; batch classifier loss: 0.633717; batch adversarial loss: 0.755353\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614616; batch adversarial loss: 0.708417\n",
      "epoch 4; iter: 0; batch classifier loss: 0.643714; batch adversarial loss: 0.701204\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580333; batch adversarial loss: 0.711314\n",
      "epoch 6; iter: 0; batch classifier loss: 0.607450; batch adversarial loss: 0.707629\n",
      "epoch 7; iter: 0; batch classifier loss: 0.598097; batch adversarial loss: 0.678317\n",
      "epoch 8; iter: 0; batch classifier loss: 0.588785; batch adversarial loss: 0.683711\n",
      "epoch 9; iter: 0; batch classifier loss: 0.629208; batch adversarial loss: 0.686295\n",
      "epoch 10; iter: 0; batch classifier loss: 0.621278; batch adversarial loss: 0.691503\n",
      "epoch 11; iter: 0; batch classifier loss: 0.654190; batch adversarial loss: 0.682092\n",
      "epoch 12; iter: 0; batch classifier loss: 0.593163; batch adversarial loss: 0.670907\n",
      "epoch 13; iter: 0; batch classifier loss: 0.590352; batch adversarial loss: 0.645536\n",
      "epoch 14; iter: 0; batch classifier loss: 0.603927; batch adversarial loss: 0.696054\n",
      "epoch 15; iter: 0; batch classifier loss: 0.642081; batch adversarial loss: 0.655843\n",
      "epoch 16; iter: 0; batch classifier loss: 0.629590; batch adversarial loss: 0.664055\n",
      "epoch 17; iter: 0; batch classifier loss: 0.577250; batch adversarial loss: 0.663261\n",
      "epoch 18; iter: 0; batch classifier loss: 0.590006; batch adversarial loss: 0.673925\n",
      "epoch 19; iter: 0; batch classifier loss: 0.586920; batch adversarial loss: 0.676094\n",
      "epoch 20; iter: 0; batch classifier loss: 0.587793; batch adversarial loss: 0.665981\n",
      "epoch 21; iter: 0; batch classifier loss: 0.611481; batch adversarial loss: 0.668631\n",
      "epoch 22; iter: 0; batch classifier loss: 0.623217; batch adversarial loss: 0.683362\n",
      "epoch 23; iter: 0; batch classifier loss: 0.661986; batch adversarial loss: 0.674570\n",
      "epoch 24; iter: 0; batch classifier loss: 0.623278; batch adversarial loss: 0.658278\n",
      "epoch 25; iter: 0; batch classifier loss: 0.576113; batch adversarial loss: 0.639505\n",
      "epoch 26; iter: 0; batch classifier loss: 0.574194; batch adversarial loss: 0.662338\n",
      "epoch 27; iter: 0; batch classifier loss: 0.614662; batch adversarial loss: 0.649525\n",
      "epoch 28; iter: 0; batch classifier loss: 0.609873; batch adversarial loss: 0.633687\n",
      "epoch 29; iter: 0; batch classifier loss: 0.622674; batch adversarial loss: 0.668205\n",
      "epoch 30; iter: 0; batch classifier loss: 0.658764; batch adversarial loss: 0.659183\n",
      "epoch 31; iter: 0; batch classifier loss: 0.616960; batch adversarial loss: 0.651225\n",
      "epoch 32; iter: 0; batch classifier loss: 0.612852; batch adversarial loss: 0.690532\n",
      "epoch 33; iter: 0; batch classifier loss: 0.637915; batch adversarial loss: 0.669529\n",
      "epoch 34; iter: 0; batch classifier loss: 0.640136; batch adversarial loss: 0.685342\n",
      "epoch 35; iter: 0; batch classifier loss: 0.638273; batch adversarial loss: 0.644593\n",
      "epoch 36; iter: 0; batch classifier loss: 0.587155; batch adversarial loss: 0.659343\n",
      "epoch 37; iter: 0; batch classifier loss: 0.699049; batch adversarial loss: 0.636708\n",
      "epoch 38; iter: 0; batch classifier loss: 0.586217; batch adversarial loss: 0.663076\n",
      "epoch 39; iter: 0; batch classifier loss: 0.641725; batch adversarial loss: 0.645716\n",
      "epoch 40; iter: 0; batch classifier loss: 0.563525; batch adversarial loss: 0.665849\n",
      "epoch 41; iter: 0; batch classifier loss: 0.604155; batch adversarial loss: 0.664413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 0; batch classifier loss: 0.616077; batch adversarial loss: 0.665513\n",
      "epoch 43; iter: 0; batch classifier loss: 0.602944; batch adversarial loss: 0.649330\n",
      "epoch 44; iter: 0; batch classifier loss: 0.649589; batch adversarial loss: 0.643099\n",
      "epoch 45; iter: 0; batch classifier loss: 0.646933; batch adversarial loss: 0.660259\n",
      "epoch 46; iter: 0; batch classifier loss: 0.634951; batch adversarial loss: 0.687801\n",
      "epoch 47; iter: 0; batch classifier loss: 0.621876; batch adversarial loss: 0.637174\n",
      "epoch 48; iter: 0; batch classifier loss: 0.676269; batch adversarial loss: 0.694898\n",
      "epoch 49; iter: 0; batch classifier loss: 0.638579; batch adversarial loss: 0.664932\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694214\n",
      "epoch 1; iter: 0; batch classifier loss: 0.657353\n",
      "epoch 2; iter: 0; batch classifier loss: 0.597048\n",
      "epoch 3; iter: 0; batch classifier loss: 0.606600\n",
      "epoch 4; iter: 0; batch classifier loss: 0.644997\n",
      "epoch 5; iter: 0; batch classifier loss: 0.601240\n",
      "epoch 6; iter: 0; batch classifier loss: 0.711792\n",
      "epoch 7; iter: 0; batch classifier loss: 0.615125\n",
      "epoch 8; iter: 0; batch classifier loss: 0.636129\n",
      "epoch 9; iter: 0; batch classifier loss: 0.632981\n",
      "epoch 10; iter: 0; batch classifier loss: 0.593353\n",
      "epoch 11; iter: 0; batch classifier loss: 0.651168\n",
      "epoch 12; iter: 0; batch classifier loss: 0.566859\n",
      "epoch 13; iter: 0; batch classifier loss: 0.618991\n",
      "epoch 14; iter: 0; batch classifier loss: 0.613399\n",
      "epoch 15; iter: 0; batch classifier loss: 0.641016\n",
      "epoch 16; iter: 0; batch classifier loss: 0.637725\n",
      "epoch 17; iter: 0; batch classifier loss: 0.592054\n",
      "epoch 18; iter: 0; batch classifier loss: 0.686879\n",
      "epoch 19; iter: 0; batch classifier loss: 0.603976\n",
      "epoch 20; iter: 0; batch classifier loss: 0.684048\n",
      "epoch 21; iter: 0; batch classifier loss: 0.637107\n",
      "epoch 22; iter: 0; batch classifier loss: 0.653069\n",
      "epoch 23; iter: 0; batch classifier loss: 0.696018\n",
      "epoch 24; iter: 0; batch classifier loss: 0.617723\n",
      "epoch 25; iter: 0; batch classifier loss: 0.606416\n",
      "epoch 26; iter: 0; batch classifier loss: 0.587068\n",
      "epoch 27; iter: 0; batch classifier loss: 0.590119\n",
      "epoch 28; iter: 0; batch classifier loss: 0.636806\n",
      "epoch 29; iter: 0; batch classifier loss: 0.637554\n",
      "epoch 30; iter: 0; batch classifier loss: 0.613591\n",
      "epoch 31; iter: 0; batch classifier loss: 0.593188\n",
      "epoch 32; iter: 0; batch classifier loss: 0.643501\n",
      "epoch 33; iter: 0; batch classifier loss: 0.601620\n",
      "epoch 34; iter: 0; batch classifier loss: 0.616149\n",
      "epoch 35; iter: 0; batch classifier loss: 0.615247\n",
      "epoch 36; iter: 0; batch classifier loss: 0.610035\n",
      "epoch 37; iter: 0; batch classifier loss: 0.605986\n",
      "epoch 38; iter: 0; batch classifier loss: 0.619284\n",
      "epoch 39; iter: 0; batch classifier loss: 0.596740\n",
      "epoch 40; iter: 0; batch classifier loss: 0.617521\n",
      "epoch 41; iter: 0; batch classifier loss: 0.629369\n",
      "epoch 42; iter: 0; batch classifier loss: 0.566311\n",
      "epoch 43; iter: 0; batch classifier loss: 0.569977\n",
      "epoch 44; iter: 0; batch classifier loss: 0.621761\n",
      "epoch 45; iter: 0; batch classifier loss: 0.600190\n",
      "epoch 46; iter: 0; batch classifier loss: 0.634154\n",
      "epoch 47; iter: 0; batch classifier loss: 0.616082\n",
      "epoch 48; iter: 0; batch classifier loss: 0.572196\n",
      "epoch 49; iter: 0; batch classifier loss: 0.626279\n",
      "run = 10\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698566; batch adversarial loss: 0.706442\n",
      "epoch 0; iter: 200; batch classifier loss: 0.653646; batch adversarial loss: 0.678091\n",
      "epoch 1; iter: 0; batch classifier loss: 0.637900; batch adversarial loss: 0.693207\n",
      "epoch 1; iter: 200; batch classifier loss: 0.633561; batch adversarial loss: 0.673317\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624713; batch adversarial loss: 0.667395\n",
      "epoch 2; iter: 200; batch classifier loss: 0.616161; batch adversarial loss: 0.659711\n",
      "epoch 3; iter: 0; batch classifier loss: 0.592925; batch adversarial loss: 0.673333\n",
      "epoch 3; iter: 200; batch classifier loss: 0.553435; batch adversarial loss: 0.675579\n",
      "epoch 4; iter: 0; batch classifier loss: 0.586540; batch adversarial loss: 0.688214\n",
      "epoch 4; iter: 200; batch classifier loss: 0.630210; batch adversarial loss: 0.664572\n",
      "epoch 5; iter: 0; batch classifier loss: 0.637503; batch adversarial loss: 0.688704\n",
      "epoch 5; iter: 200; batch classifier loss: 0.620593; batch adversarial loss: 0.709223\n",
      "epoch 6; iter: 0; batch classifier loss: 0.603948; batch adversarial loss: 0.684086\n",
      "epoch 6; iter: 200; batch classifier loss: 0.601176; batch adversarial loss: 0.652129\n",
      "epoch 7; iter: 0; batch classifier loss: 0.617443; batch adversarial loss: 0.672282\n",
      "epoch 7; iter: 200; batch classifier loss: 0.687701; batch adversarial loss: 0.663363\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571008; batch adversarial loss: 0.676730\n",
      "epoch 8; iter: 200; batch classifier loss: 0.626649; batch adversarial loss: 0.703265\n",
      "epoch 9; iter: 0; batch classifier loss: 0.645967; batch adversarial loss: 0.683125\n",
      "epoch 9; iter: 200; batch classifier loss: 0.609427; batch adversarial loss: 0.673244\n",
      "epoch 10; iter: 0; batch classifier loss: 0.585490; batch adversarial loss: 0.665644\n",
      "epoch 10; iter: 200; batch classifier loss: 0.580474; batch adversarial loss: 0.680588\n",
      "epoch 11; iter: 0; batch classifier loss: 0.588508; batch adversarial loss: 0.684399\n",
      "epoch 11; iter: 200; batch classifier loss: 0.618844; batch adversarial loss: 0.683024\n",
      "epoch 12; iter: 0; batch classifier loss: 0.627856; batch adversarial loss: 0.671091\n",
      "epoch 12; iter: 200; batch classifier loss: 0.583511; batch adversarial loss: 0.671621\n",
      "epoch 13; iter: 0; batch classifier loss: 0.606262; batch adversarial loss: 0.677080\n",
      "epoch 13; iter: 200; batch classifier loss: 0.583939; batch adversarial loss: 0.659292\n",
      "epoch 14; iter: 0; batch classifier loss: 0.593963; batch adversarial loss: 0.691336\n",
      "epoch 14; iter: 200; batch classifier loss: 0.684546; batch adversarial loss: 0.662253\n",
      "epoch 15; iter: 0; batch classifier loss: 0.606196; batch adversarial loss: 0.666233\n",
      "epoch 15; iter: 200; batch classifier loss: 0.658240; batch adversarial loss: 0.658682\n",
      "epoch 16; iter: 0; batch classifier loss: 0.580237; batch adversarial loss: 0.699680\n",
      "epoch 16; iter: 200; batch classifier loss: 0.635730; batch adversarial loss: 0.655454\n",
      "epoch 17; iter: 0; batch classifier loss: 0.640105; batch adversarial loss: 0.657172\n",
      "epoch 17; iter: 200; batch classifier loss: 0.557347; batch adversarial loss: 0.681956\n",
      "epoch 18; iter: 0; batch classifier loss: 0.669352; batch adversarial loss: 0.643554\n",
      "epoch 18; iter: 200; batch classifier loss: 0.603104; batch adversarial loss: 0.686775\n",
      "epoch 19; iter: 0; batch classifier loss: 0.645308; batch adversarial loss: 0.655140\n",
      "epoch 19; iter: 200; batch classifier loss: 0.696816; batch adversarial loss: 0.682607\n",
      "epoch 20; iter: 0; batch classifier loss: 0.601755; batch adversarial loss: 0.684902\n",
      "epoch 20; iter: 200; batch classifier loss: 0.624289; batch adversarial loss: 0.671653\n",
      "epoch 21; iter: 0; batch classifier loss: 0.628148; batch adversarial loss: 0.667878\n",
      "epoch 21; iter: 200; batch classifier loss: 0.595579; batch adversarial loss: 0.678438\n",
      "epoch 22; iter: 0; batch classifier loss: 0.650126; batch adversarial loss: 0.667896\n",
      "epoch 22; iter: 200; batch classifier loss: 0.642628; batch adversarial loss: 0.697346\n",
      "epoch 23; iter: 0; batch classifier loss: 0.610211; batch adversarial loss: 0.687730\n",
      "epoch 23; iter: 200; batch classifier loss: 0.595265; batch adversarial loss: 0.691148\n",
      "epoch 24; iter: 0; batch classifier loss: 0.641785; batch adversarial loss: 0.657210\n",
      "epoch 24; iter: 200; batch classifier loss: 0.615748; batch adversarial loss: 0.646224\n",
      "epoch 25; iter: 0; batch classifier loss: 0.624059; batch adversarial loss: 0.681392\n",
      "epoch 25; iter: 200; batch classifier loss: 0.636745; batch adversarial loss: 0.681323\n",
      "epoch 26; iter: 0; batch classifier loss: 0.621249; batch adversarial loss: 0.678295\n",
      "epoch 26; iter: 200; batch classifier loss: 0.589576; batch adversarial loss: 0.653524\n",
      "epoch 27; iter: 0; batch classifier loss: 0.620920; batch adversarial loss: 0.689812\n",
      "epoch 27; iter: 200; batch classifier loss: 0.707770; batch adversarial loss: 0.653866\n",
      "epoch 28; iter: 0; batch classifier loss: 0.619742; batch adversarial loss: 0.678393\n",
      "epoch 28; iter: 200; batch classifier loss: 0.564778; batch adversarial loss: 0.686437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 0; batch classifier loss: 0.599842; batch adversarial loss: 0.674838\n",
      "epoch 29; iter: 200; batch classifier loss: 0.592847; batch adversarial loss: 0.642261\n",
      "epoch 30; iter: 0; batch classifier loss: 0.564119; batch adversarial loss: 0.679965\n",
      "epoch 30; iter: 200; batch classifier loss: 0.570962; batch adversarial loss: 0.673437\n",
      "epoch 31; iter: 0; batch classifier loss: 0.566300; batch adversarial loss: 0.690406\n",
      "epoch 31; iter: 200; batch classifier loss: 0.578543; batch adversarial loss: 0.685791\n",
      "epoch 32; iter: 0; batch classifier loss: 0.568404; batch adversarial loss: 0.685653\n",
      "epoch 32; iter: 200; batch classifier loss: 0.591136; batch adversarial loss: 0.656958\n",
      "epoch 33; iter: 0; batch classifier loss: 0.605338; batch adversarial loss: 0.685496\n",
      "epoch 33; iter: 200; batch classifier loss: 0.637445; batch adversarial loss: 0.700784\n",
      "epoch 34; iter: 0; batch classifier loss: 0.556603; batch adversarial loss: 0.656870\n",
      "epoch 34; iter: 200; batch classifier loss: 0.666675; batch adversarial loss: 0.668708\n",
      "epoch 35; iter: 0; batch classifier loss: 0.619738; batch adversarial loss: 0.706992\n",
      "epoch 35; iter: 200; batch classifier loss: 0.610108; batch adversarial loss: 0.675807\n",
      "epoch 36; iter: 0; batch classifier loss: 0.629722; batch adversarial loss: 0.667187\n",
      "epoch 36; iter: 200; batch classifier loss: 0.606140; batch adversarial loss: 0.691470\n",
      "epoch 37; iter: 0; batch classifier loss: 0.615014; batch adversarial loss: 0.684265\n",
      "epoch 37; iter: 200; batch classifier loss: 0.641620; batch adversarial loss: 0.687019\n",
      "epoch 38; iter: 0; batch classifier loss: 0.560719; batch adversarial loss: 0.649213\n",
      "epoch 38; iter: 200; batch classifier loss: 0.597747; batch adversarial loss: 0.694524\n",
      "epoch 39; iter: 0; batch classifier loss: 0.592874; batch adversarial loss: 0.661709\n",
      "epoch 39; iter: 200; batch classifier loss: 0.592960; batch adversarial loss: 0.666451\n",
      "epoch 40; iter: 0; batch classifier loss: 0.639372; batch adversarial loss: 0.691562\n",
      "epoch 40; iter: 200; batch classifier loss: 0.642689; batch adversarial loss: 0.661716\n",
      "epoch 41; iter: 0; batch classifier loss: 0.587401; batch adversarial loss: 0.663806\n",
      "epoch 41; iter: 200; batch classifier loss: 0.602479; batch adversarial loss: 0.690891\n",
      "epoch 42; iter: 0; batch classifier loss: 0.566660; batch adversarial loss: 0.709332\n",
      "epoch 42; iter: 200; batch classifier loss: 0.613928; batch adversarial loss: 0.679982\n",
      "epoch 43; iter: 0; batch classifier loss: 0.605996; batch adversarial loss: 0.657687\n",
      "epoch 43; iter: 200; batch classifier loss: 0.599974; batch adversarial loss: 0.644350\n",
      "epoch 44; iter: 0; batch classifier loss: 0.641935; batch adversarial loss: 0.669841\n",
      "epoch 44; iter: 200; batch classifier loss: 0.553320; batch adversarial loss: 0.650242\n",
      "epoch 45; iter: 0; batch classifier loss: 0.611701; batch adversarial loss: 0.656570\n",
      "epoch 45; iter: 200; batch classifier loss: 0.635117; batch adversarial loss: 0.665451\n",
      "epoch 46; iter: 0; batch classifier loss: 0.664942; batch adversarial loss: 0.709857\n",
      "epoch 46; iter: 200; batch classifier loss: 0.614284; batch adversarial loss: 0.689752\n",
      "epoch 47; iter: 0; batch classifier loss: 0.580573; batch adversarial loss: 0.651793\n",
      "epoch 47; iter: 200; batch classifier loss: 0.634429; batch adversarial loss: 0.704641\n",
      "epoch 48; iter: 0; batch classifier loss: 0.624207; batch adversarial loss: 0.683730\n",
      "epoch 48; iter: 200; batch classifier loss: 0.607166; batch adversarial loss: 0.651516\n",
      "epoch 49; iter: 0; batch classifier loss: 0.629131; batch adversarial loss: 0.679127\n",
      "epoch 49; iter: 200; batch classifier loss: 0.581493; batch adversarial loss: 0.705540\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715176\n",
      "epoch 0; iter: 200; batch classifier loss: 0.636340\n",
      "epoch 1; iter: 0; batch classifier loss: 0.631962\n",
      "epoch 1; iter: 200; batch classifier loss: 0.603612\n",
      "epoch 2; iter: 0; batch classifier loss: 0.627469\n",
      "epoch 2; iter: 200; batch classifier loss: 0.656322\n",
      "epoch 3; iter: 0; batch classifier loss: 0.640332\n",
      "epoch 3; iter: 200; batch classifier loss: 0.617783\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557893\n",
      "epoch 4; iter: 200; batch classifier loss: 0.632153\n",
      "epoch 5; iter: 0; batch classifier loss: 0.631048\n",
      "epoch 5; iter: 200; batch classifier loss: 0.613014\n",
      "epoch 6; iter: 0; batch classifier loss: 0.613876\n",
      "epoch 6; iter: 200; batch classifier loss: 0.592117\n",
      "epoch 7; iter: 0; batch classifier loss: 0.607321\n",
      "epoch 7; iter: 200; batch classifier loss: 0.655389\n",
      "epoch 8; iter: 0; batch classifier loss: 0.594285\n",
      "epoch 8; iter: 200; batch classifier loss: 0.654628\n",
      "epoch 9; iter: 0; batch classifier loss: 0.574314\n",
      "epoch 9; iter: 200; batch classifier loss: 0.652063\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564670\n",
      "epoch 10; iter: 200; batch classifier loss: 0.629989\n",
      "epoch 11; iter: 0; batch classifier loss: 0.605837\n",
      "epoch 11; iter: 200; batch classifier loss: 0.633027\n",
      "epoch 12; iter: 0; batch classifier loss: 0.624953\n",
      "epoch 12; iter: 200; batch classifier loss: 0.666219\n",
      "epoch 13; iter: 0; batch classifier loss: 0.611029\n",
      "epoch 13; iter: 200; batch classifier loss: 0.627478\n",
      "epoch 14; iter: 0; batch classifier loss: 0.640503\n",
      "epoch 14; iter: 200; batch classifier loss: 0.580481\n",
      "epoch 15; iter: 0; batch classifier loss: 0.564147\n",
      "epoch 15; iter: 200; batch classifier loss: 0.601945\n",
      "epoch 16; iter: 0; batch classifier loss: 0.611625\n",
      "epoch 16; iter: 200; batch classifier loss: 0.597562\n",
      "epoch 17; iter: 0; batch classifier loss: 0.699545\n",
      "epoch 17; iter: 200; batch classifier loss: 0.650190\n",
      "epoch 18; iter: 0; batch classifier loss: 0.588151\n",
      "epoch 18; iter: 200; batch classifier loss: 0.644092\n",
      "epoch 19; iter: 0; batch classifier loss: 0.676064\n",
      "epoch 19; iter: 200; batch classifier loss: 0.626431\n",
      "epoch 20; iter: 0; batch classifier loss: 0.577230\n",
      "epoch 20; iter: 200; batch classifier loss: 0.624889\n",
      "epoch 21; iter: 0; batch classifier loss: 0.561853\n",
      "epoch 21; iter: 200; batch classifier loss: 0.679125\n",
      "epoch 22; iter: 0; batch classifier loss: 0.620521\n",
      "epoch 22; iter: 200; batch classifier loss: 0.651504\n",
      "epoch 23; iter: 0; batch classifier loss: 0.637454\n",
      "epoch 23; iter: 200; batch classifier loss: 0.680727\n",
      "epoch 24; iter: 0; batch classifier loss: 0.549413\n",
      "epoch 24; iter: 200; batch classifier loss: 0.606118\n",
      "epoch 25; iter: 0; batch classifier loss: 0.587661\n",
      "epoch 25; iter: 200; batch classifier loss: 0.654971\n",
      "epoch 26; iter: 0; batch classifier loss: 0.565950\n",
      "epoch 26; iter: 200; batch classifier loss: 0.677283\n",
      "epoch 27; iter: 0; batch classifier loss: 0.623333\n",
      "epoch 27; iter: 200; batch classifier loss: 0.619444\n",
      "epoch 28; iter: 0; batch classifier loss: 0.601830\n",
      "epoch 28; iter: 200; batch classifier loss: 0.618704\n",
      "epoch 29; iter: 0; batch classifier loss: 0.543271\n",
      "epoch 29; iter: 200; batch classifier loss: 0.675996\n",
      "epoch 30; iter: 0; batch classifier loss: 0.568728\n",
      "epoch 30; iter: 200; batch classifier loss: 0.583044\n",
      "epoch 31; iter: 0; batch classifier loss: 0.642015\n",
      "epoch 31; iter: 200; batch classifier loss: 0.595196\n",
      "epoch 32; iter: 0; batch classifier loss: 0.606829\n",
      "epoch 32; iter: 200; batch classifier loss: 0.593978\n",
      "epoch 33; iter: 0; batch classifier loss: 0.512926\n",
      "epoch 33; iter: 200; batch classifier loss: 0.583877\n",
      "epoch 34; iter: 0; batch classifier loss: 0.552650\n",
      "epoch 34; iter: 200; batch classifier loss: 0.642397\n",
      "epoch 35; iter: 0; batch classifier loss: 0.615844\n",
      "epoch 35; iter: 200; batch classifier loss: 0.637567\n",
      "epoch 36; iter: 0; batch classifier loss: 0.605301\n",
      "epoch 36; iter: 200; batch classifier loss: 0.604203\n",
      "epoch 37; iter: 0; batch classifier loss: 0.604746\n",
      "epoch 37; iter: 200; batch classifier loss: 0.581710\n",
      "epoch 38; iter: 0; batch classifier loss: 0.575481\n",
      "epoch 38; iter: 200; batch classifier loss: 0.643613\n",
      "epoch 39; iter: 0; batch classifier loss: 0.585152\n",
      "epoch 39; iter: 200; batch classifier loss: 0.653000\n",
      "epoch 40; iter: 0; batch classifier loss: 0.579693\n",
      "epoch 40; iter: 200; batch classifier loss: 0.636784\n",
      "epoch 41; iter: 0; batch classifier loss: 0.603833\n",
      "epoch 41; iter: 200; batch classifier loss: 0.636699\n",
      "epoch 42; iter: 0; batch classifier loss: 0.630534\n",
      "epoch 42; iter: 200; batch classifier loss: 0.580622\n",
      "epoch 43; iter: 0; batch classifier loss: 0.642429\n",
      "epoch 43; iter: 200; batch classifier loss: 0.583650\n",
      "epoch 44; iter: 0; batch classifier loss: 0.612360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 200; batch classifier loss: 0.630565\n",
      "epoch 45; iter: 0; batch classifier loss: 0.673555\n",
      "epoch 45; iter: 200; batch classifier loss: 0.654289\n",
      "epoch 46; iter: 0; batch classifier loss: 0.606021\n",
      "epoch 46; iter: 200; batch classifier loss: 0.615896\n",
      "epoch 47; iter: 0; batch classifier loss: 0.576597\n",
      "epoch 47; iter: 200; batch classifier loss: 0.575241\n",
      "epoch 48; iter: 0; batch classifier loss: 0.602093\n",
      "epoch 48; iter: 200; batch classifier loss: 0.601114\n",
      "epoch 49; iter: 0; batch classifier loss: 0.575440\n",
      "epoch 49; iter: 200; batch classifier loss: 0.567482\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673471; batch adversarial loss: 0.780975\n",
      "epoch 1; iter: 0; batch classifier loss: 0.690468; batch adversarial loss: 0.829493\n",
      "epoch 2; iter: 0; batch classifier loss: 0.667842; batch adversarial loss: 0.847133\n",
      "epoch 3; iter: 0; batch classifier loss: 0.703228; batch adversarial loss: 0.870367\n",
      "epoch 4; iter: 0; batch classifier loss: 0.765185; batch adversarial loss: 0.884526\n",
      "epoch 5; iter: 0; batch classifier loss: 0.741445; batch adversarial loss: 0.803279\n",
      "epoch 6; iter: 0; batch classifier loss: 0.707301; batch adversarial loss: 0.804303\n",
      "epoch 7; iter: 0; batch classifier loss: 0.755346; batch adversarial loss: 0.816563\n",
      "epoch 8; iter: 0; batch classifier loss: 0.704109; batch adversarial loss: 0.806876\n",
      "epoch 9; iter: 0; batch classifier loss: 0.684739; batch adversarial loss: 0.795623\n",
      "epoch 10; iter: 0; batch classifier loss: 0.659576; batch adversarial loss: 0.754266\n",
      "epoch 11; iter: 0; batch classifier loss: 0.671486; batch adversarial loss: 0.759179\n",
      "epoch 12; iter: 0; batch classifier loss: 0.718705; batch adversarial loss: 0.746318\n",
      "epoch 13; iter: 0; batch classifier loss: 0.646256; batch adversarial loss: 0.774331\n",
      "epoch 14; iter: 0; batch classifier loss: 0.608227; batch adversarial loss: 0.730508\n",
      "epoch 15; iter: 0; batch classifier loss: 0.627604; batch adversarial loss: 0.729854\n",
      "epoch 16; iter: 0; batch classifier loss: 0.614778; batch adversarial loss: 0.731237\n",
      "epoch 17; iter: 0; batch classifier loss: 0.658144; batch adversarial loss: 0.703821\n",
      "epoch 18; iter: 0; batch classifier loss: 0.701465; batch adversarial loss: 0.721158\n",
      "epoch 19; iter: 0; batch classifier loss: 0.642400; batch adversarial loss: 0.685896\n",
      "epoch 20; iter: 0; batch classifier loss: 0.626665; batch adversarial loss: 0.698289\n",
      "epoch 21; iter: 0; batch classifier loss: 0.609763; batch adversarial loss: 0.673300\n",
      "epoch 22; iter: 0; batch classifier loss: 0.630354; batch adversarial loss: 0.736203\n",
      "epoch 23; iter: 0; batch classifier loss: 0.646077; batch adversarial loss: 0.714514\n",
      "epoch 24; iter: 0; batch classifier loss: 0.610383; batch adversarial loss: 0.714846\n",
      "epoch 25; iter: 0; batch classifier loss: 0.603394; batch adversarial loss: 0.681631\n",
      "epoch 26; iter: 0; batch classifier loss: 0.668858; batch adversarial loss: 0.688490\n",
      "epoch 27; iter: 0; batch classifier loss: 0.612699; batch adversarial loss: 0.682622\n",
      "epoch 28; iter: 0; batch classifier loss: 0.626658; batch adversarial loss: 0.653481\n",
      "epoch 29; iter: 0; batch classifier loss: 0.653730; batch adversarial loss: 0.705845\n",
      "epoch 30; iter: 0; batch classifier loss: 0.657555; batch adversarial loss: 0.679282\n",
      "epoch 31; iter: 0; batch classifier loss: 0.624531; batch adversarial loss: 0.695639\n",
      "epoch 32; iter: 0; batch classifier loss: 0.589237; batch adversarial loss: 0.691094\n",
      "epoch 33; iter: 0; batch classifier loss: 0.582075; batch adversarial loss: 0.695472\n",
      "epoch 34; iter: 0; batch classifier loss: 0.583414; batch adversarial loss: 0.665878\n",
      "epoch 35; iter: 0; batch classifier loss: 0.578590; batch adversarial loss: 0.681648\n",
      "epoch 36; iter: 0; batch classifier loss: 0.598374; batch adversarial loss: 0.684723\n",
      "epoch 37; iter: 0; batch classifier loss: 0.569458; batch adversarial loss: 0.685434\n",
      "epoch 38; iter: 0; batch classifier loss: 0.625327; batch adversarial loss: 0.651416\n",
      "epoch 39; iter: 0; batch classifier loss: 0.620538; batch adversarial loss: 0.676770\n",
      "epoch 40; iter: 0; batch classifier loss: 0.597690; batch adversarial loss: 0.674156\n",
      "epoch 41; iter: 0; batch classifier loss: 0.674333; batch adversarial loss: 0.689060\n",
      "epoch 42; iter: 0; batch classifier loss: 0.606203; batch adversarial loss: 0.678689\n",
      "epoch 43; iter: 0; batch classifier loss: 0.585869; batch adversarial loss: 0.662525\n",
      "epoch 44; iter: 0; batch classifier loss: 0.617501; batch adversarial loss: 0.679103\n",
      "epoch 45; iter: 0; batch classifier loss: 0.571909; batch adversarial loss: 0.691313\n",
      "epoch 46; iter: 0; batch classifier loss: 0.621817; batch adversarial loss: 0.685307\n",
      "epoch 47; iter: 0; batch classifier loss: 0.592486; batch adversarial loss: 0.678376\n",
      "epoch 48; iter: 0; batch classifier loss: 0.569489; batch adversarial loss: 0.669828\n",
      "epoch 49; iter: 0; batch classifier loss: 0.589410; batch adversarial loss: 0.653553\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701746\n",
      "epoch 1; iter: 0; batch classifier loss: 0.637644\n",
      "epoch 2; iter: 0; batch classifier loss: 0.607883\n",
      "epoch 3; iter: 0; batch classifier loss: 0.634745\n",
      "epoch 4; iter: 0; batch classifier loss: 0.655503\n",
      "epoch 5; iter: 0; batch classifier loss: 0.642657\n",
      "epoch 6; iter: 0; batch classifier loss: 0.596547\n",
      "epoch 7; iter: 0; batch classifier loss: 0.613371\n",
      "epoch 8; iter: 0; batch classifier loss: 0.580254\n",
      "epoch 9; iter: 0; batch classifier loss: 0.628350\n",
      "epoch 10; iter: 0; batch classifier loss: 0.590478\n",
      "epoch 11; iter: 0; batch classifier loss: 0.665673\n",
      "epoch 12; iter: 0; batch classifier loss: 0.564921\n",
      "epoch 13; iter: 0; batch classifier loss: 0.602510\n",
      "epoch 14; iter: 0; batch classifier loss: 0.620158\n",
      "epoch 15; iter: 0; batch classifier loss: 0.630916\n",
      "epoch 16; iter: 0; batch classifier loss: 0.584450\n",
      "epoch 17; iter: 0; batch classifier loss: 0.624279\n",
      "epoch 18; iter: 0; batch classifier loss: 0.615879\n",
      "epoch 19; iter: 0; batch classifier loss: 0.591972\n",
      "epoch 20; iter: 0; batch classifier loss: 0.635864\n",
      "epoch 21; iter: 0; batch classifier loss: 0.620431\n",
      "epoch 22; iter: 0; batch classifier loss: 0.601267\n",
      "epoch 23; iter: 0; batch classifier loss: 0.599661\n",
      "epoch 24; iter: 0; batch classifier loss: 0.643540\n",
      "epoch 25; iter: 0; batch classifier loss: 0.634114\n",
      "epoch 26; iter: 0; batch classifier loss: 0.600452\n",
      "epoch 27; iter: 0; batch classifier loss: 0.617506\n",
      "epoch 28; iter: 0; batch classifier loss: 0.638089\n",
      "epoch 29; iter: 0; batch classifier loss: 0.586775\n",
      "epoch 30; iter: 0; batch classifier loss: 0.587606\n",
      "epoch 31; iter: 0; batch classifier loss: 0.617204\n",
      "epoch 32; iter: 0; batch classifier loss: 0.618394\n",
      "epoch 33; iter: 0; batch classifier loss: 0.645376\n",
      "epoch 34; iter: 0; batch classifier loss: 0.582934\n",
      "epoch 35; iter: 0; batch classifier loss: 0.654294\n",
      "epoch 36; iter: 0; batch classifier loss: 0.601193\n",
      "epoch 37; iter: 0; batch classifier loss: 0.613090\n",
      "epoch 38; iter: 0; batch classifier loss: 0.668430\n",
      "epoch 39; iter: 0; batch classifier loss: 0.641181\n",
      "epoch 40; iter: 0; batch classifier loss: 0.617844\n",
      "epoch 41; iter: 0; batch classifier loss: 0.598951\n",
      "epoch 42; iter: 0; batch classifier loss: 0.653061\n",
      "epoch 43; iter: 0; batch classifier loss: 0.636760\n",
      "epoch 44; iter: 0; batch classifier loss: 0.578515\n",
      "epoch 45; iter: 0; batch classifier loss: 0.622603\n",
      "epoch 46; iter: 0; batch classifier loss: 0.657862\n",
      "epoch 47; iter: 0; batch classifier loss: 0.659291\n",
      "epoch 48; iter: 0; batch classifier loss: 0.642347\n",
      "epoch 49; iter: 0; batch classifier loss: 0.612066\n",
      "\n",
      "prediction completed\n",
      "compiled all metrics\n",
      "all files saved to csv\n"
     ]
    }
   ],
   "source": [
    "privileged_groups = [{'race': 1}]\n",
    "unprivileged_groups = [{'race': 0}]\n",
    "\n",
    "print(\"Classification with Compas data set\\n\")\n",
    "# df = pd.read_csv('dataset/compas-scores-two-years.csv')\n",
    "dataset_orig = load_preproc_data_compas()\n",
    "\n",
    "matrix_accuracy_reweigh = {}\n",
    "matrix_accuracy_nonreweigh = {}\n",
    "matrix_fairness_reweigh = {}\n",
    "matrix_fairness_nonreweigh = {}\n",
    "\n",
    "runs = 10\n",
    "\n",
    "for i in range(0, runs):\n",
    "    print('run =', i+1)\n",
    "    \n",
    "    train, test = dataset_orig.split([0.7], shuffle=True)\n",
    "    train_transformed = reweighing_data(train, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # with reweighing\n",
    "    accuracy_reweigh, fairness_metrics_reweigh = make_prediction(train_transformed, test, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # Without reweighing\n",
    "    accuracy_nonreweigh, fairness_metrics_nonreweigh = make_prediction(train, test, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # store values for each run\n",
    "    matrix_accuracy_reweigh[i] = accuracy_reweigh\n",
    "    matrix_fairness_reweigh[i] = fairness_metrics_reweigh\n",
    "    matrix_accuracy_nonreweigh[i] = accuracy_nonreweigh\n",
    "    matrix_fairness_nonreweigh[i] = fairness_metrics_nonreweigh\n",
    "\n",
    "print('\\nprediction completed')\n",
    "\n",
    "metrics_adversarial_reweigh = []\n",
    "metrics_prejudice_reweigh = []\n",
    "metrics_nondebiasing_reweigh = []\n",
    "metrics_ensemble_reweigh = []\n",
    "metrics_adversarial_nonreweigh = []\n",
    "metrics_prejudice_nonreweigh = []\n",
    "metrics_nondebiasing_nonreweigh = []\n",
    "metrics_ensemble_nonreweigh = []\n",
    "\n",
    "for i in range(0, runs):\n",
    "    \n",
    "    # with reweighing\n",
    "    metrics_adversarial_reweigh.append(matrix_fairness_reweigh[i][0])\n",
    "    metrics_prejudice_reweigh.append(matrix_fairness_reweigh[i][1])\n",
    "    metrics_nondebiasing_reweigh.append(matrix_fairness_reweigh[i][2])\n",
    "    metrics_ensemble_reweigh.append(matrix_fairness_reweigh[i][3])\n",
    "    \n",
    "    # without reweighing\n",
    "    metrics_adversarial_nonreweigh.append(matrix_fairness_nonreweigh[i][0])\n",
    "    metrics_prejudice_nonreweigh.append(matrix_fairness_nonreweigh[i][1])\n",
    "    metrics_nondebiasing_nonreweigh.append(matrix_fairness_nonreweigh[i][2])\n",
    "    metrics_ensemble_nonreweigh.append(matrix_fairness_nonreweigh[i][3])\n",
    "\n",
    "print('compiled all metrics')\n",
    "\n",
    "\n",
    "# create data frame for all metrics\n",
    "columns = ['Adversarial Debiasing', 'Prejudice Remover', 'Nondebiasing', 'Ensemble']\n",
    "accuracy_reweigh = np.array(list(matrix_accuracy_reweigh.values()))\n",
    "accuracy_nonreweigh = np.array(list(matrix_accuracy_nonreweigh.values()))\n",
    "compas_accuracy_reweigh = pd.DataFrame(accuracy_reweigh, columns=columns)\n",
    "compas_accuracy_nonreweigh = pd.DataFrame(accuracy_nonreweigh, columns=columns)\n",
    "\n",
    "# fairness metrics\n",
    "columns = ['Mean Difference', 'Disparate Impact', 'Equal Opportunity Difference', 'Average Odds Difference', 'Theil Index']\n",
    "compas_adversarial_reweigh = pd.DataFrame(metrics_adversarial_reweigh, columns=columns)\n",
    "compas_prejudice_reweigh = pd.DataFrame(metrics_prejudice_reweigh, columns=columns)\n",
    "compas_nondebiasing_reweigh = pd.DataFrame(metrics_nondebiasing_reweigh, columns=columns)\n",
    "compas_ensemble_reweigh = pd.DataFrame(metrics_ensemble_reweigh, columns=columns)\n",
    "\n",
    "compas_adversarial_nonreweigh = pd.DataFrame(metrics_adversarial_nonreweigh, columns=columns)\n",
    "compas_prejudice_nonreweigh = pd.DataFrame(metrics_prejudice_nonreweigh, columns=columns)\n",
    "compas_nondebiasing_nonreweigh = pd.DataFrame(metrics_nondebiasing_nonreweigh, columns=columns)\n",
    "compas_ensemble_nonreweigh = pd.DataFrame(metrics_ensemble_nonreweigh, columns=columns)\n",
    "\n",
    "\n",
    "# save to csv\n",
    "compas_accuracy_reweigh.to_csv(\"results-11feb/race/compas/reweighed/accuracy.csv\", encoding='utf-8')\n",
    "compas_adversarial_reweigh.to_csv(\"results-11feb/race/compas/reweighed/adversarial.csv\", encoding='utf-8')\n",
    "compas_prejudice_reweigh.to_csv(\"results-11feb/race/compas/reweighed/prejudice.csv\", encoding='utf-8')\n",
    "compas_nondebiasing_reweigh.to_csv(\"results-11feb/race/compas/reweighed/neural_net.csv\", encoding='utf-8')\n",
    "compas_ensemble_reweigh.to_csv(\"results-11feb/race/compas/reweighed/ensemble.csv\", encoding='utf-8')\n",
    "\n",
    "compas_accuracy_nonreweigh.to_csv(\"results-11feb/race/compas/non-reweighed/accuracy.csv\", encoding='utf-8')\n",
    "compas_adversarial_nonreweigh.to_csv(\"results-11feb/race/compas/non-reweighed/adversarial.csv\", encoding='utf-8')\n",
    "compas_prejudice_nonreweigh.to_csv(\"results-11feb/race/compas/non-reweighed/prejudice.csv\", encoding='utf-8')\n",
    "compas_nondebiasing_nonreweigh.to_csv(\"results-11feb/race/compas/non-reweighed/neural_net.csv\", encoding='utf-8')\n",
    "compas_ensemble_nonreweigh.to_csv(\"results-11feb/race/compas/non-reweighed/ensemble.csv\", encoding='utf-8')\n",
    "\n",
    "print('all files saved to csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'scores' has no well-defined meaning out of range [0, 1].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification with German data set\n",
      "\n",
      "run = 1\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674728; batch adversarial loss: 0.507687\n",
      "epoch 1; iter: 0; batch classifier loss: 0.676047; batch adversarial loss: 0.535870\n",
      "epoch 2; iter: 0; batch classifier loss: 0.710204; batch adversarial loss: 0.658102\n",
      "epoch 3; iter: 0; batch classifier loss: 1.022655; batch adversarial loss: 0.730948\n",
      "epoch 4; iter: 0; batch classifier loss: 1.252913; batch adversarial loss: 0.649106\n",
      "epoch 5; iter: 0; batch classifier loss: 1.316567; batch adversarial loss: 0.664673\n",
      "epoch 6; iter: 0; batch classifier loss: 1.489223; batch adversarial loss: 0.670780\n",
      "epoch 7; iter: 0; batch classifier loss: 1.495940; batch adversarial loss: 0.649649\n",
      "epoch 8; iter: 0; batch classifier loss: 1.499763; batch adversarial loss: 0.613185\n",
      "epoch 9; iter: 0; batch classifier loss: 1.470350; batch adversarial loss: 0.575080\n",
      "epoch 10; iter: 0; batch classifier loss: 1.445695; batch adversarial loss: 0.532479\n",
      "epoch 11; iter: 0; batch classifier loss: 1.414117; batch adversarial loss: 0.570399\n",
      "epoch 12; iter: 0; batch classifier loss: 1.330219; batch adversarial loss: 0.512153\n",
      "epoch 13; iter: 0; batch classifier loss: 0.698002; batch adversarial loss: 0.517790\n",
      "epoch 14; iter: 0; batch classifier loss: 0.688759; batch adversarial loss: 0.519691\n",
      "epoch 15; iter: 0; batch classifier loss: 0.539930; batch adversarial loss: 0.461985\n",
      "epoch 16; iter: 0; batch classifier loss: 0.546435; batch adversarial loss: 0.464519\n",
      "epoch 17; iter: 0; batch classifier loss: 0.522541; batch adversarial loss: 0.436409\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500558; batch adversarial loss: 0.441402\n",
      "epoch 19; iter: 0; batch classifier loss: 0.469072; batch adversarial loss: 0.390354\n",
      "epoch 20; iter: 0; batch classifier loss: 0.644401; batch adversarial loss: 0.475329\n",
      "epoch 21; iter: 0; batch classifier loss: 0.526330; batch adversarial loss: 0.495741\n",
      "epoch 22; iter: 0; batch classifier loss: 0.544852; batch adversarial loss: 0.350230\n",
      "epoch 23; iter: 0; batch classifier loss: 0.577052; batch adversarial loss: 0.454023\n",
      "epoch 24; iter: 0; batch classifier loss: 0.540583; batch adversarial loss: 0.444757\n",
      "epoch 25; iter: 0; batch classifier loss: 0.621796; batch adversarial loss: 0.466520\n",
      "epoch 26; iter: 0; batch classifier loss: 0.573043; batch adversarial loss: 0.420412\n",
      "epoch 27; iter: 0; batch classifier loss: 0.513249; batch adversarial loss: 0.436469\n",
      "epoch 28; iter: 0; batch classifier loss: 0.539511; batch adversarial loss: 0.402418\n",
      "epoch 29; iter: 0; batch classifier loss: 0.494128; batch adversarial loss: 0.356693\n",
      "epoch 30; iter: 0; batch classifier loss: 0.539498; batch adversarial loss: 0.506749\n",
      "epoch 31; iter: 0; batch classifier loss: 0.545775; batch adversarial loss: 0.486934\n",
      "epoch 32; iter: 0; batch classifier loss: 0.593748; batch adversarial loss: 0.427081\n",
      "epoch 33; iter: 0; batch classifier loss: 0.602851; batch adversarial loss: 0.516648\n",
      "epoch 34; iter: 0; batch classifier loss: 0.646754; batch adversarial loss: 0.524638\n",
      "epoch 35; iter: 0; batch classifier loss: 0.586304; batch adversarial loss: 0.475419\n",
      "epoch 36; iter: 0; batch classifier loss: 0.707388; batch adversarial loss: 0.427670\n",
      "epoch 37; iter: 0; batch classifier loss: 0.669393; batch adversarial loss: 0.443739\n",
      "epoch 38; iter: 0; batch classifier loss: 0.678554; batch adversarial loss: 0.451910\n",
      "epoch 39; iter: 0; batch classifier loss: 0.693273; batch adversarial loss: 0.447013\n",
      "epoch 40; iter: 0; batch classifier loss: 0.703473; batch adversarial loss: 0.465264\n",
      "epoch 41; iter: 0; batch classifier loss: 0.714244; batch adversarial loss: 0.397489\n",
      "epoch 42; iter: 0; batch classifier loss: 0.767916; batch adversarial loss: 0.475272\n",
      "epoch 43; iter: 0; batch classifier loss: 0.670735; batch adversarial loss: 0.443490\n",
      "epoch 44; iter: 0; batch classifier loss: 0.528428; batch adversarial loss: 0.455207\n",
      "epoch 45; iter: 0; batch classifier loss: 0.626921; batch adversarial loss: 0.465678\n",
      "epoch 46; iter: 0; batch classifier loss: 0.554853; batch adversarial loss: 0.475313\n",
      "epoch 47; iter: 0; batch classifier loss: 0.511077; batch adversarial loss: 0.415233\n",
      "epoch 48; iter: 0; batch classifier loss: 0.498358; batch adversarial loss: 0.368235\n",
      "epoch 49; iter: 0; batch classifier loss: 0.521991; batch adversarial loss: 0.461653\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701046\n",
      "epoch 1; iter: 0; batch classifier loss: 0.505219\n",
      "epoch 2; iter: 0; batch classifier loss: 0.537135\n",
      "epoch 3; iter: 0; batch classifier loss: 0.464495\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546764\n",
      "epoch 5; iter: 0; batch classifier loss: 0.537935\n",
      "epoch 6; iter: 0; batch classifier loss: 0.502623\n",
      "epoch 7; iter: 0; batch classifier loss: 0.577423\n",
      "epoch 8; iter: 0; batch classifier loss: 0.543630\n",
      "epoch 9; iter: 0; batch classifier loss: 0.508195\n",
      "epoch 10; iter: 0; batch classifier loss: 0.500044\n",
      "epoch 11; iter: 0; batch classifier loss: 0.549791\n",
      "epoch 12; iter: 0; batch classifier loss: 0.512916\n",
      "epoch 13; iter: 0; batch classifier loss: 0.507984\n",
      "epoch 14; iter: 0; batch classifier loss: 0.569682\n",
      "epoch 15; iter: 0; batch classifier loss: 0.585331\n",
      "epoch 16; iter: 0; batch classifier loss: 0.494782\n",
      "epoch 17; iter: 0; batch classifier loss: 0.561285\n",
      "epoch 18; iter: 0; batch classifier loss: 0.524264\n",
      "epoch 19; iter: 0; batch classifier loss: 0.516141\n",
      "epoch 20; iter: 0; batch classifier loss: 0.614863\n",
      "epoch 21; iter: 0; batch classifier loss: 0.541018\n",
      "epoch 22; iter: 0; batch classifier loss: 0.513022\n",
      "epoch 23; iter: 0; batch classifier loss: 0.545104\n",
      "epoch 24; iter: 0; batch classifier loss: 0.580014\n",
      "epoch 25; iter: 0; batch classifier loss: 0.489262\n",
      "epoch 26; iter: 0; batch classifier loss: 0.517652\n",
      "epoch 27; iter: 0; batch classifier loss: 0.510711\n",
      "epoch 28; iter: 0; batch classifier loss: 0.520553\n",
      "epoch 29; iter: 0; batch classifier loss: 0.467993\n",
      "epoch 30; iter: 0; batch classifier loss: 0.565572\n",
      "epoch 31; iter: 0; batch classifier loss: 0.548429\n",
      "epoch 32; iter: 0; batch classifier loss: 0.512855\n",
      "epoch 33; iter: 0; batch classifier loss: 0.507615\n",
      "epoch 34; iter: 0; batch classifier loss: 0.543758\n",
      "epoch 35; iter: 0; batch classifier loss: 0.499284\n",
      "epoch 36; iter: 0; batch classifier loss: 0.554082\n",
      "epoch 37; iter: 0; batch classifier loss: 0.553373\n",
      "epoch 38; iter: 0; batch classifier loss: 0.522832\n",
      "epoch 39; iter: 0; batch classifier loss: 0.535370\n",
      "epoch 40; iter: 0; batch classifier loss: 0.561592\n",
      "epoch 41; iter: 0; batch classifier loss: 0.566535\n",
      "epoch 42; iter: 0; batch classifier loss: 0.568928\n",
      "epoch 43; iter: 0; batch classifier loss: 0.550886\n",
      "epoch 44; iter: 0; batch classifier loss: 0.497187\n",
      "epoch 45; iter: 0; batch classifier loss: 0.560677\n",
      "epoch 46; iter: 0; batch classifier loss: 0.554081\n",
      "epoch 47; iter: 0; batch classifier loss: 0.507996\n",
      "epoch 48; iter: 0; batch classifier loss: 0.497069\n",
      "epoch 49; iter: 0; batch classifier loss: 0.527725\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692640; batch adversarial loss: 0.735020\n",
      "epoch 1; iter: 0; batch classifier loss: 0.667328; batch adversarial loss: 0.750565\n",
      "epoch 2; iter: 0; batch classifier loss: 0.655781; batch adversarial loss: 0.750747\n",
      "epoch 3; iter: 0; batch classifier loss: 0.645298; batch adversarial loss: 0.746403\n",
      "epoch 4; iter: 0; batch classifier loss: 0.630292; batch adversarial loss: 0.751761\n",
      "epoch 5; iter: 0; batch classifier loss: 0.608596; batch adversarial loss: 0.746954\n",
      "epoch 6; iter: 0; batch classifier loss: 0.635469; batch adversarial loss: 0.728037\n",
      "epoch 7; iter: 0; batch classifier loss: 0.592205; batch adversarial loss: 0.742119\n",
      "epoch 8; iter: 0; batch classifier loss: 0.630911; batch adversarial loss: 0.725217\n",
      "epoch 9; iter: 0; batch classifier loss: 0.580991; batch adversarial loss: 0.726938\n",
      "epoch 10; iter: 0; batch classifier loss: 0.651524; batch adversarial loss: 0.715481\n",
      "epoch 11; iter: 0; batch classifier loss: 0.592517; batch adversarial loss: 0.721559\n",
      "epoch 12; iter: 0; batch classifier loss: 0.598386; batch adversarial loss: 0.715243\n",
      "epoch 13; iter: 0; batch classifier loss: 0.597243; batch adversarial loss: 0.720449\n",
      "epoch 14; iter: 0; batch classifier loss: 0.581877; batch adversarial loss: 0.695595\n",
      "epoch 15; iter: 0; batch classifier loss: 0.561229; batch adversarial loss: 0.715091\n",
      "epoch 16; iter: 0; batch classifier loss: 0.624211; batch adversarial loss: 0.690508\n",
      "epoch 17; iter: 0; batch classifier loss: 0.569184; batch adversarial loss: 0.692116\n",
      "epoch 18; iter: 0; batch classifier loss: 0.567895; batch adversarial loss: 0.691834\n",
      "epoch 19; iter: 0; batch classifier loss: 0.617462; batch adversarial loss: 0.696815\n",
      "epoch 20; iter: 0; batch classifier loss: 0.557840; batch adversarial loss: 0.687534\n",
      "epoch 21; iter: 0; batch classifier loss: 0.580844; batch adversarial loss: 0.679224\n",
      "epoch 22; iter: 0; batch classifier loss: 0.559504; batch adversarial loss: 0.680134\n",
      "epoch 23; iter: 0; batch classifier loss: 0.598872; batch adversarial loss: 0.671778\n",
      "epoch 24; iter: 0; batch classifier loss: 0.565652; batch adversarial loss: 0.664858\n",
      "epoch 25; iter: 0; batch classifier loss: 0.525408; batch adversarial loss: 0.668155\n",
      "epoch 26; iter: 0; batch classifier loss: 0.604303; batch adversarial loss: 0.651636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.522979; batch adversarial loss: 0.656417\n",
      "epoch 28; iter: 0; batch classifier loss: 0.554475; batch adversarial loss: 0.653743\n",
      "epoch 29; iter: 0; batch classifier loss: 0.518278; batch adversarial loss: 0.660175\n",
      "epoch 30; iter: 0; batch classifier loss: 0.586933; batch adversarial loss: 0.641512\n",
      "epoch 31; iter: 0; batch classifier loss: 0.580953; batch adversarial loss: 0.629487\n",
      "epoch 32; iter: 0; batch classifier loss: 0.663458; batch adversarial loss: 0.626686\n",
      "epoch 33; iter: 0; batch classifier loss: 0.597421; batch adversarial loss: 0.638406\n",
      "epoch 34; iter: 0; batch classifier loss: 0.491358; batch adversarial loss: 0.618261\n",
      "epoch 35; iter: 0; batch classifier loss: 0.572421; batch adversarial loss: 0.639410\n",
      "epoch 36; iter: 0; batch classifier loss: 0.578668; batch adversarial loss: 0.628781\n",
      "epoch 37; iter: 0; batch classifier loss: 0.525672; batch adversarial loss: 0.622967\n",
      "epoch 38; iter: 0; batch classifier loss: 0.571856; batch adversarial loss: 0.625723\n",
      "epoch 39; iter: 0; batch classifier loss: 0.546238; batch adversarial loss: 0.599115\n",
      "epoch 40; iter: 0; batch classifier loss: 0.541113; batch adversarial loss: 0.601001\n",
      "epoch 41; iter: 0; batch classifier loss: 0.529485; batch adversarial loss: 0.590318\n",
      "epoch 42; iter: 0; batch classifier loss: 0.489287; batch adversarial loss: 0.610729\n",
      "epoch 43; iter: 0; batch classifier loss: 0.546476; batch adversarial loss: 0.588310\n",
      "epoch 44; iter: 0; batch classifier loss: 0.551974; batch adversarial loss: 0.601963\n",
      "epoch 45; iter: 0; batch classifier loss: 0.549759; batch adversarial loss: 0.576178\n",
      "epoch 46; iter: 0; batch classifier loss: 0.488115; batch adversarial loss: 0.575227\n",
      "epoch 47; iter: 0; batch classifier loss: 0.550229; batch adversarial loss: 0.580158\n",
      "epoch 48; iter: 0; batch classifier loss: 0.538825; batch adversarial loss: 0.586908\n",
      "epoch 49; iter: 0; batch classifier loss: 0.513872; batch adversarial loss: 0.560474\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719855\n",
      "epoch 1; iter: 0; batch classifier loss: 0.650556\n",
      "epoch 2; iter: 0; batch classifier loss: 0.646847\n",
      "epoch 3; iter: 0; batch classifier loss: 0.611476\n",
      "epoch 4; iter: 0; batch classifier loss: 0.625617\n",
      "epoch 5; iter: 0; batch classifier loss: 0.556048\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584534\n",
      "epoch 7; iter: 0; batch classifier loss: 0.651776\n",
      "epoch 8; iter: 0; batch classifier loss: 0.543600\n",
      "epoch 9; iter: 0; batch classifier loss: 0.598473\n",
      "epoch 10; iter: 0; batch classifier loss: 0.581080\n",
      "epoch 11; iter: 0; batch classifier loss: 0.603857\n",
      "epoch 12; iter: 0; batch classifier loss: 0.565642\n",
      "epoch 13; iter: 0; batch classifier loss: 0.590098\n",
      "epoch 14; iter: 0; batch classifier loss: 0.542075\n",
      "epoch 15; iter: 0; batch classifier loss: 0.661730\n",
      "epoch 16; iter: 0; batch classifier loss: 0.585643\n",
      "epoch 17; iter: 0; batch classifier loss: 0.590583\n",
      "epoch 18; iter: 0; batch classifier loss: 0.561153\n",
      "epoch 19; iter: 0; batch classifier loss: 0.581923\n",
      "epoch 20; iter: 0; batch classifier loss: 0.550478\n",
      "epoch 21; iter: 0; batch classifier loss: 0.545613\n",
      "epoch 22; iter: 0; batch classifier loss: 0.567521\n",
      "epoch 23; iter: 0; batch classifier loss: 0.534112\n",
      "epoch 24; iter: 0; batch classifier loss: 0.556610\n",
      "epoch 25; iter: 0; batch classifier loss: 0.509564\n",
      "epoch 26; iter: 0; batch classifier loss: 0.571854\n",
      "epoch 27; iter: 0; batch classifier loss: 0.506182\n",
      "epoch 28; iter: 0; batch classifier loss: 0.552689\n",
      "epoch 29; iter: 0; batch classifier loss: 0.600361\n",
      "epoch 30; iter: 0; batch classifier loss: 0.553029\n",
      "epoch 31; iter: 0; batch classifier loss: 0.546404\n",
      "epoch 32; iter: 0; batch classifier loss: 0.608195\n",
      "epoch 33; iter: 0; batch classifier loss: 0.607633\n",
      "epoch 34; iter: 0; batch classifier loss: 0.533765\n",
      "epoch 35; iter: 0; batch classifier loss: 0.546352\n",
      "epoch 36; iter: 0; batch classifier loss: 0.515545\n",
      "epoch 37; iter: 0; batch classifier loss: 0.570128\n",
      "epoch 38; iter: 0; batch classifier loss: 0.647274\n",
      "epoch 39; iter: 0; batch classifier loss: 0.620820\n",
      "epoch 40; iter: 0; batch classifier loss: 0.596126\n",
      "epoch 41; iter: 0; batch classifier loss: 0.551246\n",
      "epoch 42; iter: 0; batch classifier loss: 0.541037\n",
      "epoch 43; iter: 0; batch classifier loss: 0.537179\n",
      "epoch 44; iter: 0; batch classifier loss: 0.536034\n",
      "epoch 45; iter: 0; batch classifier loss: 0.499581\n",
      "epoch 46; iter: 0; batch classifier loss: 0.557693\n",
      "epoch 47; iter: 0; batch classifier loss: 0.491060\n",
      "epoch 48; iter: 0; batch classifier loss: 0.558268\n",
      "epoch 49; iter: 0; batch classifier loss: 0.538477\n",
      "run = 2\n",
      "epoch 0; iter: 0; batch classifier loss: 0.777035; batch adversarial loss: 0.772861\n",
      "epoch 1; iter: 0; batch classifier loss: 0.563075; batch adversarial loss: 0.823459\n",
      "epoch 2; iter: 0; batch classifier loss: 0.525161; batch adversarial loss: 0.766283\n",
      "epoch 3; iter: 0; batch classifier loss: 0.609195; batch adversarial loss: 0.712483\n",
      "epoch 4; iter: 0; batch classifier loss: 0.579823; batch adversarial loss: 0.656841\n",
      "epoch 5; iter: 0; batch classifier loss: 0.617064; batch adversarial loss: 0.608865\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569583; batch adversarial loss: 0.569203\n",
      "epoch 7; iter: 0; batch classifier loss: 0.591675; batch adversarial loss: 0.565782\n",
      "epoch 8; iter: 0; batch classifier loss: 0.620098; batch adversarial loss: 0.585823\n",
      "epoch 9; iter: 0; batch classifier loss: 0.689167; batch adversarial loss: 0.547991\n",
      "epoch 10; iter: 0; batch classifier loss: 0.797216; batch adversarial loss: 0.517213\n",
      "epoch 11; iter: 0; batch classifier loss: 0.798511; batch adversarial loss: 0.543015\n",
      "epoch 12; iter: 0; batch classifier loss: 0.925424; batch adversarial loss: 0.560862\n",
      "epoch 13; iter: 0; batch classifier loss: 1.056794; batch adversarial loss: 0.543502\n",
      "epoch 14; iter: 0; batch classifier loss: 1.057714; batch adversarial loss: 0.523405\n",
      "epoch 15; iter: 0; batch classifier loss: 1.190157; batch adversarial loss: 0.510075\n",
      "epoch 16; iter: 0; batch classifier loss: 0.967865; batch adversarial loss: 0.491781\n",
      "epoch 17; iter: 0; batch classifier loss: 0.991944; batch adversarial loss: 0.512378\n",
      "epoch 18; iter: 0; batch classifier loss: 0.767496; batch adversarial loss: 0.477539\n",
      "epoch 19; iter: 0; batch classifier loss: 0.801990; batch adversarial loss: 0.453324\n",
      "epoch 20; iter: 0; batch classifier loss: 0.742120; batch adversarial loss: 0.476462\n",
      "epoch 21; iter: 0; batch classifier loss: 0.705912; batch adversarial loss: 0.466007\n",
      "epoch 22; iter: 0; batch classifier loss: 0.711678; batch adversarial loss: 0.435597\n",
      "epoch 23; iter: 0; batch classifier loss: 0.758620; batch adversarial loss: 0.431367\n",
      "epoch 24; iter: 0; batch classifier loss: 0.667304; batch adversarial loss: 0.478643\n",
      "epoch 25; iter: 0; batch classifier loss: 0.698950; batch adversarial loss: 0.492555\n",
      "epoch 26; iter: 0; batch classifier loss: 0.744754; batch adversarial loss: 0.446447\n",
      "epoch 27; iter: 0; batch classifier loss: 0.823069; batch adversarial loss: 0.472440\n",
      "epoch 28; iter: 0; batch classifier loss: 0.759220; batch adversarial loss: 0.455504\n",
      "epoch 29; iter: 0; batch classifier loss: 0.698888; batch adversarial loss: 0.490343\n",
      "epoch 30; iter: 0; batch classifier loss: 0.721968; batch adversarial loss: 0.432425\n",
      "epoch 31; iter: 0; batch classifier loss: 0.715148; batch adversarial loss: 0.389119\n",
      "epoch 32; iter: 0; batch classifier loss: 0.737178; batch adversarial loss: 0.395934\n",
      "epoch 33; iter: 0; batch classifier loss: 0.760973; batch adversarial loss: 0.490025\n",
      "epoch 34; iter: 0; batch classifier loss: 0.657146; batch adversarial loss: 0.390487\n",
      "epoch 35; iter: 0; batch classifier loss: 0.605019; batch adversarial loss: 0.378716\n",
      "epoch 36; iter: 0; batch classifier loss: 0.536300; batch adversarial loss: 0.364515\n",
      "epoch 37; iter: 0; batch classifier loss: 0.553522; batch adversarial loss: 0.458824\n",
      "epoch 38; iter: 0; batch classifier loss: 0.576399; batch adversarial loss: 0.345045\n",
      "epoch 39; iter: 0; batch classifier loss: 0.559198; batch adversarial loss: 0.401391\n",
      "epoch 40; iter: 0; batch classifier loss: 0.598412; batch adversarial loss: 0.377943\n",
      "epoch 41; iter: 0; batch classifier loss: 0.573842; batch adversarial loss: 0.337916\n",
      "epoch 42; iter: 0; batch classifier loss: 0.527834; batch adversarial loss: 0.433078\n",
      "epoch 43; iter: 0; batch classifier loss: 0.601741; batch adversarial loss: 0.429191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 0; batch classifier loss: 0.602327; batch adversarial loss: 0.418692\n",
      "epoch 45; iter: 0; batch classifier loss: 0.617552; batch adversarial loss: 0.416115\n",
      "epoch 46; iter: 0; batch classifier loss: 0.571668; batch adversarial loss: 0.388498\n",
      "epoch 47; iter: 0; batch classifier loss: 0.548667; batch adversarial loss: 0.414087\n",
      "epoch 48; iter: 0; batch classifier loss: 0.604904; batch adversarial loss: 0.403004\n",
      "epoch 49; iter: 0; batch classifier loss: 0.539955; batch adversarial loss: 0.353197\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688293\n",
      "epoch 1; iter: 0; batch classifier loss: 0.621244\n",
      "epoch 2; iter: 0; batch classifier loss: 0.601939\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614821\n",
      "epoch 4; iter: 0; batch classifier loss: 0.518311\n",
      "epoch 5; iter: 0; batch classifier loss: 0.602846\n",
      "epoch 6; iter: 0; batch classifier loss: 0.561570\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578488\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560114\n",
      "epoch 9; iter: 0; batch classifier loss: 0.598935\n",
      "epoch 10; iter: 0; batch classifier loss: 0.566600\n",
      "epoch 11; iter: 0; batch classifier loss: 0.566343\n",
      "epoch 12; iter: 0; batch classifier loss: 0.574851\n",
      "epoch 13; iter: 0; batch classifier loss: 0.610367\n",
      "epoch 14; iter: 0; batch classifier loss: 0.543239\n",
      "epoch 15; iter: 0; batch classifier loss: 0.540832\n",
      "epoch 16; iter: 0; batch classifier loss: 0.571389\n",
      "epoch 17; iter: 0; batch classifier loss: 0.619838\n",
      "epoch 18; iter: 0; batch classifier loss: 0.586314\n",
      "epoch 19; iter: 0; batch classifier loss: 0.575194\n",
      "epoch 20; iter: 0; batch classifier loss: 0.569796\n",
      "epoch 21; iter: 0; batch classifier loss: 0.591501\n",
      "epoch 22; iter: 0; batch classifier loss: 0.555118\n",
      "epoch 23; iter: 0; batch classifier loss: 0.589751\n",
      "epoch 24; iter: 0; batch classifier loss: 0.580961\n",
      "epoch 25; iter: 0; batch classifier loss: 0.501222\n",
      "epoch 26; iter: 0; batch classifier loss: 0.598960\n",
      "epoch 27; iter: 0; batch classifier loss: 0.550485\n",
      "epoch 28; iter: 0; batch classifier loss: 0.530014\n",
      "epoch 29; iter: 0; batch classifier loss: 0.550022\n",
      "epoch 30; iter: 0; batch classifier loss: 0.586412\n",
      "epoch 31; iter: 0; batch classifier loss: 0.484702\n",
      "epoch 32; iter: 0; batch classifier loss: 0.516015\n",
      "epoch 33; iter: 0; batch classifier loss: 0.581908\n",
      "epoch 34; iter: 0; batch classifier loss: 0.608842\n",
      "epoch 35; iter: 0; batch classifier loss: 0.548237\n",
      "epoch 36; iter: 0; batch classifier loss: 0.600422\n",
      "epoch 37; iter: 0; batch classifier loss: 0.565490\n",
      "epoch 38; iter: 0; batch classifier loss: 0.509722\n",
      "epoch 39; iter: 0; batch classifier loss: 0.539507\n",
      "epoch 40; iter: 0; batch classifier loss: 0.636784\n",
      "epoch 41; iter: 0; batch classifier loss: 0.563144\n",
      "epoch 42; iter: 0; batch classifier loss: 0.573823\n",
      "epoch 43; iter: 0; batch classifier loss: 0.561132\n",
      "epoch 44; iter: 0; batch classifier loss: 0.562441\n",
      "epoch 45; iter: 0; batch classifier loss: 0.504165\n",
      "epoch 46; iter: 0; batch classifier loss: 0.554066\n",
      "epoch 47; iter: 0; batch classifier loss: 0.476635\n",
      "epoch 48; iter: 0; batch classifier loss: 0.534803\n",
      "epoch 49; iter: 0; batch classifier loss: 0.480555\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707152; batch adversarial loss: 0.717887\n",
      "epoch 1; iter: 0; batch classifier loss: 0.692686; batch adversarial loss: 0.706423\n",
      "epoch 2; iter: 0; batch classifier loss: 0.672307; batch adversarial loss: 0.706555\n",
      "epoch 3; iter: 0; batch classifier loss: 0.660183; batch adversarial loss: 0.697630\n",
      "epoch 4; iter: 0; batch classifier loss: 0.617351; batch adversarial loss: 0.712764\n",
      "epoch 5; iter: 0; batch classifier loss: 0.587275; batch adversarial loss: 0.707773\n",
      "epoch 6; iter: 0; batch classifier loss: 0.652073; batch adversarial loss: 0.672071\n",
      "epoch 7; iter: 0; batch classifier loss: 0.608591; batch adversarial loss: 0.689947\n",
      "epoch 8; iter: 0; batch classifier loss: 0.574220; batch adversarial loss: 0.692409\n",
      "epoch 9; iter: 0; batch classifier loss: 0.572533; batch adversarial loss: 0.678057\n",
      "epoch 10; iter: 0; batch classifier loss: 0.553108; batch adversarial loss: 0.671323\n",
      "epoch 11; iter: 0; batch classifier loss: 0.577228; batch adversarial loss: 0.666753\n",
      "epoch 12; iter: 0; batch classifier loss: 0.655848; batch adversarial loss: 0.652075\n",
      "epoch 13; iter: 0; batch classifier loss: 0.527158; batch adversarial loss: 0.659924\n",
      "epoch 14; iter: 0; batch classifier loss: 0.558562; batch adversarial loss: 0.658410\n",
      "epoch 15; iter: 0; batch classifier loss: 0.536476; batch adversarial loss: 0.661478\n",
      "epoch 16; iter: 0; batch classifier loss: 0.595884; batch adversarial loss: 0.633439\n",
      "epoch 17; iter: 0; batch classifier loss: 0.654218; batch adversarial loss: 0.623714\n",
      "epoch 18; iter: 0; batch classifier loss: 0.579044; batch adversarial loss: 0.630762\n",
      "epoch 19; iter: 0; batch classifier loss: 0.580098; batch adversarial loss: 0.624238\n",
      "epoch 20; iter: 0; batch classifier loss: 0.633901; batch adversarial loss: 0.608074\n",
      "epoch 21; iter: 0; batch classifier loss: 0.514425; batch adversarial loss: 0.619887\n",
      "epoch 22; iter: 0; batch classifier loss: 0.585185; batch adversarial loss: 0.591439\n",
      "epoch 23; iter: 0; batch classifier loss: 0.585761; batch adversarial loss: 0.588593\n",
      "epoch 24; iter: 0; batch classifier loss: 0.628063; batch adversarial loss: 0.589650\n",
      "epoch 25; iter: 0; batch classifier loss: 0.608080; batch adversarial loss: 0.566065\n",
      "epoch 26; iter: 0; batch classifier loss: 0.539903; batch adversarial loss: 0.600081\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495349; batch adversarial loss: 0.597417\n",
      "epoch 28; iter: 0; batch classifier loss: 0.553141; batch adversarial loss: 0.595484\n",
      "epoch 29; iter: 0; batch classifier loss: 0.591053; batch adversarial loss: 0.572004\n",
      "epoch 30; iter: 0; batch classifier loss: 0.559399; batch adversarial loss: 0.571588\n",
      "epoch 31; iter: 0; batch classifier loss: 0.528167; batch adversarial loss: 0.583666\n",
      "epoch 32; iter: 0; batch classifier loss: 0.611318; batch adversarial loss: 0.570781\n",
      "epoch 33; iter: 0; batch classifier loss: 0.596015; batch adversarial loss: 0.565658\n",
      "epoch 34; iter: 0; batch classifier loss: 0.487591; batch adversarial loss: 0.584644\n",
      "epoch 35; iter: 0; batch classifier loss: 0.574861; batch adversarial loss: 0.562448\n",
      "epoch 36; iter: 0; batch classifier loss: 0.562945; batch adversarial loss: 0.550759\n",
      "epoch 37; iter: 0; batch classifier loss: 0.634792; batch adversarial loss: 0.549577\n",
      "epoch 38; iter: 0; batch classifier loss: 0.567019; batch adversarial loss: 0.563667\n",
      "epoch 39; iter: 0; batch classifier loss: 0.560430; batch adversarial loss: 0.544433\n",
      "epoch 40; iter: 0; batch classifier loss: 0.560252; batch adversarial loss: 0.545288\n",
      "epoch 41; iter: 0; batch classifier loss: 0.557346; batch adversarial loss: 0.570669\n",
      "epoch 42; iter: 0; batch classifier loss: 0.648539; batch adversarial loss: 0.527316\n",
      "epoch 43; iter: 0; batch classifier loss: 0.618427; batch adversarial loss: 0.574131\n",
      "epoch 44; iter: 0; batch classifier loss: 0.627134; batch adversarial loss: 0.552870\n",
      "epoch 45; iter: 0; batch classifier loss: 0.605017; batch adversarial loss: 0.517635\n",
      "epoch 46; iter: 0; batch classifier loss: 0.572763; batch adversarial loss: 0.522521\n",
      "epoch 47; iter: 0; batch classifier loss: 0.601746; batch adversarial loss: 0.568091\n",
      "epoch 48; iter: 0; batch classifier loss: 0.561762; batch adversarial loss: 0.499791\n",
      "epoch 49; iter: 0; batch classifier loss: 0.609676; batch adversarial loss: 0.508601\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735828\n",
      "epoch 1; iter: 0; batch classifier loss: 0.701388\n",
      "epoch 2; iter: 0; batch classifier loss: 0.636319\n",
      "epoch 3; iter: 0; batch classifier loss: 0.596174\n",
      "epoch 4; iter: 0; batch classifier loss: 0.549136\n",
      "epoch 5; iter: 0; batch classifier loss: 0.752545\n",
      "epoch 6; iter: 0; batch classifier loss: 0.604711\n",
      "epoch 7; iter: 0; batch classifier loss: 0.564035\n",
      "epoch 8; iter: 0; batch classifier loss: 0.612899\n",
      "epoch 9; iter: 0; batch classifier loss: 0.609145\n",
      "epoch 10; iter: 0; batch classifier loss: 0.592512\n",
      "epoch 11; iter: 0; batch classifier loss: 0.558509\n",
      "epoch 12; iter: 0; batch classifier loss: 0.576587\n",
      "epoch 13; iter: 0; batch classifier loss: 0.636260\n",
      "epoch 14; iter: 0; batch classifier loss: 0.565483\n",
      "epoch 15; iter: 0; batch classifier loss: 0.596786\n",
      "epoch 16; iter: 0; batch classifier loss: 0.494497\n",
      "epoch 17; iter: 0; batch classifier loss: 0.575946\n",
      "epoch 18; iter: 0; batch classifier loss: 0.599269\n",
      "epoch 19; iter: 0; batch classifier loss: 0.537412\n",
      "epoch 20; iter: 0; batch classifier loss: 0.564567\n",
      "epoch 21; iter: 0; batch classifier loss: 0.568209\n",
      "epoch 22; iter: 0; batch classifier loss: 0.583840\n",
      "epoch 23; iter: 0; batch classifier loss: 0.554724\n",
      "epoch 24; iter: 0; batch classifier loss: 0.536908\n",
      "epoch 25; iter: 0; batch classifier loss: 0.519123\n",
      "epoch 26; iter: 0; batch classifier loss: 0.574219\n",
      "epoch 27; iter: 0; batch classifier loss: 0.550502\n",
      "epoch 28; iter: 0; batch classifier loss: 0.555429\n",
      "epoch 29; iter: 0; batch classifier loss: 0.525864\n",
      "epoch 30; iter: 0; batch classifier loss: 0.555550\n",
      "epoch 31; iter: 0; batch classifier loss: 0.518897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 0; batch classifier loss: 0.572948\n",
      "epoch 33; iter: 0; batch classifier loss: 0.554013\n",
      "epoch 34; iter: 0; batch classifier loss: 0.533113\n",
      "epoch 35; iter: 0; batch classifier loss: 0.591745\n",
      "epoch 36; iter: 0; batch classifier loss: 0.542216\n",
      "epoch 37; iter: 0; batch classifier loss: 0.546634\n",
      "epoch 38; iter: 0; batch classifier loss: 0.639741\n",
      "epoch 39; iter: 0; batch classifier loss: 0.566085\n",
      "epoch 40; iter: 0; batch classifier loss: 0.585894\n",
      "epoch 41; iter: 0; batch classifier loss: 0.607124\n",
      "epoch 42; iter: 0; batch classifier loss: 0.579273\n",
      "epoch 43; iter: 0; batch classifier loss: 0.567551\n",
      "epoch 44; iter: 0; batch classifier loss: 0.612624\n",
      "epoch 45; iter: 0; batch classifier loss: 0.614969\n",
      "epoch 46; iter: 0; batch classifier loss: 0.633535\n",
      "epoch 47; iter: 0; batch classifier loss: 0.610719\n",
      "epoch 48; iter: 0; batch classifier loss: 0.553526\n",
      "epoch 49; iter: 0; batch classifier loss: 0.623612\n",
      "run = 3\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711024; batch adversarial loss: 0.532993\n",
      "epoch 1; iter: 0; batch classifier loss: 0.654848; batch adversarial loss: 0.558099\n",
      "epoch 2; iter: 0; batch classifier loss: 0.686874; batch adversarial loss: 0.738419\n",
      "epoch 3; iter: 0; batch classifier loss: 1.017050; batch adversarial loss: 0.690597\n",
      "epoch 4; iter: 0; batch classifier loss: 1.445708; batch adversarial loss: 0.824538\n",
      "epoch 5; iter: 0; batch classifier loss: 1.485109; batch adversarial loss: 0.730273\n",
      "epoch 6; iter: 0; batch classifier loss: 1.541476; batch adversarial loss: 0.736279\n",
      "epoch 7; iter: 0; batch classifier loss: 1.444312; batch adversarial loss: 0.661165\n",
      "epoch 8; iter: 0; batch classifier loss: 1.494375; batch adversarial loss: 0.613490\n",
      "epoch 9; iter: 0; batch classifier loss: 1.517634; batch adversarial loss: 0.685559\n",
      "epoch 10; iter: 0; batch classifier loss: 1.424345; batch adversarial loss: 0.634502\n",
      "epoch 11; iter: 0; batch classifier loss: 1.599755; batch adversarial loss: 0.563086\n",
      "epoch 12; iter: 0; batch classifier loss: 1.572136; batch adversarial loss: 0.641488\n",
      "epoch 13; iter: 0; batch classifier loss: 1.710197; batch adversarial loss: 0.553845\n",
      "epoch 14; iter: 0; batch classifier loss: 1.400591; batch adversarial loss: 0.591934\n",
      "epoch 15; iter: 0; batch classifier loss: 1.284643; batch adversarial loss: 0.549336\n",
      "epoch 16; iter: 0; batch classifier loss: 1.401106; batch adversarial loss: 0.467258\n",
      "epoch 17; iter: 0; batch classifier loss: 1.253026; batch adversarial loss: 0.513387\n",
      "epoch 18; iter: 0; batch classifier loss: 1.128142; batch adversarial loss: 0.463843\n",
      "epoch 19; iter: 0; batch classifier loss: 0.894261; batch adversarial loss: 0.439830\n",
      "epoch 20; iter: 0; batch classifier loss: 0.795000; batch adversarial loss: 0.427124\n",
      "epoch 21; iter: 0; batch classifier loss: 0.584587; batch adversarial loss: 0.425238\n",
      "epoch 22; iter: 0; batch classifier loss: 0.629102; batch adversarial loss: 0.407558\n",
      "epoch 23; iter: 0; batch classifier loss: 0.614101; batch adversarial loss: 0.404334\n",
      "epoch 24; iter: 0; batch classifier loss: 0.577770; batch adversarial loss: 0.425231\n",
      "epoch 25; iter: 0; batch classifier loss: 0.557739; batch adversarial loss: 0.427928\n",
      "epoch 26; iter: 0; batch classifier loss: 0.451462; batch adversarial loss: 0.465210\n",
      "epoch 27; iter: 0; batch classifier loss: 0.593013; batch adversarial loss: 0.469480\n",
      "epoch 28; iter: 0; batch classifier loss: 0.623818; batch adversarial loss: 0.478636\n",
      "epoch 29; iter: 0; batch classifier loss: 0.537855; batch adversarial loss: 0.423594\n",
      "epoch 30; iter: 0; batch classifier loss: 0.576752; batch adversarial loss: 0.422092\n",
      "epoch 31; iter: 0; batch classifier loss: 0.515236; batch adversarial loss: 0.494202\n",
      "epoch 32; iter: 0; batch classifier loss: 0.575089; batch adversarial loss: 0.494548\n",
      "epoch 33; iter: 0; batch classifier loss: 0.591130; batch adversarial loss: 0.467237\n",
      "epoch 34; iter: 0; batch classifier loss: 0.543566; batch adversarial loss: 0.371595\n",
      "epoch 35; iter: 0; batch classifier loss: 0.563598; batch adversarial loss: 0.432078\n",
      "epoch 36; iter: 0; batch classifier loss: 0.598417; batch adversarial loss: 0.420052\n",
      "epoch 37; iter: 0; batch classifier loss: 0.451234; batch adversarial loss: 0.428883\n",
      "epoch 38; iter: 0; batch classifier loss: 0.536155; batch adversarial loss: 0.405787\n",
      "epoch 39; iter: 0; batch classifier loss: 0.527051; batch adversarial loss: 0.405415\n",
      "epoch 40; iter: 0; batch classifier loss: 0.518325; batch adversarial loss: 0.415445\n",
      "epoch 41; iter: 0; batch classifier loss: 0.576274; batch adversarial loss: 0.426260\n",
      "epoch 42; iter: 0; batch classifier loss: 0.636187; batch adversarial loss: 0.428083\n",
      "epoch 43; iter: 0; batch classifier loss: 0.585643; batch adversarial loss: 0.426702\n",
      "epoch 44; iter: 0; batch classifier loss: 0.576549; batch adversarial loss: 0.473993\n",
      "epoch 45; iter: 0; batch classifier loss: 0.564740; batch adversarial loss: 0.475616\n",
      "epoch 46; iter: 0; batch classifier loss: 0.637000; batch adversarial loss: 0.388765\n",
      "epoch 47; iter: 0; batch classifier loss: 0.534968; batch adversarial loss: 0.399094\n",
      "epoch 48; iter: 0; batch classifier loss: 0.464276; batch adversarial loss: 0.434547\n",
      "epoch 49; iter: 0; batch classifier loss: 0.556815; batch adversarial loss: 0.361979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/ml-19jan/lib/python3.5/site-packages/aif360/metrics/dataset_metric.py:94: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.693104\n",
      "epoch 1; iter: 0; batch classifier loss: 0.580553\n",
      "epoch 2; iter: 0; batch classifier loss: 0.579486\n",
      "epoch 3; iter: 0; batch classifier loss: 0.541208\n",
      "epoch 4; iter: 0; batch classifier loss: 0.534424\n",
      "epoch 5; iter: 0; batch classifier loss: 0.622611\n",
      "epoch 6; iter: 0; batch classifier loss: 0.601624\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542338\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536784\n",
      "epoch 9; iter: 0; batch classifier loss: 0.450423\n",
      "epoch 10; iter: 0; batch classifier loss: 0.563679\n",
      "epoch 11; iter: 0; batch classifier loss: 0.622512\n",
      "epoch 12; iter: 0; batch classifier loss: 0.565020\n",
      "epoch 13; iter: 0; batch classifier loss: 0.567603\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527618\n",
      "epoch 15; iter: 0; batch classifier loss: 0.584911\n",
      "epoch 16; iter: 0; batch classifier loss: 0.533166\n",
      "epoch 17; iter: 0; batch classifier loss: 0.592939\n",
      "epoch 18; iter: 0; batch classifier loss: 0.528569\n",
      "epoch 19; iter: 0; batch classifier loss: 0.526540\n",
      "epoch 20; iter: 0; batch classifier loss: 0.538829\n",
      "epoch 21; iter: 0; batch classifier loss: 0.533776\n",
      "epoch 22; iter: 0; batch classifier loss: 0.481521\n",
      "epoch 23; iter: 0; batch classifier loss: 0.502144\n",
      "epoch 24; iter: 0; batch classifier loss: 0.570062\n",
      "epoch 25; iter: 0; batch classifier loss: 0.624351\n",
      "epoch 26; iter: 0; batch classifier loss: 0.543630\n",
      "epoch 27; iter: 0; batch classifier loss: 0.535570\n",
      "epoch 28; iter: 0; batch classifier loss: 0.514710\n",
      "epoch 29; iter: 0; batch classifier loss: 0.520480\n",
      "epoch 30; iter: 0; batch classifier loss: 0.512323\n",
      "epoch 31; iter: 0; batch classifier loss: 0.524073\n",
      "epoch 32; iter: 0; batch classifier loss: 0.566620\n",
      "epoch 33; iter: 0; batch classifier loss: 0.532268\n",
      "epoch 34; iter: 0; batch classifier loss: 0.598135\n",
      "epoch 35; iter: 0; batch classifier loss: 0.550661\n",
      "epoch 36; iter: 0; batch classifier loss: 0.505168\n",
      "epoch 37; iter: 0; batch classifier loss: 0.548695\n",
      "epoch 38; iter: 0; batch classifier loss: 0.575290\n",
      "epoch 39; iter: 0; batch classifier loss: 0.624044\n",
      "epoch 40; iter: 0; batch classifier loss: 0.610101\n",
      "epoch 41; iter: 0; batch classifier loss: 0.592507\n",
      "epoch 42; iter: 0; batch classifier loss: 0.522117\n",
      "epoch 43; iter: 0; batch classifier loss: 0.562623\n",
      "epoch 44; iter: 0; batch classifier loss: 0.539824\n",
      "epoch 45; iter: 0; batch classifier loss: 0.543800\n",
      "epoch 46; iter: 0; batch classifier loss: 0.574892\n",
      "epoch 47; iter: 0; batch classifier loss: 0.558248\n",
      "epoch 48; iter: 0; batch classifier loss: 0.486916\n",
      "epoch 49; iter: 0; batch classifier loss: 0.518410\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700188; batch adversarial loss: 0.537863\n",
      "epoch 1; iter: 0; batch classifier loss: 0.693542; batch adversarial loss: 0.527230\n",
      "epoch 2; iter: 0; batch classifier loss: 0.698494; batch adversarial loss: 0.580683\n",
      "epoch 3; iter: 0; batch classifier loss: 0.704381; batch adversarial loss: 0.538662\n",
      "epoch 4; iter: 0; batch classifier loss: 0.679198; batch adversarial loss: 0.538428\n",
      "epoch 5; iter: 0; batch classifier loss: 0.681446; batch adversarial loss: 0.492511\n",
      "epoch 6; iter: 0; batch classifier loss: 0.669506; batch adversarial loss: 0.498560\n",
      "epoch 7; iter: 0; batch classifier loss: 0.682047; batch adversarial loss: 0.529271\n",
      "epoch 8; iter: 0; batch classifier loss: 0.699492; batch adversarial loss: 0.533349\n",
      "epoch 9; iter: 0; batch classifier loss: 0.656896; batch adversarial loss: 0.537916\n",
      "epoch 10; iter: 0; batch classifier loss: 0.655500; batch adversarial loss: 0.567666\n",
      "epoch 11; iter: 0; batch classifier loss: 0.666625; batch adversarial loss: 0.560815\n",
      "epoch 12; iter: 0; batch classifier loss: 0.706905; batch adversarial loss: 0.486185\n",
      "epoch 13; iter: 0; batch classifier loss: 0.714021; batch adversarial loss: 0.567083\n",
      "epoch 14; iter: 0; batch classifier loss: 0.646520; batch adversarial loss: 0.594309\n",
      "epoch 15; iter: 0; batch classifier loss: 0.690244; batch adversarial loss: 0.528467\n",
      "epoch 16; iter: 0; batch classifier loss: 0.729996; batch adversarial loss: 0.622541\n",
      "epoch 17; iter: 0; batch classifier loss: 0.772710; batch adversarial loss: 0.601129\n",
      "epoch 18; iter: 0; batch classifier loss: 0.742848; batch adversarial loss: 0.607655\n",
      "epoch 19; iter: 0; batch classifier loss: 0.782891; batch adversarial loss: 0.660943\n",
      "epoch 20; iter: 0; batch classifier loss: 0.778561; batch adversarial loss: 0.638932\n",
      "epoch 21; iter: 0; batch classifier loss: 0.820721; batch adversarial loss: 0.648420\n",
      "epoch 22; iter: 0; batch classifier loss: 0.903895; batch adversarial loss: 0.681568\n",
      "epoch 23; iter: 0; batch classifier loss: 0.902894; batch adversarial loss: 0.648905\n",
      "epoch 24; iter: 0; batch classifier loss: 0.948035; batch adversarial loss: 0.696269\n",
      "epoch 25; iter: 0; batch classifier loss: 1.018772; batch adversarial loss: 0.677514\n",
      "epoch 26; iter: 0; batch classifier loss: 1.022193; batch adversarial loss: 0.700208\n",
      "epoch 27; iter: 0; batch classifier loss: 1.062030; batch adversarial loss: 0.787308\n",
      "epoch 28; iter: 0; batch classifier loss: 1.109540; batch adversarial loss: 0.727606\n",
      "epoch 29; iter: 0; batch classifier loss: 1.040991; batch adversarial loss: 0.810367\n",
      "epoch 30; iter: 0; batch classifier loss: 1.056671; batch adversarial loss: 0.817849\n",
      "epoch 31; iter: 0; batch classifier loss: 1.107800; batch adversarial loss: 0.719999\n",
      "epoch 32; iter: 0; batch classifier loss: 1.040939; batch adversarial loss: 0.785275\n",
      "epoch 33; iter: 0; batch classifier loss: 1.061206; batch adversarial loss: 0.706627\n",
      "epoch 34; iter: 0; batch classifier loss: 1.221277; batch adversarial loss: 0.721362\n",
      "epoch 35; iter: 0; batch classifier loss: 1.207626; batch adversarial loss: 0.781562\n",
      "epoch 36; iter: 0; batch classifier loss: 1.273146; batch adversarial loss: 0.751213\n",
      "epoch 37; iter: 0; batch classifier loss: 1.313767; batch adversarial loss: 0.779035\n",
      "epoch 38; iter: 0; batch classifier loss: 1.351160; batch adversarial loss: 0.719424\n",
      "epoch 39; iter: 0; batch classifier loss: 1.230927; batch adversarial loss: 0.690576\n",
      "epoch 40; iter: 0; batch classifier loss: 1.110722; batch adversarial loss: 0.788652\n",
      "epoch 41; iter: 0; batch classifier loss: 1.385813; batch adversarial loss: 0.702697\n",
      "epoch 42; iter: 0; batch classifier loss: 1.498899; batch adversarial loss: 0.643724\n",
      "epoch 43; iter: 0; batch classifier loss: 1.300238; batch adversarial loss: 0.791843\n",
      "epoch 44; iter: 0; batch classifier loss: 1.385281; batch adversarial loss: 0.727413\n",
      "epoch 45; iter: 0; batch classifier loss: 1.530364; batch adversarial loss: 0.610825\n",
      "epoch 46; iter: 0; batch classifier loss: 1.310493; batch adversarial loss: 0.763044\n",
      "epoch 47; iter: 0; batch classifier loss: 1.391930; batch adversarial loss: 0.700758\n",
      "epoch 48; iter: 0; batch classifier loss: 1.453860; batch adversarial loss: 0.749835\n",
      "epoch 49; iter: 0; batch classifier loss: 1.520141; batch adversarial loss: 0.709270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/ml-19jan/lib/python3.5/site-packages/aif360/metrics/dataset_metric.py:94: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n",
      "/home/dani/anaconda3/envs/ml-19jan/lib/python3.5/site-packages/aif360/metrics/dataset_metric.py:94: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.816431\n",
      "epoch 1; iter: 0; batch classifier loss: 0.702971\n",
      "epoch 2; iter: 0; batch classifier loss: 0.635845\n",
      "epoch 3; iter: 0; batch classifier loss: 0.617653\n",
      "epoch 4; iter: 0; batch classifier loss: 0.616171\n",
      "epoch 5; iter: 0; batch classifier loss: 0.592608\n",
      "epoch 6; iter: 0; batch classifier loss: 0.569600\n",
      "epoch 7; iter: 0; batch classifier loss: 0.533720\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569033\n",
      "epoch 9; iter: 0; batch classifier loss: 0.557028\n",
      "epoch 10; iter: 0; batch classifier loss: 0.616117\n",
      "epoch 11; iter: 0; batch classifier loss: 0.621454\n",
      "epoch 12; iter: 0; batch classifier loss: 0.535182\n",
      "epoch 13; iter: 0; batch classifier loss: 0.613529\n",
      "epoch 14; iter: 0; batch classifier loss: 0.591001\n",
      "epoch 15; iter: 0; batch classifier loss: 0.553849\n",
      "epoch 16; iter: 0; batch classifier loss: 0.635578\n",
      "epoch 17; iter: 0; batch classifier loss: 0.576323\n",
      "epoch 18; iter: 0; batch classifier loss: 0.587110\n",
      "epoch 19; iter: 0; batch classifier loss: 0.585198\n",
      "epoch 20; iter: 0; batch classifier loss: 0.527555\n",
      "epoch 21; iter: 0; batch classifier loss: 0.557611\n",
      "epoch 22; iter: 0; batch classifier loss: 0.549341\n",
      "epoch 23; iter: 0; batch classifier loss: 0.518991\n",
      "epoch 24; iter: 0; batch classifier loss: 0.516744\n",
      "epoch 25; iter: 0; batch classifier loss: 0.682405\n",
      "epoch 26; iter: 0; batch classifier loss: 0.564963\n",
      "epoch 27; iter: 0; batch classifier loss: 0.486892\n",
      "epoch 28; iter: 0; batch classifier loss: 0.495274\n",
      "epoch 29; iter: 0; batch classifier loss: 0.564157\n",
      "epoch 30; iter: 0; batch classifier loss: 0.538104\n",
      "epoch 31; iter: 0; batch classifier loss: 0.556083\n",
      "epoch 32; iter: 0; batch classifier loss: 0.509843\n",
      "epoch 33; iter: 0; batch classifier loss: 0.562966\n",
      "epoch 34; iter: 0; batch classifier loss: 0.460336\n",
      "epoch 35; iter: 0; batch classifier loss: 0.516483\n",
      "epoch 36; iter: 0; batch classifier loss: 0.609658\n",
      "epoch 37; iter: 0; batch classifier loss: 0.544979\n",
      "epoch 38; iter: 0; batch classifier loss: 0.497609\n",
      "epoch 39; iter: 0; batch classifier loss: 0.494497\n",
      "epoch 40; iter: 0; batch classifier loss: 0.592379\n",
      "epoch 41; iter: 0; batch classifier loss: 0.525755\n",
      "epoch 42; iter: 0; batch classifier loss: 0.624105\n",
      "epoch 43; iter: 0; batch classifier loss: 0.580888\n",
      "epoch 44; iter: 0; batch classifier loss: 0.529488\n",
      "epoch 45; iter: 0; batch classifier loss: 0.548906\n",
      "epoch 46; iter: 0; batch classifier loss: 0.591293\n",
      "epoch 47; iter: 0; batch classifier loss: 0.571809\n",
      "epoch 48; iter: 0; batch classifier loss: 0.563640\n",
      "epoch 49; iter: 0; batch classifier loss: 0.522200\n",
      "run = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/ml-19jan/lib/python3.5/site-packages/aif360/metrics/dataset_metric.py:94: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.675849; batch adversarial loss: 0.818154\n",
      "epoch 1; iter: 0; batch classifier loss: 0.576158; batch adversarial loss: 0.817597\n",
      "epoch 2; iter: 0; batch classifier loss: 0.590116; batch adversarial loss: 0.739295\n",
      "epoch 3; iter: 0; batch classifier loss: 0.540204; batch adversarial loss: 0.713532\n",
      "epoch 4; iter: 0; batch classifier loss: 0.602613; batch adversarial loss: 0.633636\n",
      "epoch 5; iter: 0; batch classifier loss: 0.559575; batch adversarial loss: 0.610656\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573209; batch adversarial loss: 0.600644\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558276; batch adversarial loss: 0.531098\n",
      "epoch 8; iter: 0; batch classifier loss: 0.582423; batch adversarial loss: 0.564062\n",
      "epoch 9; iter: 0; batch classifier loss: 0.484346; batch adversarial loss: 0.527473\n",
      "epoch 10; iter: 0; batch classifier loss: 0.584288; batch adversarial loss: 0.504771\n",
      "epoch 11; iter: 0; batch classifier loss: 0.604133; batch adversarial loss: 0.475657\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537843; batch adversarial loss: 0.470426\n",
      "epoch 13; iter: 0; batch classifier loss: 0.510838; batch adversarial loss: 0.487725\n",
      "epoch 14; iter: 0; batch classifier loss: 0.590279; batch adversarial loss: 0.455073\n",
      "epoch 15; iter: 0; batch classifier loss: 0.553627; batch adversarial loss: 0.433068\n",
      "epoch 16; iter: 0; batch classifier loss: 0.616186; batch adversarial loss: 0.548533\n",
      "epoch 17; iter: 0; batch classifier loss: 0.609817; batch adversarial loss: 0.449416\n",
      "epoch 18; iter: 0; batch classifier loss: 0.664042; batch adversarial loss: 0.481381\n",
      "epoch 19; iter: 0; batch classifier loss: 0.642102; batch adversarial loss: 0.503036\n",
      "epoch 20; iter: 0; batch classifier loss: 0.711565; batch adversarial loss: 0.475350\n",
      "epoch 21; iter: 0; batch classifier loss: 0.723431; batch adversarial loss: 0.468111\n",
      "epoch 22; iter: 0; batch classifier loss: 0.798607; batch adversarial loss: 0.497497\n",
      "epoch 23; iter: 0; batch classifier loss: 0.755609; batch adversarial loss: 0.542927\n",
      "epoch 24; iter: 0; batch classifier loss: 0.731530; batch adversarial loss: 0.475033\n",
      "epoch 25; iter: 0; batch classifier loss: 0.773123; batch adversarial loss: 0.466848\n",
      "epoch 26; iter: 0; batch classifier loss: 0.819460; batch adversarial loss: 0.511721\n",
      "epoch 27; iter: 0; batch classifier loss: 0.820292; batch adversarial loss: 0.486057\n",
      "epoch 28; iter: 0; batch classifier loss: 0.751638; batch adversarial loss: 0.445662\n",
      "epoch 29; iter: 0; batch classifier loss: 0.770179; batch adversarial loss: 0.465901\n",
      "epoch 30; iter: 0; batch classifier loss: 0.810307; batch adversarial loss: 0.443691\n",
      "epoch 31; iter: 0; batch classifier loss: 0.809270; batch adversarial loss: 0.472173\n",
      "epoch 32; iter: 0; batch classifier loss: 0.708039; batch adversarial loss: 0.387944\n",
      "epoch 33; iter: 0; batch classifier loss: 0.709993; batch adversarial loss: 0.457730\n",
      "epoch 34; iter: 0; batch classifier loss: 0.708076; batch adversarial loss: 0.448170\n",
      "epoch 35; iter: 0; batch classifier loss: 0.728460; batch adversarial loss: 0.475569\n",
      "epoch 36; iter: 0; batch classifier loss: 0.651620; batch adversarial loss: 0.429231\n",
      "epoch 37; iter: 0; batch classifier loss: 0.705682; batch adversarial loss: 0.546422\n",
      "epoch 38; iter: 0; batch classifier loss: 0.670363; batch adversarial loss: 0.380443\n",
      "epoch 39; iter: 0; batch classifier loss: 0.630076; batch adversarial loss: 0.537633\n",
      "epoch 40; iter: 0; batch classifier loss: 0.689450; batch adversarial loss: 0.366526\n",
      "epoch 41; iter: 0; batch classifier loss: 0.663736; batch adversarial loss: 0.363275\n",
      "epoch 42; iter: 0; batch classifier loss: 0.625410; batch adversarial loss: 0.437400\n",
      "epoch 43; iter: 0; batch classifier loss: 0.588467; batch adversarial loss: 0.444749\n",
      "epoch 44; iter: 0; batch classifier loss: 0.571863; batch adversarial loss: 0.354994\n",
      "epoch 45; iter: 0; batch classifier loss: 0.634277; batch adversarial loss: 0.363803\n",
      "epoch 46; iter: 0; batch classifier loss: 0.518595; batch adversarial loss: 0.374419\n",
      "epoch 47; iter: 0; batch classifier loss: 0.634709; batch adversarial loss: 0.373128\n",
      "epoch 48; iter: 0; batch classifier loss: 0.576295; batch adversarial loss: 0.451248\n",
      "epoch 49; iter: 0; batch classifier loss: 0.653130; batch adversarial loss: 0.382196\n",
      "epoch 0; iter: 0; batch classifier loss: 0.746917\n",
      "epoch 1; iter: 0; batch classifier loss: 0.552351\n",
      "epoch 2; iter: 0; batch classifier loss: 0.499331\n",
      "epoch 3; iter: 0; batch classifier loss: 0.610919\n",
      "epoch 4; iter: 0; batch classifier loss: 0.621783\n",
      "epoch 5; iter: 0; batch classifier loss: 0.566554\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535902\n",
      "epoch 7; iter: 0; batch classifier loss: 0.516685\n",
      "epoch 8; iter: 0; batch classifier loss: 0.565419\n",
      "epoch 9; iter: 0; batch classifier loss: 0.569783\n",
      "epoch 10; iter: 0; batch classifier loss: 0.492822\n",
      "epoch 11; iter: 0; batch classifier loss: 0.570252\n",
      "epoch 12; iter: 0; batch classifier loss: 0.596334\n",
      "epoch 13; iter: 0; batch classifier loss: 0.572501\n",
      "epoch 14; iter: 0; batch classifier loss: 0.558319\n",
      "epoch 15; iter: 0; batch classifier loss: 0.507151\n",
      "epoch 16; iter: 0; batch classifier loss: 0.575903\n",
      "epoch 17; iter: 0; batch classifier loss: 0.607960\n",
      "epoch 18; iter: 0; batch classifier loss: 0.567335\n",
      "epoch 19; iter: 0; batch classifier loss: 0.477620\n",
      "epoch 20; iter: 0; batch classifier loss: 0.540742\n",
      "epoch 21; iter: 0; batch classifier loss: 0.578451\n",
      "epoch 22; iter: 0; batch classifier loss: 0.535515\n",
      "epoch 23; iter: 0; batch classifier loss: 0.610758\n",
      "epoch 24; iter: 0; batch classifier loss: 0.491967\n",
      "epoch 25; iter: 0; batch classifier loss: 0.569506\n",
      "epoch 26; iter: 0; batch classifier loss: 0.559949\n",
      "epoch 27; iter: 0; batch classifier loss: 0.556318\n",
      "epoch 28; iter: 0; batch classifier loss: 0.628471\n",
      "epoch 29; iter: 0; batch classifier loss: 0.573313\n",
      "epoch 30; iter: 0; batch classifier loss: 0.553607\n",
      "epoch 31; iter: 0; batch classifier loss: 0.496296\n",
      "epoch 32; iter: 0; batch classifier loss: 0.562222\n",
      "epoch 33; iter: 0; batch classifier loss: 0.628019\n",
      "epoch 34; iter: 0; batch classifier loss: 0.468694\n",
      "epoch 35; iter: 0; batch classifier loss: 0.551273\n",
      "epoch 36; iter: 0; batch classifier loss: 0.597363\n",
      "epoch 37; iter: 0; batch classifier loss: 0.549415\n",
      "epoch 38; iter: 0; batch classifier loss: 0.528803\n",
      "epoch 39; iter: 0; batch classifier loss: 0.568085\n",
      "epoch 40; iter: 0; batch classifier loss: 0.571636\n",
      "epoch 41; iter: 0; batch classifier loss: 0.526941\n",
      "epoch 42; iter: 0; batch classifier loss: 0.556258\n",
      "epoch 43; iter: 0; batch classifier loss: 0.494904\n",
      "epoch 44; iter: 0; batch classifier loss: 0.633871\n",
      "epoch 45; iter: 0; batch classifier loss: 0.550102\n",
      "epoch 46; iter: 0; batch classifier loss: 0.564042\n",
      "epoch 47; iter: 0; batch classifier loss: 0.564393\n",
      "epoch 48; iter: 0; batch classifier loss: 0.560950\n",
      "epoch 49; iter: 0; batch classifier loss: 0.531901\n",
      "epoch 0; iter: 0; batch classifier loss: 0.688778; batch adversarial loss: 0.611280\n",
      "epoch 1; iter: 0; batch classifier loss: 0.663142; batch adversarial loss: 0.578925\n",
      "epoch 2; iter: 0; batch classifier loss: 0.608658; batch adversarial loss: 0.650946\n",
      "epoch 3; iter: 0; batch classifier loss: 0.618914; batch adversarial loss: 0.601407\n",
      "epoch 4; iter: 0; batch classifier loss: 0.601036; batch adversarial loss: 0.620171\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594174; batch adversarial loss: 0.596721\n",
      "epoch 6; iter: 0; batch classifier loss: 0.570010; batch adversarial loss: 0.576319\n",
      "epoch 7; iter: 0; batch classifier loss: 0.594624; batch adversarial loss: 0.583323\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555655; batch adversarial loss: 0.625153\n",
      "epoch 9; iter: 0; batch classifier loss: 0.587657; batch adversarial loss: 0.680536\n",
      "epoch 10; iter: 0; batch classifier loss: 0.632977; batch adversarial loss: 0.597050\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564419; batch adversarial loss: 0.579598\n",
      "epoch 12; iter: 0; batch classifier loss: 0.600281; batch adversarial loss: 0.574356\n",
      "epoch 13; iter: 0; batch classifier loss: 0.591534; batch adversarial loss: 0.582440\n",
      "epoch 14; iter: 0; batch classifier loss: 0.542538; batch adversarial loss: 0.575440\n",
      "epoch 15; iter: 0; batch classifier loss: 0.541697; batch adversarial loss: 0.551386\n",
      "epoch 16; iter: 0; batch classifier loss: 0.541780; batch adversarial loss: 0.537642\n",
      "epoch 17; iter: 0; batch classifier loss: 0.605547; batch adversarial loss: 0.553296\n",
      "epoch 18; iter: 0; batch classifier loss: 0.606303; batch adversarial loss: 0.508093\n",
      "epoch 19; iter: 0; batch classifier loss: 0.578149; batch adversarial loss: 0.543884\n",
      "epoch 20; iter: 0; batch classifier loss: 0.595550; batch adversarial loss: 0.548653\n",
      "epoch 21; iter: 0; batch classifier loss: 0.606457; batch adversarial loss: 0.550906\n",
      "epoch 22; iter: 0; batch classifier loss: 0.545351; batch adversarial loss: 0.513159\n",
      "epoch 23; iter: 0; batch classifier loss: 0.519195; batch adversarial loss: 0.575920\n",
      "epoch 24; iter: 0; batch classifier loss: 0.532349; batch adversarial loss: 0.509989\n",
      "epoch 25; iter: 0; batch classifier loss: 0.632455; batch adversarial loss: 0.585755\n",
      "epoch 26; iter: 0; batch classifier loss: 0.556451; batch adversarial loss: 0.538094\n",
      "epoch 27; iter: 0; batch classifier loss: 0.604156; batch adversarial loss: 0.510467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.517024; batch adversarial loss: 0.547996\n",
      "epoch 29; iter: 0; batch classifier loss: 0.570432; batch adversarial loss: 0.521699\n",
      "epoch 30; iter: 0; batch classifier loss: 0.572793; batch adversarial loss: 0.584813\n",
      "epoch 31; iter: 0; batch classifier loss: 0.591454; batch adversarial loss: 0.553829\n",
      "epoch 32; iter: 0; batch classifier loss: 0.592458; batch adversarial loss: 0.531183\n",
      "epoch 33; iter: 0; batch classifier loss: 0.559550; batch adversarial loss: 0.562417\n",
      "epoch 34; iter: 0; batch classifier loss: 0.598470; batch adversarial loss: 0.538810\n",
      "epoch 35; iter: 0; batch classifier loss: 0.528333; batch adversarial loss: 0.547468\n",
      "epoch 36; iter: 0; batch classifier loss: 0.569208; batch adversarial loss: 0.513064\n",
      "epoch 37; iter: 0; batch classifier loss: 0.578394; batch adversarial loss: 0.566724\n",
      "epoch 38; iter: 0; batch classifier loss: 0.563903; batch adversarial loss: 0.563797\n",
      "epoch 39; iter: 0; batch classifier loss: 0.577622; batch adversarial loss: 0.553983\n",
      "epoch 40; iter: 0; batch classifier loss: 0.555742; batch adversarial loss: 0.603317\n",
      "epoch 41; iter: 0; batch classifier loss: 0.523468; batch adversarial loss: 0.553828\n",
      "epoch 42; iter: 0; batch classifier loss: 0.607067; batch adversarial loss: 0.537442\n",
      "epoch 43; iter: 0; batch classifier loss: 0.566650; batch adversarial loss: 0.506332\n",
      "epoch 44; iter: 0; batch classifier loss: 0.598311; batch adversarial loss: 0.523082\n",
      "epoch 45; iter: 0; batch classifier loss: 0.517912; batch adversarial loss: 0.578888\n",
      "epoch 46; iter: 0; batch classifier loss: 0.567875; batch adversarial loss: 0.505072\n",
      "epoch 47; iter: 0; batch classifier loss: 0.590143; batch adversarial loss: 0.555253\n",
      "epoch 48; iter: 0; batch classifier loss: 0.589869; batch adversarial loss: 0.521891\n",
      "epoch 49; iter: 0; batch classifier loss: 0.546042; batch adversarial loss: 0.611188\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735716\n",
      "epoch 1; iter: 0; batch classifier loss: 0.692175\n",
      "epoch 2; iter: 0; batch classifier loss: 0.629720\n",
      "epoch 3; iter: 0; batch classifier loss: 0.618531\n",
      "epoch 4; iter: 0; batch classifier loss: 0.636964\n",
      "epoch 5; iter: 0; batch classifier loss: 0.652363\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592988\n",
      "epoch 7; iter: 0; batch classifier loss: 0.641764\n",
      "epoch 8; iter: 0; batch classifier loss: 0.609087\n",
      "epoch 9; iter: 0; batch classifier loss: 0.577430\n",
      "epoch 10; iter: 0; batch classifier loss: 0.559498\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526786\n",
      "epoch 12; iter: 0; batch classifier loss: 0.635998\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546976\n",
      "epoch 14; iter: 0; batch classifier loss: 0.493513\n",
      "epoch 15; iter: 0; batch classifier loss: 0.630822\n",
      "epoch 16; iter: 0; batch classifier loss: 0.622155\n",
      "epoch 17; iter: 0; batch classifier loss: 0.576678\n",
      "epoch 18; iter: 0; batch classifier loss: 0.556586\n",
      "epoch 19; iter: 0; batch classifier loss: 0.601418\n",
      "epoch 20; iter: 0; batch classifier loss: 0.581067\n",
      "epoch 21; iter: 0; batch classifier loss: 0.557126\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522504\n",
      "epoch 23; iter: 0; batch classifier loss: 0.480049\n",
      "epoch 24; iter: 0; batch classifier loss: 0.557423\n",
      "epoch 25; iter: 0; batch classifier loss: 0.568429\n",
      "epoch 26; iter: 0; batch classifier loss: 0.540633\n",
      "epoch 27; iter: 0; batch classifier loss: 0.598164\n",
      "epoch 28; iter: 0; batch classifier loss: 0.626244\n",
      "epoch 29; iter: 0; batch classifier loss: 0.547000\n",
      "epoch 30; iter: 0; batch classifier loss: 0.536314\n",
      "epoch 31; iter: 0; batch classifier loss: 0.545237\n",
      "epoch 32; iter: 0; batch classifier loss: 0.562011\n",
      "epoch 33; iter: 0; batch classifier loss: 0.566994\n",
      "epoch 34; iter: 0; batch classifier loss: 0.578294\n",
      "epoch 35; iter: 0; batch classifier loss: 0.533826\n",
      "epoch 36; iter: 0; batch classifier loss: 0.558846\n",
      "epoch 37; iter: 0; batch classifier loss: 0.575264\n",
      "epoch 38; iter: 0; batch classifier loss: 0.523611\n",
      "epoch 39; iter: 0; batch classifier loss: 0.586591\n",
      "epoch 40; iter: 0; batch classifier loss: 0.530692\n",
      "epoch 41; iter: 0; batch classifier loss: 0.487283\n",
      "epoch 42; iter: 0; batch classifier loss: 0.561245\n",
      "epoch 43; iter: 0; batch classifier loss: 0.567717\n",
      "epoch 44; iter: 0; batch classifier loss: 0.504064\n",
      "epoch 45; iter: 0; batch classifier loss: 0.538431\n",
      "epoch 46; iter: 0; batch classifier loss: 0.566910\n",
      "epoch 47; iter: 0; batch classifier loss: 0.543041\n",
      "epoch 48; iter: 0; batch classifier loss: 0.595408\n",
      "epoch 49; iter: 0; batch classifier loss: 0.478983\n",
      "run = 5\n",
      "epoch 0; iter: 0; batch classifier loss: 0.744808; batch adversarial loss: 1.032631\n",
      "epoch 1; iter: 0; batch classifier loss: 0.635329; batch adversarial loss: 1.434869\n",
      "epoch 2; iter: 0; batch classifier loss: 0.641982; batch adversarial loss: 1.310180\n",
      "epoch 3; iter: 0; batch classifier loss: 0.629152; batch adversarial loss: 1.240399\n",
      "epoch 4; iter: 0; batch classifier loss: 0.774426; batch adversarial loss: 1.148325\n",
      "epoch 5; iter: 0; batch classifier loss: 0.705688; batch adversarial loss: 1.091317\n",
      "epoch 6; iter: 0; batch classifier loss: 0.800820; batch adversarial loss: 1.002867\n",
      "epoch 7; iter: 0; batch classifier loss: 0.845504; batch adversarial loss: 0.953940\n",
      "epoch 8; iter: 0; batch classifier loss: 0.822567; batch adversarial loss: 0.892918\n",
      "epoch 9; iter: 0; batch classifier loss: 0.819025; batch adversarial loss: 0.825431\n",
      "epoch 10; iter: 0; batch classifier loss: 0.940795; batch adversarial loss: 0.781984\n",
      "epoch 11; iter: 0; batch classifier loss: 0.701861; batch adversarial loss: 0.698461\n",
      "epoch 12; iter: 0; batch classifier loss: 0.974519; batch adversarial loss: 0.699507\n",
      "epoch 13; iter: 0; batch classifier loss: 0.611320; batch adversarial loss: 0.609894\n",
      "epoch 14; iter: 0; batch classifier loss: 0.752986; batch adversarial loss: 0.590179\n",
      "epoch 15; iter: 0; batch classifier loss: 0.687742; batch adversarial loss: 0.567118\n",
      "epoch 16; iter: 0; batch classifier loss: 0.675687; batch adversarial loss: 0.554545\n",
      "epoch 17; iter: 0; batch classifier loss: 0.593819; batch adversarial loss: 0.527099\n",
      "epoch 18; iter: 0; batch classifier loss: 0.569067; batch adversarial loss: 0.520153\n",
      "epoch 19; iter: 0; batch classifier loss: 0.569906; batch adversarial loss: 0.498943\n",
      "epoch 20; iter: 0; batch classifier loss: 0.553037; batch adversarial loss: 0.387101\n",
      "epoch 21; iter: 0; batch classifier loss: 0.515630; batch adversarial loss: 0.448627\n",
      "epoch 22; iter: 0; batch classifier loss: 0.568530; batch adversarial loss: 0.475839\n",
      "epoch 23; iter: 0; batch classifier loss: 0.549828; batch adversarial loss: 0.439009\n",
      "epoch 24; iter: 0; batch classifier loss: 0.597421; batch adversarial loss: 0.464672\n",
      "epoch 25; iter: 0; batch classifier loss: 0.520584; batch adversarial loss: 0.492343\n",
      "epoch 26; iter: 0; batch classifier loss: 0.575944; batch adversarial loss: 0.421528\n",
      "epoch 27; iter: 0; batch classifier loss: 0.556293; batch adversarial loss: 0.494982\n",
      "epoch 28; iter: 0; batch classifier loss: 0.632284; batch adversarial loss: 0.418830\n",
      "epoch 29; iter: 0; batch classifier loss: 0.580652; batch adversarial loss: 0.463506\n",
      "epoch 30; iter: 0; batch classifier loss: 0.599455; batch adversarial loss: 0.390819\n",
      "epoch 31; iter: 0; batch classifier loss: 0.560556; batch adversarial loss: 0.463073\n",
      "epoch 32; iter: 0; batch classifier loss: 0.616261; batch adversarial loss: 0.446600\n",
      "epoch 33; iter: 0; batch classifier loss: 0.627794; batch adversarial loss: 0.423771\n",
      "epoch 34; iter: 0; batch classifier loss: 0.654031; batch adversarial loss: 0.472349\n",
      "epoch 35; iter: 0; batch classifier loss: 0.640500; batch adversarial loss: 0.392300\n",
      "epoch 36; iter: 0; batch classifier loss: 0.627596; batch adversarial loss: 0.496466\n",
      "epoch 37; iter: 0; batch classifier loss: 0.628653; batch adversarial loss: 0.402181\n",
      "epoch 38; iter: 0; batch classifier loss: 0.627392; batch adversarial loss: 0.388478\n",
      "epoch 39; iter: 0; batch classifier loss: 0.623078; batch adversarial loss: 0.435897\n",
      "epoch 40; iter: 0; batch classifier loss: 0.682064; batch adversarial loss: 0.421898\n",
      "epoch 41; iter: 0; batch classifier loss: 0.596820; batch adversarial loss: 0.365505\n",
      "epoch 42; iter: 0; batch classifier loss: 0.641587; batch adversarial loss: 0.398173\n",
      "epoch 43; iter: 0; batch classifier loss: 0.561114; batch adversarial loss: 0.467349\n",
      "epoch 44; iter: 0; batch classifier loss: 0.570087; batch adversarial loss: 0.454878\n",
      "epoch 45; iter: 0; batch classifier loss: 0.601623; batch adversarial loss: 0.395044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46; iter: 0; batch classifier loss: 0.601499; batch adversarial loss: 0.465041\n",
      "epoch 47; iter: 0; batch classifier loss: 0.605542; batch adversarial loss: 0.593180\n",
      "epoch 48; iter: 0; batch classifier loss: 0.566302; batch adversarial loss: 0.415926\n",
      "epoch 49; iter: 0; batch classifier loss: 0.547996; batch adversarial loss: 0.424902\n",
      "epoch 0; iter: 0; batch classifier loss: 0.746831\n",
      "epoch 1; iter: 0; batch classifier loss: 0.492416\n",
      "epoch 2; iter: 0; batch classifier loss: 0.556462\n",
      "epoch 3; iter: 0; batch classifier loss: 0.547440\n",
      "epoch 4; iter: 0; batch classifier loss: 0.503718\n",
      "epoch 5; iter: 0; batch classifier loss: 0.586589\n",
      "epoch 6; iter: 0; batch classifier loss: 0.555286\n",
      "epoch 7; iter: 0; batch classifier loss: 0.577739\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572143\n",
      "epoch 9; iter: 0; batch classifier loss: 0.640955\n",
      "epoch 10; iter: 0; batch classifier loss: 0.525645\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580873\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550447\n",
      "epoch 13; iter: 0; batch classifier loss: 0.560326\n",
      "epoch 14; iter: 0; batch classifier loss: 0.538050\n",
      "epoch 15; iter: 0; batch classifier loss: 0.575404\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506772\n",
      "epoch 17; iter: 0; batch classifier loss: 0.577542\n",
      "epoch 18; iter: 0; batch classifier loss: 0.559714\n",
      "epoch 19; iter: 0; batch classifier loss: 0.528974\n",
      "epoch 20; iter: 0; batch classifier loss: 0.542574\n",
      "epoch 21; iter: 0; batch classifier loss: 0.626442\n",
      "epoch 22; iter: 0; batch classifier loss: 0.509893\n",
      "epoch 23; iter: 0; batch classifier loss: 0.512214\n",
      "epoch 24; iter: 0; batch classifier loss: 0.620826\n",
      "epoch 25; iter: 0; batch classifier loss: 0.636208\n",
      "epoch 26; iter: 0; batch classifier loss: 0.511177\n",
      "epoch 27; iter: 0; batch classifier loss: 0.565571\n",
      "epoch 28; iter: 0; batch classifier loss: 0.494732\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466609\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480943\n",
      "epoch 31; iter: 0; batch classifier loss: 0.519116\n",
      "epoch 32; iter: 0; batch classifier loss: 0.545578\n",
      "epoch 33; iter: 0; batch classifier loss: 0.566843\n",
      "epoch 34; iter: 0; batch classifier loss: 0.558744\n",
      "epoch 35; iter: 0; batch classifier loss: 0.583135\n",
      "epoch 36; iter: 0; batch classifier loss: 0.509644\n",
      "epoch 37; iter: 0; batch classifier loss: 0.519266\n",
      "epoch 38; iter: 0; batch classifier loss: 0.555426\n",
      "epoch 39; iter: 0; batch classifier loss: 0.583935\n",
      "epoch 40; iter: 0; batch classifier loss: 0.551488\n",
      "epoch 41; iter: 0; batch classifier loss: 0.512972\n",
      "epoch 42; iter: 0; batch classifier loss: 0.548529\n",
      "epoch 43; iter: 0; batch classifier loss: 0.463226\n",
      "epoch 44; iter: 0; batch classifier loss: 0.553541\n",
      "epoch 45; iter: 0; batch classifier loss: 0.573728\n",
      "epoch 46; iter: 0; batch classifier loss: 0.551483\n",
      "epoch 47; iter: 0; batch classifier loss: 0.478887\n",
      "epoch 48; iter: 0; batch classifier loss: 0.520479\n",
      "epoch 49; iter: 0; batch classifier loss: 0.553928\n",
      "epoch 0; iter: 0; batch classifier loss: 0.671290; batch adversarial loss: 0.432079\n",
      "epoch 1; iter: 0; batch classifier loss: 0.667882; batch adversarial loss: 0.489685\n",
      "epoch 2; iter: 0; batch classifier loss: 0.652633; batch adversarial loss: 0.444386\n",
      "epoch 3; iter: 0; batch classifier loss: 0.641820; batch adversarial loss: 0.486479\n",
      "epoch 4; iter: 0; batch classifier loss: 0.644667; batch adversarial loss: 0.486805\n",
      "epoch 5; iter: 0; batch classifier loss: 0.638022; batch adversarial loss: 0.475224\n",
      "epoch 6; iter: 0; batch classifier loss: 0.631847; batch adversarial loss: 0.494929\n",
      "epoch 7; iter: 0; batch classifier loss: 0.612606; batch adversarial loss: 0.549620\n",
      "epoch 8; iter: 0; batch classifier loss: 0.671803; batch adversarial loss: 0.540794\n",
      "epoch 9; iter: 0; batch classifier loss: 0.625573; batch adversarial loss: 0.495256\n",
      "epoch 10; iter: 0; batch classifier loss: 0.647239; batch adversarial loss: 0.545261\n",
      "epoch 11; iter: 0; batch classifier loss: 0.657572; batch adversarial loss: 0.486922\n",
      "epoch 12; iter: 0; batch classifier loss: 0.689384; batch adversarial loss: 0.544528\n",
      "epoch 13; iter: 0; batch classifier loss: 0.640660; batch adversarial loss: 0.514516\n",
      "epoch 14; iter: 0; batch classifier loss: 0.691256; batch adversarial loss: 0.574551\n",
      "epoch 15; iter: 0; batch classifier loss: 0.683977; batch adversarial loss: 0.532158\n",
      "epoch 16; iter: 0; batch classifier loss: 0.719545; batch adversarial loss: 0.561814\n",
      "epoch 17; iter: 0; batch classifier loss: 0.703696; batch adversarial loss: 0.601306\n",
      "epoch 18; iter: 0; batch classifier loss: 0.760147; batch adversarial loss: 0.595916\n",
      "epoch 19; iter: 0; batch classifier loss: 0.708012; batch adversarial loss: 0.606711\n",
      "epoch 20; iter: 0; batch classifier loss: 0.764255; batch adversarial loss: 0.602731\n",
      "epoch 21; iter: 0; batch classifier loss: 0.767003; batch adversarial loss: 0.626751\n",
      "epoch 22; iter: 0; batch classifier loss: 0.810354; batch adversarial loss: 0.677568\n",
      "epoch 23; iter: 0; batch classifier loss: 0.793830; batch adversarial loss: 0.652379\n",
      "epoch 24; iter: 0; batch classifier loss: 0.810131; batch adversarial loss: 0.611499\n",
      "epoch 25; iter: 0; batch classifier loss: 0.851003; batch adversarial loss: 0.643903\n",
      "epoch 26; iter: 0; batch classifier loss: 0.909591; batch adversarial loss: 0.715202\n",
      "epoch 27; iter: 0; batch classifier loss: 0.897904; batch adversarial loss: 0.738666\n",
      "epoch 28; iter: 0; batch classifier loss: 1.021129; batch adversarial loss: 0.711393\n",
      "epoch 29; iter: 0; batch classifier loss: 0.912699; batch adversarial loss: 0.684482\n",
      "epoch 30; iter: 0; batch classifier loss: 1.187040; batch adversarial loss: 0.659562\n",
      "epoch 31; iter: 0; batch classifier loss: 1.018768; batch adversarial loss: 0.681934\n",
      "epoch 32; iter: 0; batch classifier loss: 1.103569; batch adversarial loss: 0.690491\n",
      "epoch 33; iter: 0; batch classifier loss: 1.190042; batch adversarial loss: 0.775394\n",
      "epoch 34; iter: 0; batch classifier loss: 1.131760; batch adversarial loss: 0.814425\n",
      "epoch 35; iter: 0; batch classifier loss: 1.109088; batch adversarial loss: 0.750608\n",
      "epoch 36; iter: 0; batch classifier loss: 1.125135; batch adversarial loss: 0.755215\n",
      "epoch 37; iter: 0; batch classifier loss: 1.372613; batch adversarial loss: 0.702520\n",
      "epoch 38; iter: 0; batch classifier loss: 1.304420; batch adversarial loss: 0.726260\n",
      "epoch 39; iter: 0; batch classifier loss: 1.197897; batch adversarial loss: 0.769510\n",
      "epoch 40; iter: 0; batch classifier loss: 1.307963; batch adversarial loss: 0.748872\n",
      "epoch 41; iter: 0; batch classifier loss: 1.259914; batch adversarial loss: 0.680026\n",
      "epoch 42; iter: 0; batch classifier loss: 1.201638; batch adversarial loss: 0.773581\n",
      "epoch 43; iter: 0; batch classifier loss: 1.392183; batch adversarial loss: 0.733378\n",
      "epoch 44; iter: 0; batch classifier loss: 1.324592; batch adversarial loss: 0.764243\n",
      "epoch 45; iter: 0; batch classifier loss: 1.441066; batch adversarial loss: 0.680751\n",
      "epoch 46; iter: 0; batch classifier loss: 1.436946; batch adversarial loss: 0.672876\n",
      "epoch 47; iter: 0; batch classifier loss: 1.447169; batch adversarial loss: 0.636372\n",
      "epoch 48; iter: 0; batch classifier loss: 1.486421; batch adversarial loss: 0.700627\n",
      "epoch 49; iter: 0; batch classifier loss: 1.475425; batch adversarial loss: 0.644503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/ml-19jan/lib/python3.5/site-packages/aif360/metrics/dataset_metric.py:94: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.673336\n",
      "epoch 1; iter: 0; batch classifier loss: 0.640574\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624743\n",
      "epoch 3; iter: 0; batch classifier loss: 0.608308\n",
      "epoch 4; iter: 0; batch classifier loss: 0.571850\n",
      "epoch 5; iter: 0; batch classifier loss: 0.640897\n",
      "epoch 6; iter: 0; batch classifier loss: 0.533662\n",
      "epoch 7; iter: 0; batch classifier loss: 0.581350\n",
      "epoch 8; iter: 0; batch classifier loss: 0.596267\n",
      "epoch 9; iter: 0; batch classifier loss: 0.568514\n",
      "epoch 10; iter: 0; batch classifier loss: 0.576473\n",
      "epoch 11; iter: 0; batch classifier loss: 0.564663\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562189\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553010\n",
      "epoch 14; iter: 0; batch classifier loss: 0.604539\n",
      "epoch 15; iter: 0; batch classifier loss: 0.586114\n",
      "epoch 16; iter: 0; batch classifier loss: 0.579015\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533936\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501178\n",
      "epoch 19; iter: 0; batch classifier loss: 0.530243\n",
      "epoch 20; iter: 0; batch classifier loss: 0.538534\n",
      "epoch 21; iter: 0; batch classifier loss: 0.546653\n",
      "epoch 22; iter: 0; batch classifier loss: 0.570976\n",
      "epoch 23; iter: 0; batch classifier loss: 0.543897\n",
      "epoch 24; iter: 0; batch classifier loss: 0.539523\n",
      "epoch 25; iter: 0; batch classifier loss: 0.579602\n",
      "epoch 26; iter: 0; batch classifier loss: 0.534504\n",
      "epoch 27; iter: 0; batch classifier loss: 0.587672\n",
      "epoch 28; iter: 0; batch classifier loss: 0.657200\n",
      "epoch 29; iter: 0; batch classifier loss: 0.522998\n",
      "epoch 30; iter: 0; batch classifier loss: 0.586667\n",
      "epoch 31; iter: 0; batch classifier loss: 0.542215\n",
      "epoch 32; iter: 0; batch classifier loss: 0.538888\n",
      "epoch 33; iter: 0; batch classifier loss: 0.573395\n",
      "epoch 34; iter: 0; batch classifier loss: 0.586949\n",
      "epoch 35; iter: 0; batch classifier loss: 0.530237\n",
      "epoch 36; iter: 0; batch classifier loss: 0.621487\n",
      "epoch 37; iter: 0; batch classifier loss: 0.540776\n",
      "epoch 38; iter: 0; batch classifier loss: 0.520319\n",
      "epoch 39; iter: 0; batch classifier loss: 0.500049\n",
      "epoch 40; iter: 0; batch classifier loss: 0.560662\n",
      "epoch 41; iter: 0; batch classifier loss: 0.607513\n",
      "epoch 42; iter: 0; batch classifier loss: 0.538996\n",
      "epoch 43; iter: 0; batch classifier loss: 0.488145\n",
      "epoch 44; iter: 0; batch classifier loss: 0.586729\n",
      "epoch 45; iter: 0; batch classifier loss: 0.618206\n",
      "epoch 46; iter: 0; batch classifier loss: 0.614941\n",
      "epoch 47; iter: 0; batch classifier loss: 0.556989\n",
      "epoch 48; iter: 0; batch classifier loss: 0.536672\n",
      "epoch 49; iter: 0; batch classifier loss: 0.547526\n",
      "run = 6\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718078; batch adversarial loss: 0.598335\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555194; batch adversarial loss: 0.593129\n",
      "epoch 2; iter: 0; batch classifier loss: 0.641686; batch adversarial loss: 0.571614\n",
      "epoch 3; iter: 0; batch classifier loss: 0.648206; batch adversarial loss: 0.515620\n",
      "epoch 4; iter: 0; batch classifier loss: 0.612985; batch adversarial loss: 0.575071\n",
      "epoch 5; iter: 0; batch classifier loss: 0.821197; batch adversarial loss: 0.626341\n",
      "epoch 6; iter: 0; batch classifier loss: 0.915394; batch adversarial loss: 0.598099\n",
      "epoch 7; iter: 0; batch classifier loss: 1.045728; batch adversarial loss: 0.551188\n",
      "epoch 8; iter: 0; batch classifier loss: 1.110174; batch adversarial loss: 0.666152\n",
      "epoch 9; iter: 0; batch classifier loss: 0.964026; batch adversarial loss: 0.579918\n",
      "epoch 10; iter: 0; batch classifier loss: 1.048070; batch adversarial loss: 0.617348\n",
      "epoch 11; iter: 0; batch classifier loss: 0.943665; batch adversarial loss: 0.505516\n",
      "epoch 12; iter: 0; batch classifier loss: 0.943680; batch adversarial loss: 0.534729\n",
      "epoch 13; iter: 0; batch classifier loss: 0.860068; batch adversarial loss: 0.515700\n",
      "epoch 14; iter: 0; batch classifier loss: 0.860128; batch adversarial loss: 0.474344\n",
      "epoch 15; iter: 0; batch classifier loss: 0.840885; batch adversarial loss: 0.450429\n",
      "epoch 16; iter: 0; batch classifier loss: 0.726794; batch adversarial loss: 0.489416\n",
      "epoch 17; iter: 0; batch classifier loss: 0.692023; batch adversarial loss: 0.484065\n",
      "epoch 18; iter: 0; batch classifier loss: 0.758625; batch adversarial loss: 0.452304\n",
      "epoch 19; iter: 0; batch classifier loss: 0.643575; batch adversarial loss: 0.437238\n",
      "epoch 20; iter: 0; batch classifier loss: 0.687063; batch adversarial loss: 0.453509\n",
      "epoch 21; iter: 0; batch classifier loss: 0.649080; batch adversarial loss: 0.437812\n",
      "epoch 22; iter: 0; batch classifier loss: 0.654274; batch adversarial loss: 0.426331\n",
      "epoch 23; iter: 0; batch classifier loss: 0.741433; batch adversarial loss: 0.504024\n",
      "epoch 24; iter: 0; batch classifier loss: 0.680922; batch adversarial loss: 0.464891\n",
      "epoch 25; iter: 0; batch classifier loss: 0.767656; batch adversarial loss: 0.392098\n",
      "epoch 26; iter: 0; batch classifier loss: 0.573630; batch adversarial loss: 0.394481\n",
      "epoch 27; iter: 0; batch classifier loss: 0.699096; batch adversarial loss: 0.437639\n",
      "epoch 28; iter: 0; batch classifier loss: 0.642904; batch adversarial loss: 0.409195\n",
      "epoch 29; iter: 0; batch classifier loss: 0.605119; batch adversarial loss: 0.402714\n",
      "epoch 30; iter: 0; batch classifier loss: 0.652315; batch adversarial loss: 0.417341\n",
      "epoch 31; iter: 0; batch classifier loss: 0.677566; batch adversarial loss: 0.451020\n",
      "epoch 32; iter: 0; batch classifier loss: 0.698322; batch adversarial loss: 0.449403\n",
      "epoch 33; iter: 0; batch classifier loss: 0.586649; batch adversarial loss: 0.448574\n",
      "epoch 34; iter: 0; batch classifier loss: 0.685235; batch adversarial loss: 0.467045\n",
      "epoch 35; iter: 0; batch classifier loss: 0.498889; batch adversarial loss: 0.399674\n",
      "epoch 36; iter: 0; batch classifier loss: 0.582755; batch adversarial loss: 0.412786\n",
      "epoch 37; iter: 0; batch classifier loss: 0.552817; batch adversarial loss: 0.428517\n",
      "epoch 38; iter: 0; batch classifier loss: 0.507352; batch adversarial loss: 0.449658\n",
      "epoch 39; iter: 0; batch classifier loss: 0.621431; batch adversarial loss: 0.412549\n",
      "epoch 40; iter: 0; batch classifier loss: 0.610355; batch adversarial loss: 0.321067\n",
      "epoch 41; iter: 0; batch classifier loss: 0.636846; batch adversarial loss: 0.346460\n",
      "epoch 42; iter: 0; batch classifier loss: 0.572643; batch adversarial loss: 0.410066\n",
      "epoch 43; iter: 0; batch classifier loss: 0.527186; batch adversarial loss: 0.414579\n",
      "epoch 44; iter: 0; batch classifier loss: 0.555501; batch adversarial loss: 0.342754\n",
      "epoch 45; iter: 0; batch classifier loss: 0.662208; batch adversarial loss: 0.369511\n",
      "epoch 46; iter: 0; batch classifier loss: 0.548757; batch adversarial loss: 0.404952\n",
      "epoch 47; iter: 0; batch classifier loss: 0.581979; batch adversarial loss: 0.416099\n",
      "epoch 48; iter: 0; batch classifier loss: 0.583424; batch adversarial loss: 0.427135\n",
      "epoch 49; iter: 0; batch classifier loss: 0.545226; batch adversarial loss: 0.413063\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722530\n",
      "epoch 1; iter: 0; batch classifier loss: 0.589141\n",
      "epoch 2; iter: 0; batch classifier loss: 0.553557\n",
      "epoch 3; iter: 0; batch classifier loss: 0.520829\n",
      "epoch 4; iter: 0; batch classifier loss: 0.528736\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532943\n",
      "epoch 6; iter: 0; batch classifier loss: 0.528910\n",
      "epoch 7; iter: 0; batch classifier loss: 0.513509\n",
      "epoch 8; iter: 0; batch classifier loss: 0.621983\n",
      "epoch 9; iter: 0; batch classifier loss: 0.645580\n",
      "epoch 10; iter: 0; batch classifier loss: 0.549776\n",
      "epoch 11; iter: 0; batch classifier loss: 0.561262\n",
      "epoch 12; iter: 0; batch classifier loss: 0.530875\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494635\n",
      "epoch 14; iter: 0; batch classifier loss: 0.583904\n",
      "epoch 15; iter: 0; batch classifier loss: 0.542503\n",
      "epoch 16; iter: 0; batch classifier loss: 0.606189\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521485\n",
      "epoch 18; iter: 0; batch classifier loss: 0.558180\n",
      "epoch 19; iter: 0; batch classifier loss: 0.635210\n",
      "epoch 20; iter: 0; batch classifier loss: 0.479435\n",
      "epoch 21; iter: 0; batch classifier loss: 0.511796\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491987\n",
      "epoch 23; iter: 0; batch classifier loss: 0.579323\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468300\n",
      "epoch 25; iter: 0; batch classifier loss: 0.543715\n",
      "epoch 26; iter: 0; batch classifier loss: 0.584900\n",
      "epoch 27; iter: 0; batch classifier loss: 0.551702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.511918\n",
      "epoch 29; iter: 0; batch classifier loss: 0.557005\n",
      "epoch 30; iter: 0; batch classifier loss: 0.567182\n",
      "epoch 31; iter: 0; batch classifier loss: 0.565138\n",
      "epoch 32; iter: 0; batch classifier loss: 0.591647\n",
      "epoch 33; iter: 0; batch classifier loss: 0.565492\n",
      "epoch 34; iter: 0; batch classifier loss: 0.534327\n",
      "epoch 35; iter: 0; batch classifier loss: 0.516916\n",
      "epoch 36; iter: 0; batch classifier loss: 0.528872\n",
      "epoch 37; iter: 0; batch classifier loss: 0.546089\n",
      "epoch 38; iter: 0; batch classifier loss: 0.588805\n",
      "epoch 39; iter: 0; batch classifier loss: 0.506699\n",
      "epoch 40; iter: 0; batch classifier loss: 0.571846\n",
      "epoch 41; iter: 0; batch classifier loss: 0.542204\n",
      "epoch 42; iter: 0; batch classifier loss: 0.542332\n",
      "epoch 43; iter: 0; batch classifier loss: 0.588624\n",
      "epoch 44; iter: 0; batch classifier loss: 0.517549\n",
      "epoch 45; iter: 0; batch classifier loss: 0.612746\n",
      "epoch 46; iter: 0; batch classifier loss: 0.515197\n",
      "epoch 47; iter: 0; batch classifier loss: 0.516575\n",
      "epoch 48; iter: 0; batch classifier loss: 0.577100\n",
      "epoch 49; iter: 0; batch classifier loss: 0.563427\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685540; batch adversarial loss: 0.934793\n",
      "epoch 1; iter: 0; batch classifier loss: 0.649751; batch adversarial loss: 0.922281\n",
      "epoch 2; iter: 0; batch classifier loss: 0.617567; batch adversarial loss: 0.878245\n",
      "epoch 3; iter: 0; batch classifier loss: 0.584196; batch adversarial loss: 0.942067\n",
      "epoch 4; iter: 0; batch classifier loss: 0.567922; batch adversarial loss: 0.888250\n",
      "epoch 5; iter: 0; batch classifier loss: 0.589498; batch adversarial loss: 0.972923\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548410; batch adversarial loss: 0.972203\n",
      "epoch 7; iter: 0; batch classifier loss: 0.587696; batch adversarial loss: 0.960999\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520592; batch adversarial loss: 0.939937\n",
      "epoch 9; iter: 0; batch classifier loss: 0.490095; batch adversarial loss: 0.955146\n",
      "epoch 10; iter: 0; batch classifier loss: 0.479729; batch adversarial loss: 0.879307\n",
      "epoch 11; iter: 0; batch classifier loss: 0.620316; batch adversarial loss: 1.038713\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562926; batch adversarial loss: 0.971088\n",
      "epoch 13; iter: 0; batch classifier loss: 0.541403; batch adversarial loss: 0.934709\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540293; batch adversarial loss: 0.947640\n",
      "epoch 15; iter: 0; batch classifier loss: 0.568620; batch adversarial loss: 0.978172\n",
      "epoch 16; iter: 0; batch classifier loss: 0.634852; batch adversarial loss: 0.963201\n",
      "epoch 17; iter: 0; batch classifier loss: 0.624823; batch adversarial loss: 0.973785\n",
      "epoch 18; iter: 0; batch classifier loss: 0.629800; batch adversarial loss: 0.963166\n",
      "epoch 19; iter: 0; batch classifier loss: 0.606446; batch adversarial loss: 0.905543\n",
      "epoch 20; iter: 0; batch classifier loss: 0.678368; batch adversarial loss: 1.044725\n",
      "epoch 21; iter: 0; batch classifier loss: 0.507702; batch adversarial loss: 0.870113\n",
      "epoch 22; iter: 0; batch classifier loss: 0.597052; batch adversarial loss: 0.905058\n",
      "epoch 23; iter: 0; batch classifier loss: 0.531552; batch adversarial loss: 0.901152\n",
      "epoch 24; iter: 0; batch classifier loss: 0.639826; batch adversarial loss: 0.981686\n",
      "epoch 25; iter: 0; batch classifier loss: 0.563007; batch adversarial loss: 0.901255\n",
      "epoch 26; iter: 0; batch classifier loss: 0.617517; batch adversarial loss: 0.867342\n",
      "epoch 27; iter: 0; batch classifier loss: 0.653610; batch adversarial loss: 0.910310\n",
      "epoch 28; iter: 0; batch classifier loss: 0.736650; batch adversarial loss: 0.970494\n",
      "epoch 29; iter: 0; batch classifier loss: 0.647271; batch adversarial loss: 0.927110\n",
      "epoch 30; iter: 0; batch classifier loss: 0.555311; batch adversarial loss: 0.865769\n",
      "epoch 31; iter: 0; batch classifier loss: 0.644864; batch adversarial loss: 0.923714\n",
      "epoch 32; iter: 0; batch classifier loss: 0.709824; batch adversarial loss: 0.945292\n",
      "epoch 33; iter: 0; batch classifier loss: 0.661781; batch adversarial loss: 0.903653\n",
      "epoch 34; iter: 0; batch classifier loss: 0.559465; batch adversarial loss: 0.813967\n",
      "epoch 35; iter: 0; batch classifier loss: 0.611778; batch adversarial loss: 0.866756\n",
      "epoch 36; iter: 0; batch classifier loss: 0.597343; batch adversarial loss: 0.844135\n",
      "epoch 37; iter: 0; batch classifier loss: 0.603400; batch adversarial loss: 0.856826\n",
      "epoch 38; iter: 0; batch classifier loss: 0.710190; batch adversarial loss: 0.920596\n",
      "epoch 39; iter: 0; batch classifier loss: 0.578720; batch adversarial loss: 0.807279\n",
      "epoch 40; iter: 0; batch classifier loss: 0.576538; batch adversarial loss: 0.814378\n",
      "epoch 41; iter: 0; batch classifier loss: 0.606676; batch adversarial loss: 0.833349\n",
      "epoch 42; iter: 0; batch classifier loss: 0.687438; batch adversarial loss: 0.867449\n",
      "epoch 43; iter: 0; batch classifier loss: 0.642149; batch adversarial loss: 0.849321\n",
      "epoch 44; iter: 0; batch classifier loss: 0.728200; batch adversarial loss: 0.879892\n",
      "epoch 45; iter: 0; batch classifier loss: 0.611654; batch adversarial loss: 0.811449\n",
      "epoch 46; iter: 0; batch classifier loss: 0.609000; batch adversarial loss: 0.805442\n",
      "epoch 47; iter: 0; batch classifier loss: 0.622036; batch adversarial loss: 0.792106\n",
      "epoch 48; iter: 0; batch classifier loss: 0.601950; batch adversarial loss: 0.790920\n",
      "epoch 49; iter: 0; batch classifier loss: 0.640517; batch adversarial loss: 0.804905\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715646\n",
      "epoch 1; iter: 0; batch classifier loss: 0.658405\n",
      "epoch 2; iter: 0; batch classifier loss: 0.632247\n",
      "epoch 3; iter: 0; batch classifier loss: 0.587911\n",
      "epoch 4; iter: 0; batch classifier loss: 0.595410\n",
      "epoch 5; iter: 0; batch classifier loss: 0.635128\n",
      "epoch 6; iter: 0; batch classifier loss: 0.603509\n",
      "epoch 7; iter: 0; batch classifier loss: 0.525596\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551252\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540427\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546109\n",
      "epoch 11; iter: 0; batch classifier loss: 0.585294\n",
      "epoch 12; iter: 0; batch classifier loss: 0.582010\n",
      "epoch 13; iter: 0; batch classifier loss: 0.574772\n",
      "epoch 14; iter: 0; batch classifier loss: 0.576285\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525648\n",
      "epoch 16; iter: 0; batch classifier loss: 0.584865\n",
      "epoch 17; iter: 0; batch classifier loss: 0.650524\n",
      "epoch 18; iter: 0; batch classifier loss: 0.539172\n",
      "epoch 19; iter: 0; batch classifier loss: 0.519124\n",
      "epoch 20; iter: 0; batch classifier loss: 0.640593\n",
      "epoch 21; iter: 0; batch classifier loss: 0.574134\n",
      "epoch 22; iter: 0; batch classifier loss: 0.582680\n",
      "epoch 23; iter: 0; batch classifier loss: 0.536512\n",
      "epoch 24; iter: 0; batch classifier loss: 0.649853\n",
      "epoch 25; iter: 0; batch classifier loss: 0.516280\n",
      "epoch 26; iter: 0; batch classifier loss: 0.555707\n",
      "epoch 27; iter: 0; batch classifier loss: 0.550857\n",
      "epoch 28; iter: 0; batch classifier loss: 0.627589\n",
      "epoch 29; iter: 0; batch classifier loss: 0.541705\n",
      "epoch 30; iter: 0; batch classifier loss: 0.493869\n",
      "epoch 31; iter: 0; batch classifier loss: 0.602618\n",
      "epoch 32; iter: 0; batch classifier loss: 0.554865\n",
      "epoch 33; iter: 0; batch classifier loss: 0.541233\n",
      "epoch 34; iter: 0; batch classifier loss: 0.544156\n",
      "epoch 35; iter: 0; batch classifier loss: 0.610057\n",
      "epoch 36; iter: 0; batch classifier loss: 0.502342\n",
      "epoch 37; iter: 0; batch classifier loss: 0.602018\n",
      "epoch 38; iter: 0; batch classifier loss: 0.493003\n",
      "epoch 39; iter: 0; batch classifier loss: 0.610063\n",
      "epoch 40; iter: 0; batch classifier loss: 0.560238\n",
      "epoch 41; iter: 0; batch classifier loss: 0.534613\n",
      "epoch 42; iter: 0; batch classifier loss: 0.572126\n",
      "epoch 43; iter: 0; batch classifier loss: 0.583012\n",
      "epoch 44; iter: 0; batch classifier loss: 0.622957\n",
      "epoch 45; iter: 0; batch classifier loss: 0.566742\n",
      "epoch 46; iter: 0; batch classifier loss: 0.482171\n",
      "epoch 47; iter: 0; batch classifier loss: 0.576792\n",
      "epoch 48; iter: 0; batch classifier loss: 0.521712\n",
      "epoch 49; iter: 0; batch classifier loss: 0.542711\n",
      "run = 7\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692812; batch adversarial loss: 0.696060\n",
      "epoch 1; iter: 0; batch classifier loss: 0.631473; batch adversarial loss: 0.701024\n",
      "epoch 2; iter: 0; batch classifier loss: 0.630351; batch adversarial loss: 0.628738\n",
      "epoch 3; iter: 0; batch classifier loss: 0.575275; batch adversarial loss: 0.603891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 0; batch classifier loss: 0.629192; batch adversarial loss: 0.586914\n",
      "epoch 5; iter: 0; batch classifier loss: 0.758058; batch adversarial loss: 0.581240\n",
      "epoch 6; iter: 0; batch classifier loss: 0.913076; batch adversarial loss: 0.613080\n",
      "epoch 7; iter: 0; batch classifier loss: 0.932600; batch adversarial loss: 0.651030\n",
      "epoch 8; iter: 0; batch classifier loss: 0.947856; batch adversarial loss: 0.621488\n",
      "epoch 9; iter: 0; batch classifier loss: 0.910043; batch adversarial loss: 0.571904\n",
      "epoch 10; iter: 0; batch classifier loss: 0.908930; batch adversarial loss: 0.540280\n",
      "epoch 11; iter: 0; batch classifier loss: 0.864395; batch adversarial loss: 0.537023\n",
      "epoch 12; iter: 0; batch classifier loss: 0.752705; batch adversarial loss: 0.568559\n",
      "epoch 13; iter: 0; batch classifier loss: 0.783846; batch adversarial loss: 0.559445\n",
      "epoch 14; iter: 0; batch classifier loss: 0.737646; batch adversarial loss: 0.533657\n",
      "epoch 15; iter: 0; batch classifier loss: 0.797111; batch adversarial loss: 0.488437\n",
      "epoch 16; iter: 0; batch classifier loss: 0.805911; batch adversarial loss: 0.556731\n",
      "epoch 17; iter: 0; batch classifier loss: 0.769620; batch adversarial loss: 0.480955\n",
      "epoch 18; iter: 0; batch classifier loss: 0.816724; batch adversarial loss: 0.458599\n",
      "epoch 19; iter: 0; batch classifier loss: 0.747741; batch adversarial loss: 0.422871\n",
      "epoch 20; iter: 0; batch classifier loss: 0.717579; batch adversarial loss: 0.480647\n",
      "epoch 21; iter: 0; batch classifier loss: 0.774106; batch adversarial loss: 0.459889\n",
      "epoch 22; iter: 0; batch classifier loss: 0.681872; batch adversarial loss: 0.515615\n",
      "epoch 23; iter: 0; batch classifier loss: 0.684175; batch adversarial loss: 0.479712\n",
      "epoch 24; iter: 0; batch classifier loss: 0.708104; batch adversarial loss: 0.445755\n",
      "epoch 25; iter: 0; batch classifier loss: 0.735531; batch adversarial loss: 0.436766\n",
      "epoch 26; iter: 0; batch classifier loss: 0.692768; batch adversarial loss: 0.451384\n",
      "epoch 27; iter: 0; batch classifier loss: 0.720001; batch adversarial loss: 0.437833\n",
      "epoch 28; iter: 0; batch classifier loss: 0.639424; batch adversarial loss: 0.397770\n",
      "epoch 29; iter: 0; batch classifier loss: 0.737204; batch adversarial loss: 0.458552\n",
      "epoch 30; iter: 0; batch classifier loss: 0.670909; batch adversarial loss: 0.472652\n",
      "epoch 31; iter: 0; batch classifier loss: 0.606890; batch adversarial loss: 0.487953\n",
      "epoch 32; iter: 0; batch classifier loss: 0.606124; batch adversarial loss: 0.355059\n",
      "epoch 33; iter: 0; batch classifier loss: 0.600749; batch adversarial loss: 0.365950\n",
      "epoch 34; iter: 0; batch classifier loss: 0.680947; batch adversarial loss: 0.454029\n",
      "epoch 35; iter: 0; batch classifier loss: 0.608594; batch adversarial loss: 0.503736\n",
      "epoch 36; iter: 0; batch classifier loss: 0.568278; batch adversarial loss: 0.460308\n",
      "epoch 37; iter: 0; batch classifier loss: 0.583609; batch adversarial loss: 0.451024\n",
      "epoch 38; iter: 0; batch classifier loss: 0.522894; batch adversarial loss: 0.459778\n",
      "epoch 39; iter: 0; batch classifier loss: 0.576773; batch adversarial loss: 0.390536\n",
      "epoch 40; iter: 0; batch classifier loss: 0.577887; batch adversarial loss: 0.432817\n",
      "epoch 41; iter: 0; batch classifier loss: 0.603762; batch adversarial loss: 0.430546\n",
      "epoch 42; iter: 0; batch classifier loss: 0.541617; batch adversarial loss: 0.364211\n",
      "epoch 43; iter: 0; batch classifier loss: 0.595629; batch adversarial loss: 0.392381\n",
      "epoch 44; iter: 0; batch classifier loss: 0.543969; batch adversarial loss: 0.465891\n",
      "epoch 45; iter: 0; batch classifier loss: 0.596593; batch adversarial loss: 0.354032\n",
      "epoch 46; iter: 0; batch classifier loss: 0.631362; batch adversarial loss: 0.378872\n",
      "epoch 47; iter: 0; batch classifier loss: 0.613476; batch adversarial loss: 0.486874\n",
      "epoch 48; iter: 0; batch classifier loss: 0.532737; batch adversarial loss: 0.318684\n",
      "epoch 49; iter: 0; batch classifier loss: 0.635251; batch adversarial loss: 0.372570\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685187\n",
      "epoch 1; iter: 0; batch classifier loss: 0.668653\n",
      "epoch 2; iter: 0; batch classifier loss: 0.557635\n",
      "epoch 3; iter: 0; batch classifier loss: 0.593339\n",
      "epoch 4; iter: 0; batch classifier loss: 0.624515\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541315\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552512\n",
      "epoch 7; iter: 0; batch classifier loss: 0.562308\n",
      "epoch 8; iter: 0; batch classifier loss: 0.562672\n",
      "epoch 9; iter: 0; batch classifier loss: 0.580324\n",
      "epoch 10; iter: 0; batch classifier loss: 0.561728\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538068\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536390\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519563\n",
      "epoch 14; iter: 0; batch classifier loss: 0.563141\n",
      "epoch 15; iter: 0; batch classifier loss: 0.529819\n",
      "epoch 16; iter: 0; batch classifier loss: 0.510831\n",
      "epoch 17; iter: 0; batch classifier loss: 0.546374\n",
      "epoch 18; iter: 0; batch classifier loss: 0.603500\n",
      "epoch 19; iter: 0; batch classifier loss: 0.574613\n",
      "epoch 20; iter: 0; batch classifier loss: 0.510323\n",
      "epoch 21; iter: 0; batch classifier loss: 0.562177\n",
      "epoch 22; iter: 0; batch classifier loss: 0.568133\n",
      "epoch 23; iter: 0; batch classifier loss: 0.504615\n",
      "epoch 24; iter: 0; batch classifier loss: 0.494233\n",
      "epoch 25; iter: 0; batch classifier loss: 0.509833\n",
      "epoch 26; iter: 0; batch classifier loss: 0.561366\n",
      "epoch 27; iter: 0; batch classifier loss: 0.601401\n",
      "epoch 28; iter: 0; batch classifier loss: 0.540326\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461983\n",
      "epoch 30; iter: 0; batch classifier loss: 0.504367\n",
      "epoch 31; iter: 0; batch classifier loss: 0.533514\n",
      "epoch 32; iter: 0; batch classifier loss: 0.545966\n",
      "epoch 33; iter: 0; batch classifier loss: 0.554742\n",
      "epoch 34; iter: 0; batch classifier loss: 0.663076\n",
      "epoch 35; iter: 0; batch classifier loss: 0.565278\n",
      "epoch 36; iter: 0; batch classifier loss: 0.616545\n",
      "epoch 37; iter: 0; batch classifier loss: 0.587529\n",
      "epoch 38; iter: 0; batch classifier loss: 0.595097\n",
      "epoch 39; iter: 0; batch classifier loss: 0.531934\n",
      "epoch 40; iter: 0; batch classifier loss: 0.494663\n",
      "epoch 41; iter: 0; batch classifier loss: 0.508846\n",
      "epoch 42; iter: 0; batch classifier loss: 0.554450\n",
      "epoch 43; iter: 0; batch classifier loss: 0.526877\n",
      "epoch 44; iter: 0; batch classifier loss: 0.564086\n",
      "epoch 45; iter: 0; batch classifier loss: 0.584980\n",
      "epoch 46; iter: 0; batch classifier loss: 0.551300\n",
      "epoch 47; iter: 0; batch classifier loss: 0.611071\n",
      "epoch 48; iter: 0; batch classifier loss: 0.560957\n",
      "epoch 49; iter: 0; batch classifier loss: 0.565969\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687786; batch adversarial loss: 0.574391\n",
      "epoch 1; iter: 0; batch classifier loss: 0.668441; batch adversarial loss: 0.539062\n",
      "epoch 2; iter: 0; batch classifier loss: 0.661061; batch adversarial loss: 0.563777\n",
      "epoch 3; iter: 0; batch classifier loss: 0.644067; batch adversarial loss: 0.565881\n",
      "epoch 4; iter: 0; batch classifier loss: 0.649566; batch adversarial loss: 0.553127\n",
      "epoch 5; iter: 0; batch classifier loss: 0.626323; batch adversarial loss: 0.604591\n",
      "epoch 6; iter: 0; batch classifier loss: 0.623144; batch adversarial loss: 0.654119\n",
      "epoch 7; iter: 0; batch classifier loss: 0.619534; batch adversarial loss: 0.554675\n",
      "epoch 8; iter: 0; batch classifier loss: 0.596529; batch adversarial loss: 0.522781\n",
      "epoch 9; iter: 0; batch classifier loss: 0.606601; batch adversarial loss: 0.553341\n",
      "epoch 10; iter: 0; batch classifier loss: 0.586321; batch adversarial loss: 0.564029\n",
      "epoch 11; iter: 0; batch classifier loss: 0.612295; batch adversarial loss: 0.492691\n",
      "epoch 12; iter: 0; batch classifier loss: 0.598214; batch adversarial loss: 0.551907\n",
      "epoch 13; iter: 0; batch classifier loss: 0.695580; batch adversarial loss: 0.569966\n",
      "epoch 14; iter: 0; batch classifier loss: 0.616627; batch adversarial loss: 0.549283\n",
      "epoch 15; iter: 0; batch classifier loss: 0.580930; batch adversarial loss: 0.509223\n",
      "epoch 16; iter: 0; batch classifier loss: 0.633071; batch adversarial loss: 0.606199\n",
      "epoch 17; iter: 0; batch classifier loss: 0.678638; batch adversarial loss: 0.561701\n",
      "epoch 18; iter: 0; batch classifier loss: 0.639570; batch adversarial loss: 0.572757\n",
      "epoch 19; iter: 0; batch classifier loss: 0.633295; batch adversarial loss: 0.526645\n",
      "epoch 20; iter: 0; batch classifier loss: 0.613730; batch adversarial loss: 0.555009\n",
      "epoch 21; iter: 0; batch classifier loss: 0.682184; batch adversarial loss: 0.613914\n",
      "epoch 22; iter: 0; batch classifier loss: 0.640020; batch adversarial loss: 0.591522\n",
      "epoch 23; iter: 0; batch classifier loss: 0.675165; batch adversarial loss: 0.597557\n",
      "epoch 24; iter: 0; batch classifier loss: 0.702028; batch adversarial loss: 0.654556\n",
      "epoch 25; iter: 0; batch classifier loss: 0.684542; batch adversarial loss: 0.592722\n",
      "epoch 26; iter: 0; batch classifier loss: 0.720373; batch adversarial loss: 0.587674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.642602; batch adversarial loss: 0.615531\n",
      "epoch 28; iter: 0; batch classifier loss: 0.708519; batch adversarial loss: 0.577367\n",
      "epoch 29; iter: 0; batch classifier loss: 0.711283; batch adversarial loss: 0.588989\n",
      "epoch 30; iter: 0; batch classifier loss: 0.735812; batch adversarial loss: 0.614419\n",
      "epoch 31; iter: 0; batch classifier loss: 0.703853; batch adversarial loss: 0.564828\n",
      "epoch 32; iter: 0; batch classifier loss: 0.699914; batch adversarial loss: 0.625199\n",
      "epoch 33; iter: 0; batch classifier loss: 0.725830; batch adversarial loss: 0.619967\n",
      "epoch 34; iter: 0; batch classifier loss: 0.770128; batch adversarial loss: 0.619923\n",
      "epoch 35; iter: 0; batch classifier loss: 0.778823; batch adversarial loss: 0.665468\n",
      "epoch 36; iter: 0; batch classifier loss: 0.730786; batch adversarial loss: 0.698853\n",
      "epoch 37; iter: 0; batch classifier loss: 0.853086; batch adversarial loss: 0.695088\n",
      "epoch 38; iter: 0; batch classifier loss: 0.860698; batch adversarial loss: 0.636043\n",
      "epoch 39; iter: 0; batch classifier loss: 0.832293; batch adversarial loss: 0.638778\n",
      "epoch 40; iter: 0; batch classifier loss: 0.911231; batch adversarial loss: 0.675868\n",
      "epoch 41; iter: 0; batch classifier loss: 0.942084; batch adversarial loss: 0.729833\n",
      "epoch 42; iter: 0; batch classifier loss: 0.923037; batch adversarial loss: 0.628922\n",
      "epoch 43; iter: 0; batch classifier loss: 0.989282; batch adversarial loss: 0.620268\n",
      "epoch 44; iter: 0; batch classifier loss: 1.077956; batch adversarial loss: 0.650954\n",
      "epoch 45; iter: 0; batch classifier loss: 1.017786; batch adversarial loss: 0.721206\n",
      "epoch 46; iter: 0; batch classifier loss: 0.942303; batch adversarial loss: 0.691700\n",
      "epoch 47; iter: 0; batch classifier loss: 1.035786; batch adversarial loss: 0.686798\n",
      "epoch 48; iter: 0; batch classifier loss: 1.037679; batch adversarial loss: 0.675118\n",
      "epoch 49; iter: 0; batch classifier loss: 0.966156; batch adversarial loss: 0.694107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/ml-19jan/lib/python3.5/site-packages/aif360/metrics/dataset_metric.py:94: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.663789\n",
      "epoch 1; iter: 0; batch classifier loss: 0.621352\n",
      "epoch 2; iter: 0; batch classifier loss: 0.610945\n",
      "epoch 3; iter: 0; batch classifier loss: 0.620516\n",
      "epoch 4; iter: 0; batch classifier loss: 0.535322\n",
      "epoch 5; iter: 0; batch classifier loss: 0.643129\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606117\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545966\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557898\n",
      "epoch 9; iter: 0; batch classifier loss: 0.608422\n",
      "epoch 10; iter: 0; batch classifier loss: 0.603929\n",
      "epoch 11; iter: 0; batch classifier loss: 0.650724\n",
      "epoch 12; iter: 0; batch classifier loss: 0.584867\n",
      "epoch 13; iter: 0; batch classifier loss: 0.568451\n",
      "epoch 14; iter: 0; batch classifier loss: 0.563294\n",
      "epoch 15; iter: 0; batch classifier loss: 0.584820\n",
      "epoch 16; iter: 0; batch classifier loss: 0.569444\n",
      "epoch 17; iter: 0; batch classifier loss: 0.619469\n",
      "epoch 18; iter: 0; batch classifier loss: 0.610684\n",
      "epoch 19; iter: 0; batch classifier loss: 0.611576\n",
      "epoch 20; iter: 0; batch classifier loss: 0.584399\n",
      "epoch 21; iter: 0; batch classifier loss: 0.584636\n",
      "epoch 22; iter: 0; batch classifier loss: 0.637279\n",
      "epoch 23; iter: 0; batch classifier loss: 0.572961\n",
      "epoch 24; iter: 0; batch classifier loss: 0.602960\n",
      "epoch 25; iter: 0; batch classifier loss: 0.537928\n",
      "epoch 26; iter: 0; batch classifier loss: 0.558515\n",
      "epoch 27; iter: 0; batch classifier loss: 0.536876\n",
      "epoch 28; iter: 0; batch classifier loss: 0.542411\n",
      "epoch 29; iter: 0; batch classifier loss: 0.555048\n",
      "epoch 30; iter: 0; batch classifier loss: 0.581300\n",
      "epoch 31; iter: 0; batch classifier loss: 0.557755\n",
      "epoch 32; iter: 0; batch classifier loss: 0.514018\n",
      "epoch 33; iter: 0; batch classifier loss: 0.587962\n",
      "epoch 34; iter: 0; batch classifier loss: 0.588485\n",
      "epoch 35; iter: 0; batch classifier loss: 0.591433\n",
      "epoch 36; iter: 0; batch classifier loss: 0.601053\n",
      "epoch 37; iter: 0; batch classifier loss: 0.544430\n",
      "epoch 38; iter: 0; batch classifier loss: 0.581901\n",
      "epoch 39; iter: 0; batch classifier loss: 0.561636\n",
      "epoch 40; iter: 0; batch classifier loss: 0.603962\n",
      "epoch 41; iter: 0; batch classifier loss: 0.562709\n",
      "epoch 42; iter: 0; batch classifier loss: 0.537278\n",
      "epoch 43; iter: 0; batch classifier loss: 0.578631\n",
      "epoch 44; iter: 0; batch classifier loss: 0.521576\n",
      "epoch 45; iter: 0; batch classifier loss: 0.591875\n",
      "epoch 46; iter: 0; batch classifier loss: 0.551171\n",
      "epoch 47; iter: 0; batch classifier loss: 0.607494\n",
      "epoch 48; iter: 0; batch classifier loss: 0.578143\n",
      "epoch 49; iter: 0; batch classifier loss: 0.553182\n",
      "run = 8\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693978; batch adversarial loss: 0.670876\n",
      "epoch 1; iter: 0; batch classifier loss: 0.566583; batch adversarial loss: 0.643567\n",
      "epoch 2; iter: 0; batch classifier loss: 0.622745; batch adversarial loss: 0.583824\n",
      "epoch 3; iter: 0; batch classifier loss: 0.784336; batch adversarial loss: 0.607408\n",
      "epoch 4; iter: 0; batch classifier loss: 0.852472; batch adversarial loss: 0.657952\n",
      "epoch 5; iter: 0; batch classifier loss: 0.947291; batch adversarial loss: 0.640391\n",
      "epoch 6; iter: 0; batch classifier loss: 0.875998; batch adversarial loss: 0.626507\n",
      "epoch 7; iter: 0; batch classifier loss: 0.887015; batch adversarial loss: 0.597885\n",
      "epoch 8; iter: 0; batch classifier loss: 0.821496; batch adversarial loss: 0.525919\n",
      "epoch 9; iter: 0; batch classifier loss: 0.780437; batch adversarial loss: 0.517452\n",
      "epoch 10; iter: 0; batch classifier loss: 0.754825; batch adversarial loss: 0.552560\n",
      "epoch 11; iter: 0; batch classifier loss: 0.853107; batch adversarial loss: 0.553883\n",
      "epoch 12; iter: 0; batch classifier loss: 0.844696; batch adversarial loss: 0.475201\n",
      "epoch 13; iter: 0; batch classifier loss: 0.740626; batch adversarial loss: 0.507431\n",
      "epoch 14; iter: 0; batch classifier loss: 0.753165; batch adversarial loss: 0.569638\n",
      "epoch 15; iter: 0; batch classifier loss: 0.748464; batch adversarial loss: 0.483720\n",
      "epoch 16; iter: 0; batch classifier loss: 0.793729; batch adversarial loss: 0.452057\n",
      "epoch 17; iter: 0; batch classifier loss: 0.714175; batch adversarial loss: 0.520232\n",
      "epoch 18; iter: 0; batch classifier loss: 0.690627; batch adversarial loss: 0.504892\n",
      "epoch 19; iter: 0; batch classifier loss: 0.697570; batch adversarial loss: 0.518497\n",
      "epoch 20; iter: 0; batch classifier loss: 0.757512; batch adversarial loss: 0.403292\n",
      "epoch 21; iter: 0; batch classifier loss: 0.675617; batch adversarial loss: 0.489456\n",
      "epoch 22; iter: 0; batch classifier loss: 0.686016; batch adversarial loss: 0.494395\n",
      "epoch 23; iter: 0; batch classifier loss: 0.674745; batch adversarial loss: 0.455579\n",
      "epoch 24; iter: 0; batch classifier loss: 0.659344; batch adversarial loss: 0.452490\n",
      "epoch 25; iter: 0; batch classifier loss: 0.664458; batch adversarial loss: 0.447730\n",
      "epoch 26; iter: 0; batch classifier loss: 0.677952; batch adversarial loss: 0.398695\n",
      "epoch 27; iter: 0; batch classifier loss: 0.608118; batch adversarial loss: 0.389526\n",
      "epoch 28; iter: 0; batch classifier loss: 0.621198; batch adversarial loss: 0.419365\n",
      "epoch 29; iter: 0; batch classifier loss: 0.640020; batch adversarial loss: 0.481083\n",
      "epoch 30; iter: 0; batch classifier loss: 0.645006; batch adversarial loss: 0.436722\n",
      "epoch 31; iter: 0; batch classifier loss: 0.582253; batch adversarial loss: 0.457793\n",
      "epoch 32; iter: 0; batch classifier loss: 0.579581; batch adversarial loss: 0.382026\n",
      "epoch 33; iter: 0; batch classifier loss: 0.616869; batch adversarial loss: 0.430159\n",
      "epoch 34; iter: 0; batch classifier loss: 0.584722; batch adversarial loss: 0.431495\n",
      "epoch 35; iter: 0; batch classifier loss: 0.583578; batch adversarial loss: 0.331170\n",
      "epoch 36; iter: 0; batch classifier loss: 0.616990; batch adversarial loss: 0.515936\n",
      "epoch 37; iter: 0; batch classifier loss: 0.569369; batch adversarial loss: 0.449887\n",
      "epoch 38; iter: 0; batch classifier loss: 0.618195; batch adversarial loss: 0.458588\n",
      "epoch 39; iter: 0; batch classifier loss: 0.587382; batch adversarial loss: 0.424558\n",
      "epoch 40; iter: 0; batch classifier loss: 0.634772; batch adversarial loss: 0.457742\n",
      "epoch 41; iter: 0; batch classifier loss: 0.598317; batch adversarial loss: 0.397350\n",
      "epoch 42; iter: 0; batch classifier loss: 0.613765; batch adversarial loss: 0.394462\n",
      "epoch 43; iter: 0; batch classifier loss: 0.575508; batch adversarial loss: 0.508405\n",
      "epoch 44; iter: 0; batch classifier loss: 0.575582; batch adversarial loss: 0.368237\n",
      "epoch 45; iter: 0; batch classifier loss: 0.583806; batch adversarial loss: 0.426683\n",
      "epoch 46; iter: 0; batch classifier loss: 0.539717; batch adversarial loss: 0.531856\n",
      "epoch 47; iter: 0; batch classifier loss: 0.686517; batch adversarial loss: 0.459854\n",
      "epoch 48; iter: 0; batch classifier loss: 0.630645; batch adversarial loss: 0.435418\n",
      "epoch 49; iter: 0; batch classifier loss: 0.571628; batch adversarial loss: 0.399326\n",
      "epoch 0; iter: 0; batch classifier loss: 0.705264\n",
      "epoch 1; iter: 0; batch classifier loss: 0.528252\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561104\n",
      "epoch 3; iter: 0; batch classifier loss: 0.540287\n",
      "epoch 4; iter: 0; batch classifier loss: 0.534086\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555338\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585478\n",
      "epoch 7; iter: 0; batch classifier loss: 0.580642\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551296\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576355\n",
      "epoch 10; iter: 0; batch classifier loss: 0.556865\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543282\n",
      "epoch 12; iter: 0; batch classifier loss: 0.571295\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539484\n",
      "epoch 14; iter: 0; batch classifier loss: 0.526206\n",
      "epoch 15; iter: 0; batch classifier loss: 0.566747\n",
      "epoch 16; iter: 0; batch classifier loss: 0.569548\n",
      "epoch 17; iter: 0; batch classifier loss: 0.526971\n",
      "epoch 18; iter: 0; batch classifier loss: 0.571807\n",
      "epoch 19; iter: 0; batch classifier loss: 0.491221\n",
      "epoch 20; iter: 0; batch classifier loss: 0.576317\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504852\n",
      "epoch 22; iter: 0; batch classifier loss: 0.531898\n",
      "epoch 23; iter: 0; batch classifier loss: 0.540815\n",
      "epoch 24; iter: 0; batch classifier loss: 0.526641\n",
      "epoch 25; iter: 0; batch classifier loss: 0.553303\n",
      "epoch 26; iter: 0; batch classifier loss: 0.527395\n",
      "epoch 27; iter: 0; batch classifier loss: 0.538231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.599002\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484482\n",
      "epoch 30; iter: 0; batch classifier loss: 0.475575\n",
      "epoch 31; iter: 0; batch classifier loss: 0.516252\n",
      "epoch 32; iter: 0; batch classifier loss: 0.572031\n",
      "epoch 33; iter: 0; batch classifier loss: 0.535397\n",
      "epoch 34; iter: 0; batch classifier loss: 0.525847\n",
      "epoch 35; iter: 0; batch classifier loss: 0.593920\n",
      "epoch 36; iter: 0; batch classifier loss: 0.527475\n",
      "epoch 37; iter: 0; batch classifier loss: 0.539033\n",
      "epoch 38; iter: 0; batch classifier loss: 0.559780\n",
      "epoch 39; iter: 0; batch classifier loss: 0.563495\n",
      "epoch 40; iter: 0; batch classifier loss: 0.507159\n",
      "epoch 41; iter: 0; batch classifier loss: 0.530748\n",
      "epoch 42; iter: 0; batch classifier loss: 0.540682\n",
      "epoch 43; iter: 0; batch classifier loss: 0.577552\n",
      "epoch 44; iter: 0; batch classifier loss: 0.566156\n",
      "epoch 45; iter: 0; batch classifier loss: 0.546388\n",
      "epoch 46; iter: 0; batch classifier loss: 0.568851\n",
      "epoch 47; iter: 0; batch classifier loss: 0.470143\n",
      "epoch 48; iter: 0; batch classifier loss: 0.505234\n",
      "epoch 49; iter: 0; batch classifier loss: 0.496144\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699254; batch adversarial loss: 0.399963\n",
      "epoch 1; iter: 0; batch classifier loss: 0.691835; batch adversarial loss: 0.443612\n",
      "epoch 2; iter: 0; batch classifier loss: 0.697965; batch adversarial loss: 0.488403\n",
      "epoch 3; iter: 0; batch classifier loss: 0.685871; batch adversarial loss: 0.444677\n",
      "epoch 4; iter: 0; batch classifier loss: 0.660139; batch adversarial loss: 0.421376\n",
      "epoch 5; iter: 0; batch classifier loss: 0.662833; batch adversarial loss: 0.476824\n",
      "epoch 6; iter: 0; batch classifier loss: 0.658372; batch adversarial loss: 0.385763\n",
      "epoch 7; iter: 0; batch classifier loss: 0.640636; batch adversarial loss: 0.497351\n",
      "epoch 8; iter: 0; batch classifier loss: 0.631649; batch adversarial loss: 0.496405\n",
      "epoch 9; iter: 0; batch classifier loss: 0.614196; batch adversarial loss: 0.425910\n",
      "epoch 10; iter: 0; batch classifier loss: 0.659405; batch adversarial loss: 0.524930\n",
      "epoch 11; iter: 0; batch classifier loss: 0.661321; batch adversarial loss: 0.602929\n",
      "epoch 12; iter: 0; batch classifier loss: 0.652802; batch adversarial loss: 0.480622\n",
      "epoch 13; iter: 0; batch classifier loss: 0.634340; batch adversarial loss: 0.574271\n",
      "epoch 14; iter: 0; batch classifier loss: 0.625288; batch adversarial loss: 0.492681\n",
      "epoch 15; iter: 0; batch classifier loss: 0.614605; batch adversarial loss: 0.498421\n",
      "epoch 16; iter: 0; batch classifier loss: 0.616515; batch adversarial loss: 0.578681\n",
      "epoch 17; iter: 0; batch classifier loss: 0.711185; batch adversarial loss: 0.475625\n",
      "epoch 18; iter: 0; batch classifier loss: 0.611949; batch adversarial loss: 0.576653\n",
      "epoch 19; iter: 0; batch classifier loss: 0.761820; batch adversarial loss: 0.594744\n",
      "epoch 20; iter: 0; batch classifier loss: 0.668158; batch adversarial loss: 0.594390\n",
      "epoch 21; iter: 0; batch classifier loss: 0.753927; batch adversarial loss: 0.574418\n",
      "epoch 22; iter: 0; batch classifier loss: 0.710749; batch adversarial loss: 0.580914\n",
      "epoch 23; iter: 0; batch classifier loss: 0.791421; batch adversarial loss: 0.573977\n",
      "epoch 24; iter: 0; batch classifier loss: 0.851899; batch adversarial loss: 0.600794\n",
      "epoch 25; iter: 0; batch classifier loss: 0.796335; batch adversarial loss: 0.668160\n",
      "epoch 26; iter: 0; batch classifier loss: 0.854115; batch adversarial loss: 0.680566\n",
      "epoch 27; iter: 0; batch classifier loss: 0.781672; batch adversarial loss: 0.667008\n",
      "epoch 28; iter: 0; batch classifier loss: 0.977062; batch adversarial loss: 0.655190\n",
      "epoch 29; iter: 0; batch classifier loss: 0.904292; batch adversarial loss: 0.682270\n",
      "epoch 30; iter: 0; batch classifier loss: 0.931661; batch adversarial loss: 0.706887\n",
      "epoch 31; iter: 0; batch classifier loss: 1.076909; batch adversarial loss: 0.668157\n",
      "epoch 32; iter: 0; batch classifier loss: 1.034777; batch adversarial loss: 0.819703\n",
      "epoch 33; iter: 0; batch classifier loss: 1.099413; batch adversarial loss: 0.820603\n",
      "epoch 34; iter: 0; batch classifier loss: 1.253479; batch adversarial loss: 0.787970\n",
      "epoch 35; iter: 0; batch classifier loss: 1.305116; batch adversarial loss: 0.765729\n",
      "epoch 36; iter: 0; batch classifier loss: 1.125325; batch adversarial loss: 0.726017\n",
      "epoch 37; iter: 0; batch classifier loss: 1.314106; batch adversarial loss: 0.700541\n",
      "epoch 38; iter: 0; batch classifier loss: 1.349397; batch adversarial loss: 0.682676\n",
      "epoch 39; iter: 0; batch classifier loss: 1.237245; batch adversarial loss: 0.712205\n",
      "epoch 40; iter: 0; batch classifier loss: 1.389964; batch adversarial loss: 0.754703\n",
      "epoch 41; iter: 0; batch classifier loss: 1.299042; batch adversarial loss: 0.830036\n",
      "epoch 42; iter: 0; batch classifier loss: 1.293294; batch adversarial loss: 0.847324\n",
      "epoch 43; iter: 0; batch classifier loss: 1.348932; batch adversarial loss: 0.769513\n",
      "epoch 44; iter: 0; batch classifier loss: 1.281603; batch adversarial loss: 0.771867\n",
      "epoch 45; iter: 0; batch classifier loss: 1.429087; batch adversarial loss: 0.693837\n",
      "epoch 46; iter: 0; batch classifier loss: 1.430802; batch adversarial loss: 0.694050\n",
      "epoch 47; iter: 0; batch classifier loss: 1.567135; batch adversarial loss: 0.723386\n",
      "epoch 48; iter: 0; batch classifier loss: 1.555743; batch adversarial loss: 0.698458\n",
      "epoch 49; iter: 0; batch classifier loss: 1.538866; batch adversarial loss: 0.723000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/ml-19jan/lib/python3.5/site-packages/aif360/metrics/dataset_metric.py:94: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.708093\n",
      "epoch 1; iter: 0; batch classifier loss: 0.642239\n",
      "epoch 2; iter: 0; batch classifier loss: 0.626431\n",
      "epoch 3; iter: 0; batch classifier loss: 0.557786\n",
      "epoch 4; iter: 0; batch classifier loss: 0.608361\n",
      "epoch 5; iter: 0; batch classifier loss: 0.597280\n",
      "epoch 6; iter: 0; batch classifier loss: 0.646842\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561929\n",
      "epoch 8; iter: 0; batch classifier loss: 0.602368\n",
      "epoch 9; iter: 0; batch classifier loss: 0.575522\n",
      "epoch 10; iter: 0; batch classifier loss: 0.564809\n",
      "epoch 11; iter: 0; batch classifier loss: 0.515048\n",
      "epoch 12; iter: 0; batch classifier loss: 0.627529\n",
      "epoch 13; iter: 0; batch classifier loss: 0.602081\n",
      "epoch 14; iter: 0; batch classifier loss: 0.644184\n",
      "epoch 15; iter: 0; batch classifier loss: 0.612060\n",
      "epoch 16; iter: 0; batch classifier loss: 0.590340\n",
      "epoch 17; iter: 0; batch classifier loss: 0.638449\n",
      "epoch 18; iter: 0; batch classifier loss: 0.606916\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536190\n",
      "epoch 20; iter: 0; batch classifier loss: 0.552312\n",
      "epoch 21; iter: 0; batch classifier loss: 0.575357\n",
      "epoch 22; iter: 0; batch classifier loss: 0.537984\n",
      "epoch 23; iter: 0; batch classifier loss: 0.582419\n",
      "epoch 24; iter: 0; batch classifier loss: 0.580945\n",
      "epoch 25; iter: 0; batch classifier loss: 0.565601\n",
      "epoch 26; iter: 0; batch classifier loss: 0.576724\n",
      "epoch 27; iter: 0; batch classifier loss: 0.602856\n",
      "epoch 28; iter: 0; batch classifier loss: 0.483880\n",
      "epoch 29; iter: 0; batch classifier loss: 0.592707\n",
      "epoch 30; iter: 0; batch classifier loss: 0.514216\n",
      "epoch 31; iter: 0; batch classifier loss: 0.606663\n",
      "epoch 32; iter: 0; batch classifier loss: 0.597082\n",
      "epoch 33; iter: 0; batch classifier loss: 0.649754\n",
      "epoch 34; iter: 0; batch classifier loss: 0.610417\n",
      "epoch 35; iter: 0; batch classifier loss: 0.571110\n",
      "epoch 36; iter: 0; batch classifier loss: 0.606805\n",
      "epoch 37; iter: 0; batch classifier loss: 0.602166\n",
      "epoch 38; iter: 0; batch classifier loss: 0.503564\n",
      "epoch 39; iter: 0; batch classifier loss: 0.620258\n",
      "epoch 40; iter: 0; batch classifier loss: 0.581908\n",
      "epoch 41; iter: 0; batch classifier loss: 0.548968\n",
      "epoch 42; iter: 0; batch classifier loss: 0.598098\n",
      "epoch 43; iter: 0; batch classifier loss: 0.558514\n",
      "epoch 44; iter: 0; batch classifier loss: 0.498339\n",
      "epoch 45; iter: 0; batch classifier loss: 0.544350\n",
      "epoch 46; iter: 0; batch classifier loss: 0.519512\n",
      "epoch 47; iter: 0; batch classifier loss: 0.671484\n",
      "epoch 48; iter: 0; batch classifier loss: 0.554038\n",
      "epoch 49; iter: 0; batch classifier loss: 0.629285\n",
      "run = 9\n",
      "epoch 0; iter: 0; batch classifier loss: 0.642655; batch adversarial loss: 0.453974\n",
      "epoch 1; iter: 0; batch classifier loss: 0.634501; batch adversarial loss: 0.489184\n",
      "epoch 2; iter: 0; batch classifier loss: 0.563165; batch adversarial loss: 0.411707\n",
      "epoch 3; iter: 0; batch classifier loss: 0.563657; batch adversarial loss: 0.393442\n",
      "epoch 4; iter: 0; batch classifier loss: 0.575576; batch adversarial loss: 0.481527\n",
      "epoch 5; iter: 0; batch classifier loss: 0.697791; batch adversarial loss: 0.642005\n",
      "epoch 6; iter: 0; batch classifier loss: 1.234086; batch adversarial loss: 0.811303\n",
      "epoch 7; iter: 0; batch classifier loss: 1.315327; batch adversarial loss: 0.754832\n",
      "epoch 8; iter: 0; batch classifier loss: 1.576880; batch adversarial loss: 0.691554\n",
      "epoch 9; iter: 0; batch classifier loss: 1.541177; batch adversarial loss: 0.691842\n",
      "epoch 10; iter: 0; batch classifier loss: 1.812978; batch adversarial loss: 0.530590\n",
      "epoch 11; iter: 0; batch classifier loss: 1.618695; batch adversarial loss: 0.618181\n",
      "epoch 12; iter: 0; batch classifier loss: 1.744107; batch adversarial loss: 0.578152\n",
      "epoch 13; iter: 0; batch classifier loss: 1.652394; batch adversarial loss: 0.556859\n",
      "epoch 14; iter: 0; batch classifier loss: 1.715057; batch adversarial loss: 0.547454\n",
      "epoch 15; iter: 0; batch classifier loss: 1.743446; batch adversarial loss: 0.462766\n",
      "epoch 16; iter: 0; batch classifier loss: 1.234025; batch adversarial loss: 0.493132\n",
      "epoch 17; iter: 0; batch classifier loss: 1.195033; batch adversarial loss: 0.464176\n",
      "epoch 18; iter: 0; batch classifier loss: 0.719372; batch adversarial loss: 0.500248\n",
      "epoch 19; iter: 0; batch classifier loss: 0.594061; batch adversarial loss: 0.453899\n",
      "epoch 20; iter: 0; batch classifier loss: 0.617874; batch adversarial loss: 0.411872\n",
      "epoch 21; iter: 0; batch classifier loss: 0.583334; batch adversarial loss: 0.429250\n",
      "epoch 22; iter: 0; batch classifier loss: 0.570750; batch adversarial loss: 0.419114\n",
      "epoch 23; iter: 0; batch classifier loss: 0.540804; batch adversarial loss: 0.495756\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518658; batch adversarial loss: 0.437208\n",
      "epoch 25; iter: 0; batch classifier loss: 0.488437; batch adversarial loss: 0.399537\n",
      "epoch 26; iter: 0; batch classifier loss: 0.589159; batch adversarial loss: 0.505404\n",
      "epoch 27; iter: 0; batch classifier loss: 0.424325; batch adversarial loss: 0.480569\n",
      "epoch 28; iter: 0; batch classifier loss: 0.671292; batch adversarial loss: 0.367284\n",
      "epoch 29; iter: 0; batch classifier loss: 0.569512; batch adversarial loss: 0.342959\n",
      "epoch 30; iter: 0; batch classifier loss: 0.566391; batch adversarial loss: 0.349626\n",
      "epoch 31; iter: 0; batch classifier loss: 0.513313; batch adversarial loss: 0.400206\n",
      "epoch 32; iter: 0; batch classifier loss: 0.533817; batch adversarial loss: 0.370242\n",
      "epoch 33; iter: 0; batch classifier loss: 0.507320; batch adversarial loss: 0.375416\n",
      "epoch 34; iter: 0; batch classifier loss: 0.566382; batch adversarial loss: 0.344101\n",
      "epoch 35; iter: 0; batch classifier loss: 0.564703; batch adversarial loss: 0.456095\n",
      "epoch 36; iter: 0; batch classifier loss: 0.515915; batch adversarial loss: 0.418492\n",
      "epoch 37; iter: 0; batch classifier loss: 0.584856; batch adversarial loss: 0.381329\n",
      "epoch 38; iter: 0; batch classifier loss: 0.685040; batch adversarial loss: 0.407076\n",
      "epoch 39; iter: 0; batch classifier loss: 0.461245; batch adversarial loss: 0.403758\n",
      "epoch 40; iter: 0; batch classifier loss: 0.540262; batch adversarial loss: 0.379752\n",
      "epoch 41; iter: 0; batch classifier loss: 0.563035; batch adversarial loss: 0.330524\n",
      "epoch 42; iter: 0; batch classifier loss: 0.509955; batch adversarial loss: 0.390138\n",
      "epoch 43; iter: 0; batch classifier loss: 0.504936; batch adversarial loss: 0.350702\n",
      "epoch 44; iter: 0; batch classifier loss: 0.490079; batch adversarial loss: 0.421983\n",
      "epoch 45; iter: 0; batch classifier loss: 0.584149; batch adversarial loss: 0.359107\n",
      "epoch 46; iter: 0; batch classifier loss: 0.548631; batch adversarial loss: 0.523968\n",
      "epoch 47; iter: 0; batch classifier loss: 0.523755; batch adversarial loss: 0.447694\n",
      "epoch 48; iter: 0; batch classifier loss: 0.520552; batch adversarial loss: 0.395080\n",
      "epoch 49; iter: 0; batch classifier loss: 0.548014; batch adversarial loss: 0.408511\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713423\n",
      "epoch 1; iter: 0; batch classifier loss: 0.586527\n",
      "epoch 2; iter: 0; batch classifier loss: 0.588253\n",
      "epoch 3; iter: 0; batch classifier loss: 0.528163\n",
      "epoch 4; iter: 0; batch classifier loss: 0.475896\n",
      "epoch 5; iter: 0; batch classifier loss: 0.483966\n",
      "epoch 6; iter: 0; batch classifier loss: 0.487369\n",
      "epoch 7; iter: 0; batch classifier loss: 0.538687\n",
      "epoch 8; iter: 0; batch classifier loss: 0.503434\n",
      "epoch 9; iter: 0; batch classifier loss: 0.426784\n",
      "epoch 10; iter: 0; batch classifier loss: 0.575312\n",
      "epoch 11; iter: 0; batch classifier loss: 0.500056\n",
      "epoch 12; iter: 0; batch classifier loss: 0.577960\n",
      "epoch 13; iter: 0; batch classifier loss: 0.519381\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515351\n",
      "epoch 15; iter: 0; batch classifier loss: 0.616516\n",
      "epoch 16; iter: 0; batch classifier loss: 0.554495\n",
      "epoch 17; iter: 0; batch classifier loss: 0.516488\n",
      "epoch 18; iter: 0; batch classifier loss: 0.464358\n",
      "epoch 19; iter: 0; batch classifier loss: 0.610375\n",
      "epoch 20; iter: 0; batch classifier loss: 0.519590\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487003\n",
      "epoch 22; iter: 0; batch classifier loss: 0.529209\n",
      "epoch 23; iter: 0; batch classifier loss: 0.528124\n",
      "epoch 24; iter: 0; batch classifier loss: 0.566703\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471887\n",
      "epoch 26; iter: 0; batch classifier loss: 0.532204\n",
      "epoch 27; iter: 0; batch classifier loss: 0.583624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.556675\n",
      "epoch 29; iter: 0; batch classifier loss: 0.477600\n",
      "epoch 30; iter: 0; batch classifier loss: 0.604063\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449450\n",
      "epoch 32; iter: 0; batch classifier loss: 0.506316\n",
      "epoch 33; iter: 0; batch classifier loss: 0.473018\n",
      "epoch 34; iter: 0; batch classifier loss: 0.488924\n",
      "epoch 35; iter: 0; batch classifier loss: 0.528444\n",
      "epoch 36; iter: 0; batch classifier loss: 0.606351\n",
      "epoch 37; iter: 0; batch classifier loss: 0.505449\n",
      "epoch 38; iter: 0; batch classifier loss: 0.550330\n",
      "epoch 39; iter: 0; batch classifier loss: 0.494101\n",
      "epoch 40; iter: 0; batch classifier loss: 0.518417\n",
      "epoch 41; iter: 0; batch classifier loss: 0.567425\n",
      "epoch 42; iter: 0; batch classifier loss: 0.499328\n",
      "epoch 43; iter: 0; batch classifier loss: 0.539350\n",
      "epoch 44; iter: 0; batch classifier loss: 0.573059\n",
      "epoch 45; iter: 0; batch classifier loss: 0.557557\n",
      "epoch 46; iter: 0; batch classifier loss: 0.481445\n",
      "epoch 47; iter: 0; batch classifier loss: 0.521632\n",
      "epoch 48; iter: 0; batch classifier loss: 0.490020\n",
      "epoch 49; iter: 0; batch classifier loss: 0.553406\n",
      "epoch 0; iter: 0; batch classifier loss: 0.800711; batch adversarial loss: 0.502262\n",
      "epoch 1; iter: 0; batch classifier loss: 0.767996; batch adversarial loss: 0.511653\n",
      "epoch 2; iter: 0; batch classifier loss: 0.749191; batch adversarial loss: 0.531437\n",
      "epoch 3; iter: 0; batch classifier loss: 0.745081; batch adversarial loss: 0.540117\n",
      "epoch 4; iter: 0; batch classifier loss: 0.718502; batch adversarial loss: 0.524172\n",
      "epoch 5; iter: 0; batch classifier loss: 0.702819; batch adversarial loss: 0.613994\n",
      "epoch 6; iter: 0; batch classifier loss: 0.681224; batch adversarial loss: 0.507624\n",
      "epoch 7; iter: 0; batch classifier loss: 0.683746; batch adversarial loss: 0.514743\n",
      "epoch 8; iter: 0; batch classifier loss: 0.692331; batch adversarial loss: 0.483620\n",
      "epoch 9; iter: 0; batch classifier loss: 0.691464; batch adversarial loss: 0.580173\n",
      "epoch 10; iter: 0; batch classifier loss: 0.702592; batch adversarial loss: 0.549709\n",
      "epoch 11; iter: 0; batch classifier loss: 0.695269; batch adversarial loss: 0.490404\n",
      "epoch 12; iter: 0; batch classifier loss: 0.666385; batch adversarial loss: 0.532785\n",
      "epoch 13; iter: 0; batch classifier loss: 0.750056; batch adversarial loss: 0.672167\n",
      "epoch 14; iter: 0; batch classifier loss: 0.715923; batch adversarial loss: 0.535190\n",
      "epoch 15; iter: 0; batch classifier loss: 0.717511; batch adversarial loss: 0.590659\n",
      "epoch 16; iter: 0; batch classifier loss: 0.791661; batch adversarial loss: 0.627221\n",
      "epoch 17; iter: 0; batch classifier loss: 0.783000; batch adversarial loss: 0.725190\n",
      "epoch 18; iter: 0; batch classifier loss: 0.796729; batch adversarial loss: 0.652884\n",
      "epoch 19; iter: 0; batch classifier loss: 0.832491; batch adversarial loss: 0.709263\n",
      "epoch 20; iter: 0; batch classifier loss: 0.848058; batch adversarial loss: 0.625677\n",
      "epoch 21; iter: 0; batch classifier loss: 0.900835; batch adversarial loss: 0.655991\n",
      "epoch 22; iter: 0; batch classifier loss: 0.896206; batch adversarial loss: 0.723631\n",
      "epoch 23; iter: 0; batch classifier loss: 0.935212; batch adversarial loss: 0.725888\n",
      "epoch 24; iter: 0; batch classifier loss: 1.091719; batch adversarial loss: 0.701522\n",
      "epoch 25; iter: 0; batch classifier loss: 1.090765; batch adversarial loss: 0.711539\n",
      "epoch 26; iter: 0; batch classifier loss: 1.093937; batch adversarial loss: 0.690307\n",
      "epoch 27; iter: 0; batch classifier loss: 1.093841; batch adversarial loss: 0.850311\n",
      "epoch 28; iter: 0; batch classifier loss: 1.163023; batch adversarial loss: 0.694117\n",
      "epoch 29; iter: 0; batch classifier loss: 1.272242; batch adversarial loss: 0.784684\n",
      "epoch 30; iter: 0; batch classifier loss: 1.182292; batch adversarial loss: 0.741808\n",
      "epoch 31; iter: 0; batch classifier loss: 1.215550; batch adversarial loss: 0.791313\n",
      "epoch 32; iter: 0; batch classifier loss: 1.339175; batch adversarial loss: 0.777689\n",
      "epoch 33; iter: 0; batch classifier loss: 1.351136; batch adversarial loss: 0.743724\n",
      "epoch 34; iter: 0; batch classifier loss: 1.313876; batch adversarial loss: 0.762019\n",
      "epoch 35; iter: 0; batch classifier loss: 1.370388; batch adversarial loss: 0.742509\n",
      "epoch 36; iter: 0; batch classifier loss: 1.271951; batch adversarial loss: 0.817663\n",
      "epoch 37; iter: 0; batch classifier loss: 1.417270; batch adversarial loss: 0.676367\n",
      "epoch 38; iter: 0; batch classifier loss: 1.399400; batch adversarial loss: 0.768003\n",
      "epoch 39; iter: 0; batch classifier loss: 1.550016; batch adversarial loss: 0.693884\n",
      "epoch 40; iter: 0; batch classifier loss: 1.415416; batch adversarial loss: 0.811548\n",
      "epoch 41; iter: 0; batch classifier loss: 1.435326; batch adversarial loss: 0.730379\n",
      "epoch 42; iter: 0; batch classifier loss: 1.457737; batch adversarial loss: 0.739980\n",
      "epoch 43; iter: 0; batch classifier loss: 1.557276; batch adversarial loss: 0.762343\n",
      "epoch 44; iter: 0; batch classifier loss: 1.471565; batch adversarial loss: 0.769823\n",
      "epoch 45; iter: 0; batch classifier loss: 1.586582; batch adversarial loss: 0.777575\n",
      "epoch 46; iter: 0; batch classifier loss: 1.561926; batch adversarial loss: 0.680864\n",
      "epoch 47; iter: 0; batch classifier loss: 1.468120; batch adversarial loss: 0.769924\n",
      "epoch 48; iter: 0; batch classifier loss: 1.361270; batch adversarial loss: 0.744783\n",
      "epoch 49; iter: 0; batch classifier loss: 1.499946; batch adversarial loss: 0.777395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/ml-19jan/lib/python3.5/site-packages/aif360/metrics/dataset_metric.py:94: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.702313\n",
      "epoch 1; iter: 0; batch classifier loss: 0.653784\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624428\n",
      "epoch 3; iter: 0; batch classifier loss: 0.530635\n",
      "epoch 4; iter: 0; batch classifier loss: 0.502238\n",
      "epoch 5; iter: 0; batch classifier loss: 0.631842\n",
      "epoch 6; iter: 0; batch classifier loss: 0.504143\n",
      "epoch 7; iter: 0; batch classifier loss: 0.691968\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530739\n",
      "epoch 9; iter: 0; batch classifier loss: 0.539838\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535095\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539878\n",
      "epoch 12; iter: 0; batch classifier loss: 0.581040\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539105\n",
      "epoch 14; iter: 0; batch classifier loss: 0.548719\n",
      "epoch 15; iter: 0; batch classifier loss: 0.510625\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528183\n",
      "epoch 17; iter: 0; batch classifier loss: 0.458212\n",
      "epoch 18; iter: 0; batch classifier loss: 0.549639\n",
      "epoch 19; iter: 0; batch classifier loss: 0.501361\n",
      "epoch 20; iter: 0; batch classifier loss: 0.551130\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482357\n",
      "epoch 22; iter: 0; batch classifier loss: 0.566909\n",
      "epoch 23; iter: 0; batch classifier loss: 0.538719\n",
      "epoch 24; iter: 0; batch classifier loss: 0.531542\n",
      "epoch 25; iter: 0; batch classifier loss: 0.492197\n",
      "epoch 26; iter: 0; batch classifier loss: 0.520966\n",
      "epoch 27; iter: 0; batch classifier loss: 0.556897\n",
      "epoch 28; iter: 0; batch classifier loss: 0.510032\n",
      "epoch 29; iter: 0; batch classifier loss: 0.516206\n",
      "epoch 30; iter: 0; batch classifier loss: 0.542669\n",
      "epoch 31; iter: 0; batch classifier loss: 0.516650\n",
      "epoch 32; iter: 0; batch classifier loss: 0.578070\n",
      "epoch 33; iter: 0; batch classifier loss: 0.509881\n",
      "epoch 34; iter: 0; batch classifier loss: 0.575773\n",
      "epoch 35; iter: 0; batch classifier loss: 0.575909\n",
      "epoch 36; iter: 0; batch classifier loss: 0.515550\n",
      "epoch 37; iter: 0; batch classifier loss: 0.509046\n",
      "epoch 38; iter: 0; batch classifier loss: 0.532475\n",
      "epoch 39; iter: 0; batch classifier loss: 0.531016\n",
      "epoch 40; iter: 0; batch classifier loss: 0.507759\n",
      "epoch 41; iter: 0; batch classifier loss: 0.577047\n",
      "epoch 42; iter: 0; batch classifier loss: 0.554646\n",
      "epoch 43; iter: 0; batch classifier loss: 0.527592\n",
      "epoch 44; iter: 0; batch classifier loss: 0.589694\n",
      "epoch 45; iter: 0; batch classifier loss: 0.550703\n",
      "epoch 46; iter: 0; batch classifier loss: 0.549997\n",
      "epoch 47; iter: 0; batch classifier loss: 0.521169\n",
      "epoch 48; iter: 0; batch classifier loss: 0.532724\n",
      "epoch 49; iter: 0; batch classifier loss: 0.503721\n",
      "run = 10\n",
      "epoch 0; iter: 0; batch classifier loss: 0.689586; batch adversarial loss: 0.724212\n",
      "epoch 1; iter: 0; batch classifier loss: 0.620954; batch adversarial loss: 0.778069\n",
      "epoch 2; iter: 0; batch classifier loss: 0.628770; batch adversarial loss: 0.721413\n",
      "epoch 3; iter: 0; batch classifier loss: 0.516478; batch adversarial loss: 0.610454\n",
      "epoch 4; iter: 0; batch classifier loss: 0.515520; batch adversarial loss: 0.579709\n",
      "epoch 5; iter: 0; batch classifier loss: 0.539102; batch adversarial loss: 0.605424\n",
      "epoch 6; iter: 0; batch classifier loss: 0.553559; batch adversarial loss: 0.536738\n",
      "epoch 7; iter: 0; batch classifier loss: 0.481329; batch adversarial loss: 0.559880\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534505; batch adversarial loss: 0.548289\n",
      "epoch 9; iter: 0; batch classifier loss: 0.502191; batch adversarial loss: 0.544986\n",
      "epoch 10; iter: 0; batch classifier loss: 0.531154; batch adversarial loss: 0.567581\n",
      "epoch 11; iter: 0; batch classifier loss: 0.521362; batch adversarial loss: 0.427160\n",
      "epoch 12; iter: 0; batch classifier loss: 0.602878; batch adversarial loss: 0.488836\n",
      "epoch 13; iter: 0; batch classifier loss: 0.515141; batch adversarial loss: 0.612852\n",
      "epoch 14; iter: 0; batch classifier loss: 0.591763; batch adversarial loss: 0.420877\n",
      "epoch 15; iter: 0; batch classifier loss: 0.609373; batch adversarial loss: 0.448671\n",
      "epoch 16; iter: 0; batch classifier loss: 0.665294; batch adversarial loss: 0.578444\n",
      "epoch 17; iter: 0; batch classifier loss: 0.652164; batch adversarial loss: 0.529466\n",
      "epoch 18; iter: 0; batch classifier loss: 0.646735; batch adversarial loss: 0.519170\n",
      "epoch 19; iter: 0; batch classifier loss: 0.615509; batch adversarial loss: 0.452311\n",
      "epoch 20; iter: 0; batch classifier loss: 0.576416; batch adversarial loss: 0.520227\n",
      "epoch 21; iter: 0; batch classifier loss: 0.677491; batch adversarial loss: 0.498735\n",
      "epoch 22; iter: 0; batch classifier loss: 0.632103; batch adversarial loss: 0.527414\n",
      "epoch 23; iter: 0; batch classifier loss: 0.655122; batch adversarial loss: 0.492393\n",
      "epoch 24; iter: 0; batch classifier loss: 0.569791; batch adversarial loss: 0.543361\n",
      "epoch 25; iter: 0; batch classifier loss: 0.593067; batch adversarial loss: 0.488399\n",
      "epoch 26; iter: 0; batch classifier loss: 0.624922; batch adversarial loss: 0.468946\n",
      "epoch 27; iter: 0; batch classifier loss: 0.575582; batch adversarial loss: 0.507808\n",
      "epoch 28; iter: 0; batch classifier loss: 0.651877; batch adversarial loss: 0.441022\n",
      "epoch 29; iter: 0; batch classifier loss: 0.594551; batch adversarial loss: 0.408966\n",
      "epoch 30; iter: 0; batch classifier loss: 0.568899; batch adversarial loss: 0.485320\n",
      "epoch 31; iter: 0; batch classifier loss: 0.575930; batch adversarial loss: 0.420502\n",
      "epoch 32; iter: 0; batch classifier loss: 0.553637; batch adversarial loss: 0.477291\n",
      "epoch 33; iter: 0; batch classifier loss: 0.568732; batch adversarial loss: 0.452046\n",
      "epoch 34; iter: 0; batch classifier loss: 0.619114; batch adversarial loss: 0.404825\n",
      "epoch 35; iter: 0; batch classifier loss: 0.616768; batch adversarial loss: 0.468615\n",
      "epoch 36; iter: 0; batch classifier loss: 0.554133; batch adversarial loss: 0.458772\n",
      "epoch 37; iter: 0; batch classifier loss: 0.553204; batch adversarial loss: 0.460606\n",
      "epoch 38; iter: 0; batch classifier loss: 0.671183; batch adversarial loss: 0.432883\n",
      "epoch 39; iter: 0; batch classifier loss: 0.520450; batch adversarial loss: 0.434188\n",
      "epoch 40; iter: 0; batch classifier loss: 0.560686; batch adversarial loss: 0.463661\n",
      "epoch 41; iter: 0; batch classifier loss: 0.522815; batch adversarial loss: 0.440267\n",
      "epoch 42; iter: 0; batch classifier loss: 0.502477; batch adversarial loss: 0.516006\n",
      "epoch 43; iter: 0; batch classifier loss: 0.550961; batch adversarial loss: 0.468292\n",
      "epoch 44; iter: 0; batch classifier loss: 0.569201; batch adversarial loss: 0.495305\n",
      "epoch 45; iter: 0; batch classifier loss: 0.521281; batch adversarial loss: 0.370765\n",
      "epoch 46; iter: 0; batch classifier loss: 0.563696; batch adversarial loss: 0.385781\n",
      "epoch 47; iter: 0; batch classifier loss: 0.612080; batch adversarial loss: 0.469044\n",
      "epoch 48; iter: 0; batch classifier loss: 0.576074; batch adversarial loss: 0.393012\n",
      "epoch 49; iter: 0; batch classifier loss: 0.619789; batch adversarial loss: 0.486714\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731352\n",
      "epoch 1; iter: 0; batch classifier loss: 0.670083\n",
      "epoch 2; iter: 0; batch classifier loss: 0.596043\n",
      "epoch 3; iter: 0; batch classifier loss: 0.621611\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542225\n",
      "epoch 5; iter: 0; batch classifier loss: 0.539187\n",
      "epoch 6; iter: 0; batch classifier loss: 0.614162\n",
      "epoch 7; iter: 0; batch classifier loss: 0.609851\n",
      "epoch 8; iter: 0; batch classifier loss: 0.619534\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556555\n",
      "epoch 10; iter: 0; batch classifier loss: 0.495666\n",
      "epoch 11; iter: 0; batch classifier loss: 0.562102\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498240\n",
      "epoch 13; iter: 0; batch classifier loss: 0.542691\n",
      "epoch 14; iter: 0; batch classifier loss: 0.525729\n",
      "epoch 15; iter: 0; batch classifier loss: 0.563561\n",
      "epoch 16; iter: 0; batch classifier loss: 0.557194\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474122\n",
      "epoch 18; iter: 0; batch classifier loss: 0.598829\n",
      "epoch 19; iter: 0; batch classifier loss: 0.568186\n",
      "epoch 20; iter: 0; batch classifier loss: 0.539218\n",
      "epoch 21; iter: 0; batch classifier loss: 0.596265\n",
      "epoch 22; iter: 0; batch classifier loss: 0.549384\n",
      "epoch 23; iter: 0; batch classifier loss: 0.510101\n",
      "epoch 24; iter: 0; batch classifier loss: 0.512369\n",
      "epoch 25; iter: 0; batch classifier loss: 0.517930\n",
      "epoch 26; iter: 0; batch classifier loss: 0.530420\n",
      "epoch 27; iter: 0; batch classifier loss: 0.508477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 0; batch classifier loss: 0.577733\n",
      "epoch 29; iter: 0; batch classifier loss: 0.507871\n",
      "epoch 30; iter: 0; batch classifier loss: 0.575643\n",
      "epoch 31; iter: 0; batch classifier loss: 0.512980\n",
      "epoch 32; iter: 0; batch classifier loss: 0.608648\n",
      "epoch 33; iter: 0; batch classifier loss: 0.531883\n",
      "epoch 34; iter: 0; batch classifier loss: 0.478486\n",
      "epoch 35; iter: 0; batch classifier loss: 0.565017\n",
      "epoch 36; iter: 0; batch classifier loss: 0.539549\n",
      "epoch 37; iter: 0; batch classifier loss: 0.511149\n",
      "epoch 38; iter: 0; batch classifier loss: 0.490012\n",
      "epoch 39; iter: 0; batch classifier loss: 0.483139\n",
      "epoch 40; iter: 0; batch classifier loss: 0.500665\n",
      "epoch 41; iter: 0; batch classifier loss: 0.615146\n",
      "epoch 42; iter: 0; batch classifier loss: 0.501526\n",
      "epoch 43; iter: 0; batch classifier loss: 0.486841\n",
      "epoch 44; iter: 0; batch classifier loss: 0.561623\n",
      "epoch 45; iter: 0; batch classifier loss: 0.568142\n",
      "epoch 46; iter: 0; batch classifier loss: 0.511183\n",
      "epoch 47; iter: 0; batch classifier loss: 0.429731\n",
      "epoch 48; iter: 0; batch classifier loss: 0.539386\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450895\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701407; batch adversarial loss: 0.992791\n",
      "epoch 1; iter: 0; batch classifier loss: 0.674940; batch adversarial loss: 1.073040\n",
      "epoch 2; iter: 0; batch classifier loss: 0.606263; batch adversarial loss: 1.217344\n",
      "epoch 3; iter: 0; batch classifier loss: 0.603970; batch adversarial loss: 1.232543\n",
      "epoch 4; iter: 0; batch classifier loss: 0.627619; batch adversarial loss: 1.252431\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580582; batch adversarial loss: 1.321126\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592514; batch adversarial loss: 1.361566\n",
      "epoch 7; iter: 0; batch classifier loss: 0.617595; batch adversarial loss: 1.400863\n",
      "epoch 8; iter: 0; batch classifier loss: 0.693786; batch adversarial loss: 1.375585\n",
      "epoch 9; iter: 0; batch classifier loss: 0.558671; batch adversarial loss: 1.406955\n",
      "epoch 10; iter: 0; batch classifier loss: 0.617653; batch adversarial loss: 1.402740\n",
      "epoch 11; iter: 0; batch classifier loss: 0.610441; batch adversarial loss: 1.352819\n",
      "epoch 12; iter: 0; batch classifier loss: 0.701338; batch adversarial loss: 1.378598\n",
      "epoch 13; iter: 0; batch classifier loss: 0.681186; batch adversarial loss: 1.387097\n",
      "epoch 14; iter: 0; batch classifier loss: 0.557217; batch adversarial loss: 1.317709\n",
      "epoch 15; iter: 0; batch classifier loss: 0.558977; batch adversarial loss: 1.380652\n",
      "epoch 16; iter: 0; batch classifier loss: 0.567469; batch adversarial loss: 1.385883\n",
      "epoch 17; iter: 0; batch classifier loss: 0.647495; batch adversarial loss: 1.284175\n",
      "epoch 18; iter: 0; batch classifier loss: 0.636360; batch adversarial loss: 1.304583\n",
      "epoch 19; iter: 0; batch classifier loss: 0.478439; batch adversarial loss: 1.251700\n",
      "epoch 20; iter: 0; batch classifier loss: 0.699912; batch adversarial loss: 1.298055\n",
      "epoch 21; iter: 0; batch classifier loss: 0.672412; batch adversarial loss: 1.306659\n",
      "epoch 22; iter: 0; batch classifier loss: 0.617128; batch adversarial loss: 1.264714\n",
      "epoch 23; iter: 0; batch classifier loss: 0.613304; batch adversarial loss: 1.307251\n",
      "epoch 24; iter: 0; batch classifier loss: 0.638090; batch adversarial loss: 1.271467\n",
      "epoch 25; iter: 0; batch classifier loss: 0.528670; batch adversarial loss: 1.294575\n",
      "epoch 26; iter: 0; batch classifier loss: 0.578090; batch adversarial loss: 1.278462\n",
      "epoch 27; iter: 0; batch classifier loss: 0.706420; batch adversarial loss: 1.184311\n",
      "epoch 28; iter: 0; batch classifier loss: 0.608329; batch adversarial loss: 1.248453\n",
      "epoch 29; iter: 0; batch classifier loss: 0.581555; batch adversarial loss: 1.278360\n",
      "epoch 30; iter: 0; batch classifier loss: 0.693368; batch adversarial loss: 1.254950\n",
      "epoch 31; iter: 0; batch classifier loss: 0.694306; batch adversarial loss: 1.218775\n",
      "epoch 32; iter: 0; batch classifier loss: 0.660387; batch adversarial loss: 1.217788\n",
      "epoch 33; iter: 0; batch classifier loss: 0.654376; batch adversarial loss: 1.251649\n",
      "epoch 34; iter: 0; batch classifier loss: 0.563803; batch adversarial loss: 1.211629\n",
      "epoch 35; iter: 0; batch classifier loss: 0.701432; batch adversarial loss: 1.120068\n",
      "epoch 36; iter: 0; batch classifier loss: 0.470666; batch adversarial loss: 1.197648\n",
      "epoch 37; iter: 0; batch classifier loss: 0.616268; batch adversarial loss: 1.140694\n",
      "epoch 38; iter: 0; batch classifier loss: 0.468323; batch adversarial loss: 1.201945\n",
      "epoch 39; iter: 0; batch classifier loss: 0.597089; batch adversarial loss: 1.167707\n",
      "epoch 40; iter: 0; batch classifier loss: 0.686675; batch adversarial loss: 1.161346\n",
      "epoch 41; iter: 0; batch classifier loss: 0.703341; batch adversarial loss: 1.162907\n",
      "epoch 42; iter: 0; batch classifier loss: 0.595738; batch adversarial loss: 1.159086\n",
      "epoch 43; iter: 0; batch classifier loss: 0.755827; batch adversarial loss: 1.139363\n",
      "epoch 44; iter: 0; batch classifier loss: 0.604962; batch adversarial loss: 1.145418\n",
      "epoch 45; iter: 0; batch classifier loss: 0.616323; batch adversarial loss: 1.125522\n",
      "epoch 46; iter: 0; batch classifier loss: 0.638472; batch adversarial loss: 1.098077\n",
      "epoch 47; iter: 0; batch classifier loss: 0.721769; batch adversarial loss: 1.109712\n",
      "epoch 48; iter: 0; batch classifier loss: 0.527762; batch adversarial loss: 1.138365\n",
      "epoch 49; iter: 0; batch classifier loss: 0.624983; batch adversarial loss: 1.083429\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683419\n",
      "epoch 1; iter: 0; batch classifier loss: 0.637150\n",
      "epoch 2; iter: 0; batch classifier loss: 0.622487\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614596\n",
      "epoch 4; iter: 0; batch classifier loss: 0.573093\n",
      "epoch 5; iter: 0; batch classifier loss: 0.595460\n",
      "epoch 6; iter: 0; batch classifier loss: 0.632355\n",
      "epoch 7; iter: 0; batch classifier loss: 0.604404\n",
      "epoch 8; iter: 0; batch classifier loss: 0.612073\n",
      "epoch 9; iter: 0; batch classifier loss: 0.619886\n",
      "epoch 10; iter: 0; batch classifier loss: 0.555271\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554693\n",
      "epoch 12; iter: 0; batch classifier loss: 0.532623\n",
      "epoch 13; iter: 0; batch classifier loss: 0.571437\n",
      "epoch 14; iter: 0; batch classifier loss: 0.584419\n",
      "epoch 15; iter: 0; batch classifier loss: 0.580322\n",
      "epoch 16; iter: 0; batch classifier loss: 0.486993\n",
      "epoch 17; iter: 0; batch classifier loss: 0.542197\n",
      "epoch 18; iter: 0; batch classifier loss: 0.543916\n",
      "epoch 19; iter: 0; batch classifier loss: 0.616892\n",
      "epoch 20; iter: 0; batch classifier loss: 0.660982\n",
      "epoch 21; iter: 0; batch classifier loss: 0.461610\n",
      "epoch 22; iter: 0; batch classifier loss: 0.531151\n",
      "epoch 23; iter: 0; batch classifier loss: 0.613110\n",
      "epoch 24; iter: 0; batch classifier loss: 0.630032\n",
      "epoch 25; iter: 0; batch classifier loss: 0.513372\n",
      "epoch 26; iter: 0; batch classifier loss: 0.531411\n",
      "epoch 27; iter: 0; batch classifier loss: 0.620224\n",
      "epoch 28; iter: 0; batch classifier loss: 0.589039\n",
      "epoch 29; iter: 0; batch classifier loss: 0.559649\n",
      "epoch 30; iter: 0; batch classifier loss: 0.568520\n",
      "epoch 31; iter: 0; batch classifier loss: 0.632914\n",
      "epoch 32; iter: 0; batch classifier loss: 0.563237\n",
      "epoch 33; iter: 0; batch classifier loss: 0.486640\n",
      "epoch 34; iter: 0; batch classifier loss: 0.527576\n",
      "epoch 35; iter: 0; batch classifier loss: 0.584508\n",
      "epoch 36; iter: 0; batch classifier loss: 0.552055\n",
      "epoch 37; iter: 0; batch classifier loss: 0.545450\n",
      "epoch 38; iter: 0; batch classifier loss: 0.533839\n",
      "epoch 39; iter: 0; batch classifier loss: 0.587174\n",
      "epoch 40; iter: 0; batch classifier loss: 0.505908\n",
      "epoch 41; iter: 0; batch classifier loss: 0.534493\n",
      "epoch 42; iter: 0; batch classifier loss: 0.579136\n",
      "epoch 43; iter: 0; batch classifier loss: 0.582402\n",
      "epoch 44; iter: 0; batch classifier loss: 0.499941\n",
      "epoch 45; iter: 0; batch classifier loss: 0.520771\n",
      "epoch 46; iter: 0; batch classifier loss: 0.516452\n",
      "epoch 47; iter: 0; batch classifier loss: 0.519853\n",
      "epoch 48; iter: 0; batch classifier loss: 0.468478\n",
      "epoch 49; iter: 0; batch classifier loss: 0.496887\n",
      "\n",
      "prediction completed\n",
      "compiled all metrics\n",
      "all files saved to csv\n"
     ]
    }
   ],
   "source": [
    "privileged_groups = [{'age': 1}]\n",
    "unprivileged_groups = [{'age': 0}]\n",
    "\n",
    "print(\"Classification with German data set\\n\")\n",
    "# df = pd.read_csv('dataset/compas-scores-two-years.csv')\n",
    "dataset_orig = load_preproc_data_german()\n",
    "\n",
    "matrix_accuracy_reweigh = {}\n",
    "matrix_accuracy_nonreweigh = {}\n",
    "matrix_fairness_reweigh = {}\n",
    "matrix_fairness_nonreweigh = {}\n",
    "\n",
    "runs = 10\n",
    "\n",
    "for i in range(0, runs):\n",
    "    print('run =', i+1)\n",
    "    \n",
    "    train, test = dataset_orig.split([0.7], shuffle=True)\n",
    "    train_transformed = reweighing_data(train, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # with reweighing\n",
    "    accuracy_reweigh, fairness_metrics_reweigh = make_prediction(train_transformed, test, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # Without reweighing\n",
    "    accuracy_nonreweigh, fairness_metrics_nonreweigh = make_prediction(train, test, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # store values for each run\n",
    "    matrix_accuracy_reweigh[i] = accuracy_reweigh\n",
    "    matrix_fairness_reweigh[i] = fairness_metrics_reweigh\n",
    "    matrix_accuracy_nonreweigh[i] = accuracy_nonreweigh\n",
    "    matrix_fairness_nonreweigh[i] = fairness_metrics_nonreweigh\n",
    "\n",
    "print('\\nprediction completed')\n",
    "\n",
    "metrics_adversarial_reweigh = []\n",
    "metrics_prejudice_reweigh = []\n",
    "metrics_nondebiasing_reweigh = []\n",
    "metrics_ensemble_reweigh = []\n",
    "metrics_adversarial_nonreweigh = []\n",
    "metrics_prejudice_nonreweigh = []\n",
    "metrics_nondebiasing_nonreweigh = []\n",
    "metrics_ensemble_nonreweigh = []\n",
    "\n",
    "for i in range(0, runs):\n",
    "    \n",
    "    # with reweighing\n",
    "    metrics_adversarial_reweigh.append(matrix_fairness_reweigh[i][0])\n",
    "    metrics_prejudice_reweigh.append(matrix_fairness_reweigh[i][1])\n",
    "    metrics_nondebiasing_reweigh.append(matrix_fairness_reweigh[i][2])\n",
    "    metrics_ensemble_reweigh.append(matrix_fairness_reweigh[i][3])\n",
    "    \n",
    "    # without reweighing\n",
    "    metrics_adversarial_nonreweigh.append(matrix_fairness_nonreweigh[i][0])\n",
    "    metrics_prejudice_nonreweigh.append(matrix_fairness_nonreweigh[i][1])\n",
    "    metrics_nondebiasing_nonreweigh.append(matrix_fairness_nonreweigh[i][2])\n",
    "    metrics_ensemble_nonreweigh.append(matrix_fairness_nonreweigh[i][3])\n",
    "\n",
    "print('compiled all metrics')\n",
    "\n",
    "\n",
    "# create data frame for all metrics\n",
    "columns = ['Adversarial Debiasing', 'Prejudice Remover', 'Nondebiasing', 'Ensemble']\n",
    "accuracy_reweigh = np.array(list(matrix_accuracy_reweigh.values()))\n",
    "accuracy_nonreweigh = np.array(list(matrix_accuracy_nonreweigh.values()))\n",
    "compas_accuracy_reweigh = pd.DataFrame(accuracy_reweigh, columns=columns)\n",
    "compas_accuracy_nonreweigh = pd.DataFrame(accuracy_nonreweigh, columns=columns)\n",
    "\n",
    "# fairness metrics\n",
    "columns = ['Mean Difference', 'Disparate Impact', 'Equal Opportunity Difference', 'Average Odds Difference', 'Theil Index']\n",
    "compas_adversarial_reweigh = pd.DataFrame(metrics_adversarial_reweigh, columns=columns)\n",
    "compas_prejudice_reweigh = pd.DataFrame(metrics_prejudice_reweigh, columns=columns)\n",
    "compas_nondebiasing_reweigh = pd.DataFrame(metrics_nondebiasing_reweigh, columns=columns)\n",
    "compas_ensemble_reweigh = pd.DataFrame(metrics_ensemble_reweigh, columns=columns)\n",
    "\n",
    "compas_adversarial_nonreweigh = pd.DataFrame(metrics_adversarial_nonreweigh, columns=columns)\n",
    "compas_prejudice_nonreweigh = pd.DataFrame(metrics_prejudice_nonreweigh, columns=columns)\n",
    "compas_nondebiasing_nonreweigh = pd.DataFrame(metrics_nondebiasing_nonreweigh, columns=columns)\n",
    "compas_ensemble_nonreweigh = pd.DataFrame(metrics_ensemble_nonreweigh, columns=columns)\n",
    "\n",
    "\n",
    "# save to csv\n",
    "compas_accuracy_reweigh.to_csv(\"results-11feb/race/german/reweighed/accuracy.csv\", encoding='utf-8')\n",
    "compas_adversarial_reweigh.to_csv(\"results-11feb/race/german/reweighed/adversarial.csv\", encoding='utf-8')\n",
    "compas_prejudice_reweigh.to_csv(\"results-11feb/race/german/reweighed/prejudice.csv\", encoding='utf-8')\n",
    "compas_nondebiasing_reweigh.to_csv(\"results-11feb/race/german/reweighed/neural_net.csv\", encoding='utf-8')\n",
    "compas_ensemble_reweigh.to_csv(\"results-11feb/race/german/reweighed/ensemble.csv\", encoding='utf-8')\n",
    "\n",
    "compas_accuracy_nonreweigh.to_csv(\"results-11feb/race/german/non-reweighed/accuracy.csv\", encoding='utf-8')\n",
    "compas_adversarial_nonreweigh.to_csv(\"results-11feb/race/german/non-reweighed/adversarial.csv\", encoding='utf-8')\n",
    "compas_prejudice_nonreweigh.to_csv(\"results-11feb/race/german/non-reweighed/prejudice.csv\", encoding='utf-8')\n",
    "compas_nondebiasing_nonreweigh.to_csv(\"results-11feb/race/german/non-reweighed/neural_net.csv\", encoding='utf-8')\n",
    "compas_ensemble_nonreweigh.to_csv(\"results-11feb/race/german/non-reweighed/ensemble.csv\", encoding='utf-8')\n",
    "\n",
    "print('all files saved to csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification with Adult data set\n",
      "\n",
      "run = 1\n",
      "epoch 0; iter: 0; batch classifier loss: 0.754099; batch adversarial loss: 0.745721\n",
      "epoch 0; iter: 200; batch classifier loss: 0.490396; batch adversarial loss: 0.640205\n",
      "epoch 0; iter: 400; batch classifier loss: 0.418454; batch adversarial loss: 0.584018\n",
      "epoch 0; iter: 600; batch classifier loss: 0.382492; batch adversarial loss: 0.523020\n",
      "epoch 0; iter: 800; batch classifier loss: 0.437498; batch adversarial loss: 0.467506\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.460201; batch adversarial loss: 0.498694\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.390761; batch adversarial loss: 0.395536\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.422271; batch adversarial loss: 0.539811\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.454482; batch adversarial loss: 0.475391\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.388615; batch adversarial loss: 0.430075\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.501411; batch adversarial loss: 0.518137\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.541569; batch adversarial loss: 0.398723\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.439626; batch adversarial loss: 0.368786\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.427998; batch adversarial loss: 0.340431\n",
      "epoch 1; iter: 0; batch classifier loss: 0.377956; batch adversarial loss: 0.430986\n",
      "epoch 1; iter: 200; batch classifier loss: 0.366753; batch adversarial loss: 0.438878\n",
      "epoch 1; iter: 400; batch classifier loss: 0.387381; batch adversarial loss: 0.413772\n",
      "epoch 1; iter: 600; batch classifier loss: 0.449459; batch adversarial loss: 0.458515\n",
      "epoch 1; iter: 800; batch classifier loss: 0.394487; batch adversarial loss: 0.320101\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.455935; batch adversarial loss: 0.511328\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.402840; batch adversarial loss: 0.316603\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.313475; batch adversarial loss: 0.312851\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.473800; batch adversarial loss: 0.365415\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.483721; batch adversarial loss: 0.528127\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.388211; batch adversarial loss: 0.338510\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.399078; batch adversarial loss: 0.406162\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.404001; batch adversarial loss: 0.406593\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.407553; batch adversarial loss: 0.420050\n",
      "epoch 2; iter: 0; batch classifier loss: 0.343868; batch adversarial loss: 0.337735\n",
      "epoch 2; iter: 200; batch classifier loss: 0.365340; batch adversarial loss: 0.418859\n",
      "epoch 2; iter: 400; batch classifier loss: 0.447368; batch adversarial loss: 0.447262\n",
      "epoch 2; iter: 600; batch classifier loss: 0.396946; batch adversarial loss: 0.529913\n",
      "epoch 2; iter: 800; batch classifier loss: 0.407434; batch adversarial loss: 0.417879\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.386035; batch adversarial loss: 0.518130\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.364916; batch adversarial loss: 0.392324\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.442948; batch adversarial loss: 0.474833\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.361533; batch adversarial loss: 0.432635\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.405702; batch adversarial loss: 0.503877\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.391842; batch adversarial loss: 0.432476\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.498785; batch adversarial loss: 0.379941\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.469617; batch adversarial loss: 0.423103\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.303582; batch adversarial loss: 0.475534\n",
      "epoch 3; iter: 0; batch classifier loss: 0.373000; batch adversarial loss: 0.545491\n",
      "epoch 3; iter: 200; batch classifier loss: 0.394163; batch adversarial loss: 0.308855\n",
      "epoch 3; iter: 400; batch classifier loss: 0.404096; batch adversarial loss: 0.391154\n",
      "epoch 3; iter: 600; batch classifier loss: 0.385335; batch adversarial loss: 0.404937\n",
      "epoch 3; iter: 800; batch classifier loss: 0.408211; batch adversarial loss: 0.392279\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.426131; batch adversarial loss: 0.378579\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.360579; batch adversarial loss: 0.432888\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.401351; batch adversarial loss: 0.392875\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.406535; batch adversarial loss: 0.378857\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.378516; batch adversarial loss: 0.323511\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.370803; batch adversarial loss: 0.434080\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.433679; batch adversarial loss: 0.404378\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.434937; batch adversarial loss: 0.350976\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.419590; batch adversarial loss: 0.462033\n",
      "epoch 4; iter: 0; batch classifier loss: 0.343288; batch adversarial loss: 0.418207\n",
      "epoch 4; iter: 200; batch classifier loss: 0.395980; batch adversarial loss: 0.377731\n",
      "epoch 4; iter: 400; batch classifier loss: 0.366618; batch adversarial loss: 0.502944\n",
      "epoch 4; iter: 600; batch classifier loss: 0.492757; batch adversarial loss: 0.460599\n",
      "epoch 4; iter: 800; batch classifier loss: 0.407454; batch adversarial loss: 0.406192\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.409794; batch adversarial loss: 0.365981\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.480029; batch adversarial loss: 0.393089\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.457608; batch adversarial loss: 0.475916\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.449775; batch adversarial loss: 0.446922\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.323900; batch adversarial loss: 0.435297\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.474962; batch adversarial loss: 0.296960\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.381240; batch adversarial loss: 0.432638\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.450561; batch adversarial loss: 0.473529\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.414406; batch adversarial loss: 0.418010\n",
      "epoch 5; iter: 0; batch classifier loss: 0.363719; batch adversarial loss: 0.461413\n",
      "epoch 5; iter: 200; batch classifier loss: 0.425307; batch adversarial loss: 0.351130\n",
      "epoch 5; iter: 400; batch classifier loss: 0.440112; batch adversarial loss: 0.365998\n",
      "epoch 5; iter: 600; batch classifier loss: 0.300993; batch adversarial loss: 0.380555\n",
      "epoch 5; iter: 800; batch classifier loss: 0.480211; batch adversarial loss: 0.363924\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.471209; batch adversarial loss: 0.363247\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.380495; batch adversarial loss: 0.410072\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.502905; batch adversarial loss: 0.351463\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.420116; batch adversarial loss: 0.419274\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.400288; batch adversarial loss: 0.407629\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.401146; batch adversarial loss: 0.444951\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.373404; batch adversarial loss: 0.392044\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.357372; batch adversarial loss: 0.434741\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.457751; batch adversarial loss: 0.420113\n",
      "epoch 6; iter: 0; batch classifier loss: 0.398062; batch adversarial loss: 0.419460\n",
      "epoch 6; iter: 200; batch classifier loss: 0.317084; batch adversarial loss: 0.364888\n",
      "epoch 6; iter: 400; batch classifier loss: 0.380303; batch adversarial loss: 0.419820\n",
      "epoch 6; iter: 600; batch classifier loss: 0.422010; batch adversarial loss: 0.502753\n",
      "epoch 6; iter: 800; batch classifier loss: 0.366180; batch adversarial loss: 0.501643\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.392917; batch adversarial loss: 0.379180\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.368129; batch adversarial loss: 0.350373\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.456709; batch adversarial loss: 0.375758\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.427557; batch adversarial loss: 0.404834\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.421886; batch adversarial loss: 0.420554\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.487915; batch adversarial loss: 0.378087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 2200; batch classifier loss: 0.480280; batch adversarial loss: 0.489400\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.440526; batch adversarial loss: 0.431703\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.383873; batch adversarial loss: 0.444845\n",
      "epoch 7; iter: 0; batch classifier loss: 0.329551; batch adversarial loss: 0.407541\n",
      "epoch 7; iter: 200; batch classifier loss: 0.361848; batch adversarial loss: 0.378791\n",
      "epoch 7; iter: 400; batch classifier loss: 0.409997; batch adversarial loss: 0.420720\n",
      "epoch 7; iter: 600; batch classifier loss: 0.382279; batch adversarial loss: 0.462574\n",
      "epoch 7; iter: 800; batch classifier loss: 0.331458; batch adversarial loss: 0.408880\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.419890; batch adversarial loss: 0.418779\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.416843; batch adversarial loss: 0.365991\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.335010; batch adversarial loss: 0.365995\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.421079; batch adversarial loss: 0.352590\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.550253; batch adversarial loss: 0.406805\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.433207; batch adversarial loss: 0.380148\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.399971; batch adversarial loss: 0.376046\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.393747; batch adversarial loss: 0.516517\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.416472; batch adversarial loss: 0.502464\n",
      "epoch 8; iter: 0; batch classifier loss: 0.400668; batch adversarial loss: 0.375933\n",
      "epoch 8; iter: 200; batch classifier loss: 0.401699; batch adversarial loss: 0.433392\n",
      "epoch 8; iter: 400; batch classifier loss: 0.479477; batch adversarial loss: 0.446205\n",
      "epoch 8; iter: 600; batch classifier loss: 0.405844; batch adversarial loss: 0.517885\n",
      "epoch 8; iter: 800; batch classifier loss: 0.390656; batch adversarial loss: 0.393585\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.463446; batch adversarial loss: 0.447343\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.524331; batch adversarial loss: 0.392279\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.405851; batch adversarial loss: 0.514761\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.445068; batch adversarial loss: 0.502809\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.319298; batch adversarial loss: 0.460876\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.325805; batch adversarial loss: 0.336164\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.473909; batch adversarial loss: 0.281283\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.433197; batch adversarial loss: 0.417875\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.401550; batch adversarial loss: 0.378699\n",
      "epoch 9; iter: 0; batch classifier loss: 0.453319; batch adversarial loss: 0.340467\n",
      "epoch 9; iter: 200; batch classifier loss: 0.466896; batch adversarial loss: 0.334413\n",
      "epoch 9; iter: 400; batch classifier loss: 0.354960; batch adversarial loss: 0.489846\n",
      "epoch 9; iter: 600; batch classifier loss: 0.396109; batch adversarial loss: 0.379039\n",
      "epoch 9; iter: 800; batch classifier loss: 0.396523; batch adversarial loss: 0.337657\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.420763; batch adversarial loss: 0.446258\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.533343; batch adversarial loss: 0.379788\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.391603; batch adversarial loss: 0.443731\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.440463; batch adversarial loss: 0.473823\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.390822; batch adversarial loss: 0.416970\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.518147; batch adversarial loss: 0.474828\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.432324; batch adversarial loss: 0.446289\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.342551; batch adversarial loss: 0.474452\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.393689; batch adversarial loss: 0.488701\n",
      "epoch 10; iter: 0; batch classifier loss: 0.425490; batch adversarial loss: 0.362783\n",
      "epoch 10; iter: 200; batch classifier loss: 0.374333; batch adversarial loss: 0.377450\n",
      "epoch 10; iter: 400; batch classifier loss: 0.420167; batch adversarial loss: 0.610341\n",
      "epoch 10; iter: 600; batch classifier loss: 0.420728; batch adversarial loss: 0.377229\n",
      "epoch 10; iter: 800; batch classifier loss: 0.351878; batch adversarial loss: 0.378365\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.461389; batch adversarial loss: 0.461243\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.451682; batch adversarial loss: 0.461216\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.424282; batch adversarial loss: 0.391005\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.360057; batch adversarial loss: 0.406803\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.357153; batch adversarial loss: 0.393142\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.474022; batch adversarial loss: 0.419211\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.404059; batch adversarial loss: 0.446872\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.436840; batch adversarial loss: 0.488216\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.368661; batch adversarial loss: 0.325161\n",
      "epoch 11; iter: 0; batch classifier loss: 0.419497; batch adversarial loss: 0.378935\n",
      "epoch 11; iter: 200; batch classifier loss: 0.355157; batch adversarial loss: 0.364643\n",
      "epoch 11; iter: 400; batch classifier loss: 0.384457; batch adversarial loss: 0.376785\n",
      "epoch 11; iter: 600; batch classifier loss: 0.447596; batch adversarial loss: 0.433549\n",
      "epoch 11; iter: 800; batch classifier loss: 0.461361; batch adversarial loss: 0.434222\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.414002; batch adversarial loss: 0.434960\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.367852; batch adversarial loss: 0.379908\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.467169; batch adversarial loss: 0.365579\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.452281; batch adversarial loss: 0.448539\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.378785; batch adversarial loss: 0.404151\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.384728; batch adversarial loss: 0.404944\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.519483; batch adversarial loss: 0.296379\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.402309; batch adversarial loss: 0.432937\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.393169; batch adversarial loss: 0.363896\n",
      "epoch 12; iter: 0; batch classifier loss: 0.367036; batch adversarial loss: 0.433398\n",
      "epoch 12; iter: 200; batch classifier loss: 0.426722; batch adversarial loss: 0.473613\n",
      "epoch 12; iter: 400; batch classifier loss: 0.484307; batch adversarial loss: 0.434971\n",
      "epoch 12; iter: 600; batch classifier loss: 0.424292; batch adversarial loss: 0.405958\n",
      "epoch 12; iter: 800; batch classifier loss: 0.421532; batch adversarial loss: 0.379865\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.406230; batch adversarial loss: 0.420918\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.418705; batch adversarial loss: 0.392353\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.345756; batch adversarial loss: 0.432721\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.392029; batch adversarial loss: 0.378875\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.418429; batch adversarial loss: 0.351734\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.470085; batch adversarial loss: 0.478254\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.446791; batch adversarial loss: 0.434440\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.373756; batch adversarial loss: 0.366985\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.360251; batch adversarial loss: 0.459981\n",
      "epoch 13; iter: 0; batch classifier loss: 0.458576; batch adversarial loss: 0.487925\n",
      "epoch 13; iter: 200; batch classifier loss: 0.509137; batch adversarial loss: 0.366324\n",
      "epoch 13; iter: 400; batch classifier loss: 0.373195; batch adversarial loss: 0.350965\n",
      "epoch 13; iter: 600; batch classifier loss: 0.435479; batch adversarial loss: 0.434367\n",
      "epoch 13; iter: 800; batch classifier loss: 0.458989; batch adversarial loss: 0.379310\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.465602; batch adversarial loss: 0.475534\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.379568; batch adversarial loss: 0.325025\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.401563; batch adversarial loss: 0.392993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13; iter: 1600; batch classifier loss: 0.391217; batch adversarial loss: 0.420082\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.401406; batch adversarial loss: 0.407822\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.540501; batch adversarial loss: 0.363910\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.391011; batch adversarial loss: 0.379258\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.422675; batch adversarial loss: 0.365995\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.416614; batch adversarial loss: 0.446188\n",
      "epoch 14; iter: 0; batch classifier loss: 0.378994; batch adversarial loss: 0.351728\n",
      "epoch 14; iter: 200; batch classifier loss: 0.298794; batch adversarial loss: 0.433250\n",
      "epoch 14; iter: 400; batch classifier loss: 0.418559; batch adversarial loss: 0.353160\n",
      "epoch 14; iter: 600; batch classifier loss: 0.475833; batch adversarial loss: 0.402977\n",
      "epoch 14; iter: 800; batch classifier loss: 0.450172; batch adversarial loss: 0.337027\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.430938; batch adversarial loss: 0.529682\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.419013; batch adversarial loss: 0.406457\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.379010; batch adversarial loss: 0.365647\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.425813; batch adversarial loss: 0.433473\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.402131; batch adversarial loss: 0.500306\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.436837; batch adversarial loss: 0.393099\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.471208; batch adversarial loss: 0.461230\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.425790; batch adversarial loss: 0.446999\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.426915; batch adversarial loss: 0.352121\n",
      "epoch 15; iter: 0; batch classifier loss: 0.549310; batch adversarial loss: 0.461122\n",
      "epoch 15; iter: 200; batch classifier loss: 0.430964; batch adversarial loss: 0.337710\n",
      "epoch 15; iter: 400; batch classifier loss: 0.473716; batch adversarial loss: 0.434883\n",
      "epoch 15; iter: 600; batch classifier loss: 0.438752; batch adversarial loss: 0.432566\n",
      "epoch 15; iter: 800; batch classifier loss: 0.460526; batch adversarial loss: 0.380657\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.413869; batch adversarial loss: 0.380988\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.355296; batch adversarial loss: 0.352498\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.458548; batch adversarial loss: 0.338821\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.471887; batch adversarial loss: 0.378161\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.369264; batch adversarial loss: 0.406470\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.436484; batch adversarial loss: 0.475463\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.464822; batch adversarial loss: 0.450288\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.416772; batch adversarial loss: 0.406991\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.414945; batch adversarial loss: 0.391570\n",
      "epoch 16; iter: 0; batch classifier loss: 0.448434; batch adversarial loss: 0.514909\n",
      "epoch 16; iter: 200; batch classifier loss: 0.394643; batch adversarial loss: 0.377391\n",
      "epoch 16; iter: 400; batch classifier loss: 0.374963; batch adversarial loss: 0.351771\n",
      "epoch 16; iter: 600; batch classifier loss: 0.391353; batch adversarial loss: 0.377982\n",
      "epoch 16; iter: 800; batch classifier loss: 0.341530; batch adversarial loss: 0.462055\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.377903; batch adversarial loss: 0.363747\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.399525; batch adversarial loss: 0.460075\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.321293; batch adversarial loss: 0.477470\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.458392; batch adversarial loss: 0.362579\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.469206; batch adversarial loss: 0.337509\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.487426; batch adversarial loss: 0.433892\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.313214; batch adversarial loss: 0.406846\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.441870; batch adversarial loss: 0.474628\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.413821; batch adversarial loss: 0.405777\n",
      "epoch 17; iter: 0; batch classifier loss: 0.373355; batch adversarial loss: 0.462337\n",
      "epoch 17; iter: 200; batch classifier loss: 0.423626; batch adversarial loss: 0.392109\n",
      "epoch 17; iter: 400; batch classifier loss: 0.413962; batch adversarial loss: 0.543887\n",
      "epoch 17; iter: 600; batch classifier loss: 0.346217; batch adversarial loss: 0.463935\n",
      "epoch 17; iter: 800; batch classifier loss: 0.381308; batch adversarial loss: 0.502037\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.285715; batch adversarial loss: 0.337884\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.340844; batch adversarial loss: 0.420311\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.352102; batch adversarial loss: 0.421179\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.382555; batch adversarial loss: 0.392396\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.389647; batch adversarial loss: 0.378850\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.379620; batch adversarial loss: 0.421477\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.355117; batch adversarial loss: 0.433731\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.438726; batch adversarial loss: 0.434885\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.500037; batch adversarial loss: 0.487940\n",
      "epoch 18; iter: 0; batch classifier loss: 0.430298; batch adversarial loss: 0.365211\n",
      "epoch 18; iter: 200; batch classifier loss: 0.399293; batch adversarial loss: 0.406883\n",
      "epoch 18; iter: 400; batch classifier loss: 0.443187; batch adversarial loss: 0.421773\n",
      "epoch 18; iter: 600; batch classifier loss: 0.461443; batch adversarial loss: 0.488757\n",
      "epoch 18; iter: 800; batch classifier loss: 0.365958; batch adversarial loss: 0.337759\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.478187; batch adversarial loss: 0.393745\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.360925; batch adversarial loss: 0.394384\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.415521; batch adversarial loss: 0.501347\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.426257; batch adversarial loss: 0.323286\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.424760; batch adversarial loss: 0.435253\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.347118; batch adversarial loss: 0.366581\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.493475; batch adversarial loss: 0.405308\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.466453; batch adversarial loss: 0.323760\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.404509; batch adversarial loss: 0.404994\n",
      "epoch 19; iter: 0; batch classifier loss: 0.436600; batch adversarial loss: 0.472767\n",
      "epoch 19; iter: 200; batch classifier loss: 0.434105; batch adversarial loss: 0.460862\n",
      "epoch 19; iter: 400; batch classifier loss: 0.359518; batch adversarial loss: 0.447886\n",
      "epoch 19; iter: 600; batch classifier loss: 0.380079; batch adversarial loss: 0.282966\n",
      "epoch 19; iter: 800; batch classifier loss: 0.374719; batch adversarial loss: 0.462704\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.519128; batch adversarial loss: 0.419664\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.507715; batch adversarial loss: 0.503487\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.469230; batch adversarial loss: 0.517746\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.385752; batch adversarial loss: 0.488743\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.437497; batch adversarial loss: 0.364959\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.404134; batch adversarial loss: 0.324512\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.468037; batch adversarial loss: 0.394197\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.416927; batch adversarial loss: 0.393884\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.462442; batch adversarial loss: 0.392430\n",
      "epoch 20; iter: 0; batch classifier loss: 0.437363; batch adversarial loss: 0.351076\n",
      "epoch 20; iter: 200; batch classifier loss: 0.412490; batch adversarial loss: 0.352335\n",
      "epoch 20; iter: 400; batch classifier loss: 0.426362; batch adversarial loss: 0.422812\n",
      "epoch 20; iter: 600; batch classifier loss: 0.452544; batch adversarial loss: 0.474695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 800; batch classifier loss: 0.403659; batch adversarial loss: 0.490536\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.351765; batch adversarial loss: 0.392317\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.413582; batch adversarial loss: 0.407055\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.377743; batch adversarial loss: 0.364352\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.453260; batch adversarial loss: 0.379150\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.482487; batch adversarial loss: 0.405900\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.305830; batch adversarial loss: 0.430752\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.365335; batch adversarial loss: 0.419711\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.320365; batch adversarial loss: 0.423927\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.459641; batch adversarial loss: 0.490478\n",
      "epoch 21; iter: 0; batch classifier loss: 0.395610; batch adversarial loss: 0.379204\n",
      "epoch 21; iter: 200; batch classifier loss: 0.388517; batch adversarial loss: 0.530304\n",
      "epoch 21; iter: 400; batch classifier loss: 0.488366; batch adversarial loss: 0.461711\n",
      "epoch 21; iter: 600; batch classifier loss: 0.503280; batch adversarial loss: 0.336714\n",
      "epoch 21; iter: 800; batch classifier loss: 0.392656; batch adversarial loss: 0.380733\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.348631; batch adversarial loss: 0.419013\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.352814; batch adversarial loss: 0.462678\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.418993; batch adversarial loss: 0.367633\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.458890; batch adversarial loss: 0.476892\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.410639; batch adversarial loss: 0.378510\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.457329; batch adversarial loss: 0.405161\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.338439; batch adversarial loss: 0.474167\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.288690; batch adversarial loss: 0.516213\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.379172; batch adversarial loss: 0.406681\n",
      "epoch 22; iter: 0; batch classifier loss: 0.454648; batch adversarial loss: 0.460356\n",
      "epoch 22; iter: 200; batch classifier loss: 0.403093; batch adversarial loss: 0.460637\n",
      "epoch 22; iter: 400; batch classifier loss: 0.405148; batch adversarial loss: 0.380266\n",
      "epoch 22; iter: 600; batch classifier loss: 0.496839; batch adversarial loss: 0.447688\n",
      "epoch 22; iter: 800; batch classifier loss: 0.438649; batch adversarial loss: 0.473909\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.390835; batch adversarial loss: 0.461131\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.339516; batch adversarial loss: 0.433261\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.379676; batch adversarial loss: 0.433775\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.328519; batch adversarial loss: 0.446955\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.388206; batch adversarial loss: 0.447258\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.419142; batch adversarial loss: 0.462427\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.406348; batch adversarial loss: 0.448274\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.431762; batch adversarial loss: 0.407001\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.395398; batch adversarial loss: 0.472640\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439558; batch adversarial loss: 0.378932\n",
      "epoch 23; iter: 200; batch classifier loss: 0.463509; batch adversarial loss: 0.557760\n",
      "epoch 23; iter: 400; batch classifier loss: 0.433771; batch adversarial loss: 0.434246\n",
      "epoch 23; iter: 600; batch classifier loss: 0.312200; batch adversarial loss: 0.434907\n",
      "epoch 23; iter: 800; batch classifier loss: 0.351708; batch adversarial loss: 0.419578\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.418097; batch adversarial loss: 0.477516\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.393050; batch adversarial loss: 0.488681\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.385779; batch adversarial loss: 0.448478\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.412626; batch adversarial loss: 0.407598\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.431999; batch adversarial loss: 0.407069\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.379332; batch adversarial loss: 0.487914\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.528897; batch adversarial loss: 0.404449\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.389284; batch adversarial loss: 0.405409\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.445083; batch adversarial loss: 0.541055\n",
      "epoch 24; iter: 0; batch classifier loss: 0.399988; batch adversarial loss: 0.433875\n",
      "epoch 24; iter: 200; batch classifier loss: 0.475886; batch adversarial loss: 0.378577\n",
      "epoch 24; iter: 400; batch classifier loss: 0.428582; batch adversarial loss: 0.420174\n",
      "epoch 24; iter: 600; batch classifier loss: 0.364620; batch adversarial loss: 0.350442\n",
      "epoch 24; iter: 800; batch classifier loss: 0.385716; batch adversarial loss: 0.448275\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.345945; batch adversarial loss: 0.473856\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.455676; batch adversarial loss: 0.391666\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.518483; batch adversarial loss: 0.378987\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.328876; batch adversarial loss: 0.405920\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.447099; batch adversarial loss: 0.407101\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.510599; batch adversarial loss: 0.391286\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.432929; batch adversarial loss: 0.434041\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.438431; batch adversarial loss: 0.461069\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.412475; batch adversarial loss: 0.351756\n",
      "epoch 25; iter: 0; batch classifier loss: 0.399142; batch adversarial loss: 0.459401\n",
      "epoch 25; iter: 200; batch classifier loss: 0.408081; batch adversarial loss: 0.365365\n",
      "epoch 25; iter: 400; batch classifier loss: 0.459703; batch adversarial loss: 0.420705\n",
      "epoch 25; iter: 600; batch classifier loss: 0.385721; batch adversarial loss: 0.475552\n",
      "epoch 25; iter: 800; batch classifier loss: 0.368780; batch adversarial loss: 0.404286\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.375562; batch adversarial loss: 0.434748\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.442435; batch adversarial loss: 0.434559\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.404569; batch adversarial loss: 0.391343\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.406199; batch adversarial loss: 0.364889\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.440389; batch adversarial loss: 0.460298\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.394472; batch adversarial loss: 0.351906\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.407007; batch adversarial loss: 0.350656\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.427936; batch adversarial loss: 0.378040\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.361703; batch adversarial loss: 0.488419\n",
      "epoch 26; iter: 0; batch classifier loss: 0.372451; batch adversarial loss: 0.406514\n",
      "epoch 26; iter: 200; batch classifier loss: 0.343023; batch adversarial loss: 0.433678\n",
      "epoch 26; iter: 400; batch classifier loss: 0.398497; batch adversarial loss: 0.463266\n",
      "epoch 26; iter: 600; batch classifier loss: 0.485773; batch adversarial loss: 0.351076\n",
      "epoch 26; iter: 800; batch classifier loss: 0.345037; batch adversarial loss: 0.406031\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.346199; batch adversarial loss: 0.435385\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.453237; batch adversarial loss: 0.446178\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.337461; batch adversarial loss: 0.434816\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.445311; batch adversarial loss: 0.446126\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.441955; batch adversarial loss: 0.377309\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.513988; batch adversarial loss: 0.406730\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.422523; batch adversarial loss: 0.503208\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.439263; batch adversarial loss: 0.421276\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.385712; batch adversarial loss: 0.462526\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437542; batch adversarial loss: 0.447487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 200; batch classifier loss: 0.419108; batch adversarial loss: 0.392055\n",
      "epoch 27; iter: 400; batch classifier loss: 0.466198; batch adversarial loss: 0.407188\n",
      "epoch 27; iter: 600; batch classifier loss: 0.490239; batch adversarial loss: 0.325302\n",
      "epoch 27; iter: 800; batch classifier loss: 0.419466; batch adversarial loss: 0.351012\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.411487; batch adversarial loss: 0.364654\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.343702; batch adversarial loss: 0.366087\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.413363; batch adversarial loss: 0.392481\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.460624; batch adversarial loss: 0.379024\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.390951; batch adversarial loss: 0.434569\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.383666; batch adversarial loss: 0.405670\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.363008; batch adversarial loss: 0.405675\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.444119; batch adversarial loss: 0.392048\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.328351; batch adversarial loss: 0.515996\n",
      "epoch 28; iter: 0; batch classifier loss: 0.406948; batch adversarial loss: 0.461343\n",
      "epoch 28; iter: 200; batch classifier loss: 0.476758; batch adversarial loss: 0.390132\n",
      "epoch 28; iter: 400; batch classifier loss: 0.491629; batch adversarial loss: 0.421553\n",
      "epoch 28; iter: 600; batch classifier loss: 0.362736; batch adversarial loss: 0.458586\n",
      "epoch 28; iter: 800; batch classifier loss: 0.413929; batch adversarial loss: 0.350579\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.388390; batch adversarial loss: 0.461226\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.410466; batch adversarial loss: 0.392660\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.462686; batch adversarial loss: 0.405736\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.423224; batch adversarial loss: 0.405560\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.488959; batch adversarial loss: 0.418581\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.500965; batch adversarial loss: 0.474634\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.360404; batch adversarial loss: 0.460244\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.433088; batch adversarial loss: 0.419581\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.417559; batch adversarial loss: 0.504101\n",
      "epoch 29; iter: 0; batch classifier loss: 0.471693; batch adversarial loss: 0.517150\n",
      "epoch 29; iter: 200; batch classifier loss: 0.358780; batch adversarial loss: 0.434731\n",
      "epoch 29; iter: 400; batch classifier loss: 0.398527; batch adversarial loss: 0.432963\n",
      "epoch 29; iter: 600; batch classifier loss: 0.487921; batch adversarial loss: 0.379172\n",
      "epoch 29; iter: 800; batch classifier loss: 0.414255; batch adversarial loss: 0.407170\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.399144; batch adversarial loss: 0.365484\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.466136; batch adversarial loss: 0.406048\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.340252; batch adversarial loss: 0.392583\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.358771; batch adversarial loss: 0.419479\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.378447; batch adversarial loss: 0.476212\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.370539; batch adversarial loss: 0.418768\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.356060; batch adversarial loss: 0.446350\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.458438; batch adversarial loss: 0.391737\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.478587; batch adversarial loss: 0.392474\n",
      "epoch 30; iter: 0; batch classifier loss: 0.430744; batch adversarial loss: 0.475970\n",
      "epoch 30; iter: 200; batch classifier loss: 0.457719; batch adversarial loss: 0.393203\n",
      "epoch 30; iter: 400; batch classifier loss: 0.416958; batch adversarial loss: 0.365537\n",
      "epoch 30; iter: 600; batch classifier loss: 0.435875; batch adversarial loss: 0.503933\n",
      "epoch 30; iter: 800; batch classifier loss: 0.414345; batch adversarial loss: 0.404539\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.392852; batch adversarial loss: 0.420033\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.390753; batch adversarial loss: 0.514330\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.516476; batch adversarial loss: 0.462171\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.400442; batch adversarial loss: 0.459658\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.470023; batch adversarial loss: 0.403357\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.474315; batch adversarial loss: 0.474820\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.466365; batch adversarial loss: 0.516352\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.399498; batch adversarial loss: 0.449545\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.386160; batch adversarial loss: 0.377286\n",
      "epoch 31; iter: 0; batch classifier loss: 0.370294; batch adversarial loss: 0.462792\n",
      "epoch 31; iter: 200; batch classifier loss: 0.427869; batch adversarial loss: 0.324308\n",
      "epoch 31; iter: 400; batch classifier loss: 0.425109; batch adversarial loss: 0.458406\n",
      "epoch 31; iter: 600; batch classifier loss: 0.438819; batch adversarial loss: 0.351446\n",
      "epoch 31; iter: 800; batch classifier loss: 0.462430; batch adversarial loss: 0.379569\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.343861; batch adversarial loss: 0.336652\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.389519; batch adversarial loss: 0.267995\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.377625; batch adversarial loss: 0.502408\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.374889; batch adversarial loss: 0.324028\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.466338; batch adversarial loss: 0.432612\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.451612; batch adversarial loss: 0.406532\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.369371; batch adversarial loss: 0.448329\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.548715; batch adversarial loss: 0.447911\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.367829; batch adversarial loss: 0.337599\n",
      "epoch 32; iter: 0; batch classifier loss: 0.392426; batch adversarial loss: 0.323653\n",
      "epoch 32; iter: 200; batch classifier loss: 0.458359; batch adversarial loss: 0.448668\n",
      "epoch 32; iter: 400; batch classifier loss: 0.359404; batch adversarial loss: 0.463474\n",
      "epoch 32; iter: 600; batch classifier loss: 0.323219; batch adversarial loss: 0.459413\n",
      "epoch 32; iter: 800; batch classifier loss: 0.461854; batch adversarial loss: 0.543110\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.347079; batch adversarial loss: 0.308954\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.424774; batch adversarial loss: 0.472997\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.484091; batch adversarial loss: 0.365585\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.470258; batch adversarial loss: 0.488666\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.380271; batch adversarial loss: 0.405425\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.351012; batch adversarial loss: 0.448706\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.415000; batch adversarial loss: 0.378872\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.468593; batch adversarial loss: 0.446403\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.443363; batch adversarial loss: 0.419588\n",
      "epoch 33; iter: 0; batch classifier loss: 0.367918; batch adversarial loss: 0.475047\n",
      "epoch 33; iter: 200; batch classifier loss: 0.393576; batch adversarial loss: 0.394196\n",
      "epoch 33; iter: 400; batch classifier loss: 0.422234; batch adversarial loss: 0.408306\n",
      "epoch 33; iter: 600; batch classifier loss: 0.463385; batch adversarial loss: 0.433126\n",
      "epoch 33; iter: 800; batch classifier loss: 0.423097; batch adversarial loss: 0.379255\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.389198; batch adversarial loss: 0.405945\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.406251; batch adversarial loss: 0.490416\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.376426; batch adversarial loss: 0.475206\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.341961; batch adversarial loss: 0.392260\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.495500; batch adversarial loss: 0.338340\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.416326; batch adversarial loss: 0.516944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 2200; batch classifier loss: 0.368848; batch adversarial loss: 0.363376\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.394978; batch adversarial loss: 0.296946\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.312750; batch adversarial loss: 0.352069\n",
      "epoch 34; iter: 0; batch classifier loss: 0.391860; batch adversarial loss: 0.378223\n",
      "epoch 34; iter: 200; batch classifier loss: 0.396139; batch adversarial loss: 0.448000\n",
      "epoch 34; iter: 400; batch classifier loss: 0.452963; batch adversarial loss: 0.418667\n",
      "epoch 34; iter: 600; batch classifier loss: 0.400771; batch adversarial loss: 0.323214\n",
      "epoch 34; iter: 800; batch classifier loss: 0.451296; batch adversarial loss: 0.462985\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.424351; batch adversarial loss: 0.418171\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.382391; batch adversarial loss: 0.421290\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.400227; batch adversarial loss: 0.433053\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.420220; batch adversarial loss: 0.405438\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.474528; batch adversarial loss: 0.393759\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.443690; batch adversarial loss: 0.405816\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.344890; batch adversarial loss: 0.432245\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.407372; batch adversarial loss: 0.363609\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.400810; batch adversarial loss: 0.418815\n",
      "epoch 35; iter: 0; batch classifier loss: 0.474639; batch adversarial loss: 0.446866\n",
      "epoch 35; iter: 200; batch classifier loss: 0.379540; batch adversarial loss: 0.324592\n",
      "epoch 35; iter: 400; batch classifier loss: 0.429146; batch adversarial loss: 0.434891\n",
      "epoch 35; iter: 600; batch classifier loss: 0.442171; batch adversarial loss: 0.324411\n",
      "epoch 35; iter: 800; batch classifier loss: 0.356743; batch adversarial loss: 0.308364\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.425232; batch adversarial loss: 0.308259\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.517031; batch adversarial loss: 0.447307\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.427668; batch adversarial loss: 0.406277\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.438117; batch adversarial loss: 0.461859\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.482275; batch adversarial loss: 0.365654\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.441552; batch adversarial loss: 0.406445\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.418445; batch adversarial loss: 0.433637\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.432372; batch adversarial loss: 0.447481\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.426763; batch adversarial loss: 0.336740\n",
      "epoch 36; iter: 0; batch classifier loss: 0.421613; batch adversarial loss: 0.377320\n",
      "epoch 36; iter: 200; batch classifier loss: 0.342771; batch adversarial loss: 0.444447\n",
      "epoch 36; iter: 400; batch classifier loss: 0.483969; batch adversarial loss: 0.405876\n",
      "epoch 36; iter: 600; batch classifier loss: 0.414748; batch adversarial loss: 0.460284\n",
      "epoch 36; iter: 800; batch classifier loss: 0.552806; batch adversarial loss: 0.434780\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.366274; batch adversarial loss: 0.352683\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.471592; batch adversarial loss: 0.461704\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.386364; batch adversarial loss: 0.431969\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.429403; batch adversarial loss: 0.379877\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.519902; batch adversarial loss: 0.472300\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.399630; batch adversarial loss: 0.392425\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.461287; batch adversarial loss: 0.447338\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.445619; batch adversarial loss: 0.377912\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.380016; batch adversarial loss: 0.449026\n",
      "epoch 37; iter: 0; batch classifier loss: 0.395598; batch adversarial loss: 0.474400\n",
      "epoch 37; iter: 200; batch classifier loss: 0.314926; batch adversarial loss: 0.433947\n",
      "epoch 37; iter: 400; batch classifier loss: 0.371809; batch adversarial loss: 0.364493\n",
      "epoch 37; iter: 600; batch classifier loss: 0.470311; batch adversarial loss: 0.504729\n",
      "epoch 37; iter: 800; batch classifier loss: 0.438719; batch adversarial loss: 0.364862\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.453638; batch adversarial loss: 0.420152\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.553995; batch adversarial loss: 0.432382\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.432159; batch adversarial loss: 0.449391\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.453627; batch adversarial loss: 0.323550\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.507747; batch adversarial loss: 0.390067\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.489880; batch adversarial loss: 0.448172\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.395684; batch adversarial loss: 0.268990\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.440245; batch adversarial loss: 0.392739\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.482688; batch adversarial loss: 0.363517\n",
      "epoch 38; iter: 0; batch classifier loss: 0.440655; batch adversarial loss: 0.391434\n",
      "epoch 38; iter: 200; batch classifier loss: 0.397131; batch adversarial loss: 0.433302\n",
      "epoch 38; iter: 400; batch classifier loss: 0.413587; batch adversarial loss: 0.419859\n",
      "epoch 38; iter: 600; batch classifier loss: 0.418771; batch adversarial loss: 0.393879\n",
      "epoch 38; iter: 800; batch classifier loss: 0.462998; batch adversarial loss: 0.447589\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.452335; batch adversarial loss: 0.352315\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.463028; batch adversarial loss: 0.461613\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.405828; batch adversarial loss: 0.420143\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.416425; batch adversarial loss: 0.407403\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.425852; batch adversarial loss: 0.379824\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.415314; batch adversarial loss: 0.406964\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.412673; batch adversarial loss: 0.364619\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.354013; batch adversarial loss: 0.487071\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.462997; batch adversarial loss: 0.459750\n",
      "epoch 39; iter: 0; batch classifier loss: 0.440255; batch adversarial loss: 0.366682\n",
      "epoch 39; iter: 200; batch classifier loss: 0.411518; batch adversarial loss: 0.447011\n",
      "epoch 39; iter: 400; batch classifier loss: 0.332493; batch adversarial loss: 0.418772\n",
      "epoch 39; iter: 600; batch classifier loss: 0.353583; batch adversarial loss: 0.392202\n",
      "epoch 39; iter: 800; batch classifier loss: 0.398822; batch adversarial loss: 0.392082\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.421469; batch adversarial loss: 0.430595\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.433944; batch adversarial loss: 0.489450\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.439882; batch adversarial loss: 0.516096\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.424968; batch adversarial loss: 0.475605\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.488436; batch adversarial loss: 0.378749\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.369230; batch adversarial loss: 0.530048\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.398833; batch adversarial loss: 0.434025\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.383329; batch adversarial loss: 0.404569\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.373659; batch adversarial loss: 0.352436\n",
      "epoch 40; iter: 0; batch classifier loss: 0.357061; batch adversarial loss: 0.432559\n",
      "epoch 40; iter: 200; batch classifier loss: 0.420864; batch adversarial loss: 0.447782\n",
      "epoch 40; iter: 400; batch classifier loss: 0.448196; batch adversarial loss: 0.473338\n",
      "epoch 40; iter: 600; batch classifier loss: 0.447817; batch adversarial loss: 0.432692\n",
      "epoch 40; iter: 800; batch classifier loss: 0.371991; batch adversarial loss: 0.638899\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.378679; batch adversarial loss: 0.336984\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.381007; batch adversarial loss: 0.516561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 1400; batch classifier loss: 0.403215; batch adversarial loss: 0.283125\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.365541; batch adversarial loss: 0.379168\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.405266; batch adversarial loss: 0.449270\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.399198; batch adversarial loss: 0.418491\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.498602; batch adversarial loss: 0.407423\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.413778; batch adversarial loss: 0.392430\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.468245; batch adversarial loss: 0.394651\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464111; batch adversarial loss: 0.459342\n",
      "epoch 41; iter: 200; batch classifier loss: 0.438971; batch adversarial loss: 0.420297\n",
      "epoch 41; iter: 400; batch classifier loss: 0.483683; batch adversarial loss: 0.337314\n",
      "epoch 41; iter: 600; batch classifier loss: 0.407083; batch adversarial loss: 0.282760\n",
      "epoch 41; iter: 800; batch classifier loss: 0.401136; batch adversarial loss: 0.390935\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.393535; batch adversarial loss: 0.339141\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.407627; batch adversarial loss: 0.366176\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.423596; batch adversarial loss: 0.407339\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.457901; batch adversarial loss: 0.350884\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.438719; batch adversarial loss: 0.363815\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.347379; batch adversarial loss: 0.393325\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.373390; batch adversarial loss: 0.434199\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.506785; batch adversarial loss: 0.461356\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.518101; batch adversarial loss: 0.322829\n",
      "epoch 42; iter: 0; batch classifier loss: 0.405170; batch adversarial loss: 0.461754\n",
      "epoch 42; iter: 200; batch classifier loss: 0.390403; batch adversarial loss: 0.418336\n",
      "epoch 42; iter: 400; batch classifier loss: 0.455887; batch adversarial loss: 0.420287\n",
      "epoch 42; iter: 600; batch classifier loss: 0.327315; batch adversarial loss: 0.487747\n",
      "epoch 42; iter: 800; batch classifier loss: 0.409965; batch adversarial loss: 0.515279\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.424974; batch adversarial loss: 0.365391\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.377736; batch adversarial loss: 0.310950\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.399223; batch adversarial loss: 0.379250\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.371575; batch adversarial loss: 0.474910\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.394159; batch adversarial loss: 0.419753\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.366195; batch adversarial loss: 0.392915\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.439765; batch adversarial loss: 0.448652\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.455828; batch adversarial loss: 0.377981\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.460074; batch adversarial loss: 0.390810\n",
      "epoch 43; iter: 0; batch classifier loss: 0.450236; batch adversarial loss: 0.350780\n",
      "epoch 43; iter: 200; batch classifier loss: 0.367610; batch adversarial loss: 0.377886\n",
      "epoch 43; iter: 400; batch classifier loss: 0.482061; batch adversarial loss: 0.406580\n",
      "epoch 43; iter: 600; batch classifier loss: 0.432757; batch adversarial loss: 0.379671\n",
      "epoch 43; iter: 800; batch classifier loss: 0.416104; batch adversarial loss: 0.419130\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.477963; batch adversarial loss: 0.365221\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.444880; batch adversarial loss: 0.390616\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.382147; batch adversarial loss: 0.488894\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.436348; batch adversarial loss: 0.489661\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.414520; batch adversarial loss: 0.392097\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.516815; batch adversarial loss: 0.406043\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.418716; batch adversarial loss: 0.324368\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.454959; batch adversarial loss: 0.377274\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.403697; batch adversarial loss: 0.407498\n",
      "epoch 44; iter: 0; batch classifier loss: 0.459674; batch adversarial loss: 0.377304\n",
      "epoch 44; iter: 200; batch classifier loss: 0.411739; batch adversarial loss: 0.404940\n",
      "epoch 44; iter: 400; batch classifier loss: 0.350969; batch adversarial loss: 0.380035\n",
      "epoch 44; iter: 600; batch classifier loss: 0.324278; batch adversarial loss: 0.351555\n",
      "epoch 44; iter: 800; batch classifier loss: 0.327600; batch adversarial loss: 0.390672\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.424275; batch adversarial loss: 0.324198\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.400559; batch adversarial loss: 0.460712\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.447113; batch adversarial loss: 0.392954\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.331366; batch adversarial loss: 0.474875\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.468068; batch adversarial loss: 0.419784\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.389128; batch adversarial loss: 0.282724\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.413906; batch adversarial loss: 0.407518\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.419892; batch adversarial loss: 0.529083\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.393165; batch adversarial loss: 0.432413\n",
      "epoch 45; iter: 0; batch classifier loss: 0.411237; batch adversarial loss: 0.381054\n",
      "epoch 45; iter: 200; batch classifier loss: 0.515414; batch adversarial loss: 0.391785\n",
      "epoch 45; iter: 400; batch classifier loss: 0.417518; batch adversarial loss: 0.407648\n",
      "epoch 45; iter: 600; batch classifier loss: 0.440818; batch adversarial loss: 0.364576\n",
      "epoch 45; iter: 800; batch classifier loss: 0.422387; batch adversarial loss: 0.475736\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.422597; batch adversarial loss: 0.434123\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.428016; batch adversarial loss: 0.405641\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.420259; batch adversarial loss: 0.377835\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.406142; batch adversarial loss: 0.446714\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.448400; batch adversarial loss: 0.392003\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.440926; batch adversarial loss: 0.462016\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.389387; batch adversarial loss: 0.432842\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.416075; batch adversarial loss: 0.391620\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.467324; batch adversarial loss: 0.460687\n",
      "epoch 46; iter: 0; batch classifier loss: 0.395147; batch adversarial loss: 0.392417\n",
      "epoch 46; iter: 200; batch classifier loss: 0.427362; batch adversarial loss: 0.378893\n",
      "epoch 46; iter: 400; batch classifier loss: 0.336598; batch adversarial loss: 0.405097\n",
      "epoch 46; iter: 600; batch classifier loss: 0.394750; batch adversarial loss: 0.418356\n",
      "epoch 46; iter: 800; batch classifier loss: 0.374182; batch adversarial loss: 0.475573\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.375750; batch adversarial loss: 0.406788\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.391884; batch adversarial loss: 0.377662\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.459346; batch adversarial loss: 0.460882\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.408850; batch adversarial loss: 0.446327\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.452392; batch adversarial loss: 0.366751\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.390985; batch adversarial loss: 0.364383\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.409647; batch adversarial loss: 0.434254\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.351647; batch adversarial loss: 0.377944\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.405081; batch adversarial loss: 0.407375\n",
      "epoch 47; iter: 0; batch classifier loss: 0.479630; batch adversarial loss: 0.420851\n",
      "epoch 47; iter: 200; batch classifier loss: 0.449719; batch adversarial loss: 0.502460\n",
      "epoch 47; iter: 400; batch classifier loss: 0.434657; batch adversarial loss: 0.419633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 600; batch classifier loss: 0.400200; batch adversarial loss: 0.406145\n",
      "epoch 47; iter: 800; batch classifier loss: 0.398054; batch adversarial loss: 0.432325\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.449520; batch adversarial loss: 0.489376\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.363738; batch adversarial loss: 0.404457\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.350039; batch adversarial loss: 0.392897\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.399361; batch adversarial loss: 0.405532\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.454102; batch adversarial loss: 0.421142\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.346688; batch adversarial loss: 0.488162\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.475667; batch adversarial loss: 0.432167\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.423578; batch adversarial loss: 0.445973\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.369986; batch adversarial loss: 0.406247\n",
      "epoch 48; iter: 0; batch classifier loss: 0.420479; batch adversarial loss: 0.324111\n",
      "epoch 48; iter: 200; batch classifier loss: 0.446410; batch adversarial loss: 0.378837\n",
      "epoch 48; iter: 400; batch classifier loss: 0.389663; batch adversarial loss: 0.405225\n",
      "epoch 48; iter: 600; batch classifier loss: 0.487612; batch adversarial loss: 0.366074\n",
      "epoch 48; iter: 800; batch classifier loss: 0.379299; batch adversarial loss: 0.475071\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.376055; batch adversarial loss: 0.352111\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.379823; batch adversarial loss: 0.528455\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.427933; batch adversarial loss: 0.448506\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.363730; batch adversarial loss: 0.407495\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.471457; batch adversarial loss: 0.393767\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.382099; batch adversarial loss: 0.462135\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.459943; batch adversarial loss: 0.420331\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.374983; batch adversarial loss: 0.461235\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.339690; batch adversarial loss: 0.449483\n",
      "epoch 49; iter: 0; batch classifier loss: 0.412934; batch adversarial loss: 0.434042\n",
      "epoch 49; iter: 200; batch classifier loss: 0.427784; batch adversarial loss: 0.335974\n",
      "epoch 49; iter: 400; batch classifier loss: 0.380282; batch adversarial loss: 0.381041\n",
      "epoch 49; iter: 600; batch classifier loss: 0.386993; batch adversarial loss: 0.402497\n",
      "epoch 49; iter: 800; batch classifier loss: 0.456748; batch adversarial loss: 0.446571\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.343140; batch adversarial loss: 0.392206\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.477078; batch adversarial loss: 0.420003\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.429442; batch adversarial loss: 0.393314\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.458499; batch adversarial loss: 0.406349\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.357922; batch adversarial loss: 0.377951\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.416356; batch adversarial loss: 0.473126\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.389766; batch adversarial loss: 0.475276\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.374017; batch adversarial loss: 0.364381\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.315181; batch adversarial loss: 0.433240\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695771\n",
      "epoch 0; iter: 200; batch classifier loss: 0.418157\n",
      "epoch 0; iter: 400; batch classifier loss: 0.513623\n",
      "epoch 0; iter: 600; batch classifier loss: 0.467600\n",
      "epoch 0; iter: 800; batch classifier loss: 0.408938\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.408303\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.515086\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.422762\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.509847\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.364817\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.430364\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.487706\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.491164\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.397626\n",
      "epoch 1; iter: 0; batch classifier loss: 0.423361\n",
      "epoch 1; iter: 200; batch classifier loss: 0.385699\n",
      "epoch 1; iter: 400; batch classifier loss: 0.454294\n",
      "epoch 1; iter: 600; batch classifier loss: 0.307974\n",
      "epoch 1; iter: 800; batch classifier loss: 0.466578\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.496713\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.347456\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.559975\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.485245\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.430370\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.417594\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.360200\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.519773\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.412406\n",
      "epoch 2; iter: 0; batch classifier loss: 0.431319\n",
      "epoch 2; iter: 200; batch classifier loss: 0.427990\n",
      "epoch 2; iter: 400; batch classifier loss: 0.425875\n",
      "epoch 2; iter: 600; batch classifier loss: 0.391247\n",
      "epoch 2; iter: 800; batch classifier loss: 0.398900\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.370685\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.359813\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.506302\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.387818\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.337084\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.442821\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.430871\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.490118\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.365896\n",
      "epoch 3; iter: 0; batch classifier loss: 0.397593\n",
      "epoch 3; iter: 200; batch classifier loss: 0.413000\n",
      "epoch 3; iter: 400; batch classifier loss: 0.469721\n",
      "epoch 3; iter: 600; batch classifier loss: 0.381636\n",
      "epoch 3; iter: 800; batch classifier loss: 0.371162\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.435910\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.435916\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.359531\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.424597\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.402963\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.383765\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.430348\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.370390\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.347237\n",
      "epoch 4; iter: 0; batch classifier loss: 0.378165\n",
      "epoch 4; iter: 200; batch classifier loss: 0.391582\n",
      "epoch 4; iter: 400; batch classifier loss: 0.454864\n",
      "epoch 4; iter: 600; batch classifier loss: 0.433799\n",
      "epoch 4; iter: 800; batch classifier loss: 0.456075\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.353059\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.419931\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.401084\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.432767\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.376556\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.521883\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.454734\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.419122\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.445104\n",
      "epoch 5; iter: 0; batch classifier loss: 0.442643\n",
      "epoch 5; iter: 200; batch classifier loss: 0.493878\n",
      "epoch 5; iter: 400; batch classifier loss: 0.460075\n",
      "epoch 5; iter: 600; batch classifier loss: 0.349230\n",
      "epoch 5; iter: 800; batch classifier loss: 0.411369\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.309214\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.480422\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.372103\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.414585\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.376643\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.464906\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.405138\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.432123\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.429803\n",
      "epoch 6; iter: 0; batch classifier loss: 0.345950\n",
      "epoch 6; iter: 200; batch classifier loss: 0.429428\n",
      "epoch 6; iter: 400; batch classifier loss: 0.350037\n",
      "epoch 6; iter: 600; batch classifier loss: 0.425700\n",
      "epoch 6; iter: 800; batch classifier loss: 0.409585\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.384960\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.442841\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.483049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 1600; batch classifier loss: 0.403102\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.349201\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.375917\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.425654\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.370111\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.425502\n",
      "epoch 7; iter: 0; batch classifier loss: 0.369885\n",
      "epoch 7; iter: 200; batch classifier loss: 0.446424\n",
      "epoch 7; iter: 400; batch classifier loss: 0.446372\n",
      "epoch 7; iter: 600; batch classifier loss: 0.403432\n",
      "epoch 7; iter: 800; batch classifier loss: 0.370222\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.348015\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.415225\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.398795\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.465331\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.405281\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.353261\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.491762\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.343563\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.365486\n",
      "epoch 8; iter: 0; batch classifier loss: 0.397479\n",
      "epoch 8; iter: 200; batch classifier loss: 0.501886\n",
      "epoch 8; iter: 400; batch classifier loss: 0.395025\n",
      "epoch 8; iter: 600; batch classifier loss: 0.426061\n",
      "epoch 8; iter: 800; batch classifier loss: 0.439324\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.370177\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.431193\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.477491\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.350306\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.419517\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.426217\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.410122\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.451627\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.441689\n",
      "epoch 9; iter: 0; batch classifier loss: 0.460971\n",
      "epoch 9; iter: 200; batch classifier loss: 0.343830\n",
      "epoch 9; iter: 400; batch classifier loss: 0.470839\n",
      "epoch 9; iter: 600; batch classifier loss: 0.410379\n",
      "epoch 9; iter: 800; batch classifier loss: 0.442692\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.373298\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.359546\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.490763\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.404735\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.458041\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.426368\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.419184\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.524107\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.416929\n",
      "epoch 10; iter: 0; batch classifier loss: 0.479476\n",
      "epoch 10; iter: 200; batch classifier loss: 0.508797\n",
      "epoch 10; iter: 400; batch classifier loss: 0.412244\n",
      "epoch 10; iter: 600; batch classifier loss: 0.379698\n",
      "epoch 10; iter: 800; batch classifier loss: 0.328417\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.457780\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.391330\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.422345\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.418823\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.424191\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.452456\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.388890\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.360898\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.399525\n",
      "epoch 11; iter: 0; batch classifier loss: 0.364462\n",
      "epoch 11; iter: 200; batch classifier loss: 0.325505\n",
      "epoch 11; iter: 400; batch classifier loss: 0.350118\n",
      "epoch 11; iter: 600; batch classifier loss: 0.421436\n",
      "epoch 11; iter: 800; batch classifier loss: 0.454759\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.409677\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.451635\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.363294\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.426462\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.333435\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.437913\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.423848\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.401006\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.460812\n",
      "epoch 12; iter: 0; batch classifier loss: 0.428708\n",
      "epoch 12; iter: 200; batch classifier loss: 0.432213\n",
      "epoch 12; iter: 400; batch classifier loss: 0.464571\n",
      "epoch 12; iter: 600; batch classifier loss: 0.503922\n",
      "epoch 12; iter: 800; batch classifier loss: 0.338475\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.373066\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.429056\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.428395\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.443127\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.442645\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.397603\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.405859\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.451740\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.468667\n",
      "epoch 13; iter: 0; batch classifier loss: 0.377086\n",
      "epoch 13; iter: 200; batch classifier loss: 0.435702\n",
      "epoch 13; iter: 400; batch classifier loss: 0.385016\n",
      "epoch 13; iter: 600; batch classifier loss: 0.426098\n",
      "epoch 13; iter: 800; batch classifier loss: 0.435630\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.469830\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.464627\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.378687\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.504432\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.425644\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.458123\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.373031\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.327854\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.440631\n",
      "epoch 14; iter: 0; batch classifier loss: 0.450368\n",
      "epoch 14; iter: 200; batch classifier loss: 0.407176\n",
      "epoch 14; iter: 400; batch classifier loss: 0.405396\n",
      "epoch 14; iter: 600; batch classifier loss: 0.396862\n",
      "epoch 14; iter: 800; batch classifier loss: 0.378435\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.439308\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.374163\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.399993\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.343452\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.386241\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.353953\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.398329\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.406943\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.424151\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516449\n",
      "epoch 15; iter: 200; batch classifier loss: 0.423491\n",
      "epoch 15; iter: 400; batch classifier loss: 0.366215\n",
      "epoch 15; iter: 600; batch classifier loss: 0.451894\n",
      "epoch 15; iter: 800; batch classifier loss: 0.439251\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.397397\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.386559\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.353229\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.455336\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.424746\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.384473\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.434096\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.477070\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.461491\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503658\n",
      "epoch 16; iter: 200; batch classifier loss: 0.446597\n",
      "epoch 16; iter: 400; batch classifier loss: 0.369015\n",
      "epoch 16; iter: 600; batch classifier loss: 0.440710\n",
      "epoch 16; iter: 800; batch classifier loss: 0.445324\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.459879\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.419117\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.405549\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.443265\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.342612\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.483006\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.379535\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.402661\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.455278\n",
      "epoch 17; iter: 0; batch classifier loss: 0.407266\n",
      "epoch 17; iter: 200; batch classifier loss: 0.445803\n",
      "epoch 17; iter: 400; batch classifier loss: 0.440692\n",
      "epoch 17; iter: 600; batch classifier loss: 0.389269\n",
      "epoch 17; iter: 800; batch classifier loss: 0.430290\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.455300\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.391905\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.424711\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.413704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 1800; batch classifier loss: 0.428991\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.405346\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.405629\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.381904\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.464554\n",
      "epoch 18; iter: 0; batch classifier loss: 0.379433\n",
      "epoch 18; iter: 200; batch classifier loss: 0.381968\n",
      "epoch 18; iter: 400; batch classifier loss: 0.300130\n",
      "epoch 18; iter: 600; batch classifier loss: 0.463364\n",
      "epoch 18; iter: 800; batch classifier loss: 0.411088\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.437703\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.403891\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.359239\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.488501\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.510566\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.399409\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.464697\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.322028\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.382133\n",
      "epoch 19; iter: 0; batch classifier loss: 0.402282\n",
      "epoch 19; iter: 200; batch classifier loss: 0.400914\n",
      "epoch 19; iter: 400; batch classifier loss: 0.341664\n",
      "epoch 19; iter: 600; batch classifier loss: 0.387237\n",
      "epoch 19; iter: 800; batch classifier loss: 0.368504\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.433188\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.353799\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.386211\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.323642\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.389915\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.432289\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.436497\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.443983\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.394022\n",
      "epoch 20; iter: 0; batch classifier loss: 0.310193\n",
      "epoch 20; iter: 200; batch classifier loss: 0.485278\n",
      "epoch 20; iter: 400; batch classifier loss: 0.422455\n",
      "epoch 20; iter: 600; batch classifier loss: 0.415124\n",
      "epoch 20; iter: 800; batch classifier loss: 0.415040\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.357122\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.382369\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.563876\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.406660\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.364077\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.440388\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.538859\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.327176\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.444960\n",
      "epoch 21; iter: 0; batch classifier loss: 0.316502\n",
      "epoch 21; iter: 200; batch classifier loss: 0.435488\n",
      "epoch 21; iter: 400; batch classifier loss: 0.436755\n",
      "epoch 21; iter: 600; batch classifier loss: 0.386051\n",
      "epoch 21; iter: 800; batch classifier loss: 0.454318\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.440803\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.395498\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.463704\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.438900\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.454906\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.419542\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.473056\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.395421\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.402460\n",
      "epoch 22; iter: 0; batch classifier loss: 0.501549\n",
      "epoch 22; iter: 200; batch classifier loss: 0.409174\n",
      "epoch 22; iter: 400; batch classifier loss: 0.491859\n",
      "epoch 22; iter: 600; batch classifier loss: 0.374882\n",
      "epoch 22; iter: 800; batch classifier loss: 0.404527\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.435532\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.443341\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.410948\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.407483\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.460485\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.418941\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.368855\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.413701\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.373645\n",
      "epoch 23; iter: 0; batch classifier loss: 0.428305\n",
      "epoch 23; iter: 200; batch classifier loss: 0.411455\n",
      "epoch 23; iter: 400; batch classifier loss: 0.443536\n",
      "epoch 23; iter: 600; batch classifier loss: 0.353382\n",
      "epoch 23; iter: 800; batch classifier loss: 0.436781\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.422340\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.436686\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.389217\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.450853\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.462532\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.404798\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.469667\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.405405\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.437325\n",
      "epoch 24; iter: 0; batch classifier loss: 0.467207\n",
      "epoch 24; iter: 200; batch classifier loss: 0.348966\n",
      "epoch 24; iter: 400; batch classifier loss: 0.475893\n",
      "epoch 24; iter: 600; batch classifier loss: 0.343840\n",
      "epoch 24; iter: 800; batch classifier loss: 0.376458\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.368094\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.426499\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.525136\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.433848\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.429775\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.417992\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.313805\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.395830\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.375226\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432820\n",
      "epoch 25; iter: 200; batch classifier loss: 0.477447\n",
      "epoch 25; iter: 400; batch classifier loss: 0.395478\n",
      "epoch 25; iter: 600; batch classifier loss: 0.423572\n",
      "epoch 25; iter: 800; batch classifier loss: 0.456645\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.405851\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.322841\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.396769\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.472508\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.398245\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.402136\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.448806\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.400047\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.424706\n",
      "epoch 26; iter: 0; batch classifier loss: 0.346490\n",
      "epoch 26; iter: 200; batch classifier loss: 0.451067\n",
      "epoch 26; iter: 400; batch classifier loss: 0.378187\n",
      "epoch 26; iter: 600; batch classifier loss: 0.491852\n",
      "epoch 26; iter: 800; batch classifier loss: 0.402358\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.552741\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.451049\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.440670\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.376781\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.407096\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.479959\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.508727\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.505647\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.384864\n",
      "epoch 27; iter: 0; batch classifier loss: 0.387493\n",
      "epoch 27; iter: 200; batch classifier loss: 0.409172\n",
      "epoch 27; iter: 400; batch classifier loss: 0.461104\n",
      "epoch 27; iter: 600; batch classifier loss: 0.380610\n",
      "epoch 27; iter: 800; batch classifier loss: 0.414207\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.364281\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.424072\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.397347\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.445983\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.408594\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.390963\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.432512\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.391874\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.456092\n",
      "epoch 28; iter: 0; batch classifier loss: 0.364433\n",
      "epoch 28; iter: 200; batch classifier loss: 0.439186\n",
      "epoch 28; iter: 400; batch classifier loss: 0.451871\n",
      "epoch 28; iter: 600; batch classifier loss: 0.418065\n",
      "epoch 28; iter: 800; batch classifier loss: 0.410194\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.418849\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.519558\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.448253\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.411978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 1800; batch classifier loss: 0.377256\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.346416\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.396738\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.420908\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.471722\n",
      "epoch 29; iter: 0; batch classifier loss: 0.424122\n",
      "epoch 29; iter: 200; batch classifier loss: 0.508498\n",
      "epoch 29; iter: 400; batch classifier loss: 0.401893\n",
      "epoch 29; iter: 600; batch classifier loss: 0.388943\n",
      "epoch 29; iter: 800; batch classifier loss: 0.407832\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.390482\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.398516\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.442327\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.423164\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.334056\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.452792\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.399545\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.488656\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.341203\n",
      "epoch 30; iter: 0; batch classifier loss: 0.489666\n",
      "epoch 30; iter: 200; batch classifier loss: 0.387775\n",
      "epoch 30; iter: 400; batch classifier loss: 0.468985\n",
      "epoch 30; iter: 600; batch classifier loss: 0.444847\n",
      "epoch 30; iter: 800; batch classifier loss: 0.397562\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.457317\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.439595\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.377535\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.422651\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.420823\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.304163\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.459514\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.402456\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.430350\n",
      "epoch 31; iter: 0; batch classifier loss: 0.403348\n",
      "epoch 31; iter: 200; batch classifier loss: 0.482758\n",
      "epoch 31; iter: 400; batch classifier loss: 0.395583\n",
      "epoch 31; iter: 600; batch classifier loss: 0.375758\n",
      "epoch 31; iter: 800; batch classifier loss: 0.408720\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.497864\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.381555\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.457071\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.435555\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.521753\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.465439\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.426216\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.394441\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.367588\n",
      "epoch 32; iter: 0; batch classifier loss: 0.442771\n",
      "epoch 32; iter: 200; batch classifier loss: 0.400454\n",
      "epoch 32; iter: 400; batch classifier loss: 0.412452\n",
      "epoch 32; iter: 600; batch classifier loss: 0.500053\n",
      "epoch 32; iter: 800; batch classifier loss: 0.471283\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.402055\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.294638\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.494733\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.462391\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.375662\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.381101\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.477782\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.473921\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.357744\n",
      "epoch 33; iter: 0; batch classifier loss: 0.444832\n",
      "epoch 33; iter: 200; batch classifier loss: 0.389150\n",
      "epoch 33; iter: 400; batch classifier loss: 0.440991\n",
      "epoch 33; iter: 600; batch classifier loss: 0.394586\n",
      "epoch 33; iter: 800; batch classifier loss: 0.438344\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.370747\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.309097\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.403666\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.435087\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.441024\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.339342\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.369193\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.432112\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.425909\n",
      "epoch 34; iter: 0; batch classifier loss: 0.380709\n",
      "epoch 34; iter: 200; batch classifier loss: 0.413448\n",
      "epoch 34; iter: 400; batch classifier loss: 0.358282\n",
      "epoch 34; iter: 600; batch classifier loss: 0.367138\n",
      "epoch 34; iter: 800; batch classifier loss: 0.457746\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.462105\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.361685\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.370063\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.365999\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.395403\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.420336\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.462565\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.443725\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.323042\n",
      "epoch 35; iter: 0; batch classifier loss: 0.413256\n",
      "epoch 35; iter: 200; batch classifier loss: 0.323826\n",
      "epoch 35; iter: 400; batch classifier loss: 0.522454\n",
      "epoch 35; iter: 600; batch classifier loss: 0.313316\n",
      "epoch 35; iter: 800; batch classifier loss: 0.304267\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.383517\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.385540\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.421862\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.354881\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.488402\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.370321\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.422615\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.398962\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.410378\n",
      "epoch 36; iter: 0; batch classifier loss: 0.410112\n",
      "epoch 36; iter: 200; batch classifier loss: 0.503889\n",
      "epoch 36; iter: 400; batch classifier loss: 0.381582\n",
      "epoch 36; iter: 600; batch classifier loss: 0.408964\n",
      "epoch 36; iter: 800; batch classifier loss: 0.427195\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.456623\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.362475\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.482338\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.423989\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.447237\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.430765\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.382866\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.406663\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.394050\n",
      "epoch 37; iter: 0; batch classifier loss: 0.375649\n",
      "epoch 37; iter: 200; batch classifier loss: 0.412096\n",
      "epoch 37; iter: 400; batch classifier loss: 0.383894\n",
      "epoch 37; iter: 600; batch classifier loss: 0.398582\n",
      "epoch 37; iter: 800; batch classifier loss: 0.393758\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.373256\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.461159\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.523941\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.451443\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.447325\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.379137\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.391742\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.412941\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.385572\n",
      "epoch 38; iter: 0; batch classifier loss: 0.427275\n",
      "epoch 38; iter: 200; batch classifier loss: 0.452186\n",
      "epoch 38; iter: 400; batch classifier loss: 0.379713\n",
      "epoch 38; iter: 600; batch classifier loss: 0.378015\n",
      "epoch 38; iter: 800; batch classifier loss: 0.477671\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.395894\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.382405\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.508825\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.400877\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.394726\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.438515\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.452906\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.345048\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.455742\n",
      "epoch 39; iter: 0; batch classifier loss: 0.340719\n",
      "epoch 39; iter: 200; batch classifier loss: 0.501944\n",
      "epoch 39; iter: 400; batch classifier loss: 0.354394\n",
      "epoch 39; iter: 600; batch classifier loss: 0.396731\n",
      "epoch 39; iter: 800; batch classifier loss: 0.323801\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.371638\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.460061\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.379272\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.443347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 1800; batch classifier loss: 0.397199\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.362434\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.340808\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.469509\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.360277\n",
      "epoch 40; iter: 0; batch classifier loss: 0.372593\n",
      "epoch 40; iter: 200; batch classifier loss: 0.469763\n",
      "epoch 40; iter: 400; batch classifier loss: 0.332941\n",
      "epoch 40; iter: 600; batch classifier loss: 0.408259\n",
      "epoch 40; iter: 800; batch classifier loss: 0.379812\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.510727\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.429496\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.405250\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.434958\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.297818\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.431681\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.352087\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.511981\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.417430\n",
      "epoch 41; iter: 0; batch classifier loss: 0.392812\n",
      "epoch 41; iter: 200; batch classifier loss: 0.396944\n",
      "epoch 41; iter: 400; batch classifier loss: 0.478861\n",
      "epoch 41; iter: 600; batch classifier loss: 0.435119\n",
      "epoch 41; iter: 800; batch classifier loss: 0.360682\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.411137\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.333063\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.391545\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.381818\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.458482\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.456838\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.481778\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.355638\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.464637\n",
      "epoch 42; iter: 0; batch classifier loss: 0.448618\n",
      "epoch 42; iter: 200; batch classifier loss: 0.419227\n",
      "epoch 42; iter: 400; batch classifier loss: 0.424671\n",
      "epoch 42; iter: 600; batch classifier loss: 0.354739\n",
      "epoch 42; iter: 800; batch classifier loss: 0.360123\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.381145\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.438350\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.440579\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.517496\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.468120\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.396171\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.500215\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.444957\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.449163\n",
      "epoch 43; iter: 0; batch classifier loss: 0.423595\n",
      "epoch 43; iter: 200; batch classifier loss: 0.436638\n",
      "epoch 43; iter: 400; batch classifier loss: 0.479440\n",
      "epoch 43; iter: 600; batch classifier loss: 0.492254\n",
      "epoch 43; iter: 800; batch classifier loss: 0.405698\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.354332\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.472216\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.500455\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.493614\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.422173\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.368016\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.425925\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.407063\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.441277\n",
      "epoch 44; iter: 0; batch classifier loss: 0.361372\n",
      "epoch 44; iter: 200; batch classifier loss: 0.430557\n",
      "epoch 44; iter: 400; batch classifier loss: 0.415715\n",
      "epoch 44; iter: 600; batch classifier loss: 0.448415\n",
      "epoch 44; iter: 800; batch classifier loss: 0.386441\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.441966\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.412171\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.387636\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.424792\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.367333\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.388967\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.397060\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.407027\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.327011\n",
      "epoch 45; iter: 0; batch classifier loss: 0.467538\n",
      "epoch 45; iter: 200; batch classifier loss: 0.379756\n",
      "epoch 45; iter: 400; batch classifier loss: 0.399065\n",
      "epoch 45; iter: 600; batch classifier loss: 0.491247\n",
      "epoch 45; iter: 800; batch classifier loss: 0.392673\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.377782\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.411606\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.448444\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.399200\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.401904\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.490106\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.474789\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.418257\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.446994\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430683\n",
      "epoch 46; iter: 200; batch classifier loss: 0.346604\n",
      "epoch 46; iter: 400; batch classifier loss: 0.395683\n",
      "epoch 46; iter: 600; batch classifier loss: 0.433951\n",
      "epoch 46; iter: 800; batch classifier loss: 0.419165\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.456343\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.342399\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.378856\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.424506\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.431176\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.407637\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.401819\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.394695\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.435918\n",
      "epoch 47; iter: 0; batch classifier loss: 0.493832\n",
      "epoch 47; iter: 200; batch classifier loss: 0.421338\n",
      "epoch 47; iter: 400; batch classifier loss: 0.407987\n",
      "epoch 47; iter: 600; batch classifier loss: 0.408923\n",
      "epoch 47; iter: 800; batch classifier loss: 0.370853\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.420117\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.313956\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.352848\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.406011\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.428437\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.467970\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.415924\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.376932\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.337687\n",
      "epoch 48; iter: 0; batch classifier loss: 0.377556\n",
      "epoch 48; iter: 200; batch classifier loss: 0.486694\n",
      "epoch 48; iter: 400; batch classifier loss: 0.440008\n",
      "epoch 48; iter: 600; batch classifier loss: 0.453400\n",
      "epoch 48; iter: 800; batch classifier loss: 0.402254\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.388311\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.337916\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.441559\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.419939\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.498511\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.439450\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.425885\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.419299\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.367250\n",
      "epoch 49; iter: 0; batch classifier loss: 0.363234\n",
      "epoch 49; iter: 200; batch classifier loss: 0.343512\n",
      "epoch 49; iter: 400; batch classifier loss: 0.533526\n",
      "epoch 49; iter: 600; batch classifier loss: 0.387390\n",
      "epoch 49; iter: 800; batch classifier loss: 0.487503\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.383795\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.339258\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.406220\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.445841\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.480219\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.505962\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.446686\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.388049\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.395366\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669298; batch adversarial loss: 0.716582\n",
      "epoch 0; iter: 200; batch classifier loss: 0.515638; batch adversarial loss: 0.619751\n",
      "epoch 1; iter: 0; batch classifier loss: 0.395052; batch adversarial loss: 0.621803\n",
      "epoch 1; iter: 200; batch classifier loss: 0.430859; batch adversarial loss: 0.533935\n",
      "epoch 2; iter: 0; batch classifier loss: 0.504262; batch adversarial loss: 0.584274\n",
      "epoch 2; iter: 200; batch classifier loss: 0.515667; batch adversarial loss: 0.515308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.494494; batch adversarial loss: 0.487830\n",
      "epoch 3; iter: 200; batch classifier loss: 0.412870; batch adversarial loss: 0.484058\n",
      "epoch 4; iter: 0; batch classifier loss: 0.438765; batch adversarial loss: 0.502152\n",
      "epoch 4; iter: 200; batch classifier loss: 0.424422; batch adversarial loss: 0.380605\n",
      "epoch 5; iter: 0; batch classifier loss: 0.447630; batch adversarial loss: 0.450428\n",
      "epoch 5; iter: 200; batch classifier loss: 0.379794; batch adversarial loss: 0.453249\n",
      "epoch 6; iter: 0; batch classifier loss: 0.479802; batch adversarial loss: 0.409410\n",
      "epoch 6; iter: 200; batch classifier loss: 0.496844; batch adversarial loss: 0.378714\n",
      "epoch 7; iter: 0; batch classifier loss: 0.408933; batch adversarial loss: 0.430500\n",
      "epoch 7; iter: 200; batch classifier loss: 0.422886; batch adversarial loss: 0.471890\n",
      "epoch 8; iter: 0; batch classifier loss: 0.334252; batch adversarial loss: 0.542181\n",
      "epoch 8; iter: 200; batch classifier loss: 0.394679; batch adversarial loss: 0.393518\n",
      "epoch 9; iter: 0; batch classifier loss: 0.479540; batch adversarial loss: 0.381795\n",
      "epoch 9; iter: 200; batch classifier loss: 0.371685; batch adversarial loss: 0.358461\n",
      "epoch 10; iter: 0; batch classifier loss: 0.430678; batch adversarial loss: 0.387708\n",
      "epoch 10; iter: 200; batch classifier loss: 0.454239; batch adversarial loss: 0.443635\n",
      "epoch 11; iter: 0; batch classifier loss: 0.440267; batch adversarial loss: 0.408796\n",
      "epoch 11; iter: 200; batch classifier loss: 0.494508; batch adversarial loss: 0.402731\n",
      "epoch 12; iter: 0; batch classifier loss: 0.475082; batch adversarial loss: 0.350562\n",
      "epoch 12; iter: 200; batch classifier loss: 0.423866; batch adversarial loss: 0.364260\n",
      "epoch 13; iter: 0; batch classifier loss: 0.384680; batch adversarial loss: 0.447471\n",
      "epoch 13; iter: 200; batch classifier loss: 0.412687; batch adversarial loss: 0.388836\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509414; batch adversarial loss: 0.362073\n",
      "epoch 14; iter: 200; batch classifier loss: 0.440976; batch adversarial loss: 0.290629\n",
      "epoch 15; iter: 0; batch classifier loss: 0.428253; batch adversarial loss: 0.375524\n",
      "epoch 15; iter: 200; batch classifier loss: 0.506615; batch adversarial loss: 0.393445\n",
      "epoch 16; iter: 0; batch classifier loss: 0.392600; batch adversarial loss: 0.346279\n",
      "epoch 16; iter: 200; batch classifier loss: 0.456200; batch adversarial loss: 0.402425\n",
      "epoch 17; iter: 0; batch classifier loss: 0.472628; batch adversarial loss: 0.290640\n",
      "epoch 17; iter: 200; batch classifier loss: 0.353312; batch adversarial loss: 0.406713\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476802; batch adversarial loss: 0.529500\n",
      "epoch 18; iter: 200; batch classifier loss: 0.382688; batch adversarial loss: 0.516781\n",
      "epoch 19; iter: 0; batch classifier loss: 0.385750; batch adversarial loss: 0.444402\n",
      "epoch 19; iter: 200; batch classifier loss: 0.453793; batch adversarial loss: 0.356802\n",
      "epoch 20; iter: 0; batch classifier loss: 0.513863; batch adversarial loss: 0.450800\n",
      "epoch 20; iter: 200; batch classifier loss: 0.466823; batch adversarial loss: 0.328613\n",
      "epoch 21; iter: 0; batch classifier loss: 0.429332; batch adversarial loss: 0.315465\n",
      "epoch 21; iter: 200; batch classifier loss: 0.447666; batch adversarial loss: 0.401779\n",
      "epoch 22; iter: 0; batch classifier loss: 0.422372; batch adversarial loss: 0.385616\n",
      "epoch 22; iter: 200; batch classifier loss: 0.360397; batch adversarial loss: 0.362016\n",
      "epoch 23; iter: 0; batch classifier loss: 0.437880; batch adversarial loss: 0.455767\n",
      "epoch 23; iter: 200; batch classifier loss: 0.427944; batch adversarial loss: 0.426564\n",
      "epoch 24; iter: 0; batch classifier loss: 0.423686; batch adversarial loss: 0.374349\n",
      "epoch 24; iter: 200; batch classifier loss: 0.423879; batch adversarial loss: 0.465029\n",
      "epoch 25; iter: 0; batch classifier loss: 0.443909; batch adversarial loss: 0.454667\n",
      "epoch 25; iter: 200; batch classifier loss: 0.494894; batch adversarial loss: 0.357115\n",
      "epoch 26; iter: 0; batch classifier loss: 0.455083; batch adversarial loss: 0.413757\n",
      "epoch 26; iter: 200; batch classifier loss: 0.383173; batch adversarial loss: 0.355218\n",
      "epoch 27; iter: 0; batch classifier loss: 0.337714; batch adversarial loss: 0.362152\n",
      "epoch 27; iter: 200; batch classifier loss: 0.446780; batch adversarial loss: 0.447969\n",
      "epoch 28; iter: 0; batch classifier loss: 0.515627; batch adversarial loss: 0.460994\n",
      "epoch 28; iter: 200; batch classifier loss: 0.362922; batch adversarial loss: 0.411241\n",
      "epoch 29; iter: 0; batch classifier loss: 0.503036; batch adversarial loss: 0.392890\n",
      "epoch 29; iter: 200; batch classifier loss: 0.443232; batch adversarial loss: 0.488440\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449461; batch adversarial loss: 0.514184\n",
      "epoch 30; iter: 200; batch classifier loss: 0.506695; batch adversarial loss: 0.479548\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470925; batch adversarial loss: 0.460952\n",
      "epoch 31; iter: 200; batch classifier loss: 0.449974; batch adversarial loss: 0.542990\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423335; batch adversarial loss: 0.487076\n",
      "epoch 32; iter: 200; batch classifier loss: 0.424552; batch adversarial loss: 0.409301\n",
      "epoch 33; iter: 0; batch classifier loss: 0.442853; batch adversarial loss: 0.486199\n",
      "epoch 33; iter: 200; batch classifier loss: 0.399015; batch adversarial loss: 0.352356\n",
      "epoch 34; iter: 0; batch classifier loss: 0.421720; batch adversarial loss: 0.330535\n",
      "epoch 34; iter: 200; batch classifier loss: 0.423127; batch adversarial loss: 0.363392\n",
      "epoch 35; iter: 0; batch classifier loss: 0.528680; batch adversarial loss: 0.540665\n",
      "epoch 35; iter: 200; batch classifier loss: 0.457881; batch adversarial loss: 0.450697\n",
      "epoch 36; iter: 0; batch classifier loss: 0.450140; batch adversarial loss: 0.330435\n",
      "epoch 36; iter: 200; batch classifier loss: 0.369954; batch adversarial loss: 0.371477\n",
      "epoch 37; iter: 0; batch classifier loss: 0.490195; batch adversarial loss: 0.332398\n",
      "epoch 37; iter: 200; batch classifier loss: 0.357604; batch adversarial loss: 0.400719\n",
      "epoch 38; iter: 0; batch classifier loss: 0.466866; batch adversarial loss: 0.444101\n",
      "epoch 38; iter: 200; batch classifier loss: 0.468063; batch adversarial loss: 0.347854\n",
      "epoch 39; iter: 0; batch classifier loss: 0.371565; batch adversarial loss: 0.341440\n",
      "epoch 39; iter: 200; batch classifier loss: 0.430469; batch adversarial loss: 0.482111\n",
      "epoch 40; iter: 0; batch classifier loss: 0.364434; batch adversarial loss: 0.385973\n",
      "epoch 40; iter: 200; batch classifier loss: 0.430102; batch adversarial loss: 0.414780\n",
      "epoch 41; iter: 0; batch classifier loss: 0.463894; batch adversarial loss: 0.308216\n",
      "epoch 41; iter: 200; batch classifier loss: 0.364395; batch adversarial loss: 0.350365\n",
      "epoch 42; iter: 0; batch classifier loss: 0.354282; batch adversarial loss: 0.429292\n",
      "epoch 42; iter: 200; batch classifier loss: 0.411123; batch adversarial loss: 0.376710\n",
      "epoch 43; iter: 0; batch classifier loss: 0.404784; batch adversarial loss: 0.428120\n",
      "epoch 43; iter: 200; batch classifier loss: 0.426262; batch adversarial loss: 0.468933\n",
      "epoch 44; iter: 0; batch classifier loss: 0.352570; batch adversarial loss: 0.388251\n",
      "epoch 44; iter: 200; batch classifier loss: 0.494879; batch adversarial loss: 0.421904\n",
      "epoch 45; iter: 0; batch classifier loss: 0.407268; batch adversarial loss: 0.448852\n",
      "epoch 45; iter: 200; batch classifier loss: 0.358726; batch adversarial loss: 0.433712\n",
      "epoch 46; iter: 0; batch classifier loss: 0.380230; batch adversarial loss: 0.440095\n",
      "epoch 46; iter: 200; batch classifier loss: 0.393179; batch adversarial loss: 0.401255\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399167; batch adversarial loss: 0.425808\n",
      "epoch 47; iter: 200; batch classifier loss: 0.315596; batch adversarial loss: 0.434858\n",
      "epoch 48; iter: 0; batch classifier loss: 0.475009; batch adversarial loss: 0.431117\n",
      "epoch 48; iter: 200; batch classifier loss: 0.433072; batch adversarial loss: 0.412444\n",
      "epoch 49; iter: 0; batch classifier loss: 0.487231; batch adversarial loss: 0.399330\n",
      "epoch 49; iter: 200; batch classifier loss: 0.421495; batch adversarial loss: 0.478608\n",
      "epoch 0; iter: 0; batch classifier loss: 0.821701\n",
      "epoch 0; iter: 200; batch classifier loss: 0.385443\n",
      "epoch 1; iter: 0; batch classifier loss: 0.391157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1; iter: 200; batch classifier loss: 0.440986\n",
      "epoch 2; iter: 0; batch classifier loss: 0.446107\n",
      "epoch 2; iter: 200; batch classifier loss: 0.383363\n",
      "epoch 3; iter: 0; batch classifier loss: 0.430998\n",
      "epoch 3; iter: 200; batch classifier loss: 0.393053\n",
      "epoch 4; iter: 0; batch classifier loss: 0.415893\n",
      "epoch 4; iter: 200; batch classifier loss: 0.435340\n",
      "epoch 5; iter: 0; batch classifier loss: 0.396475\n",
      "epoch 5; iter: 200; batch classifier loss: 0.450719\n",
      "epoch 6; iter: 0; batch classifier loss: 0.437347\n",
      "epoch 6; iter: 200; batch classifier loss: 0.424688\n",
      "epoch 7; iter: 0; batch classifier loss: 0.352128\n",
      "epoch 7; iter: 200; batch classifier loss: 0.372600\n",
      "epoch 8; iter: 0; batch classifier loss: 0.340629\n",
      "epoch 8; iter: 200; batch classifier loss: 0.476868\n",
      "epoch 9; iter: 0; batch classifier loss: 0.346554\n",
      "epoch 9; iter: 200; batch classifier loss: 0.366305\n",
      "epoch 10; iter: 0; batch classifier loss: 0.493357\n",
      "epoch 10; iter: 200; batch classifier loss: 0.419406\n",
      "epoch 11; iter: 0; batch classifier loss: 0.406728\n",
      "epoch 11; iter: 200; batch classifier loss: 0.448794\n",
      "epoch 12; iter: 0; batch classifier loss: 0.394786\n",
      "epoch 12; iter: 200; batch classifier loss: 0.466896\n",
      "epoch 13; iter: 0; batch classifier loss: 0.413787\n",
      "epoch 13; iter: 200; batch classifier loss: 0.433759\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469356\n",
      "epoch 14; iter: 200; batch classifier loss: 0.423318\n",
      "epoch 15; iter: 0; batch classifier loss: 0.459072\n",
      "epoch 15; iter: 200; batch classifier loss: 0.379923\n",
      "epoch 16; iter: 0; batch classifier loss: 0.423099\n",
      "epoch 16; iter: 200; batch classifier loss: 0.386430\n",
      "epoch 17; iter: 0; batch classifier loss: 0.489293\n",
      "epoch 17; iter: 200; batch classifier loss: 0.407555\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471533\n",
      "epoch 18; iter: 200; batch classifier loss: 0.445331\n",
      "epoch 19; iter: 0; batch classifier loss: 0.400706\n",
      "epoch 19; iter: 200; batch classifier loss: 0.479299\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463344\n",
      "epoch 20; iter: 200; batch classifier loss: 0.450740\n",
      "epoch 21; iter: 0; batch classifier loss: 0.431481\n",
      "epoch 21; iter: 200; batch classifier loss: 0.389413\n",
      "epoch 22; iter: 0; batch classifier loss: 0.400484\n",
      "epoch 22; iter: 200; batch classifier loss: 0.433377\n",
      "epoch 23; iter: 0; batch classifier loss: 0.401495\n",
      "epoch 23; iter: 200; batch classifier loss: 0.317279\n",
      "epoch 24; iter: 0; batch classifier loss: 0.365194\n",
      "epoch 24; iter: 200; batch classifier loss: 0.385778\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457858\n",
      "epoch 25; iter: 200; batch classifier loss: 0.395443\n",
      "epoch 26; iter: 0; batch classifier loss: 0.437614\n",
      "epoch 26; iter: 200; batch classifier loss: 0.373526\n",
      "epoch 27; iter: 0; batch classifier loss: 0.405972\n",
      "epoch 27; iter: 200; batch classifier loss: 0.421277\n",
      "epoch 28; iter: 0; batch classifier loss: 0.369965\n",
      "epoch 28; iter: 200; batch classifier loss: 0.345938\n",
      "epoch 29; iter: 0; batch classifier loss: 0.378711\n",
      "epoch 29; iter: 200; batch classifier loss: 0.390693\n",
      "epoch 30; iter: 0; batch classifier loss: 0.336467\n",
      "epoch 30; iter: 200; batch classifier loss: 0.458637\n",
      "epoch 31; iter: 0; batch classifier loss: 0.413344\n",
      "epoch 31; iter: 200; batch classifier loss: 0.443154\n",
      "epoch 32; iter: 0; batch classifier loss: 0.487425\n",
      "epoch 32; iter: 200; batch classifier loss: 0.437876\n",
      "epoch 33; iter: 0; batch classifier loss: 0.429955\n",
      "epoch 33; iter: 200; batch classifier loss: 0.601253\n",
      "epoch 34; iter: 0; batch classifier loss: 0.409081\n",
      "epoch 34; iter: 200; batch classifier loss: 0.408317\n",
      "epoch 35; iter: 0; batch classifier loss: 0.358375\n",
      "epoch 35; iter: 200; batch classifier loss: 0.383058\n",
      "epoch 36; iter: 0; batch classifier loss: 0.348041\n",
      "epoch 36; iter: 200; batch classifier loss: 0.401918\n",
      "epoch 37; iter: 0; batch classifier loss: 0.485184\n",
      "epoch 37; iter: 200; batch classifier loss: 0.416760\n",
      "epoch 38; iter: 0; batch classifier loss: 0.372476\n",
      "epoch 38; iter: 200; batch classifier loss: 0.463845\n",
      "epoch 39; iter: 0; batch classifier loss: 0.422696\n",
      "epoch 39; iter: 200; batch classifier loss: 0.444650\n",
      "epoch 40; iter: 0; batch classifier loss: 0.410288\n",
      "epoch 40; iter: 200; batch classifier loss: 0.382266\n",
      "epoch 41; iter: 0; batch classifier loss: 0.436505\n",
      "epoch 41; iter: 200; batch classifier loss: 0.373793\n",
      "epoch 42; iter: 0; batch classifier loss: 0.338479\n",
      "epoch 42; iter: 200; batch classifier loss: 0.420508\n",
      "epoch 43; iter: 0; batch classifier loss: 0.532020\n",
      "epoch 43; iter: 200; batch classifier loss: 0.403902\n",
      "epoch 44; iter: 0; batch classifier loss: 0.428020\n",
      "epoch 44; iter: 200; batch classifier loss: 0.402169\n",
      "epoch 45; iter: 0; batch classifier loss: 0.419717\n",
      "epoch 45; iter: 200; batch classifier loss: 0.426789\n",
      "epoch 46; iter: 0; batch classifier loss: 0.469840\n",
      "epoch 46; iter: 200; batch classifier loss: 0.372289\n",
      "epoch 47; iter: 0; batch classifier loss: 0.384938\n",
      "epoch 47; iter: 200; batch classifier loss: 0.428210\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405389\n",
      "epoch 48; iter: 200; batch classifier loss: 0.370145\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400074\n",
      "epoch 49; iter: 200; batch classifier loss: 0.340839\n",
      "run = 2\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686193; batch adversarial loss: 0.821035\n",
      "epoch 0; iter: 200; batch classifier loss: 0.941226; batch adversarial loss: 0.733079\n",
      "epoch 0; iter: 400; batch classifier loss: 0.452609; batch adversarial loss: 0.607666\n",
      "epoch 0; iter: 600; batch classifier loss: 0.420146; batch adversarial loss: 0.526693\n",
      "epoch 0; iter: 800; batch classifier loss: 0.406404; batch adversarial loss: 0.565229\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.311659; batch adversarial loss: 0.483846\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.416814; batch adversarial loss: 0.486498\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.427664; batch adversarial loss: 0.466648\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.369845; batch adversarial loss: 0.455828\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.513537; batch adversarial loss: 0.427299\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.340139; batch adversarial loss: 0.366841\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.390584; batch adversarial loss: 0.399016\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.426353; batch adversarial loss: 0.434989\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.410895; batch adversarial loss: 0.404233\n",
      "epoch 1; iter: 0; batch classifier loss: 0.473798; batch adversarial loss: 0.492540\n",
      "epoch 1; iter: 200; batch classifier loss: 0.460506; batch adversarial loss: 0.491547\n",
      "epoch 1; iter: 400; batch classifier loss: 0.565275; batch adversarial loss: 0.456488\n",
      "epoch 1; iter: 600; batch classifier loss: 0.336917; batch adversarial loss: 0.360708\n",
      "epoch 1; iter: 800; batch classifier loss: 0.454485; batch adversarial loss: 0.439172\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.463088; batch adversarial loss: 0.548921\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.443453; batch adversarial loss: 0.498775\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.431566; batch adversarial loss: 0.420259\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.454583; batch adversarial loss: 0.445862\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.410428; batch adversarial loss: 0.419992\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.329594; batch adversarial loss: 0.550187\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.416068; batch adversarial loss: 0.471335\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.468203; batch adversarial loss: 0.352739\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.373928; batch adversarial loss: 0.364238\n",
      "epoch 2; iter: 0; batch classifier loss: 0.353471; batch adversarial loss: 0.430723\n",
      "epoch 2; iter: 200; batch classifier loss: 0.370860; batch adversarial loss: 0.324078\n",
      "epoch 2; iter: 400; batch classifier loss: 0.409537; batch adversarial loss: 0.392285\n",
      "epoch 2; iter: 600; batch classifier loss: 0.487358; batch adversarial loss: 0.394333\n",
      "epoch 2; iter: 800; batch classifier loss: 0.492340; batch adversarial loss: 0.392920\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.517976; batch adversarial loss: 0.366886\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.481620; batch adversarial loss: 0.421252\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.432628; batch adversarial loss: 0.534748\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.391063; batch adversarial loss: 0.445507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 1800; batch classifier loss: 0.423166; batch adversarial loss: 0.379359\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.452643; batch adversarial loss: 0.418629\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.368586; batch adversarial loss: 0.337591\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.474665; batch adversarial loss: 0.567991\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.355191; batch adversarial loss: 0.352574\n",
      "epoch 3; iter: 0; batch classifier loss: 0.366157; batch adversarial loss: 0.568990\n",
      "epoch 3; iter: 200; batch classifier loss: 0.405178; batch adversarial loss: 0.364202\n",
      "epoch 3; iter: 400; batch classifier loss: 0.460126; batch adversarial loss: 0.481970\n",
      "epoch 3; iter: 600; batch classifier loss: 0.426613; batch adversarial loss: 0.446522\n",
      "epoch 3; iter: 800; batch classifier loss: 0.361485; batch adversarial loss: 0.478031\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.494972; batch adversarial loss: 0.307857\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.440356; batch adversarial loss: 0.355863\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.367585; batch adversarial loss: 0.441944\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.386388; batch adversarial loss: 0.365660\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.455235; batch adversarial loss: 0.423667\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.347976; batch adversarial loss: 0.517828\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.510516; batch adversarial loss: 0.466268\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.391093; batch adversarial loss: 0.446529\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.414319; batch adversarial loss: 0.460529\n",
      "epoch 4; iter: 0; batch classifier loss: 0.378175; batch adversarial loss: 0.512784\n",
      "epoch 4; iter: 200; batch classifier loss: 0.401398; batch adversarial loss: 0.462074\n",
      "epoch 4; iter: 400; batch classifier loss: 0.431139; batch adversarial loss: 0.323642\n",
      "epoch 4; iter: 600; batch classifier loss: 0.325009; batch adversarial loss: 0.420885\n",
      "epoch 4; iter: 800; batch classifier loss: 0.437500; batch adversarial loss: 0.459387\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.423171; batch adversarial loss: 0.442310\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.308630; batch adversarial loss: 0.417454\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.376316; batch adversarial loss: 0.326350\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.455355; batch adversarial loss: 0.377560\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.386430; batch adversarial loss: 0.408202\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.448057; batch adversarial loss: 0.498988\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.424743; batch adversarial loss: 0.535123\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.348542; batch adversarial loss: 0.349721\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.429138; batch adversarial loss: 0.418012\n",
      "epoch 5; iter: 0; batch classifier loss: 0.354928; batch adversarial loss: 0.409729\n",
      "epoch 5; iter: 200; batch classifier loss: 0.411296; batch adversarial loss: 0.402164\n",
      "epoch 5; iter: 400; batch classifier loss: 0.450205; batch adversarial loss: 0.353645\n",
      "epoch 5; iter: 600; batch classifier loss: 0.367721; batch adversarial loss: 0.416285\n",
      "epoch 5; iter: 800; batch classifier loss: 0.392936; batch adversarial loss: 0.378949\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.355519; batch adversarial loss: 0.440225\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.399879; batch adversarial loss: 0.349399\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.382294; batch adversarial loss: 0.453609\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.582683; batch adversarial loss: 0.394588\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.399359; batch adversarial loss: 0.320834\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.404411; batch adversarial loss: 0.435650\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.385757; batch adversarial loss: 0.445724\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.437610; batch adversarial loss: 0.419885\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.477543; batch adversarial loss: 0.406930\n",
      "epoch 6; iter: 0; batch classifier loss: 0.490083; batch adversarial loss: 0.486313\n",
      "epoch 6; iter: 200; batch classifier loss: 0.385877; batch adversarial loss: 0.409616\n",
      "epoch 6; iter: 400; batch classifier loss: 0.348703; batch adversarial loss: 0.490743\n",
      "epoch 6; iter: 600; batch classifier loss: 0.506933; batch adversarial loss: 0.537159\n",
      "epoch 6; iter: 800; batch classifier loss: 0.427496; batch adversarial loss: 0.434185\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.421926; batch adversarial loss: 0.406993\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.452374; batch adversarial loss: 0.400687\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.324970; batch adversarial loss: 0.475799\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.482597; batch adversarial loss: 0.420046\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.448527; batch adversarial loss: 0.390412\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.505382; batch adversarial loss: 0.511846\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.367147; batch adversarial loss: 0.429949\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.477393; batch adversarial loss: 0.368851\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.450001; batch adversarial loss: 0.488029\n",
      "epoch 7; iter: 0; batch classifier loss: 0.426285; batch adversarial loss: 0.400638\n",
      "epoch 7; iter: 200; batch classifier loss: 0.358430; batch adversarial loss: 0.392377\n",
      "epoch 7; iter: 400; batch classifier loss: 0.421987; batch adversarial loss: 0.417939\n",
      "epoch 7; iter: 600; batch classifier loss: 0.478095; batch adversarial loss: 0.435729\n",
      "epoch 7; iter: 800; batch classifier loss: 0.408469; batch adversarial loss: 0.465012\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.346152; batch adversarial loss: 0.521089\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.483788; batch adversarial loss: 0.339073\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.362515; batch adversarial loss: 0.368147\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.417547; batch adversarial loss: 0.440778\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.373945; batch adversarial loss: 0.446855\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.400223; batch adversarial loss: 0.451693\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.412688; batch adversarial loss: 0.392983\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.380638; batch adversarial loss: 0.434190\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.424901; batch adversarial loss: 0.461226\n",
      "epoch 8; iter: 0; batch classifier loss: 0.429897; batch adversarial loss: 0.489620\n",
      "epoch 8; iter: 200; batch classifier loss: 0.364880; batch adversarial loss: 0.353519\n",
      "epoch 8; iter: 400; batch classifier loss: 0.459155; batch adversarial loss: 0.422295\n",
      "epoch 8; iter: 600; batch classifier loss: 0.384166; batch adversarial loss: 0.366707\n",
      "epoch 8; iter: 800; batch classifier loss: 0.385706; batch adversarial loss: 0.374739\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.388267; batch adversarial loss: 0.390339\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.435292; batch adversarial loss: 0.382094\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.392357; batch adversarial loss: 0.406466\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.441468; batch adversarial loss: 0.442549\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.491726; batch adversarial loss: 0.434092\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.399868; batch adversarial loss: 0.433957\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.470022; batch adversarial loss: 0.454924\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.391930; batch adversarial loss: 0.377026\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.448733; batch adversarial loss: 0.421387\n",
      "epoch 9; iter: 0; batch classifier loss: 0.420172; batch adversarial loss: 0.431275\n",
      "epoch 9; iter: 200; batch classifier loss: 0.443099; batch adversarial loss: 0.434680\n",
      "epoch 9; iter: 400; batch classifier loss: 0.427960; batch adversarial loss: 0.448417\n",
      "epoch 9; iter: 600; batch classifier loss: 0.448459; batch adversarial loss: 0.349362\n",
      "epoch 9; iter: 800; batch classifier loss: 0.390929; batch adversarial loss: 0.488126\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.371563; batch adversarial loss: 0.433516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 1200; batch classifier loss: 0.346910; batch adversarial loss: 0.406547\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.352596; batch adversarial loss: 0.417547\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.460166; batch adversarial loss: 0.417963\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.460141; batch adversarial loss: 0.366833\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.421310; batch adversarial loss: 0.375872\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.374106; batch adversarial loss: 0.552833\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.370348; batch adversarial loss: 0.406910\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.425839; batch adversarial loss: 0.419727\n",
      "epoch 10; iter: 0; batch classifier loss: 0.325748; batch adversarial loss: 0.435155\n",
      "epoch 10; iter: 200; batch classifier loss: 0.525043; batch adversarial loss: 0.390649\n",
      "epoch 10; iter: 400; batch classifier loss: 0.387444; batch adversarial loss: 0.325272\n",
      "epoch 10; iter: 600; batch classifier loss: 0.463586; batch adversarial loss: 0.420911\n",
      "epoch 10; iter: 800; batch classifier loss: 0.381949; batch adversarial loss: 0.406823\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.426134; batch adversarial loss: 0.461337\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.420148; batch adversarial loss: 0.271184\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.450778; batch adversarial loss: 0.404164\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.430751; batch adversarial loss: 0.415994\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.480992; batch adversarial loss: 0.408807\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.362802; batch adversarial loss: 0.396915\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.438279; batch adversarial loss: 0.422039\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.450398; batch adversarial loss: 0.430009\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.398727; batch adversarial loss: 0.379718\n",
      "epoch 11; iter: 0; batch classifier loss: 0.430624; batch adversarial loss: 0.376814\n",
      "epoch 11; iter: 200; batch classifier loss: 0.394103; batch adversarial loss: 0.421249\n",
      "epoch 11; iter: 400; batch classifier loss: 0.438484; batch adversarial loss: 0.406331\n",
      "epoch 11; iter: 600; batch classifier loss: 0.361206; batch adversarial loss: 0.405506\n",
      "epoch 11; iter: 800; batch classifier loss: 0.403809; batch adversarial loss: 0.323559\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.400778; batch adversarial loss: 0.463502\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.440221; batch adversarial loss: 0.437396\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.407003; batch adversarial loss: 0.389816\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.382210; batch adversarial loss: 0.402387\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.383211; batch adversarial loss: 0.433445\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.384254; batch adversarial loss: 0.369196\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.504227; batch adversarial loss: 0.436166\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.436841; batch adversarial loss: 0.421095\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.407870; batch adversarial loss: 0.501249\n",
      "epoch 12; iter: 0; batch classifier loss: 0.501497; batch adversarial loss: 0.501814\n",
      "epoch 12; iter: 200; batch classifier loss: 0.348271; batch adversarial loss: 0.416766\n",
      "epoch 12; iter: 400; batch classifier loss: 0.369969; batch adversarial loss: 0.403476\n",
      "epoch 12; iter: 600; batch classifier loss: 0.436430; batch adversarial loss: 0.557257\n",
      "epoch 12; iter: 800; batch classifier loss: 0.498904; batch adversarial loss: 0.432217\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.409611; batch adversarial loss: 0.445055\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.372078; batch adversarial loss: 0.499778\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.342889; batch adversarial loss: 0.390501\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.379797; batch adversarial loss: 0.432230\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.500604; batch adversarial loss: 0.449784\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.497920; batch adversarial loss: 0.460513\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.421812; batch adversarial loss: 0.364306\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.423497; batch adversarial loss: 0.403754\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.397284; batch adversarial loss: 0.433814\n",
      "epoch 13; iter: 0; batch classifier loss: 0.432159; batch adversarial loss: 0.389716\n",
      "epoch 13; iter: 200; batch classifier loss: 0.408547; batch adversarial loss: 0.436470\n",
      "epoch 13; iter: 400; batch classifier loss: 0.371908; batch adversarial loss: 0.421131\n",
      "epoch 13; iter: 600; batch classifier loss: 0.472754; batch adversarial loss: 0.421805\n",
      "epoch 13; iter: 800; batch classifier loss: 0.390535; batch adversarial loss: 0.442708\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.492962; batch adversarial loss: 0.513445\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.468042; batch adversarial loss: 0.409938\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.443077; batch adversarial loss: 0.452323\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.413066; batch adversarial loss: 0.402549\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.394117; batch adversarial loss: 0.375868\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.433584; batch adversarial loss: 0.475382\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.355755; batch adversarial loss: 0.432715\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.396030; batch adversarial loss: 0.433675\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.416468; batch adversarial loss: 0.435932\n",
      "epoch 14; iter: 0; batch classifier loss: 0.426103; batch adversarial loss: 0.408064\n",
      "epoch 14; iter: 200; batch classifier loss: 0.339053; batch adversarial loss: 0.369260\n",
      "epoch 14; iter: 400; batch classifier loss: 0.436808; batch adversarial loss: 0.354091\n",
      "epoch 14; iter: 600; batch classifier loss: 0.352322; batch adversarial loss: 0.374917\n",
      "epoch 14; iter: 800; batch classifier loss: 0.337851; batch adversarial loss: 0.403354\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.417196; batch adversarial loss: 0.379407\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.362309; batch adversarial loss: 0.485110\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.432754; batch adversarial loss: 0.477402\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.414310; batch adversarial loss: 0.435396\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.453603; batch adversarial loss: 0.487586\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.428995; batch adversarial loss: 0.446403\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.416927; batch adversarial loss: 0.389767\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.392193; batch adversarial loss: 0.435161\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.420032; batch adversarial loss: 0.316007\n",
      "epoch 15; iter: 0; batch classifier loss: 0.364149; batch adversarial loss: 0.377309\n",
      "epoch 15; iter: 200; batch classifier loss: 0.471992; batch adversarial loss: 0.501547\n",
      "epoch 15; iter: 400; batch classifier loss: 0.433514; batch adversarial loss: 0.418236\n",
      "epoch 15; iter: 600; batch classifier loss: 0.456880; batch adversarial loss: 0.419012\n",
      "epoch 15; iter: 800; batch classifier loss: 0.393859; batch adversarial loss: 0.350608\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.423136; batch adversarial loss: 0.418284\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.364656; batch adversarial loss: 0.420572\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.417000; batch adversarial loss: 0.414752\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.394208; batch adversarial loss: 0.351519\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.506474; batch adversarial loss: 0.488310\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.380191; batch adversarial loss: 0.323687\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.394071; batch adversarial loss: 0.422539\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.400084; batch adversarial loss: 0.461468\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.425897; batch adversarial loss: 0.458404\n",
      "epoch 16; iter: 0; batch classifier loss: 0.465416; batch adversarial loss: 0.393276\n",
      "epoch 16; iter: 200; batch classifier loss: 0.355182; batch adversarial loss: 0.463240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 400; batch classifier loss: 0.433048; batch adversarial loss: 0.449365\n",
      "epoch 16; iter: 600; batch classifier loss: 0.404650; batch adversarial loss: 0.435960\n",
      "epoch 16; iter: 800; batch classifier loss: 0.408696; batch adversarial loss: 0.379616\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.397801; batch adversarial loss: 0.396800\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.392059; batch adversarial loss: 0.446769\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.406818; batch adversarial loss: 0.395143\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.450982; batch adversarial loss: 0.479778\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.395965; batch adversarial loss: 0.369857\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.419027; batch adversarial loss: 0.308793\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.397291; batch adversarial loss: 0.405451\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.388589; batch adversarial loss: 0.339455\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.498885; batch adversarial loss: 0.365639\n",
      "epoch 17; iter: 0; batch classifier loss: 0.410940; batch adversarial loss: 0.415320\n",
      "epoch 17; iter: 200; batch classifier loss: 0.401922; batch adversarial loss: 0.325579\n",
      "epoch 17; iter: 400; batch classifier loss: 0.439604; batch adversarial loss: 0.432925\n",
      "epoch 17; iter: 600; batch classifier loss: 0.436310; batch adversarial loss: 0.490907\n",
      "epoch 17; iter: 800; batch classifier loss: 0.426890; batch adversarial loss: 0.471486\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.370812; batch adversarial loss: 0.461051\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.421560; batch adversarial loss: 0.335067\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.405334; batch adversarial loss: 0.488304\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.363116; batch adversarial loss: 0.387816\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.458131; batch adversarial loss: 0.462218\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.309787; batch adversarial loss: 0.375113\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.407307; batch adversarial loss: 0.381336\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.358066; batch adversarial loss: 0.406688\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.452686; batch adversarial loss: 0.445591\n",
      "epoch 18; iter: 0; batch classifier loss: 0.362801; batch adversarial loss: 0.433974\n",
      "epoch 18; iter: 200; batch classifier loss: 0.402309; batch adversarial loss: 0.408512\n",
      "epoch 18; iter: 400; batch classifier loss: 0.431249; batch adversarial loss: 0.458929\n",
      "epoch 18; iter: 600; batch classifier loss: 0.489142; batch adversarial loss: 0.503033\n",
      "epoch 18; iter: 800; batch classifier loss: 0.521851; batch adversarial loss: 0.350682\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.439992; batch adversarial loss: 0.405021\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.366825; batch adversarial loss: 0.396081\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.438253; batch adversarial loss: 0.570450\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.398345; batch adversarial loss: 0.431937\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.430359; batch adversarial loss: 0.404366\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.446410; batch adversarial loss: 0.419726\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.471721; batch adversarial loss: 0.446124\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.396957; batch adversarial loss: 0.461166\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.356019; batch adversarial loss: 0.473534\n",
      "epoch 19; iter: 0; batch classifier loss: 0.442603; batch adversarial loss: 0.408058\n",
      "epoch 19; iter: 200; batch classifier loss: 0.417906; batch adversarial loss: 0.354318\n",
      "epoch 19; iter: 400; batch classifier loss: 0.400322; batch adversarial loss: 0.364579\n",
      "epoch 19; iter: 600; batch classifier loss: 0.422129; batch adversarial loss: 0.364955\n",
      "epoch 19; iter: 800; batch classifier loss: 0.366367; batch adversarial loss: 0.434163\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.393696; batch adversarial loss: 0.349753\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.425634; batch adversarial loss: 0.444933\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.349371; batch adversarial loss: 0.458058\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.475325; batch adversarial loss: 0.407313\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.462137; batch adversarial loss: 0.366114\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.451396; batch adversarial loss: 0.527166\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.386327; batch adversarial loss: 0.432516\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.450375; batch adversarial loss: 0.363191\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.395484; batch adversarial loss: 0.394187\n",
      "epoch 20; iter: 0; batch classifier loss: 0.574519; batch adversarial loss: 0.368961\n",
      "epoch 20; iter: 200; batch classifier loss: 0.501961; batch adversarial loss: 0.424516\n",
      "epoch 20; iter: 400; batch classifier loss: 0.421678; batch adversarial loss: 0.431935\n",
      "epoch 20; iter: 600; batch classifier loss: 0.449281; batch adversarial loss: 0.393968\n",
      "epoch 20; iter: 800; batch classifier loss: 0.401046; batch adversarial loss: 0.351291\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.501165; batch adversarial loss: 0.366791\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.433485; batch adversarial loss: 0.422872\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.476595; batch adversarial loss: 0.458127\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.381704; batch adversarial loss: 0.353057\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.471076; batch adversarial loss: 0.475767\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.396520; batch adversarial loss: 0.402370\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.368494; batch adversarial loss: 0.350340\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.320617; batch adversarial loss: 0.500677\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.425333; batch adversarial loss: 0.435679\n",
      "epoch 21; iter: 0; batch classifier loss: 0.403728; batch adversarial loss: 0.322669\n",
      "epoch 21; iter: 200; batch classifier loss: 0.443770; batch adversarial loss: 0.474889\n",
      "epoch 21; iter: 400; batch classifier loss: 0.484792; batch adversarial loss: 0.417399\n",
      "epoch 21; iter: 600; batch classifier loss: 0.515411; batch adversarial loss: 0.430224\n",
      "epoch 21; iter: 800; batch classifier loss: 0.380939; batch adversarial loss: 0.366434\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.426978; batch adversarial loss: 0.407728\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.500558; batch adversarial loss: 0.432683\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.469143; batch adversarial loss: 0.449788\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.392407; batch adversarial loss: 0.484466\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.520017; batch adversarial loss: 0.419869\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.452081; batch adversarial loss: 0.391127\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.337828; batch adversarial loss: 0.365520\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.436240; batch adversarial loss: 0.410999\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.469886; batch adversarial loss: 0.378469\n",
      "epoch 22; iter: 0; batch classifier loss: 0.420840; batch adversarial loss: 0.408340\n",
      "epoch 22; iter: 200; batch classifier loss: 0.388280; batch adversarial loss: 0.381599\n",
      "epoch 22; iter: 400; batch classifier loss: 0.515897; batch adversarial loss: 0.334995\n",
      "epoch 22; iter: 600; batch classifier loss: 0.458735; batch adversarial loss: 0.477594\n",
      "epoch 22; iter: 800; batch classifier loss: 0.454448; batch adversarial loss: 0.500795\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.504171; batch adversarial loss: 0.351257\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.413279; batch adversarial loss: 0.401784\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.354065; batch adversarial loss: 0.486839\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.419883; batch adversarial loss: 0.434553\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.359764; batch adversarial loss: 0.406479\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.494221; batch adversarial loss: 0.436795\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.481958; batch adversarial loss: 0.353361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 2400; batch classifier loss: 0.460413; batch adversarial loss: 0.407506\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.323892; batch adversarial loss: 0.489811\n",
      "epoch 23; iter: 0; batch classifier loss: 0.422152; batch adversarial loss: 0.395920\n",
      "epoch 23; iter: 200; batch classifier loss: 0.376883; batch adversarial loss: 0.366802\n",
      "epoch 23; iter: 400; batch classifier loss: 0.436535; batch adversarial loss: 0.431852\n",
      "epoch 23; iter: 600; batch classifier loss: 0.370055; batch adversarial loss: 0.444754\n",
      "epoch 23; iter: 800; batch classifier loss: 0.484070; batch adversarial loss: 0.359575\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.510447; batch adversarial loss: 0.336661\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.443409; batch adversarial loss: 0.446533\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.416396; batch adversarial loss: 0.474220\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.408252; batch adversarial loss: 0.378327\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.555301; batch adversarial loss: 0.422311\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.436933; batch adversarial loss: 0.488722\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.461077; batch adversarial loss: 0.409838\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.458004; batch adversarial loss: 0.357520\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.412440; batch adversarial loss: 0.406087\n",
      "epoch 24; iter: 0; batch classifier loss: 0.341996; batch adversarial loss: 0.448625\n",
      "epoch 24; iter: 200; batch classifier loss: 0.393927; batch adversarial loss: 0.503061\n",
      "epoch 24; iter: 400; batch classifier loss: 0.417291; batch adversarial loss: 0.472631\n",
      "epoch 24; iter: 600; batch classifier loss: 0.327813; batch adversarial loss: 0.298747\n",
      "epoch 24; iter: 800; batch classifier loss: 0.421499; batch adversarial loss: 0.472377\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.346856; batch adversarial loss: 0.429832\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.422228; batch adversarial loss: 0.517350\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.408419; batch adversarial loss: 0.322740\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.473107; batch adversarial loss: 0.406567\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.516173; batch adversarial loss: 0.472323\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.432411; batch adversarial loss: 0.337758\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.473556; batch adversarial loss: 0.435200\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.434968; batch adversarial loss: 0.456705\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.344928; batch adversarial loss: 0.366148\n",
      "epoch 25; iter: 0; batch classifier loss: 0.404861; batch adversarial loss: 0.393313\n",
      "epoch 25; iter: 200; batch classifier loss: 0.371745; batch adversarial loss: 0.472646\n",
      "epoch 25; iter: 400; batch classifier loss: 0.419008; batch adversarial loss: 0.407945\n",
      "epoch 25; iter: 600; batch classifier loss: 0.501382; batch adversarial loss: 0.417721\n",
      "epoch 25; iter: 800; batch classifier loss: 0.498078; batch adversarial loss: 0.434819\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.379073; batch adversarial loss: 0.339545\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.400376; batch adversarial loss: 0.450308\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.457013; batch adversarial loss: 0.352060\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.332644; batch adversarial loss: 0.394050\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.428917; batch adversarial loss: 0.475016\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.412597; batch adversarial loss: 0.334648\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.409377; batch adversarial loss: 0.459960\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.460598; batch adversarial loss: 0.339964\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.404333; batch adversarial loss: 0.376822\n",
      "epoch 26; iter: 0; batch classifier loss: 0.464195; batch adversarial loss: 0.468382\n",
      "epoch 26; iter: 200; batch classifier loss: 0.310955; batch adversarial loss: 0.417065\n",
      "epoch 26; iter: 400; batch classifier loss: 0.467703; batch adversarial loss: 0.376792\n",
      "epoch 26; iter: 600; batch classifier loss: 0.578075; batch adversarial loss: 0.381573\n",
      "epoch 26; iter: 800; batch classifier loss: 0.458181; batch adversarial loss: 0.339384\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.425822; batch adversarial loss: 0.430141\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.365450; batch adversarial loss: 0.396202\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.491763; batch adversarial loss: 0.464788\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.453699; batch adversarial loss: 0.422008\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.422834; batch adversarial loss: 0.350459\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.441871; batch adversarial loss: 0.310143\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.444112; batch adversarial loss: 0.377825\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.495368; batch adversarial loss: 0.432290\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.408529; batch adversarial loss: 0.501745\n",
      "epoch 27; iter: 0; batch classifier loss: 0.388341; batch adversarial loss: 0.266163\n",
      "epoch 27; iter: 200; batch classifier loss: 0.366865; batch adversarial loss: 0.378556\n",
      "epoch 27; iter: 400; batch classifier loss: 0.450369; batch adversarial loss: 0.393951\n",
      "epoch 27; iter: 600; batch classifier loss: 0.418518; batch adversarial loss: 0.490155\n",
      "epoch 27; iter: 800; batch classifier loss: 0.367583; batch adversarial loss: 0.378578\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.508694; batch adversarial loss: 0.520860\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.383191; batch adversarial loss: 0.434523\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.370477; batch adversarial loss: 0.315184\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.395226; batch adversarial loss: 0.541210\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.440008; batch adversarial loss: 0.446889\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.457291; batch adversarial loss: 0.445222\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.403115; batch adversarial loss: 0.445981\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.417237; batch adversarial loss: 0.512788\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.480619; batch adversarial loss: 0.390172\n",
      "epoch 28; iter: 0; batch classifier loss: 0.491723; batch adversarial loss: 0.380863\n",
      "epoch 28; iter: 200; batch classifier loss: 0.436160; batch adversarial loss: 0.439724\n",
      "epoch 28; iter: 400; batch classifier loss: 0.344194; batch adversarial loss: 0.367248\n",
      "epoch 28; iter: 600; batch classifier loss: 0.385047; batch adversarial loss: 0.381462\n",
      "epoch 28; iter: 800; batch classifier loss: 0.347688; batch adversarial loss: 0.419390\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.386926; batch adversarial loss: 0.431514\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.444123; batch adversarial loss: 0.497215\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.421338; batch adversarial loss: 0.420011\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.440610; batch adversarial loss: 0.336281\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.276679; batch adversarial loss: 0.379944\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.534004; batch adversarial loss: 0.394056\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.409173; batch adversarial loss: 0.407844\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.414805; batch adversarial loss: 0.436210\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.411791; batch adversarial loss: 0.382240\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476645; batch adversarial loss: 0.488313\n",
      "epoch 29; iter: 200; batch classifier loss: 0.320956; batch adversarial loss: 0.477846\n",
      "epoch 29; iter: 400; batch classifier loss: 0.322851; batch adversarial loss: 0.471109\n",
      "epoch 29; iter: 600; batch classifier loss: 0.484119; batch adversarial loss: 0.424625\n",
      "epoch 29; iter: 800; batch classifier loss: 0.487601; batch adversarial loss: 0.418174\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.330271; batch adversarial loss: 0.391184\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.437788; batch adversarial loss: 0.496507\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.395009; batch adversarial loss: 0.410019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 1600; batch classifier loss: 0.394610; batch adversarial loss: 0.458630\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.350542; batch adversarial loss: 0.431556\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.439120; batch adversarial loss: 0.393291\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.452966; batch adversarial loss: 0.356112\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.394070; batch adversarial loss: 0.381068\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.382919; batch adversarial loss: 0.529309\n",
      "epoch 30; iter: 0; batch classifier loss: 0.397319; batch adversarial loss: 0.419239\n",
      "epoch 30; iter: 200; batch classifier loss: 0.369378; batch adversarial loss: 0.407764\n",
      "epoch 30; iter: 400; batch classifier loss: 0.357267; batch adversarial loss: 0.459640\n",
      "epoch 30; iter: 600; batch classifier loss: 0.420134; batch adversarial loss: 0.445157\n",
      "epoch 30; iter: 800; batch classifier loss: 0.417456; batch adversarial loss: 0.500395\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.495643; batch adversarial loss: 0.419163\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.377560; batch adversarial loss: 0.472918\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.483130; batch adversarial loss: 0.431594\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.443548; batch adversarial loss: 0.464371\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.393097; batch adversarial loss: 0.364926\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.454814; batch adversarial loss: 0.432954\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.451089; batch adversarial loss: 0.379682\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.341174; batch adversarial loss: 0.326253\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.336503; batch adversarial loss: 0.473228\n",
      "epoch 31; iter: 0; batch classifier loss: 0.449734; batch adversarial loss: 0.446186\n",
      "epoch 31; iter: 200; batch classifier loss: 0.434658; batch adversarial loss: 0.363246\n",
      "epoch 31; iter: 400; batch classifier loss: 0.333515; batch adversarial loss: 0.433514\n",
      "epoch 31; iter: 600; batch classifier loss: 0.456249; batch adversarial loss: 0.365110\n",
      "epoch 31; iter: 800; batch classifier loss: 0.491615; batch adversarial loss: 0.374051\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.516207; batch adversarial loss: 0.487473\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.428648; batch adversarial loss: 0.418403\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.424117; batch adversarial loss: 0.338564\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.386911; batch adversarial loss: 0.417768\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.548937; batch adversarial loss: 0.444857\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.442771; batch adversarial loss: 0.397440\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.431336; batch adversarial loss: 0.310632\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.471525; batch adversarial loss: 0.435935\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.379281; batch adversarial loss: 0.336918\n",
      "epoch 32; iter: 0; batch classifier loss: 0.408917; batch adversarial loss: 0.365723\n",
      "epoch 32; iter: 200; batch classifier loss: 0.461363; batch adversarial loss: 0.362348\n",
      "epoch 32; iter: 400; batch classifier loss: 0.392169; batch adversarial loss: 0.477112\n",
      "epoch 32; iter: 600; batch classifier loss: 0.382138; batch adversarial loss: 0.447177\n",
      "epoch 32; iter: 800; batch classifier loss: 0.460244; batch adversarial loss: 0.436934\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.445449; batch adversarial loss: 0.498141\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.520391; batch adversarial loss: 0.474182\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.499595; batch adversarial loss: 0.405349\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.488963; batch adversarial loss: 0.436485\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.405447; batch adversarial loss: 0.416345\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.404305; batch adversarial loss: 0.392123\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.460196; batch adversarial loss: 0.443586\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.396685; batch adversarial loss: 0.341550\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.458684; batch adversarial loss: 0.432946\n",
      "epoch 33; iter: 0; batch classifier loss: 0.335619; batch adversarial loss: 0.434070\n",
      "epoch 33; iter: 200; batch classifier loss: 0.444177; batch adversarial loss: 0.447541\n",
      "epoch 33; iter: 400; batch classifier loss: 0.398641; batch adversarial loss: 0.486473\n",
      "epoch 33; iter: 600; batch classifier loss: 0.359765; batch adversarial loss: 0.432882\n",
      "epoch 33; iter: 800; batch classifier loss: 0.453986; batch adversarial loss: 0.446076\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.414140; batch adversarial loss: 0.474460\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.442387; batch adversarial loss: 0.454432\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.412992; batch adversarial loss: 0.448507\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.300644; batch adversarial loss: 0.447911\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.358317; batch adversarial loss: 0.375693\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.409896; batch adversarial loss: 0.366141\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.392236; batch adversarial loss: 0.449996\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.366031; batch adversarial loss: 0.433918\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.384228; batch adversarial loss: 0.493138\n",
      "epoch 34; iter: 0; batch classifier loss: 0.408551; batch adversarial loss: 0.327354\n",
      "epoch 34; iter: 200; batch classifier loss: 0.359721; batch adversarial loss: 0.363622\n",
      "epoch 34; iter: 400; batch classifier loss: 0.434556; batch adversarial loss: 0.464726\n",
      "epoch 34; iter: 600; batch classifier loss: 0.334995; batch adversarial loss: 0.430785\n",
      "epoch 34; iter: 800; batch classifier loss: 0.413177; batch adversarial loss: 0.469229\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.393429; batch adversarial loss: 0.379317\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.413543; batch adversarial loss: 0.434495\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.434899; batch adversarial loss: 0.446943\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.363038; batch adversarial loss: 0.379702\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.387579; batch adversarial loss: 0.407201\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.391522; batch adversarial loss: 0.341011\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.375364; batch adversarial loss: 0.429232\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.407460; batch adversarial loss: 0.376721\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.500060; batch adversarial loss: 0.327208\n",
      "epoch 35; iter: 0; batch classifier loss: 0.412000; batch adversarial loss: 0.447456\n",
      "epoch 35; iter: 200; batch classifier loss: 0.408279; batch adversarial loss: 0.444852\n",
      "epoch 35; iter: 400; batch classifier loss: 0.482941; batch adversarial loss: 0.433166\n",
      "epoch 35; iter: 600; batch classifier loss: 0.449727; batch adversarial loss: 0.376180\n",
      "epoch 35; iter: 800; batch classifier loss: 0.460474; batch adversarial loss: 0.366795\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.354663; batch adversarial loss: 0.391897\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.452326; batch adversarial loss: 0.431131\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.479015; batch adversarial loss: 0.414297\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.349917; batch adversarial loss: 0.422266\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.398757; batch adversarial loss: 0.418037\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.408897; batch adversarial loss: 0.366769\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.414444; batch adversarial loss: 0.487165\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.450688; batch adversarial loss: 0.365513\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.325849; batch adversarial loss: 0.379485\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476052; batch adversarial loss: 0.423226\n",
      "epoch 36; iter: 200; batch classifier loss: 0.443128; batch adversarial loss: 0.404504\n",
      "epoch 36; iter: 400; batch classifier loss: 0.382084; batch adversarial loss: 0.416196\n",
      "epoch 36; iter: 600; batch classifier loss: 0.473800; batch adversarial loss: 0.423400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 800; batch classifier loss: 0.405090; batch adversarial loss: 0.413176\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.347290; batch adversarial loss: 0.364960\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.385471; batch adversarial loss: 0.461817\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.593119; batch adversarial loss: 0.391654\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.367083; batch adversarial loss: 0.407788\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.414877; batch adversarial loss: 0.394237\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.426018; batch adversarial loss: 0.434206\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.443405; batch adversarial loss: 0.394919\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.365295; batch adversarial loss: 0.433658\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.397236; batch adversarial loss: 0.403100\n",
      "epoch 37; iter: 0; batch classifier loss: 0.443017; batch adversarial loss: 0.475666\n",
      "epoch 37; iter: 200; batch classifier loss: 0.412376; batch adversarial loss: 0.417611\n",
      "epoch 37; iter: 400; batch classifier loss: 0.379649; batch adversarial loss: 0.378081\n",
      "epoch 37; iter: 600; batch classifier loss: 0.487201; batch adversarial loss: 0.325357\n",
      "epoch 37; iter: 800; batch classifier loss: 0.344996; batch adversarial loss: 0.379206\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.502979; batch adversarial loss: 0.407226\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.364769; batch adversarial loss: 0.355291\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.454802; batch adversarial loss: 0.420877\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.446301; batch adversarial loss: 0.376271\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.358806; batch adversarial loss: 0.431398\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.482825; batch adversarial loss: 0.443323\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.428937; batch adversarial loss: 0.432853\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.323225; batch adversarial loss: 0.529541\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.410061; batch adversarial loss: 0.446566\n",
      "epoch 38; iter: 0; batch classifier loss: 0.438815; batch adversarial loss: 0.444348\n",
      "epoch 38; iter: 200; batch classifier loss: 0.459607; batch adversarial loss: 0.325609\n",
      "epoch 38; iter: 400; batch classifier loss: 0.423813; batch adversarial loss: 0.419927\n",
      "epoch 38; iter: 600; batch classifier loss: 0.412685; batch adversarial loss: 0.361803\n",
      "epoch 38; iter: 800; batch classifier loss: 0.455860; batch adversarial loss: 0.365139\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.433221; batch adversarial loss: 0.451592\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.415578; batch adversarial loss: 0.395493\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.470844; batch adversarial loss: 0.402476\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.412135; batch adversarial loss: 0.404522\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.390821; batch adversarial loss: 0.512464\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.401097; batch adversarial loss: 0.434962\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.500954; batch adversarial loss: 0.365267\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.440943; batch adversarial loss: 0.436248\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.361748; batch adversarial loss: 0.498086\n",
      "epoch 39; iter: 0; batch classifier loss: 0.363601; batch adversarial loss: 0.473003\n",
      "epoch 39; iter: 200; batch classifier loss: 0.397871; batch adversarial loss: 0.336076\n",
      "epoch 39; iter: 400; batch classifier loss: 0.454913; batch adversarial loss: 0.520178\n",
      "epoch 39; iter: 600; batch classifier loss: 0.429763; batch adversarial loss: 0.380049\n",
      "epoch 39; iter: 800; batch classifier loss: 0.321907; batch adversarial loss: 0.354758\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.540632; batch adversarial loss: 0.429750\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.443101; batch adversarial loss: 0.403182\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.417787; batch adversarial loss: 0.405166\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.400551; batch adversarial loss: 0.432418\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.421961; batch adversarial loss: 0.416034\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.457779; batch adversarial loss: 0.406746\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.558074; batch adversarial loss: 0.407372\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.596302; batch adversarial loss: 0.421040\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.409473; batch adversarial loss: 0.377524\n",
      "epoch 40; iter: 0; batch classifier loss: 0.526562; batch adversarial loss: 0.536017\n",
      "epoch 40; iter: 200; batch classifier loss: 0.385342; batch adversarial loss: 0.337096\n",
      "epoch 40; iter: 400; batch classifier loss: 0.410060; batch adversarial loss: 0.440877\n",
      "epoch 40; iter: 600; batch classifier loss: 0.395015; batch adversarial loss: 0.388592\n",
      "epoch 40; iter: 800; batch classifier loss: 0.466183; batch adversarial loss: 0.391016\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.371573; batch adversarial loss: 0.394244\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.360633; batch adversarial loss: 0.432086\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.360245; batch adversarial loss: 0.420665\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.400080; batch adversarial loss: 0.473391\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.410429; batch adversarial loss: 0.337921\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.405300; batch adversarial loss: 0.470216\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.371392; batch adversarial loss: 0.451315\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.403907; batch adversarial loss: 0.449844\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.408352; batch adversarial loss: 0.352912\n",
      "epoch 41; iter: 0; batch classifier loss: 0.488084; batch adversarial loss: 0.421724\n",
      "epoch 41; iter: 200; batch classifier loss: 0.422103; batch adversarial loss: 0.489716\n",
      "epoch 41; iter: 400; batch classifier loss: 0.497233; batch adversarial loss: 0.434053\n",
      "epoch 41; iter: 600; batch classifier loss: 0.444211; batch adversarial loss: 0.379870\n",
      "epoch 41; iter: 800; batch classifier loss: 0.394164; batch adversarial loss: 0.446558\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.435258; batch adversarial loss: 0.437580\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.436494; batch adversarial loss: 0.449930\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.287064; batch adversarial loss: 0.432077\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.401863; batch adversarial loss: 0.322520\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.341025; batch adversarial loss: 0.409592\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.416772; batch adversarial loss: 0.379657\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.452311; batch adversarial loss: 0.349400\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.394821; batch adversarial loss: 0.378894\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.584010; batch adversarial loss: 0.327523\n",
      "epoch 42; iter: 0; batch classifier loss: 0.331788; batch adversarial loss: 0.593835\n",
      "epoch 42; iter: 200; batch classifier loss: 0.417467; batch adversarial loss: 0.365895\n",
      "epoch 42; iter: 400; batch classifier loss: 0.458769; batch adversarial loss: 0.400895\n",
      "epoch 42; iter: 600; batch classifier loss: 0.401751; batch adversarial loss: 0.443745\n",
      "epoch 42; iter: 800; batch classifier loss: 0.433816; batch adversarial loss: 0.472900\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.388057; batch adversarial loss: 0.445950\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.422845; batch adversarial loss: 0.407245\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.406090; batch adversarial loss: 0.455999\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.480248; batch adversarial loss: 0.419132\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.495404; batch adversarial loss: 0.407986\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.391443; batch adversarial loss: 0.442288\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.405293; batch adversarial loss: 0.390026\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.523394; batch adversarial loss: 0.502271\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.444354; batch adversarial loss: 0.376333\n",
      "epoch 43; iter: 0; batch classifier loss: 0.347168; batch adversarial loss: 0.515418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43; iter: 200; batch classifier loss: 0.387562; batch adversarial loss: 0.321863\n",
      "epoch 43; iter: 400; batch classifier loss: 0.383802; batch adversarial loss: 0.379672\n",
      "epoch 43; iter: 600; batch classifier loss: 0.441440; batch adversarial loss: 0.464856\n",
      "epoch 43; iter: 800; batch classifier loss: 0.493637; batch adversarial loss: 0.489864\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.334939; batch adversarial loss: 0.421214\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.382178; batch adversarial loss: 0.513152\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.388638; batch adversarial loss: 0.389992\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.379820; batch adversarial loss: 0.337057\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.378719; batch adversarial loss: 0.434398\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.393063; batch adversarial loss: 0.417362\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.485181; batch adversarial loss: 0.380521\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.364708; batch adversarial loss: 0.378398\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.392549; batch adversarial loss: 0.502451\n",
      "epoch 44; iter: 0; batch classifier loss: 0.377111; batch adversarial loss: 0.314032\n",
      "epoch 44; iter: 200; batch classifier loss: 0.332858; batch adversarial loss: 0.424280\n",
      "epoch 44; iter: 400; batch classifier loss: 0.360392; batch adversarial loss: 0.579063\n",
      "epoch 44; iter: 600; batch classifier loss: 0.396313; batch adversarial loss: 0.418461\n",
      "epoch 44; iter: 800; batch classifier loss: 0.386259; batch adversarial loss: 0.407283\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.418546; batch adversarial loss: 0.405557\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.495601; batch adversarial loss: 0.461112\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.381075; batch adversarial loss: 0.350763\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.545095; batch adversarial loss: 0.518419\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.497385; batch adversarial loss: 0.375136\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.401861; batch adversarial loss: 0.365828\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.353336; batch adversarial loss: 0.381391\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.401104; batch adversarial loss: 0.394346\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.411722; batch adversarial loss: 0.535317\n",
      "epoch 45; iter: 0; batch classifier loss: 0.397980; batch adversarial loss: 0.392414\n",
      "epoch 45; iter: 200; batch classifier loss: 0.469534; batch adversarial loss: 0.488598\n",
      "epoch 45; iter: 400; batch classifier loss: 0.490186; batch adversarial loss: 0.360327\n",
      "epoch 45; iter: 600; batch classifier loss: 0.415119; batch adversarial loss: 0.340583\n",
      "epoch 45; iter: 800; batch classifier loss: 0.531180; batch adversarial loss: 0.353728\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.418852; batch adversarial loss: 0.376306\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.431901; batch adversarial loss: 0.430451\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.392069; batch adversarial loss: 0.541626\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.487875; batch adversarial loss: 0.449721\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.392652; batch adversarial loss: 0.504643\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.387640; batch adversarial loss: 0.447713\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.356013; batch adversarial loss: 0.409188\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.476806; batch adversarial loss: 0.449389\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.353155; batch adversarial loss: 0.474557\n",
      "epoch 46; iter: 0; batch classifier loss: 0.349075; batch adversarial loss: 0.364663\n",
      "epoch 46; iter: 200; batch classifier loss: 0.463339; batch adversarial loss: 0.434737\n",
      "epoch 46; iter: 400; batch classifier loss: 0.424362; batch adversarial loss: 0.351510\n",
      "epoch 46; iter: 600; batch classifier loss: 0.509053; batch adversarial loss: 0.445457\n",
      "epoch 46; iter: 800; batch classifier loss: 0.433348; batch adversarial loss: 0.476336\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.461888; batch adversarial loss: 0.418014\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.406254; batch adversarial loss: 0.394675\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.455080; batch adversarial loss: 0.377159\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.473217; batch adversarial loss: 0.324856\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.337295; batch adversarial loss: 0.390914\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.376866; batch adversarial loss: 0.445736\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.385650; batch adversarial loss: 0.529749\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.479322; batch adversarial loss: 0.376758\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.505687; batch adversarial loss: 0.498693\n",
      "epoch 47; iter: 0; batch classifier loss: 0.462750; batch adversarial loss: 0.434887\n",
      "epoch 47; iter: 200; batch classifier loss: 0.408163; batch adversarial loss: 0.456511\n",
      "epoch 47; iter: 400; batch classifier loss: 0.415691; batch adversarial loss: 0.379987\n",
      "epoch 47; iter: 600; batch classifier loss: 0.379016; batch adversarial loss: 0.497268\n",
      "epoch 47; iter: 800; batch classifier loss: 0.380508; batch adversarial loss: 0.395672\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.440360; batch adversarial loss: 0.297636\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.397423; batch adversarial loss: 0.446432\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.333582; batch adversarial loss: 0.445846\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.443522; batch adversarial loss: 0.471931\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.474369; batch adversarial loss: 0.460464\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.385742; batch adversarial loss: 0.309988\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.402794; batch adversarial loss: 0.488330\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.430630; batch adversarial loss: 0.470885\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.401120; batch adversarial loss: 0.497673\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370705; batch adversarial loss: 0.512097\n",
      "epoch 48; iter: 200; batch classifier loss: 0.371668; batch adversarial loss: 0.407444\n",
      "epoch 48; iter: 400; batch classifier loss: 0.470168; batch adversarial loss: 0.488993\n",
      "epoch 48; iter: 600; batch classifier loss: 0.321731; batch adversarial loss: 0.378591\n",
      "epoch 48; iter: 800; batch classifier loss: 0.431382; batch adversarial loss: 0.460137\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.389908; batch adversarial loss: 0.474038\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.395398; batch adversarial loss: 0.459740\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.413617; batch adversarial loss: 0.351664\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.370042; batch adversarial loss: 0.469917\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.333948; batch adversarial loss: 0.309847\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.355848; batch adversarial loss: 0.421242\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.368869; batch adversarial loss: 0.476747\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.467145; batch adversarial loss: 0.393153\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.412630; batch adversarial loss: 0.445558\n",
      "epoch 49; iter: 0; batch classifier loss: 0.477276; batch adversarial loss: 0.429385\n",
      "epoch 49; iter: 200; batch classifier loss: 0.475277; batch adversarial loss: 0.417696\n",
      "epoch 49; iter: 400; batch classifier loss: 0.323407; batch adversarial loss: 0.418262\n",
      "epoch 49; iter: 600; batch classifier loss: 0.435556; batch adversarial loss: 0.405257\n",
      "epoch 49; iter: 800; batch classifier loss: 0.381338; batch adversarial loss: 0.404372\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.322465; batch adversarial loss: 0.366681\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.421825; batch adversarial loss: 0.504081\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.366059; batch adversarial loss: 0.419074\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.431217; batch adversarial loss: 0.376851\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.386621; batch adversarial loss: 0.447648\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.360215; batch adversarial loss: 0.417028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49; iter: 2200; batch classifier loss: 0.358370; batch adversarial loss: 0.338291\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.363736; batch adversarial loss: 0.361039\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.380520; batch adversarial loss: 0.458878\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684070\n",
      "epoch 0; iter: 200; batch classifier loss: 0.495966\n",
      "epoch 0; iter: 400; batch classifier loss: 0.346587\n",
      "epoch 0; iter: 600; batch classifier loss: 0.438158\n",
      "epoch 0; iter: 800; batch classifier loss: 0.406639\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.401536\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.460415\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.379983\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.382620\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.483081\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.425401\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.414010\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.381827\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.453627\n",
      "epoch 1; iter: 0; batch classifier loss: 0.442174\n",
      "epoch 1; iter: 200; batch classifier loss: 0.518733\n",
      "epoch 1; iter: 400; batch classifier loss: 0.525059\n",
      "epoch 1; iter: 600; batch classifier loss: 0.412441\n",
      "epoch 1; iter: 800; batch classifier loss: 0.475650\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.506086\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.539486\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.384586\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.431677\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.450832\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.380279\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.357559\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.373370\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.410207\n",
      "epoch 2; iter: 0; batch classifier loss: 0.450273\n",
      "epoch 2; iter: 200; batch classifier loss: 0.373499\n",
      "epoch 2; iter: 400; batch classifier loss: 0.562919\n",
      "epoch 2; iter: 600; batch classifier loss: 0.414769\n",
      "epoch 2; iter: 800; batch classifier loss: 0.407359\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.398073\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.423841\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.399084\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.454535\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.423153\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.390749\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.438027\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.498244\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.426854\n",
      "epoch 3; iter: 0; batch classifier loss: 0.436377\n",
      "epoch 3; iter: 200; batch classifier loss: 0.381996\n",
      "epoch 3; iter: 400; batch classifier loss: 0.436082\n",
      "epoch 3; iter: 600; batch classifier loss: 0.381811\n",
      "epoch 3; iter: 800; batch classifier loss: 0.443383\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.497558\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.408552\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.381212\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.459929\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.481853\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.373103\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.397145\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.405489\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.394153\n",
      "epoch 4; iter: 0; batch classifier loss: 0.506585\n",
      "epoch 4; iter: 200; batch classifier loss: 0.398305\n",
      "epoch 4; iter: 400; batch classifier loss: 0.418329\n",
      "epoch 4; iter: 600; batch classifier loss: 0.522716\n",
      "epoch 4; iter: 800; batch classifier loss: 0.422109\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.421440\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.452424\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.495351\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.407919\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.443553\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.445302\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.428157\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.452111\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.444588\n",
      "epoch 5; iter: 0; batch classifier loss: 0.465990\n",
      "epoch 5; iter: 200; batch classifier loss: 0.471687\n",
      "epoch 5; iter: 400; batch classifier loss: 0.499975\n",
      "epoch 5; iter: 600; batch classifier loss: 0.425165\n",
      "epoch 5; iter: 800; batch classifier loss: 0.427149\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.490550\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.404204\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.381280\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.455195\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.406156\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.458737\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.442237\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.371788\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.444377\n",
      "epoch 6; iter: 0; batch classifier loss: 0.327872\n",
      "epoch 6; iter: 200; batch classifier loss: 0.364751\n",
      "epoch 6; iter: 400; batch classifier loss: 0.304852\n",
      "epoch 6; iter: 600; batch classifier loss: 0.365077\n",
      "epoch 6; iter: 800; batch classifier loss: 0.348651\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.501214\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.474969\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.449682\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.438129\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.396256\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.369189\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.392881\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.459755\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.351368\n",
      "epoch 7; iter: 0; batch classifier loss: 0.420174\n",
      "epoch 7; iter: 200; batch classifier loss: 0.306101\n",
      "epoch 7; iter: 400; batch classifier loss: 0.380784\n",
      "epoch 7; iter: 600; batch classifier loss: 0.489122\n",
      "epoch 7; iter: 800; batch classifier loss: 0.342687\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.349073\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.452782\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.530298\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.411271\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.410495\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.416928\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.400200\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.420074\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.418852\n",
      "epoch 8; iter: 0; batch classifier loss: 0.442383\n",
      "epoch 8; iter: 200; batch classifier loss: 0.498673\n",
      "epoch 8; iter: 400; batch classifier loss: 0.413304\n",
      "epoch 8; iter: 600; batch classifier loss: 0.424424\n",
      "epoch 8; iter: 800; batch classifier loss: 0.517235\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.432391\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.414022\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.367790\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.345978\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.422083\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.413833\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.417143\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.432760\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.505073\n",
      "epoch 9; iter: 0; batch classifier loss: 0.372962\n",
      "epoch 9; iter: 200; batch classifier loss: 0.329900\n",
      "epoch 9; iter: 400; batch classifier loss: 0.526689\n",
      "epoch 9; iter: 600; batch classifier loss: 0.300586\n",
      "epoch 9; iter: 800; batch classifier loss: 0.515976\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.388128\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.344033\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.379250\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.393956\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.364786\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.444077\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.429558\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.501478\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.367989\n",
      "epoch 10; iter: 0; batch classifier loss: 0.416361\n",
      "epoch 10; iter: 200; batch classifier loss: 0.465313\n",
      "epoch 10; iter: 400; batch classifier loss: 0.410712\n",
      "epoch 10; iter: 600; batch classifier loss: 0.337011\n",
      "epoch 10; iter: 800; batch classifier loss: 0.421157\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.444702\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.416864\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.418552\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.396023\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.394055\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.450894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 2200; batch classifier loss: 0.484688\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.429320\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.399062\n",
      "epoch 11; iter: 0; batch classifier loss: 0.371322\n",
      "epoch 11; iter: 200; batch classifier loss: 0.516735\n",
      "epoch 11; iter: 400; batch classifier loss: 0.348105\n",
      "epoch 11; iter: 600; batch classifier loss: 0.362723\n",
      "epoch 11; iter: 800; batch classifier loss: 0.454920\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.423365\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.386891\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.431862\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.421907\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.381244\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.417183\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.401154\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.426479\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.383090\n",
      "epoch 12; iter: 0; batch classifier loss: 0.378069\n",
      "epoch 12; iter: 200; batch classifier loss: 0.343819\n",
      "epoch 12; iter: 400; batch classifier loss: 0.460035\n",
      "epoch 12; iter: 600; batch classifier loss: 0.360473\n",
      "epoch 12; iter: 800; batch classifier loss: 0.416559\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.394664\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.428962\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.521093\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.425512\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.436378\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.402907\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.431127\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.497433\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.495085\n",
      "epoch 13; iter: 0; batch classifier loss: 0.458124\n",
      "epoch 13; iter: 200; batch classifier loss: 0.418634\n",
      "epoch 13; iter: 400; batch classifier loss: 0.416173\n",
      "epoch 13; iter: 600; batch classifier loss: 0.391568\n",
      "epoch 13; iter: 800; batch classifier loss: 0.413535\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.347590\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.428835\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.353045\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.431634\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.405118\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.478557\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.419476\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.454166\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.426491\n",
      "epoch 14; iter: 0; batch classifier loss: 0.466604\n",
      "epoch 14; iter: 200; batch classifier loss: 0.367895\n",
      "epoch 14; iter: 400; batch classifier loss: 0.379716\n",
      "epoch 14; iter: 600; batch classifier loss: 0.345137\n",
      "epoch 14; iter: 800; batch classifier loss: 0.340208\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.413932\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.400028\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.437701\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.383956\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.410054\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.381443\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.451804\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.474829\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.388085\n",
      "epoch 15; iter: 0; batch classifier loss: 0.334532\n",
      "epoch 15; iter: 200; batch classifier loss: 0.399949\n",
      "epoch 15; iter: 400; batch classifier loss: 0.412504\n",
      "epoch 15; iter: 600; batch classifier loss: 0.478508\n",
      "epoch 15; iter: 800; batch classifier loss: 0.438016\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.418607\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.378181\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.433694\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.460478\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.419121\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.447358\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.460419\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.387740\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.391954\n",
      "epoch 16; iter: 0; batch classifier loss: 0.361886\n",
      "epoch 16; iter: 200; batch classifier loss: 0.425762\n",
      "epoch 16; iter: 400; batch classifier loss: 0.347229\n",
      "epoch 16; iter: 600; batch classifier loss: 0.431628\n",
      "epoch 16; iter: 800; batch classifier loss: 0.416396\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.361081\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.428230\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.414263\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.448302\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.390321\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.399157\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.310456\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.455958\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.357399\n",
      "epoch 17; iter: 0; batch classifier loss: 0.519098\n",
      "epoch 17; iter: 200; batch classifier loss: 0.401221\n",
      "epoch 17; iter: 400; batch classifier loss: 0.341618\n",
      "epoch 17; iter: 600; batch classifier loss: 0.542015\n",
      "epoch 17; iter: 800; batch classifier loss: 0.378870\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.460181\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.452212\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.388243\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.436218\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.340893\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.392060\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.453126\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.291559\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.359148\n",
      "epoch 18; iter: 0; batch classifier loss: 0.370268\n",
      "epoch 18; iter: 200; batch classifier loss: 0.479559\n",
      "epoch 18; iter: 400; batch classifier loss: 0.486252\n",
      "epoch 18; iter: 600; batch classifier loss: 0.398219\n",
      "epoch 18; iter: 800; batch classifier loss: 0.412389\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.446662\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.387960\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.426600\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.541803\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.418120\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.405950\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.426229\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.419490\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.449754\n",
      "epoch 19; iter: 0; batch classifier loss: 0.433454\n",
      "epoch 19; iter: 200; batch classifier loss: 0.418445\n",
      "epoch 19; iter: 400; batch classifier loss: 0.386270\n",
      "epoch 19; iter: 600; batch classifier loss: 0.388450\n",
      "epoch 19; iter: 800; batch classifier loss: 0.439921\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.364774\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.432504\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.430610\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.402295\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.379597\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.403850\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.385201\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.484179\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.460717\n",
      "epoch 20; iter: 0; batch classifier loss: 0.444440\n",
      "epoch 20; iter: 200; batch classifier loss: 0.407590\n",
      "epoch 20; iter: 400; batch classifier loss: 0.411371\n",
      "epoch 20; iter: 600; batch classifier loss: 0.408179\n",
      "epoch 20; iter: 800; batch classifier loss: 0.419857\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.435475\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.381149\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.404117\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.335379\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.448066\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.421351\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.424779\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.392835\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.463695\n",
      "epoch 21; iter: 0; batch classifier loss: 0.409484\n",
      "epoch 21; iter: 200; batch classifier loss: 0.400430\n",
      "epoch 21; iter: 400; batch classifier loss: 0.349926\n",
      "epoch 21; iter: 600; batch classifier loss: 0.418511\n",
      "epoch 21; iter: 800; batch classifier loss: 0.397864\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.448875\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.377589\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.479971\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.473834\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.396397\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.385308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 2200; batch classifier loss: 0.355702\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.361985\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.400618\n",
      "epoch 22; iter: 0; batch classifier loss: 0.396103\n",
      "epoch 22; iter: 200; batch classifier loss: 0.371686\n",
      "epoch 22; iter: 400; batch classifier loss: 0.460510\n",
      "epoch 22; iter: 600; batch classifier loss: 0.426760\n",
      "epoch 22; iter: 800; batch classifier loss: 0.392820\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.436268\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.475932\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.472443\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.411610\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.474819\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.421542\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.464048\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.498010\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.389259\n",
      "epoch 23; iter: 0; batch classifier loss: 0.376862\n",
      "epoch 23; iter: 200; batch classifier loss: 0.451556\n",
      "epoch 23; iter: 400; batch classifier loss: 0.443657\n",
      "epoch 23; iter: 600; batch classifier loss: 0.423505\n",
      "epoch 23; iter: 800; batch classifier loss: 0.502846\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.337002\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.374845\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.394440\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.404604\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.460327\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.377956\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.423958\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.398854\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.455140\n",
      "epoch 24; iter: 0; batch classifier loss: 0.462611\n",
      "epoch 24; iter: 200; batch classifier loss: 0.399831\n",
      "epoch 24; iter: 400; batch classifier loss: 0.353613\n",
      "epoch 24; iter: 600; batch classifier loss: 0.402725\n",
      "epoch 24; iter: 800; batch classifier loss: 0.406537\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.345160\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.394606\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.427014\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.403320\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.388697\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.407226\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.475717\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.442924\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.471651\n",
      "epoch 25; iter: 0; batch classifier loss: 0.373250\n",
      "epoch 25; iter: 200; batch classifier loss: 0.376983\n",
      "epoch 25; iter: 400; batch classifier loss: 0.418996\n",
      "epoch 25; iter: 600; batch classifier loss: 0.394870\n",
      "epoch 25; iter: 800; batch classifier loss: 0.318786\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.369422\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.493491\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.324638\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.358964\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.471910\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.397225\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.361490\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.526394\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.328556\n",
      "epoch 26; iter: 0; batch classifier loss: 0.501578\n",
      "epoch 26; iter: 200; batch classifier loss: 0.557343\n",
      "epoch 26; iter: 400; batch classifier loss: 0.476800\n",
      "epoch 26; iter: 600; batch classifier loss: 0.384711\n",
      "epoch 26; iter: 800; batch classifier loss: 0.449407\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.361040\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.422528\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.334963\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.371917\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.402517\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.448514\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.369441\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.378294\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.329144\n",
      "epoch 27; iter: 0; batch classifier loss: 0.479551\n",
      "epoch 27; iter: 200; batch classifier loss: 0.532079\n",
      "epoch 27; iter: 400; batch classifier loss: 0.433664\n",
      "epoch 27; iter: 600; batch classifier loss: 0.461655\n",
      "epoch 27; iter: 800; batch classifier loss: 0.406311\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.482183\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.540067\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.485510\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.365668\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.419438\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.401525\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.391031\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.409839\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.466555\n",
      "epoch 28; iter: 0; batch classifier loss: 0.386460\n",
      "epoch 28; iter: 200; batch classifier loss: 0.325430\n",
      "epoch 28; iter: 400; batch classifier loss: 0.438974\n",
      "epoch 28; iter: 600; batch classifier loss: 0.397020\n",
      "epoch 28; iter: 800; batch classifier loss: 0.416092\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.505216\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.348266\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.343683\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.495719\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.402658\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.378176\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.400694\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.491248\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.544675\n",
      "epoch 29; iter: 0; batch classifier loss: 0.339511\n",
      "epoch 29; iter: 200; batch classifier loss: 0.396154\n",
      "epoch 29; iter: 400; batch classifier loss: 0.399887\n",
      "epoch 29; iter: 600; batch classifier loss: 0.404534\n",
      "epoch 29; iter: 800; batch classifier loss: 0.389829\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.358848\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.407650\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.446821\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.494213\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.424322\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.424107\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.436517\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.442174\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.484119\n",
      "epoch 30; iter: 0; batch classifier loss: 0.442392\n",
      "epoch 30; iter: 200; batch classifier loss: 0.371144\n",
      "epoch 30; iter: 400; batch classifier loss: 0.397191\n",
      "epoch 30; iter: 600; batch classifier loss: 0.410636\n",
      "epoch 30; iter: 800; batch classifier loss: 0.432821\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.378857\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.369054\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.342602\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.366532\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.455299\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.400502\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.459166\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.372469\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.445828\n",
      "epoch 31; iter: 0; batch classifier loss: 0.433114\n",
      "epoch 31; iter: 200; batch classifier loss: 0.407467\n",
      "epoch 31; iter: 400; batch classifier loss: 0.402067\n",
      "epoch 31; iter: 600; batch classifier loss: 0.391684\n",
      "epoch 31; iter: 800; batch classifier loss: 0.379839\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.505888\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.414668\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.471207\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.412315\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.389103\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.372433\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.446958\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.436167\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.329855\n",
      "epoch 32; iter: 0; batch classifier loss: 0.320069\n",
      "epoch 32; iter: 200; batch classifier loss: 0.394977\n",
      "epoch 32; iter: 400; batch classifier loss: 0.350787\n",
      "epoch 32; iter: 600; batch classifier loss: 0.379257\n",
      "epoch 32; iter: 800; batch classifier loss: 0.424631\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.357237\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.416852\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.462819\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.458472\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.390303\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.454100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 2200; batch classifier loss: 0.515867\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.471976\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.442070\n",
      "epoch 33; iter: 0; batch classifier loss: 0.496856\n",
      "epoch 33; iter: 200; batch classifier loss: 0.441807\n",
      "epoch 33; iter: 400; batch classifier loss: 0.521743\n",
      "epoch 33; iter: 600; batch classifier loss: 0.371082\n",
      "epoch 33; iter: 800; batch classifier loss: 0.441193\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.422857\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.363913\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.375415\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.456349\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.492227\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.358483\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.433122\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.478663\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.420638\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429639\n",
      "epoch 34; iter: 200; batch classifier loss: 0.399060\n",
      "epoch 34; iter: 400; batch classifier loss: 0.430361\n",
      "epoch 34; iter: 600; batch classifier loss: 0.445745\n",
      "epoch 34; iter: 800; batch classifier loss: 0.411076\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.396826\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.376010\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.388960\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.408182\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.341600\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.345231\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.435769\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.373988\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.412272\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421678\n",
      "epoch 35; iter: 200; batch classifier loss: 0.376144\n",
      "epoch 35; iter: 400; batch classifier loss: 0.345399\n",
      "epoch 35; iter: 600; batch classifier loss: 0.442831\n",
      "epoch 35; iter: 800; batch classifier loss: 0.402490\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.391029\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.461040\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.437335\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.389668\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.383742\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.422892\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.438648\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.400766\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.366329\n",
      "epoch 36; iter: 0; batch classifier loss: 0.360683\n",
      "epoch 36; iter: 200; batch classifier loss: 0.388998\n",
      "epoch 36; iter: 400; batch classifier loss: 0.354727\n",
      "epoch 36; iter: 600; batch classifier loss: 0.373216\n",
      "epoch 36; iter: 800; batch classifier loss: 0.313519\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.431662\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.446734\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.366028\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.369271\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.401068\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.486210\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.497097\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.404627\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.486560\n",
      "epoch 37; iter: 0; batch classifier loss: 0.422083\n",
      "epoch 37; iter: 200; batch classifier loss: 0.453115\n",
      "epoch 37; iter: 400; batch classifier loss: 0.351239\n",
      "epoch 37; iter: 600; batch classifier loss: 0.494991\n",
      "epoch 37; iter: 800; batch classifier loss: 0.374819\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.412591\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.399922\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.392899\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.398602\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.364765\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.404888\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.451012\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.382563\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.378511\n",
      "epoch 38; iter: 0; batch classifier loss: 0.437708\n",
      "epoch 38; iter: 200; batch classifier loss: 0.350025\n",
      "epoch 38; iter: 400; batch classifier loss: 0.392534\n",
      "epoch 38; iter: 600; batch classifier loss: 0.437717\n",
      "epoch 38; iter: 800; batch classifier loss: 0.451362\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.352239\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.323256\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.328407\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.412638\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.419731\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.489291\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.429732\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.402302\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.378741\n",
      "epoch 39; iter: 0; batch classifier loss: 0.617868\n",
      "epoch 39; iter: 200; batch classifier loss: 0.361265\n",
      "epoch 39; iter: 400; batch classifier loss: 0.431361\n",
      "epoch 39; iter: 600; batch classifier loss: 0.379500\n",
      "epoch 39; iter: 800; batch classifier loss: 0.401406\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.463204\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.416832\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.420410\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.428552\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.325902\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.415528\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.504450\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.395031\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.410955\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460359\n",
      "epoch 40; iter: 200; batch classifier loss: 0.448726\n",
      "epoch 40; iter: 400; batch classifier loss: 0.411769\n",
      "epoch 40; iter: 600; batch classifier loss: 0.490191\n",
      "epoch 40; iter: 800; batch classifier loss: 0.464924\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.380834\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.442160\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.372614\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.477329\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.476128\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.402182\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.405762\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.502469\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.451754\n",
      "epoch 41; iter: 0; batch classifier loss: 0.488245\n",
      "epoch 41; iter: 200; batch classifier loss: 0.363236\n",
      "epoch 41; iter: 400; batch classifier loss: 0.387340\n",
      "epoch 41; iter: 600; batch classifier loss: 0.353330\n",
      "epoch 41; iter: 800; batch classifier loss: 0.357643\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.444206\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.444261\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.343897\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.526543\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.440129\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.456798\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.462717\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.417915\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.328753\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436664\n",
      "epoch 42; iter: 200; batch classifier loss: 0.420332\n",
      "epoch 42; iter: 400; batch classifier loss: 0.363347\n",
      "epoch 42; iter: 600; batch classifier loss: 0.371671\n",
      "epoch 42; iter: 800; batch classifier loss: 0.417933\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.398136\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.389852\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.387529\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.355338\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.362133\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.517783\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.472457\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.338997\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.431727\n",
      "epoch 43; iter: 0; batch classifier loss: 0.481810\n",
      "epoch 43; iter: 200; batch classifier loss: 0.443588\n",
      "epoch 43; iter: 400; batch classifier loss: 0.348384\n",
      "epoch 43; iter: 600; batch classifier loss: 0.436079\n",
      "epoch 43; iter: 800; batch classifier loss: 0.403152\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.360084\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.369822\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.302487\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.309084\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.455485\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.350182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43; iter: 2200; batch classifier loss: 0.437216\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.351956\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.415378\n",
      "epoch 44; iter: 0; batch classifier loss: 0.328166\n",
      "epoch 44; iter: 200; batch classifier loss: 0.466036\n",
      "epoch 44; iter: 400; batch classifier loss: 0.520518\n",
      "epoch 44; iter: 600; batch classifier loss: 0.427787\n",
      "epoch 44; iter: 800; batch classifier loss: 0.445653\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.342889\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.484879\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.424667\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.347933\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.375420\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.434402\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.406075\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.374802\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.426835\n",
      "epoch 45; iter: 0; batch classifier loss: 0.447821\n",
      "epoch 45; iter: 200; batch classifier loss: 0.348203\n",
      "epoch 45; iter: 400; batch classifier loss: 0.431521\n",
      "epoch 45; iter: 600; batch classifier loss: 0.471046\n",
      "epoch 45; iter: 800; batch classifier loss: 0.371669\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.507982\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.534113\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.442376\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.316456\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.349937\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.366396\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.426502\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.340193\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.385045\n",
      "epoch 46; iter: 0; batch classifier loss: 0.397681\n",
      "epoch 46; iter: 200; batch classifier loss: 0.362198\n",
      "epoch 46; iter: 400; batch classifier loss: 0.274493\n",
      "epoch 46; iter: 600; batch classifier loss: 0.493851\n",
      "epoch 46; iter: 800; batch classifier loss: 0.422080\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.451403\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.399476\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.318079\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.398155\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.423280\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.430244\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.432985\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.388083\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.451301\n",
      "epoch 47; iter: 0; batch classifier loss: 0.386871\n",
      "epoch 47; iter: 200; batch classifier loss: 0.438568\n",
      "epoch 47; iter: 400; batch classifier loss: 0.435306\n",
      "epoch 47; iter: 600; batch classifier loss: 0.408981\n",
      "epoch 47; iter: 800; batch classifier loss: 0.362884\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.348658\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.311889\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.515264\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.391525\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.439493\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.377206\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.405611\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.404584\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.416557\n",
      "epoch 48; iter: 0; batch classifier loss: 0.410765\n",
      "epoch 48; iter: 200; batch classifier loss: 0.439077\n",
      "epoch 48; iter: 400; batch classifier loss: 0.419413\n",
      "epoch 48; iter: 600; batch classifier loss: 0.431269\n",
      "epoch 48; iter: 800; batch classifier loss: 0.400206\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.363755\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.456857\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.420827\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.453118\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.339137\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.419509\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.492634\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.397962\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.349924\n",
      "epoch 49; iter: 0; batch classifier loss: 0.480137\n",
      "epoch 49; iter: 200; batch classifier loss: 0.348228\n",
      "epoch 49; iter: 400; batch classifier loss: 0.503107\n",
      "epoch 49; iter: 600; batch classifier loss: 0.399921\n",
      "epoch 49; iter: 800; batch classifier loss: 0.371085\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.456644\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.454949\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.483277\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.422896\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.409215\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.418748\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.384862\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.397915\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.387935\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677975; batch adversarial loss: 0.845567\n",
      "epoch 0; iter: 200; batch classifier loss: 1.316757; batch adversarial loss: 0.882827\n",
      "epoch 1; iter: 0; batch classifier loss: 1.329300; batch adversarial loss: 0.784209\n",
      "epoch 1; iter: 200; batch classifier loss: 0.780264; batch adversarial loss: 0.611722\n",
      "epoch 2; iter: 0; batch classifier loss: 0.722077; batch adversarial loss: 0.568098\n",
      "epoch 2; iter: 200; batch classifier loss: 0.475739; batch adversarial loss: 0.536334\n",
      "epoch 3; iter: 0; batch classifier loss: 0.400441; batch adversarial loss: 0.537375\n",
      "epoch 3; iter: 200; batch classifier loss: 0.475700; batch adversarial loss: 0.505802\n",
      "epoch 4; iter: 0; batch classifier loss: 0.445217; batch adversarial loss: 0.509690\n",
      "epoch 4; iter: 200; batch classifier loss: 0.422195; batch adversarial loss: 0.486200\n",
      "epoch 5; iter: 0; batch classifier loss: 0.462727; batch adversarial loss: 0.490050\n",
      "epoch 5; iter: 200; batch classifier loss: 0.441121; batch adversarial loss: 0.440054\n",
      "epoch 6; iter: 0; batch classifier loss: 0.393631; batch adversarial loss: 0.466876\n",
      "epoch 6; iter: 200; batch classifier loss: 0.500635; batch adversarial loss: 0.451600\n",
      "epoch 7; iter: 0; batch classifier loss: 0.461851; batch adversarial loss: 0.459242\n",
      "epoch 7; iter: 200; batch classifier loss: 0.375607; batch adversarial loss: 0.397962\n",
      "epoch 8; iter: 0; batch classifier loss: 0.387017; batch adversarial loss: 0.435838\n",
      "epoch 8; iter: 200; batch classifier loss: 0.470847; batch adversarial loss: 0.446572\n",
      "epoch 9; iter: 0; batch classifier loss: 0.428615; batch adversarial loss: 0.428874\n",
      "epoch 9; iter: 200; batch classifier loss: 0.427374; batch adversarial loss: 0.439160\n",
      "epoch 10; iter: 0; batch classifier loss: 0.407142; batch adversarial loss: 0.396411\n",
      "epoch 10; iter: 200; batch classifier loss: 0.388754; batch adversarial loss: 0.462212\n",
      "epoch 11; iter: 0; batch classifier loss: 0.391086; batch adversarial loss: 0.444626\n",
      "epoch 11; iter: 200; batch classifier loss: 0.447965; batch adversarial loss: 0.421623\n",
      "epoch 12; iter: 0; batch classifier loss: 0.363679; batch adversarial loss: 0.521556\n",
      "epoch 12; iter: 200; batch classifier loss: 0.432988; batch adversarial loss: 0.451978\n",
      "epoch 13; iter: 0; batch classifier loss: 0.411640; batch adversarial loss: 0.417993\n",
      "epoch 13; iter: 200; batch classifier loss: 0.413799; batch adversarial loss: 0.398600\n",
      "epoch 14; iter: 0; batch classifier loss: 0.436688; batch adversarial loss: 0.380641\n",
      "epoch 14; iter: 200; batch classifier loss: 0.455640; batch adversarial loss: 0.389550\n",
      "epoch 15; iter: 0; batch classifier loss: 0.458934; batch adversarial loss: 0.374026\n",
      "epoch 15; iter: 200; batch classifier loss: 0.440132; batch adversarial loss: 0.400068\n",
      "epoch 16; iter: 0; batch classifier loss: 0.476518; batch adversarial loss: 0.415774\n",
      "epoch 16; iter: 200; batch classifier loss: 0.427474; batch adversarial loss: 0.449191\n",
      "epoch 17; iter: 0; batch classifier loss: 0.455477; batch adversarial loss: 0.465218\n",
      "epoch 17; iter: 200; batch classifier loss: 0.396185; batch adversarial loss: 0.374281\n",
      "epoch 18; iter: 0; batch classifier loss: 0.339877; batch adversarial loss: 0.519734\n",
      "epoch 18; iter: 200; batch classifier loss: 0.369042; batch adversarial loss: 0.420847\n",
      "epoch 19; iter: 0; batch classifier loss: 0.431829; batch adversarial loss: 0.336262\n",
      "epoch 19; iter: 200; batch classifier loss: 0.439300; batch adversarial loss: 0.515739\n",
      "epoch 20; iter: 0; batch classifier loss: 0.478759; batch adversarial loss: 0.455062\n",
      "epoch 20; iter: 200; batch classifier loss: 0.461385; batch adversarial loss: 0.382535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.421972; batch adversarial loss: 0.404833\n",
      "epoch 21; iter: 200; batch classifier loss: 0.411840; batch adversarial loss: 0.381702\n",
      "epoch 22; iter: 0; batch classifier loss: 0.391871; batch adversarial loss: 0.423873\n",
      "epoch 22; iter: 200; batch classifier loss: 0.424488; batch adversarial loss: 0.453340\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477561; batch adversarial loss: 0.331721\n",
      "epoch 23; iter: 200; batch classifier loss: 0.295539; batch adversarial loss: 0.377810\n",
      "epoch 24; iter: 0; batch classifier loss: 0.442264; batch adversarial loss: 0.355011\n",
      "epoch 24; iter: 200; batch classifier loss: 0.411094; batch adversarial loss: 0.300727\n",
      "epoch 25; iter: 0; batch classifier loss: 0.434163; batch adversarial loss: 0.376683\n",
      "epoch 25; iter: 200; batch classifier loss: 0.403107; batch adversarial loss: 0.398027\n",
      "epoch 26; iter: 0; batch classifier loss: 0.355756; batch adversarial loss: 0.428995\n",
      "epoch 26; iter: 200; batch classifier loss: 0.373565; batch adversarial loss: 0.533827\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445722; batch adversarial loss: 0.420684\n",
      "epoch 27; iter: 200; batch classifier loss: 0.347405; batch adversarial loss: 0.474876\n",
      "epoch 28; iter: 0; batch classifier loss: 0.456490; batch adversarial loss: 0.382135\n",
      "epoch 28; iter: 200; batch classifier loss: 0.456305; batch adversarial loss: 0.420038\n",
      "epoch 29; iter: 0; batch classifier loss: 0.453565; batch adversarial loss: 0.470727\n",
      "epoch 29; iter: 200; batch classifier loss: 0.475906; batch adversarial loss: 0.494653\n",
      "epoch 30; iter: 0; batch classifier loss: 0.373245; batch adversarial loss: 0.407914\n",
      "epoch 30; iter: 200; batch classifier loss: 0.353723; batch adversarial loss: 0.457689\n",
      "epoch 31; iter: 0; batch classifier loss: 0.455540; batch adversarial loss: 0.455810\n",
      "epoch 31; iter: 200; batch classifier loss: 0.397595; batch adversarial loss: 0.473497\n",
      "epoch 32; iter: 0; batch classifier loss: 0.435048; batch adversarial loss: 0.398854\n",
      "epoch 32; iter: 200; batch classifier loss: 0.430152; batch adversarial loss: 0.326861\n",
      "epoch 33; iter: 0; batch classifier loss: 0.403990; batch adversarial loss: 0.322747\n",
      "epoch 33; iter: 200; batch classifier loss: 0.426071; batch adversarial loss: 0.343552\n",
      "epoch 34; iter: 0; batch classifier loss: 0.343016; batch adversarial loss: 0.507779\n",
      "epoch 34; iter: 200; batch classifier loss: 0.420252; batch adversarial loss: 0.353345\n",
      "epoch 35; iter: 0; batch classifier loss: 0.540706; batch adversarial loss: 0.414565\n",
      "epoch 35; iter: 200; batch classifier loss: 0.424182; batch adversarial loss: 0.476466\n",
      "epoch 36; iter: 0; batch classifier loss: 0.347570; batch adversarial loss: 0.441092\n",
      "epoch 36; iter: 200; batch classifier loss: 0.467449; batch adversarial loss: 0.390985\n",
      "epoch 37; iter: 0; batch classifier loss: 0.448041; batch adversarial loss: 0.458773\n",
      "epoch 37; iter: 200; batch classifier loss: 0.422657; batch adversarial loss: 0.424860\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447958; batch adversarial loss: 0.533196\n",
      "epoch 38; iter: 200; batch classifier loss: 0.424110; batch adversarial loss: 0.429585\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463096; batch adversarial loss: 0.508810\n",
      "epoch 39; iter: 200; batch classifier loss: 0.438497; batch adversarial loss: 0.353861\n",
      "epoch 40; iter: 0; batch classifier loss: 0.375708; batch adversarial loss: 0.593421\n",
      "epoch 40; iter: 200; batch classifier loss: 0.460792; batch adversarial loss: 0.405168\n",
      "epoch 41; iter: 0; batch classifier loss: 0.440076; batch adversarial loss: 0.330369\n",
      "epoch 41; iter: 200; batch classifier loss: 0.429342; batch adversarial loss: 0.425686\n",
      "epoch 42; iter: 0; batch classifier loss: 0.339734; batch adversarial loss: 0.443406\n",
      "epoch 42; iter: 200; batch classifier loss: 0.447839; batch adversarial loss: 0.340251\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401214; batch adversarial loss: 0.380713\n",
      "epoch 43; iter: 200; batch classifier loss: 0.472253; batch adversarial loss: 0.323550\n",
      "epoch 44; iter: 0; batch classifier loss: 0.482110; batch adversarial loss: 0.426327\n",
      "epoch 44; iter: 200; batch classifier loss: 0.418232; batch adversarial loss: 0.469755\n",
      "epoch 45; iter: 0; batch classifier loss: 0.455765; batch adversarial loss: 0.417639\n",
      "epoch 45; iter: 200; batch classifier loss: 0.396162; batch adversarial loss: 0.375817\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448612; batch adversarial loss: 0.419839\n",
      "epoch 46; iter: 200; batch classifier loss: 0.459620; batch adversarial loss: 0.404797\n",
      "epoch 47; iter: 0; batch classifier loss: 0.472481; batch adversarial loss: 0.358049\n",
      "epoch 47; iter: 200; batch classifier loss: 0.455616; batch adversarial loss: 0.408554\n",
      "epoch 48; iter: 0; batch classifier loss: 0.424978; batch adversarial loss: 0.428248\n",
      "epoch 48; iter: 200; batch classifier loss: 0.371480; batch adversarial loss: 0.377550\n",
      "epoch 49; iter: 0; batch classifier loss: 0.449538; batch adversarial loss: 0.497279\n",
      "epoch 49; iter: 200; batch classifier loss: 0.494201; batch adversarial loss: 0.508699\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675396\n",
      "epoch 0; iter: 200; batch classifier loss: 0.464512\n",
      "epoch 1; iter: 0; batch classifier loss: 0.434496\n",
      "epoch 1; iter: 200; batch classifier loss: 0.296383\n",
      "epoch 2; iter: 0; batch classifier loss: 0.480471\n",
      "epoch 2; iter: 200; batch classifier loss: 0.458957\n",
      "epoch 3; iter: 0; batch classifier loss: 0.377135\n",
      "epoch 3; iter: 200; batch classifier loss: 0.403275\n",
      "epoch 4; iter: 0; batch classifier loss: 0.362280\n",
      "epoch 4; iter: 200; batch classifier loss: 0.463344\n",
      "epoch 5; iter: 0; batch classifier loss: 0.404657\n",
      "epoch 5; iter: 200; batch classifier loss: 0.329441\n",
      "epoch 6; iter: 0; batch classifier loss: 0.395916\n",
      "epoch 6; iter: 200; batch classifier loss: 0.483055\n",
      "epoch 7; iter: 0; batch classifier loss: 0.400068\n",
      "epoch 7; iter: 200; batch classifier loss: 0.423123\n",
      "epoch 8; iter: 0; batch classifier loss: 0.436545\n",
      "epoch 8; iter: 200; batch classifier loss: 0.373801\n",
      "epoch 9; iter: 0; batch classifier loss: 0.443162\n",
      "epoch 9; iter: 200; batch classifier loss: 0.516556\n",
      "epoch 10; iter: 0; batch classifier loss: 0.381838\n",
      "epoch 10; iter: 200; batch classifier loss: 0.404829\n",
      "epoch 11; iter: 0; batch classifier loss: 0.414373\n",
      "epoch 11; iter: 200; batch classifier loss: 0.435237\n",
      "epoch 12; iter: 0; batch classifier loss: 0.345917\n",
      "epoch 12; iter: 200; batch classifier loss: 0.512364\n",
      "epoch 13; iter: 0; batch classifier loss: 0.489965\n",
      "epoch 13; iter: 200; batch classifier loss: 0.458601\n",
      "epoch 14; iter: 0; batch classifier loss: 0.431801\n",
      "epoch 14; iter: 200; batch classifier loss: 0.515495\n",
      "epoch 15; iter: 0; batch classifier loss: 0.516727\n",
      "epoch 15; iter: 200; batch classifier loss: 0.381074\n",
      "epoch 16; iter: 0; batch classifier loss: 0.430520\n",
      "epoch 16; iter: 200; batch classifier loss: 0.378321\n",
      "epoch 17; iter: 0; batch classifier loss: 0.546949\n",
      "epoch 17; iter: 200; batch classifier loss: 0.529662\n",
      "epoch 18; iter: 0; batch classifier loss: 0.424480\n",
      "epoch 18; iter: 200; batch classifier loss: 0.360372\n",
      "epoch 19; iter: 0; batch classifier loss: 0.481928\n",
      "epoch 19; iter: 200; batch classifier loss: 0.425668\n",
      "epoch 20; iter: 0; batch classifier loss: 0.335379\n",
      "epoch 20; iter: 200; batch classifier loss: 0.495420\n",
      "epoch 21; iter: 0; batch classifier loss: 0.424450\n",
      "epoch 21; iter: 200; batch classifier loss: 0.345682\n",
      "epoch 22; iter: 0; batch classifier loss: 0.376062\n",
      "epoch 22; iter: 200; batch classifier loss: 0.457131\n",
      "epoch 23; iter: 0; batch classifier loss: 0.480177\n",
      "epoch 23; iter: 200; batch classifier loss: 0.395390\n",
      "epoch 24; iter: 0; batch classifier loss: 0.369724\n",
      "epoch 24; iter: 200; batch classifier loss: 0.425157\n",
      "epoch 25; iter: 0; batch classifier loss: 0.340609\n",
      "epoch 25; iter: 200; batch classifier loss: 0.502583\n",
      "epoch 26; iter: 0; batch classifier loss: 0.340377\n",
      "epoch 26; iter: 200; batch classifier loss: 0.423019\n",
      "epoch 27; iter: 0; batch classifier loss: 0.505726\n",
      "epoch 27; iter: 200; batch classifier loss: 0.445392\n",
      "epoch 28; iter: 0; batch classifier loss: 0.393908\n",
      "epoch 28; iter: 200; batch classifier loss: 0.424230\n",
      "epoch 29; iter: 0; batch classifier loss: 0.383573\n",
      "epoch 29; iter: 200; batch classifier loss: 0.390667\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477718\n",
      "epoch 30; iter: 200; batch classifier loss: 0.443040\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31; iter: 200; batch classifier loss: 0.388053\n",
      "epoch 32; iter: 0; batch classifier loss: 0.359139\n",
      "epoch 32; iter: 200; batch classifier loss: 0.565170\n",
      "epoch 33; iter: 0; batch classifier loss: 0.400149\n",
      "epoch 33; iter: 200; batch classifier loss: 0.424233\n",
      "epoch 34; iter: 0; batch classifier loss: 0.412936\n",
      "epoch 34; iter: 200; batch classifier loss: 0.434257\n",
      "epoch 35; iter: 0; batch classifier loss: 0.401007\n",
      "epoch 35; iter: 200; batch classifier loss: 0.485806\n",
      "epoch 36; iter: 0; batch classifier loss: 0.390464\n",
      "epoch 36; iter: 200; batch classifier loss: 0.505134\n",
      "epoch 37; iter: 0; batch classifier loss: 0.397652\n",
      "epoch 37; iter: 200; batch classifier loss: 0.465504\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451294\n",
      "epoch 38; iter: 200; batch classifier loss: 0.403384\n",
      "epoch 39; iter: 0; batch classifier loss: 0.389829\n",
      "epoch 39; iter: 200; batch classifier loss: 0.363333\n",
      "epoch 40; iter: 0; batch classifier loss: 0.490395\n",
      "epoch 40; iter: 200; batch classifier loss: 0.471113\n",
      "epoch 41; iter: 0; batch classifier loss: 0.348381\n",
      "epoch 41; iter: 200; batch classifier loss: 0.413004\n",
      "epoch 42; iter: 0; batch classifier loss: 0.376313\n",
      "epoch 42; iter: 200; batch classifier loss: 0.376552\n",
      "epoch 43; iter: 0; batch classifier loss: 0.375029\n",
      "epoch 43; iter: 200; batch classifier loss: 0.367584\n",
      "epoch 44; iter: 0; batch classifier loss: 0.386937\n",
      "epoch 44; iter: 200; batch classifier loss: 0.424584\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463829\n",
      "epoch 45; iter: 200; batch classifier loss: 0.464631\n",
      "epoch 46; iter: 0; batch classifier loss: 0.428543\n",
      "epoch 46; iter: 200; batch classifier loss: 0.329967\n",
      "epoch 47; iter: 0; batch classifier loss: 0.393921\n",
      "epoch 47; iter: 200; batch classifier loss: 0.382034\n",
      "epoch 48; iter: 0; batch classifier loss: 0.409947\n",
      "epoch 48; iter: 200; batch classifier loss: 0.355377\n",
      "epoch 49; iter: 0; batch classifier loss: 0.428495\n",
      "epoch 49; iter: 200; batch classifier loss: 0.451138\n",
      "run = 3\n",
      "epoch 0; iter: 0; batch classifier loss: 0.753950; batch adversarial loss: 0.515155\n",
      "epoch 0; iter: 200; batch classifier loss: 0.373085; batch adversarial loss: 0.621309\n",
      "epoch 0; iter: 400; batch classifier loss: 0.556544; batch adversarial loss: 0.594326\n",
      "epoch 0; iter: 600; batch classifier loss: 0.340119; batch adversarial loss: 0.559163\n",
      "epoch 0; iter: 800; batch classifier loss: 0.400852; batch adversarial loss: 0.511874\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.511743; batch adversarial loss: 0.461861\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.467095; batch adversarial loss: 0.503597\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.435094; batch adversarial loss: 0.495777\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.424335; batch adversarial loss: 0.461940\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.520732; batch adversarial loss: 0.419164\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.437299; batch adversarial loss: 0.419334\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.418456; batch adversarial loss: 0.417450\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.373673; batch adversarial loss: 0.438748\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.447160; batch adversarial loss: 0.339061\n",
      "epoch 1; iter: 0; batch classifier loss: 0.402700; batch adversarial loss: 0.579755\n",
      "epoch 1; iter: 200; batch classifier loss: 0.425604; batch adversarial loss: 0.359859\n",
      "epoch 1; iter: 400; batch classifier loss: 0.450316; batch adversarial loss: 0.370245\n",
      "epoch 1; iter: 600; batch classifier loss: 0.448825; batch adversarial loss: 0.472473\n",
      "epoch 1; iter: 800; batch classifier loss: 0.427549; batch adversarial loss: 0.394032\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.430218; batch adversarial loss: 0.472937\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.454907; batch adversarial loss: 0.314237\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.489500; batch adversarial loss: 0.420495\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.356240; batch adversarial loss: 0.446636\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.432626; batch adversarial loss: 0.462053\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.463322; batch adversarial loss: 0.430861\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.360372; batch adversarial loss: 0.435027\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.454292; batch adversarial loss: 0.566020\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.342096; batch adversarial loss: 0.447289\n",
      "epoch 2; iter: 0; batch classifier loss: 0.433741; batch adversarial loss: 0.488538\n",
      "epoch 2; iter: 200; batch classifier loss: 0.482010; batch adversarial loss: 0.459561\n",
      "epoch 2; iter: 400; batch classifier loss: 0.334878; batch adversarial loss: 0.474692\n",
      "epoch 2; iter: 600; batch classifier loss: 0.430252; batch adversarial loss: 0.391039\n",
      "epoch 2; iter: 800; batch classifier loss: 0.441810; batch adversarial loss: 0.392822\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.434025; batch adversarial loss: 0.488828\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.397822; batch adversarial loss: 0.435279\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.484734; batch adversarial loss: 0.491394\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.411218; batch adversarial loss: 0.435059\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.383810; batch adversarial loss: 0.408510\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.404115; batch adversarial loss: 0.381380\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.438442; batch adversarial loss: 0.445935\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.423725; batch adversarial loss: 0.378424\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.440751; batch adversarial loss: 0.422348\n",
      "epoch 3; iter: 0; batch classifier loss: 0.424910; batch adversarial loss: 0.340121\n",
      "epoch 3; iter: 200; batch classifier loss: 0.335554; batch adversarial loss: 0.420020\n",
      "epoch 3; iter: 400; batch classifier loss: 0.403260; batch adversarial loss: 0.358277\n",
      "epoch 3; iter: 600; batch classifier loss: 0.464850; batch adversarial loss: 0.442826\n",
      "epoch 3; iter: 800; batch classifier loss: 0.422960; batch adversarial loss: 0.449374\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.406999; batch adversarial loss: 0.417137\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.417980; batch adversarial loss: 0.517867\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.448853; batch adversarial loss: 0.503308\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.466503; batch adversarial loss: 0.408427\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.332479; batch adversarial loss: 0.457870\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.350637; batch adversarial loss: 0.403183\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.358570; batch adversarial loss: 0.364116\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.378845; batch adversarial loss: 0.338126\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.439556; batch adversarial loss: 0.406729\n",
      "epoch 4; iter: 0; batch classifier loss: 0.476617; batch adversarial loss: 0.310676\n",
      "epoch 4; iter: 200; batch classifier loss: 0.467352; batch adversarial loss: 0.422629\n",
      "epoch 4; iter: 400; batch classifier loss: 0.372591; batch adversarial loss: 0.458323\n",
      "epoch 4; iter: 600; batch classifier loss: 0.429875; batch adversarial loss: 0.420589\n",
      "epoch 4; iter: 800; batch classifier loss: 0.381474; batch adversarial loss: 0.362150\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.400305; batch adversarial loss: 0.472113\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.473595; batch adversarial loss: 0.431634\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.410658; batch adversarial loss: 0.406115\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.410431; batch adversarial loss: 0.351663\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.440030; batch adversarial loss: 0.323947\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.405974; batch adversarial loss: 0.515870\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.438557; batch adversarial loss: 0.409265\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.419041; batch adversarial loss: 0.419245\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.390459; batch adversarial loss: 0.367209\n",
      "epoch 5; iter: 0; batch classifier loss: 0.430178; batch adversarial loss: 0.512731\n",
      "epoch 5; iter: 200; batch classifier loss: 0.440306; batch adversarial loss: 0.379058\n",
      "epoch 5; iter: 400; batch classifier loss: 0.437793; batch adversarial loss: 0.339282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 600; batch classifier loss: 0.377155; batch adversarial loss: 0.442776\n",
      "epoch 5; iter: 800; batch classifier loss: 0.488111; batch adversarial loss: 0.447237\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.371206; batch adversarial loss: 0.402126\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.438261; batch adversarial loss: 0.505179\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.465173; batch adversarial loss: 0.374086\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.340159; batch adversarial loss: 0.428761\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.456562; batch adversarial loss: 0.416516\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.395022; batch adversarial loss: 0.269494\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.456175; batch adversarial loss: 0.532168\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.417410; batch adversarial loss: 0.448356\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.411200; batch adversarial loss: 0.393194\n",
      "epoch 6; iter: 0; batch classifier loss: 0.434122; batch adversarial loss: 0.393168\n",
      "epoch 6; iter: 200; batch classifier loss: 0.433785; batch adversarial loss: 0.323112\n",
      "epoch 6; iter: 400; batch classifier loss: 0.368642; batch adversarial loss: 0.459205\n",
      "epoch 6; iter: 600; batch classifier loss: 0.315115; batch adversarial loss: 0.471110\n",
      "epoch 6; iter: 800; batch classifier loss: 0.396244; batch adversarial loss: 0.459783\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.417461; batch adversarial loss: 0.447459\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.426488; batch adversarial loss: 0.392679\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.436981; batch adversarial loss: 0.447170\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.406566; batch adversarial loss: 0.353843\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.319073; batch adversarial loss: 0.418764\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.415930; batch adversarial loss: 0.443323\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.451464; batch adversarial loss: 0.555657\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.412605; batch adversarial loss: 0.461153\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.364598; batch adversarial loss: 0.351231\n",
      "epoch 7; iter: 0; batch classifier loss: 0.418100; batch adversarial loss: 0.376904\n",
      "epoch 7; iter: 200; batch classifier loss: 0.402296; batch adversarial loss: 0.445853\n",
      "epoch 7; iter: 400; batch classifier loss: 0.436907; batch adversarial loss: 0.338738\n",
      "epoch 7; iter: 600; batch classifier loss: 0.389978; batch adversarial loss: 0.448872\n",
      "epoch 7; iter: 800; batch classifier loss: 0.459049; batch adversarial loss: 0.415817\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.367868; batch adversarial loss: 0.375949\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.444016; batch adversarial loss: 0.391796\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.393902; batch adversarial loss: 0.470504\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.394072; batch adversarial loss: 0.436188\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.425842; batch adversarial loss: 0.460616\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.339947; batch adversarial loss: 0.390350\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.422830; batch adversarial loss: 0.445641\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.351499; batch adversarial loss: 0.351655\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.448316; batch adversarial loss: 0.435054\n",
      "epoch 8; iter: 0; batch classifier loss: 0.325379; batch adversarial loss: 0.390247\n",
      "epoch 8; iter: 200; batch classifier loss: 0.412141; batch adversarial loss: 0.420001\n",
      "epoch 8; iter: 400; batch classifier loss: 0.382322; batch adversarial loss: 0.394915\n",
      "epoch 8; iter: 600; batch classifier loss: 0.371281; batch adversarial loss: 0.337101\n",
      "epoch 8; iter: 800; batch classifier loss: 0.343424; batch adversarial loss: 0.529692\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.364011; batch adversarial loss: 0.502911\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.447695; batch adversarial loss: 0.554322\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.421236; batch adversarial loss: 0.461850\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.380734; batch adversarial loss: 0.475827\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.409418; batch adversarial loss: 0.380313\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.421388; batch adversarial loss: 0.446352\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.448691; batch adversarial loss: 0.460227\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.464659; batch adversarial loss: 0.460633\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.379711; batch adversarial loss: 0.450085\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488260; batch adversarial loss: 0.462632\n",
      "epoch 9; iter: 200; batch classifier loss: 0.439379; batch adversarial loss: 0.460717\n",
      "epoch 9; iter: 400; batch classifier loss: 0.317223; batch adversarial loss: 0.405013\n",
      "epoch 9; iter: 600; batch classifier loss: 0.409696; batch adversarial loss: 0.434102\n",
      "epoch 9; iter: 800; batch classifier loss: 0.395914; batch adversarial loss: 0.420909\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.425643; batch adversarial loss: 0.511524\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.450385; batch adversarial loss: 0.447470\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.458779; batch adversarial loss: 0.393450\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.405589; batch adversarial loss: 0.338252\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.439214; batch adversarial loss: 0.536954\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.337827; batch adversarial loss: 0.363272\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.442601; batch adversarial loss: 0.434398\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.461054; batch adversarial loss: 0.449903\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.373529; batch adversarial loss: 0.418316\n",
      "epoch 10; iter: 0; batch classifier loss: 0.436852; batch adversarial loss: 0.405866\n",
      "epoch 10; iter: 200; batch classifier loss: 0.379161; batch adversarial loss: 0.486960\n",
      "epoch 10; iter: 400; batch classifier loss: 0.520014; batch adversarial loss: 0.472467\n",
      "epoch 10; iter: 600; batch classifier loss: 0.477205; batch adversarial loss: 0.419588\n",
      "epoch 10; iter: 800; batch classifier loss: 0.293244; batch adversarial loss: 0.366173\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.430586; batch adversarial loss: 0.378071\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.332216; batch adversarial loss: 0.377628\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.366035; batch adversarial loss: 0.434618\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.445912; batch adversarial loss: 0.390001\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.395306; batch adversarial loss: 0.408119\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.439936; batch adversarial loss: 0.447008\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.462806; batch adversarial loss: 0.433826\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.433517; batch adversarial loss: 0.434855\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.415891; batch adversarial loss: 0.461154\n",
      "epoch 11; iter: 0; batch classifier loss: 0.429736; batch adversarial loss: 0.353136\n",
      "epoch 11; iter: 200; batch classifier loss: 0.379917; batch adversarial loss: 0.459058\n",
      "epoch 11; iter: 400; batch classifier loss: 0.410664; batch adversarial loss: 0.404127\n",
      "epoch 11; iter: 600; batch classifier loss: 0.409957; batch adversarial loss: 0.350078\n",
      "epoch 11; iter: 800; batch classifier loss: 0.411063; batch adversarial loss: 0.420253\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.416550; batch adversarial loss: 0.557952\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.357251; batch adversarial loss: 0.336281\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.499046; batch adversarial loss: 0.378703\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.440221; batch adversarial loss: 0.417895\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.376869; batch adversarial loss: 0.448527\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.431715; batch adversarial loss: 0.376489\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.397302; batch adversarial loss: 0.431006\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.403343; batch adversarial loss: 0.405045\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.362477; batch adversarial loss: 0.458341\n",
      "epoch 12; iter: 0; batch classifier loss: 0.402708; batch adversarial loss: 0.436333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 200; batch classifier loss: 0.416237; batch adversarial loss: 0.391716\n",
      "epoch 12; iter: 400; batch classifier loss: 0.393439; batch adversarial loss: 0.406985\n",
      "epoch 12; iter: 600; batch classifier loss: 0.380233; batch adversarial loss: 0.491943\n",
      "epoch 12; iter: 800; batch classifier loss: 0.378112; batch adversarial loss: 0.407745\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.438619; batch adversarial loss: 0.417456\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.409249; batch adversarial loss: 0.325177\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.313488; batch adversarial loss: 0.403802\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.402834; batch adversarial loss: 0.543067\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.350365; batch adversarial loss: 0.419865\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.426412; batch adversarial loss: 0.404506\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.451980; batch adversarial loss: 0.471244\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.465049; batch adversarial loss: 0.441532\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.402775; batch adversarial loss: 0.474757\n",
      "epoch 13; iter: 0; batch classifier loss: 0.293387; batch adversarial loss: 0.379886\n",
      "epoch 13; iter: 200; batch classifier loss: 0.445503; batch adversarial loss: 0.463140\n",
      "epoch 13; iter: 400; batch classifier loss: 0.398255; batch adversarial loss: 0.365995\n",
      "epoch 13; iter: 600; batch classifier loss: 0.508710; batch adversarial loss: 0.432772\n",
      "epoch 13; iter: 800; batch classifier loss: 0.378083; batch adversarial loss: 0.446806\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.370562; batch adversarial loss: 0.447111\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.368756; batch adversarial loss: 0.527806\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.318507; batch adversarial loss: 0.298721\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.367377; batch adversarial loss: 0.408613\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.410958; batch adversarial loss: 0.391707\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.454711; batch adversarial loss: 0.447930\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.444479; batch adversarial loss: 0.417870\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.366490; batch adversarial loss: 0.406852\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.420553; batch adversarial loss: 0.364126\n",
      "epoch 14; iter: 0; batch classifier loss: 0.427723; batch adversarial loss: 0.379640\n",
      "epoch 14; iter: 200; batch classifier loss: 0.399418; batch adversarial loss: 0.421876\n",
      "epoch 14; iter: 400; batch classifier loss: 0.425565; batch adversarial loss: 0.503209\n",
      "epoch 14; iter: 600; batch classifier loss: 0.360162; batch adversarial loss: 0.434289\n",
      "epoch 14; iter: 800; batch classifier loss: 0.457179; batch adversarial loss: 0.417432\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.438582; batch adversarial loss: 0.350309\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.482060; batch adversarial loss: 0.392093\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.386569; batch adversarial loss: 0.433565\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.396945; batch adversarial loss: 0.420060\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.403365; batch adversarial loss: 0.325196\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.367141; batch adversarial loss: 0.377433\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.467334; batch adversarial loss: 0.390570\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.486181; batch adversarial loss: 0.515449\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.437893; batch adversarial loss: 0.422318\n",
      "epoch 15; iter: 0; batch classifier loss: 0.383937; batch adversarial loss: 0.363907\n",
      "epoch 15; iter: 200; batch classifier loss: 0.420738; batch adversarial loss: 0.406946\n",
      "epoch 15; iter: 400; batch classifier loss: 0.449398; batch adversarial loss: 0.407014\n",
      "epoch 15; iter: 600; batch classifier loss: 0.320182; batch adversarial loss: 0.394078\n",
      "epoch 15; iter: 800; batch classifier loss: 0.435772; batch adversarial loss: 0.489370\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.433293; batch adversarial loss: 0.431234\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.468797; batch adversarial loss: 0.392107\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.371518; batch adversarial loss: 0.378645\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.390607; batch adversarial loss: 0.446007\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.517951; batch adversarial loss: 0.460875\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.502165; batch adversarial loss: 0.404693\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.471404; batch adversarial loss: 0.462853\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.442008; batch adversarial loss: 0.434246\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.359849; batch adversarial loss: 0.391030\n",
      "epoch 16; iter: 0; batch classifier loss: 0.392027; batch adversarial loss: 0.447872\n",
      "epoch 16; iter: 200; batch classifier loss: 0.336251; batch adversarial loss: 0.338812\n",
      "epoch 16; iter: 400; batch classifier loss: 0.331176; batch adversarial loss: 0.514541\n",
      "epoch 16; iter: 600; batch classifier loss: 0.397356; batch adversarial loss: 0.366456\n",
      "epoch 16; iter: 800; batch classifier loss: 0.458696; batch adversarial loss: 0.445814\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.314073; batch adversarial loss: 0.419998\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.375400; batch adversarial loss: 0.352035\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.446069; batch adversarial loss: 0.393157\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.463527; batch adversarial loss: 0.446164\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.438544; batch adversarial loss: 0.420379\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.354709; batch adversarial loss: 0.338142\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.444374; batch adversarial loss: 0.485093\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.399037; batch adversarial loss: 0.460992\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.392278; batch adversarial loss: 0.446519\n",
      "epoch 17; iter: 0; batch classifier loss: 0.440070; batch adversarial loss: 0.419695\n",
      "epoch 17; iter: 200; batch classifier loss: 0.336790; batch adversarial loss: 0.459915\n",
      "epoch 17; iter: 400; batch classifier loss: 0.352677; batch adversarial loss: 0.339104\n",
      "epoch 17; iter: 600; batch classifier loss: 0.429423; batch adversarial loss: 0.393203\n",
      "epoch 17; iter: 800; batch classifier loss: 0.485805; batch adversarial loss: 0.390765\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.419249; batch adversarial loss: 0.407156\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.453937; batch adversarial loss: 0.406013\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.439173; batch adversarial loss: 0.376994\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.383950; batch adversarial loss: 0.462498\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.469088; batch adversarial loss: 0.393415\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.357053; batch adversarial loss: 0.367674\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.421145; batch adversarial loss: 0.408312\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.449359; batch adversarial loss: 0.408778\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.414934; batch adversarial loss: 0.515525\n",
      "epoch 18; iter: 0; batch classifier loss: 0.423209; batch adversarial loss: 0.445371\n",
      "epoch 18; iter: 200; batch classifier loss: 0.352609; batch adversarial loss: 0.366364\n",
      "epoch 18; iter: 400; batch classifier loss: 0.388104; batch adversarial loss: 0.323018\n",
      "epoch 18; iter: 600; batch classifier loss: 0.486512; batch adversarial loss: 0.395853\n",
      "epoch 18; iter: 800; batch classifier loss: 0.408392; batch adversarial loss: 0.485632\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.531985; batch adversarial loss: 0.377435\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.420511; batch adversarial loss: 0.367818\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.407900; batch adversarial loss: 0.296482\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.399780; batch adversarial loss: 0.461617\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.381226; batch adversarial loss: 0.379892\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.457398; batch adversarial loss: 0.419612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18; iter: 2200; batch classifier loss: 0.432849; batch adversarial loss: 0.420246\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.508213; batch adversarial loss: 0.391269\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.387524; batch adversarial loss: 0.460447\n",
      "epoch 19; iter: 0; batch classifier loss: 0.375805; batch adversarial loss: 0.460937\n",
      "epoch 19; iter: 200; batch classifier loss: 0.413545; batch adversarial loss: 0.365480\n",
      "epoch 19; iter: 400; batch classifier loss: 0.391936; batch adversarial loss: 0.447179\n",
      "epoch 19; iter: 600; batch classifier loss: 0.460003; batch adversarial loss: 0.417659\n",
      "epoch 19; iter: 800; batch classifier loss: 0.413381; batch adversarial loss: 0.473152\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.463457; batch adversarial loss: 0.474700\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.446955; batch adversarial loss: 0.351215\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.472570; batch adversarial loss: 0.487404\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.396100; batch adversarial loss: 0.516723\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.373172; batch adversarial loss: 0.473203\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.381367; batch adversarial loss: 0.404365\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.389372; batch adversarial loss: 0.526342\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.524075; batch adversarial loss: 0.489174\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.399702; batch adversarial loss: 0.474984\n",
      "epoch 20; iter: 0; batch classifier loss: 0.447062; batch adversarial loss: 0.364927\n",
      "epoch 20; iter: 200; batch classifier loss: 0.459097; batch adversarial loss: 0.377980\n",
      "epoch 20; iter: 400; batch classifier loss: 0.469551; batch adversarial loss: 0.433103\n",
      "epoch 20; iter: 600; batch classifier loss: 0.421638; batch adversarial loss: 0.472728\n",
      "epoch 20; iter: 800; batch classifier loss: 0.417944; batch adversarial loss: 0.378736\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.423829; batch adversarial loss: 0.351112\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.353977; batch adversarial loss: 0.351452\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.425829; batch adversarial loss: 0.391888\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.467266; batch adversarial loss: 0.406809\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.409332; batch adversarial loss: 0.378450\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.390459; batch adversarial loss: 0.323200\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.410160; batch adversarial loss: 0.421163\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.443048; batch adversarial loss: 0.459508\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.337954; batch adversarial loss: 0.416309\n",
      "epoch 21; iter: 0; batch classifier loss: 0.424998; batch adversarial loss: 0.528328\n",
      "epoch 21; iter: 200; batch classifier loss: 0.416652; batch adversarial loss: 0.476164\n",
      "epoch 21; iter: 400; batch classifier loss: 0.374351; batch adversarial loss: 0.403881\n",
      "epoch 21; iter: 600; batch classifier loss: 0.393180; batch adversarial loss: 0.377060\n",
      "epoch 21; iter: 800; batch classifier loss: 0.369993; batch adversarial loss: 0.436786\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.338769; batch adversarial loss: 0.380160\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.437677; batch adversarial loss: 0.353199\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.409663; batch adversarial loss: 0.488535\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.483200; batch adversarial loss: 0.473490\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.405681; batch adversarial loss: 0.448352\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.449608; batch adversarial loss: 0.461854\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.439918; batch adversarial loss: 0.432950\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.381682; batch adversarial loss: 0.449516\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.434699; batch adversarial loss: 0.378332\n",
      "epoch 22; iter: 0; batch classifier loss: 0.362307; batch adversarial loss: 0.404950\n",
      "epoch 22; iter: 200; batch classifier loss: 0.398814; batch adversarial loss: 0.391739\n",
      "epoch 22; iter: 400; batch classifier loss: 0.345629; batch adversarial loss: 0.392883\n",
      "epoch 22; iter: 600; batch classifier loss: 0.386651; batch adversarial loss: 0.353794\n",
      "epoch 22; iter: 800; batch classifier loss: 0.465685; batch adversarial loss: 0.419146\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.390125; batch adversarial loss: 0.445562\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.406520; batch adversarial loss: 0.457359\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.437292; batch adversarial loss: 0.474647\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.383057; batch adversarial loss: 0.463742\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.375006; batch adversarial loss: 0.404164\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.398857; batch adversarial loss: 0.406182\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.481650; batch adversarial loss: 0.420054\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.538705; batch adversarial loss: 0.515508\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.414548; batch adversarial loss: 0.337213\n",
      "epoch 23; iter: 0; batch classifier loss: 0.368932; batch adversarial loss: 0.408742\n",
      "epoch 23; iter: 200; batch classifier loss: 0.374361; batch adversarial loss: 0.462541\n",
      "epoch 23; iter: 400; batch classifier loss: 0.475187; batch adversarial loss: 0.421670\n",
      "epoch 23; iter: 600; batch classifier loss: 0.404692; batch adversarial loss: 0.352347\n",
      "epoch 23; iter: 800; batch classifier loss: 0.344488; batch adversarial loss: 0.380763\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.424086; batch adversarial loss: 0.432505\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.449366; batch adversarial loss: 0.379281\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.413684; batch adversarial loss: 0.338773\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.424649; batch adversarial loss: 0.363927\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.500528; batch adversarial loss: 0.351746\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.436440; batch adversarial loss: 0.406771\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.428626; batch adversarial loss: 0.380065\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.450145; batch adversarial loss: 0.445829\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.418969; batch adversarial loss: 0.405629\n",
      "epoch 24; iter: 0; batch classifier loss: 0.428718; batch adversarial loss: 0.433059\n",
      "epoch 24; iter: 200; batch classifier loss: 0.385979; batch adversarial loss: 0.377948\n",
      "epoch 24; iter: 400; batch classifier loss: 0.455230; batch adversarial loss: 0.432639\n",
      "epoch 24; iter: 600; batch classifier loss: 0.446382; batch adversarial loss: 0.459519\n",
      "epoch 24; iter: 800; batch classifier loss: 0.380004; batch adversarial loss: 0.462914\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.389182; batch adversarial loss: 0.491563\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.448475; batch adversarial loss: 0.392012\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.441708; batch adversarial loss: 0.420503\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.500676; batch adversarial loss: 0.484767\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.384805; batch adversarial loss: 0.390842\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.457095; batch adversarial loss: 0.420274\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.339399; batch adversarial loss: 0.434118\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.393848; batch adversarial loss: 0.487019\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.482199; batch adversarial loss: 0.376387\n",
      "epoch 25; iter: 0; batch classifier loss: 0.482136; batch adversarial loss: 0.444796\n",
      "epoch 25; iter: 200; batch classifier loss: 0.455120; batch adversarial loss: 0.377888\n",
      "epoch 25; iter: 400; batch classifier loss: 0.388349; batch adversarial loss: 0.435119\n",
      "epoch 25; iter: 600; batch classifier loss: 0.370197; batch adversarial loss: 0.404474\n",
      "epoch 25; iter: 800; batch classifier loss: 0.417577; batch adversarial loss: 0.448397\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.397039; batch adversarial loss: 0.392028\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.342893; batch adversarial loss: 0.390931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25; iter: 1400; batch classifier loss: 0.460447; batch adversarial loss: 0.383220\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.407855; batch adversarial loss: 0.408798\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.388620; batch adversarial loss: 0.445923\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.393270; batch adversarial loss: 0.393017\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.390581; batch adversarial loss: 0.447003\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.396169; batch adversarial loss: 0.476361\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.419784; batch adversarial loss: 0.514955\n",
      "epoch 26; iter: 0; batch classifier loss: 0.424466; batch adversarial loss: 0.432351\n",
      "epoch 26; iter: 200; batch classifier loss: 0.425616; batch adversarial loss: 0.351897\n",
      "epoch 26; iter: 400; batch classifier loss: 0.476040; batch adversarial loss: 0.393994\n",
      "epoch 26; iter: 600; batch classifier loss: 0.424281; batch adversarial loss: 0.404426\n",
      "epoch 26; iter: 800; batch classifier loss: 0.394328; batch adversarial loss: 0.432066\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.409756; batch adversarial loss: 0.404225\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.358878; batch adversarial loss: 0.420091\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.381480; batch adversarial loss: 0.463058\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.441100; batch adversarial loss: 0.351108\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.472857; batch adversarial loss: 0.389170\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.408810; batch adversarial loss: 0.407499\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.451162; batch adversarial loss: 0.419715\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.516863; batch adversarial loss: 0.348400\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.444219; batch adversarial loss: 0.460202\n",
      "epoch 27; iter: 0; batch classifier loss: 0.389546; batch adversarial loss: 0.461513\n",
      "epoch 27; iter: 200; batch classifier loss: 0.394555; batch adversarial loss: 0.432462\n",
      "epoch 27; iter: 400; batch classifier loss: 0.434932; batch adversarial loss: 0.361214\n",
      "epoch 27; iter: 600; batch classifier loss: 0.395988; batch adversarial loss: 0.322614\n",
      "epoch 27; iter: 800; batch classifier loss: 0.343769; batch adversarial loss: 0.394088\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.423971; batch adversarial loss: 0.459752\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.460473; batch adversarial loss: 0.488052\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.367644; batch adversarial loss: 0.379477\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.473486; batch adversarial loss: 0.419813\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.469906; batch adversarial loss: 0.420149\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.440096; batch adversarial loss: 0.403778\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.426935; batch adversarial loss: 0.416979\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.472802; batch adversarial loss: 0.487105\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.294024; batch adversarial loss: 0.418560\n",
      "epoch 28; iter: 0; batch classifier loss: 0.362160; batch adversarial loss: 0.429267\n",
      "epoch 28; iter: 200; batch classifier loss: 0.316220; batch adversarial loss: 0.393650\n",
      "epoch 28; iter: 400; batch classifier loss: 0.420585; batch adversarial loss: 0.448628\n",
      "epoch 28; iter: 600; batch classifier loss: 0.356617; batch adversarial loss: 0.447525\n",
      "epoch 28; iter: 800; batch classifier loss: 0.414652; batch adversarial loss: 0.462938\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.353196; batch adversarial loss: 0.415997\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.379735; batch adversarial loss: 0.392068\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.403771; batch adversarial loss: 0.502366\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.374244; batch adversarial loss: 0.350953\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.353006; batch adversarial loss: 0.308677\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.369631; batch adversarial loss: 0.353479\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.427591; batch adversarial loss: 0.484352\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.398097; batch adversarial loss: 0.338848\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.463568; batch adversarial loss: 0.421074\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456886; batch adversarial loss: 0.363310\n",
      "epoch 29; iter: 200; batch classifier loss: 0.373450; batch adversarial loss: 0.395117\n",
      "epoch 29; iter: 400; batch classifier loss: 0.462233; batch adversarial loss: 0.564916\n",
      "epoch 29; iter: 600; batch classifier loss: 0.427427; batch adversarial loss: 0.487196\n",
      "epoch 29; iter: 800; batch classifier loss: 0.376598; batch adversarial loss: 0.447547\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.477585; batch adversarial loss: 0.394417\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.398062; batch adversarial loss: 0.419047\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.423950; batch adversarial loss: 0.528606\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.409968; batch adversarial loss: 0.433029\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.418636; batch adversarial loss: 0.366789\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.387667; batch adversarial loss: 0.363440\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.412293; batch adversarial loss: 0.391482\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.289522; batch adversarial loss: 0.354254\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.408463; batch adversarial loss: 0.419593\n",
      "epoch 30; iter: 0; batch classifier loss: 0.418258; batch adversarial loss: 0.489577\n",
      "epoch 30; iter: 200; batch classifier loss: 0.343883; batch adversarial loss: 0.486750\n",
      "epoch 30; iter: 400; batch classifier loss: 0.422132; batch adversarial loss: 0.462384\n",
      "epoch 30; iter: 600; batch classifier loss: 0.368544; batch adversarial loss: 0.351269\n",
      "epoch 30; iter: 800; batch classifier loss: 0.415009; batch adversarial loss: 0.476850\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.434224; batch adversarial loss: 0.407707\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.489555; batch adversarial loss: 0.381539\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.488769; batch adversarial loss: 0.434823\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.484260; batch adversarial loss: 0.460439\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.506486; batch adversarial loss: 0.405881\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.508319; batch adversarial loss: 0.447443\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.429493; batch adversarial loss: 0.418424\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.380142; batch adversarial loss: 0.461655\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.422303; batch adversarial loss: 0.458961\n",
      "epoch 31; iter: 0; batch classifier loss: 0.417684; batch adversarial loss: 0.446808\n",
      "epoch 31; iter: 200; batch classifier loss: 0.367462; batch adversarial loss: 0.405440\n",
      "epoch 31; iter: 400; batch classifier loss: 0.398250; batch adversarial loss: 0.378803\n",
      "epoch 31; iter: 600; batch classifier loss: 0.379442; batch adversarial loss: 0.433276\n",
      "epoch 31; iter: 800; batch classifier loss: 0.364851; batch adversarial loss: 0.419418\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.342308; batch adversarial loss: 0.393260\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.421588; batch adversarial loss: 0.484286\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.428817; batch adversarial loss: 0.540853\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.399355; batch adversarial loss: 0.421198\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.407839; batch adversarial loss: 0.296355\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.390510; batch adversarial loss: 0.515502\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.478396; batch adversarial loss: 0.404541\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.398421; batch adversarial loss: 0.434136\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.294302; batch adversarial loss: 0.473798\n",
      "epoch 32; iter: 0; batch classifier loss: 0.435790; batch adversarial loss: 0.393555\n",
      "epoch 32; iter: 200; batch classifier loss: 0.532895; batch adversarial loss: 0.449343\n",
      "epoch 32; iter: 400; batch classifier loss: 0.451727; batch adversarial loss: 0.337763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 600; batch classifier loss: 0.380075; batch adversarial loss: 0.450340\n",
      "epoch 32; iter: 800; batch classifier loss: 0.427409; batch adversarial loss: 0.325672\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.513952; batch adversarial loss: 0.380221\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.478052; batch adversarial loss: 0.489099\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.319439; batch adversarial loss: 0.607140\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.425619; batch adversarial loss: 0.433867\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.512720; batch adversarial loss: 0.338466\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.429948; batch adversarial loss: 0.477033\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.371120; batch adversarial loss: 0.337909\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.446092; batch adversarial loss: 0.419447\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.397830; batch adversarial loss: 0.337394\n",
      "epoch 33; iter: 0; batch classifier loss: 0.481016; batch adversarial loss: 0.461377\n",
      "epoch 33; iter: 200; batch classifier loss: 0.411570; batch adversarial loss: 0.351861\n",
      "epoch 33; iter: 400; batch classifier loss: 0.409428; batch adversarial loss: 0.407140\n",
      "epoch 33; iter: 600; batch classifier loss: 0.444181; batch adversarial loss: 0.487664\n",
      "epoch 33; iter: 800; batch classifier loss: 0.466052; batch adversarial loss: 0.463691\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.406152; batch adversarial loss: 0.526623\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.426605; batch adversarial loss: 0.378763\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.388519; batch adversarial loss: 0.362627\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.366048; batch adversarial loss: 0.460753\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.467481; batch adversarial loss: 0.394274\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.397054; batch adversarial loss: 0.461482\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.376134; batch adversarial loss: 0.405553\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.370046; batch adversarial loss: 0.364762\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.434525; batch adversarial loss: 0.452661\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429009; batch adversarial loss: 0.364570\n",
      "epoch 34; iter: 200; batch classifier loss: 0.457980; batch adversarial loss: 0.446209\n",
      "epoch 34; iter: 400; batch classifier loss: 0.406186; batch adversarial loss: 0.352382\n",
      "epoch 34; iter: 600; batch classifier loss: 0.411446; batch adversarial loss: 0.462625\n",
      "epoch 34; iter: 800; batch classifier loss: 0.457826; batch adversarial loss: 0.489549\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.475629; batch adversarial loss: 0.502130\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.407472; batch adversarial loss: 0.460328\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.399407; batch adversarial loss: 0.429899\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.389605; batch adversarial loss: 0.392332\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.432413; batch adversarial loss: 0.433978\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.378101; batch adversarial loss: 0.444754\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.434682; batch adversarial loss: 0.419388\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.433540; batch adversarial loss: 0.446819\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.411196; batch adversarial loss: 0.422605\n",
      "epoch 35; iter: 0; batch classifier loss: 0.410060; batch adversarial loss: 0.460503\n",
      "epoch 35; iter: 200; batch classifier loss: 0.451688; batch adversarial loss: 0.396184\n",
      "epoch 35; iter: 400; batch classifier loss: 0.407000; batch adversarial loss: 0.435202\n",
      "epoch 35; iter: 600; batch classifier loss: 0.512269; batch adversarial loss: 0.434689\n",
      "epoch 35; iter: 800; batch classifier loss: 0.454314; batch adversarial loss: 0.379847\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.505726; batch adversarial loss: 0.378795\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.410439; batch adversarial loss: 0.500490\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.418548; batch adversarial loss: 0.432835\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.329857; batch adversarial loss: 0.544608\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.419597; batch adversarial loss: 0.337801\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.446138; batch adversarial loss: 0.418083\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.439747; batch adversarial loss: 0.460855\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.420848; batch adversarial loss: 0.421602\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.471949; batch adversarial loss: 0.513790\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424264; batch adversarial loss: 0.474108\n",
      "epoch 36; iter: 200; batch classifier loss: 0.477237; batch adversarial loss: 0.477396\n",
      "epoch 36; iter: 400; batch classifier loss: 0.411114; batch adversarial loss: 0.473446\n",
      "epoch 36; iter: 600; batch classifier loss: 0.424917; batch adversarial loss: 0.393382\n",
      "epoch 36; iter: 800; batch classifier loss: 0.331234; batch adversarial loss: 0.407385\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.304844; batch adversarial loss: 0.408017\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.417440; batch adversarial loss: 0.405741\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.507750; batch adversarial loss: 0.458640\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.396145; batch adversarial loss: 0.446876\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.475256; batch adversarial loss: 0.391851\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.437938; batch adversarial loss: 0.338677\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.459811; batch adversarial loss: 0.499116\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.424415; batch adversarial loss: 0.349755\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.409457; batch adversarial loss: 0.405982\n",
      "epoch 37; iter: 0; batch classifier loss: 0.404225; batch adversarial loss: 0.407660\n",
      "epoch 37; iter: 200; batch classifier loss: 0.419508; batch adversarial loss: 0.512849\n",
      "epoch 37; iter: 400; batch classifier loss: 0.378041; batch adversarial loss: 0.433658\n",
      "epoch 37; iter: 600; batch classifier loss: 0.402614; batch adversarial loss: 0.419559\n",
      "epoch 37; iter: 800; batch classifier loss: 0.465644; batch adversarial loss: 0.363721\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.353678; batch adversarial loss: 0.337935\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.439710; batch adversarial loss: 0.458492\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.403640; batch adversarial loss: 0.474892\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.452123; batch adversarial loss: 0.393756\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.374433; batch adversarial loss: 0.378557\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.452486; batch adversarial loss: 0.446682\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.426393; batch adversarial loss: 0.556691\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.440921; batch adversarial loss: 0.391422\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.592071; batch adversarial loss: 0.435745\n",
      "epoch 38; iter: 0; batch classifier loss: 0.386842; batch adversarial loss: 0.417540\n",
      "epoch 38; iter: 200; batch classifier loss: 0.374852; batch adversarial loss: 0.393393\n",
      "epoch 38; iter: 400; batch classifier loss: 0.369676; batch adversarial loss: 0.350025\n",
      "epoch 38; iter: 600; batch classifier loss: 0.388179; batch adversarial loss: 0.498515\n",
      "epoch 38; iter: 800; batch classifier loss: 0.422144; batch adversarial loss: 0.391191\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.463590; batch adversarial loss: 0.406014\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.396117; batch adversarial loss: 0.363972\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.441636; batch adversarial loss: 0.270543\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.469806; batch adversarial loss: 0.473392\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.394589; batch adversarial loss: 0.379024\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.394869; batch adversarial loss: 0.393282\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.366987; batch adversarial loss: 0.462266\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.482596; batch adversarial loss: 0.364666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 2600; batch classifier loss: 0.314311; batch adversarial loss: 0.515258\n",
      "epoch 39; iter: 0; batch classifier loss: 0.385562; batch adversarial loss: 0.406953\n",
      "epoch 39; iter: 200; batch classifier loss: 0.400215; batch adversarial loss: 0.363825\n",
      "epoch 39; iter: 400; batch classifier loss: 0.420843; batch adversarial loss: 0.394244\n",
      "epoch 39; iter: 600; batch classifier loss: 0.476826; batch adversarial loss: 0.473773\n",
      "epoch 39; iter: 800; batch classifier loss: 0.424290; batch adversarial loss: 0.378239\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.313714; batch adversarial loss: 0.403526\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.425293; batch adversarial loss: 0.431152\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.499285; batch adversarial loss: 0.366037\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.384730; batch adversarial loss: 0.393335\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.381549; batch adversarial loss: 0.459737\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.472043; batch adversarial loss: 0.450268\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.407086; batch adversarial loss: 0.516506\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.523146; batch adversarial loss: 0.434524\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.372881; batch adversarial loss: 0.461437\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430421; batch adversarial loss: 0.390097\n",
      "epoch 40; iter: 200; batch classifier loss: 0.404394; batch adversarial loss: 0.393113\n",
      "epoch 40; iter: 400; batch classifier loss: 0.430099; batch adversarial loss: 0.310492\n",
      "epoch 40; iter: 600; batch classifier loss: 0.306635; batch adversarial loss: 0.448862\n",
      "epoch 40; iter: 800; batch classifier loss: 0.446156; batch adversarial loss: 0.557269\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.407941; batch adversarial loss: 0.474085\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.451753; batch adversarial loss: 0.353885\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.421704; batch adversarial loss: 0.377845\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.377883; batch adversarial loss: 0.447698\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.437725; batch adversarial loss: 0.352053\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.378902; batch adversarial loss: 0.418850\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.456667; batch adversarial loss: 0.338013\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.505029; batch adversarial loss: 0.407856\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.349207; batch adversarial loss: 0.406230\n",
      "epoch 41; iter: 0; batch classifier loss: 0.361068; batch adversarial loss: 0.462154\n",
      "epoch 41; iter: 200; batch classifier loss: 0.370930; batch adversarial loss: 0.349880\n",
      "epoch 41; iter: 400; batch classifier loss: 0.433383; batch adversarial loss: 0.420461\n",
      "epoch 41; iter: 600; batch classifier loss: 0.478177; batch adversarial loss: 0.432727\n",
      "epoch 41; iter: 800; batch classifier loss: 0.420068; batch adversarial loss: 0.405830\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.394521; batch adversarial loss: 0.407547\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.461015; batch adversarial loss: 0.405959\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.381134; batch adversarial loss: 0.434074\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.407460; batch adversarial loss: 0.296812\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.415015; batch adversarial loss: 0.350925\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.366745; batch adversarial loss: 0.336734\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.440611; batch adversarial loss: 0.447003\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.373310; batch adversarial loss: 0.433349\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.390826; batch adversarial loss: 0.529065\n",
      "epoch 42; iter: 0; batch classifier loss: 0.378454; batch adversarial loss: 0.324692\n",
      "epoch 42; iter: 200; batch classifier loss: 0.361382; batch adversarial loss: 0.408305\n",
      "epoch 42; iter: 400; batch classifier loss: 0.362021; batch adversarial loss: 0.491606\n",
      "epoch 42; iter: 600; batch classifier loss: 0.376691; batch adversarial loss: 0.475216\n",
      "epoch 42; iter: 800; batch classifier loss: 0.390152; batch adversarial loss: 0.377856\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.376924; batch adversarial loss: 0.365278\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.381147; batch adversarial loss: 0.418727\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.475242; batch adversarial loss: 0.446955\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.443133; batch adversarial loss: 0.432004\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.418535; batch adversarial loss: 0.366568\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.404062; batch adversarial loss: 0.434912\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.417344; batch adversarial loss: 0.351726\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.414066; batch adversarial loss: 0.338184\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.383258; batch adversarial loss: 0.475280\n",
      "epoch 43; iter: 0; batch classifier loss: 0.361518; batch adversarial loss: 0.381071\n",
      "epoch 43; iter: 200; batch classifier loss: 0.391852; batch adversarial loss: 0.431812\n",
      "epoch 43; iter: 400; batch classifier loss: 0.370697; batch adversarial loss: 0.377940\n",
      "epoch 43; iter: 600; batch classifier loss: 0.426636; batch adversarial loss: 0.323595\n",
      "epoch 43; iter: 800; batch classifier loss: 0.274530; batch adversarial loss: 0.451136\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.400405; batch adversarial loss: 0.405653\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.487872; batch adversarial loss: 0.418562\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.453913; batch adversarial loss: 0.421918\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.364786; batch adversarial loss: 0.502746\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.457512; batch adversarial loss: 0.353489\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.420630; batch adversarial loss: 0.283901\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.372417; batch adversarial loss: 0.446033\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.406197; batch adversarial loss: 0.392947\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.436019; batch adversarial loss: 0.488209\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410268; batch adversarial loss: 0.378615\n",
      "epoch 44; iter: 200; batch classifier loss: 0.383736; batch adversarial loss: 0.461143\n",
      "epoch 44; iter: 400; batch classifier loss: 0.504560; batch adversarial loss: 0.324615\n",
      "epoch 44; iter: 600; batch classifier loss: 0.466465; batch adversarial loss: 0.515723\n",
      "epoch 44; iter: 800; batch classifier loss: 0.387985; batch adversarial loss: 0.364311\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.478510; batch adversarial loss: 0.407812\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.443660; batch adversarial loss: 0.417723\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.385186; batch adversarial loss: 0.445385\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.398326; batch adversarial loss: 0.434568\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.355316; batch adversarial loss: 0.501712\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.448958; batch adversarial loss: 0.392834\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.441453; batch adversarial loss: 0.434132\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.360723; batch adversarial loss: 0.418055\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.451136; batch adversarial loss: 0.456866\n",
      "epoch 45; iter: 0; batch classifier loss: 0.401487; batch adversarial loss: 0.473982\n",
      "epoch 45; iter: 200; batch classifier loss: 0.408083; batch adversarial loss: 0.541090\n",
      "epoch 45; iter: 400; batch classifier loss: 0.451653; batch adversarial loss: 0.488266\n",
      "epoch 45; iter: 600; batch classifier loss: 0.467587; batch adversarial loss: 0.378876\n",
      "epoch 45; iter: 800; batch classifier loss: 0.475149; batch adversarial loss: 0.365877\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.423086; batch adversarial loss: 0.445627\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.400060; batch adversarial loss: 0.394586\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.451937; batch adversarial loss: 0.367715\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.454362; batch adversarial loss: 0.405823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 1800; batch classifier loss: 0.366460; batch adversarial loss: 0.449114\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.388336; batch adversarial loss: 0.377173\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.474661; batch adversarial loss: 0.364803\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.361386; batch adversarial loss: 0.518060\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.420352; batch adversarial loss: 0.515411\n",
      "epoch 46; iter: 0; batch classifier loss: 0.378779; batch adversarial loss: 0.462357\n",
      "epoch 46; iter: 200; batch classifier loss: 0.470394; batch adversarial loss: 0.500874\n",
      "epoch 46; iter: 400; batch classifier loss: 0.407314; batch adversarial loss: 0.404352\n",
      "epoch 46; iter: 600; batch classifier loss: 0.401625; batch adversarial loss: 0.463735\n",
      "epoch 46; iter: 800; batch classifier loss: 0.402244; batch adversarial loss: 0.339862\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.360595; batch adversarial loss: 0.569201\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.486904; batch adversarial loss: 0.309551\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.434667; batch adversarial loss: 0.416632\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.503221; batch adversarial loss: 0.475823\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.394737; batch adversarial loss: 0.362820\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.429338; batch adversarial loss: 0.446245\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.388673; batch adversarial loss: 0.407401\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.394282; batch adversarial loss: 0.403941\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.382711; batch adversarial loss: 0.487650\n",
      "epoch 47; iter: 0; batch classifier loss: 0.444000; batch adversarial loss: 0.460613\n",
      "epoch 47; iter: 200; batch classifier loss: 0.380163; batch adversarial loss: 0.338062\n",
      "epoch 47; iter: 400; batch classifier loss: 0.355402; batch adversarial loss: 0.473481\n",
      "epoch 47; iter: 600; batch classifier loss: 0.481299; batch adversarial loss: 0.500084\n",
      "epoch 47; iter: 800; batch classifier loss: 0.437760; batch adversarial loss: 0.488953\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.431369; batch adversarial loss: 0.490695\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.464882; batch adversarial loss: 0.391328\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.320960; batch adversarial loss: 0.271324\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.477110; batch adversarial loss: 0.406672\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.419262; batch adversarial loss: 0.529715\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.419976; batch adversarial loss: 0.420729\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.428946; batch adversarial loss: 0.490429\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.515383; batch adversarial loss: 0.406061\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.463649; batch adversarial loss: 0.462910\n",
      "epoch 48; iter: 0; batch classifier loss: 0.400640; batch adversarial loss: 0.516385\n",
      "epoch 48; iter: 200; batch classifier loss: 0.334775; batch adversarial loss: 0.462960\n",
      "epoch 48; iter: 400; batch classifier loss: 0.397434; batch adversarial loss: 0.364907\n",
      "epoch 48; iter: 600; batch classifier loss: 0.385065; batch adversarial loss: 0.447489\n",
      "epoch 48; iter: 800; batch classifier loss: 0.427017; batch adversarial loss: 0.379169\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.394475; batch adversarial loss: 0.406534\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.366414; batch adversarial loss: 0.483819\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.478858; batch adversarial loss: 0.518254\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.432032; batch adversarial loss: 0.407809\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.368721; batch adversarial loss: 0.486429\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.404769; batch adversarial loss: 0.380166\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.425342; batch adversarial loss: 0.460828\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.483679; batch adversarial loss: 0.446059\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.341033; batch adversarial loss: 0.365857\n",
      "epoch 49; iter: 0; batch classifier loss: 0.376099; batch adversarial loss: 0.461735\n",
      "epoch 49; iter: 200; batch classifier loss: 0.389608; batch adversarial loss: 0.445954\n",
      "epoch 49; iter: 400; batch classifier loss: 0.470572; batch adversarial loss: 0.394424\n",
      "epoch 49; iter: 600; batch classifier loss: 0.378851; batch adversarial loss: 0.336938\n",
      "epoch 49; iter: 800; batch classifier loss: 0.372562; batch adversarial loss: 0.368284\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.468633; batch adversarial loss: 0.404628\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.444793; batch adversarial loss: 0.489932\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.416220; batch adversarial loss: 0.393814\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.396429; batch adversarial loss: 0.394855\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.342808; batch adversarial loss: 0.422913\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.393408; batch adversarial loss: 0.435380\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.380773; batch adversarial loss: 0.541412\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.452920; batch adversarial loss: 0.475855\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.439212; batch adversarial loss: 0.447724\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722956\n",
      "epoch 0; iter: 200; batch classifier loss: 0.467339\n",
      "epoch 0; iter: 400; batch classifier loss: 0.559645\n",
      "epoch 0; iter: 600; batch classifier loss: 0.351296\n",
      "epoch 0; iter: 800; batch classifier loss: 0.404046\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.386479\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.426268\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.543794\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.408655\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.431081\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.337498\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.447407\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.362484\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.449730\n",
      "epoch 1; iter: 0; batch classifier loss: 0.311952\n",
      "epoch 1; iter: 200; batch classifier loss: 0.311708\n",
      "epoch 1; iter: 400; batch classifier loss: 0.424811\n",
      "epoch 1; iter: 600; batch classifier loss: 0.416503\n",
      "epoch 1; iter: 800; batch classifier loss: 0.505658\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.406459\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.429230\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.425534\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.365575\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.426106\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.391382\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.357197\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.353202\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.412479\n",
      "epoch 2; iter: 0; batch classifier loss: 0.376102\n",
      "epoch 2; iter: 200; batch classifier loss: 0.439811\n",
      "epoch 2; iter: 400; batch classifier loss: 0.431748\n",
      "epoch 2; iter: 600; batch classifier loss: 0.474830\n",
      "epoch 2; iter: 800; batch classifier loss: 0.384315\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.397684\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.459013\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.379340\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.405514\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.381018\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.514613\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.455149\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.390824\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.375000\n",
      "epoch 3; iter: 0; batch classifier loss: 0.466317\n",
      "epoch 3; iter: 200; batch classifier loss: 0.398108\n",
      "epoch 3; iter: 400; batch classifier loss: 0.411640\n",
      "epoch 3; iter: 600; batch classifier loss: 0.383916\n",
      "epoch 3; iter: 800; batch classifier loss: 0.362835\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.344500\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.487107\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.384097\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.441706\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.413868\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.396059\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.446017\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.390135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 2600; batch classifier loss: 0.314906\n",
      "epoch 4; iter: 0; batch classifier loss: 0.380613\n",
      "epoch 4; iter: 200; batch classifier loss: 0.458802\n",
      "epoch 4; iter: 400; batch classifier loss: 0.377426\n",
      "epoch 4; iter: 600; batch classifier loss: 0.324265\n",
      "epoch 4; iter: 800; batch classifier loss: 0.411392\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.397924\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.440507\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.456818\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.449577\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.443551\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.421914\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.449735\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.404380\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.477279\n",
      "epoch 5; iter: 0; batch classifier loss: 0.405023\n",
      "epoch 5; iter: 200; batch classifier loss: 0.462425\n",
      "epoch 5; iter: 400; batch classifier loss: 0.395864\n",
      "epoch 5; iter: 600; batch classifier loss: 0.310205\n",
      "epoch 5; iter: 800; batch classifier loss: 0.510823\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.494034\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.427883\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.367647\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.482639\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.427429\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.462336\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.466528\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.454274\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.443458\n",
      "epoch 6; iter: 0; batch classifier loss: 0.471541\n",
      "epoch 6; iter: 200; batch classifier loss: 0.448069\n",
      "epoch 6; iter: 400; batch classifier loss: 0.453530\n",
      "epoch 6; iter: 600; batch classifier loss: 0.379704\n",
      "epoch 6; iter: 800; batch classifier loss: 0.409793\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.366753\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.387208\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.441704\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.450937\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.394546\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.595361\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.470341\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.376272\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.343267\n",
      "epoch 7; iter: 0; batch classifier loss: 0.370689\n",
      "epoch 7; iter: 200; batch classifier loss: 0.382928\n",
      "epoch 7; iter: 400; batch classifier loss: 0.455317\n",
      "epoch 7; iter: 600; batch classifier loss: 0.359354\n",
      "epoch 7; iter: 800; batch classifier loss: 0.425855\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.467783\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.432990\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.391608\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.386269\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.419676\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.383374\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.336195\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.446029\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.521148\n",
      "epoch 8; iter: 0; batch classifier loss: 0.438797\n",
      "epoch 8; iter: 200; batch classifier loss: 0.391079\n",
      "epoch 8; iter: 400; batch classifier loss: 0.432103\n",
      "epoch 8; iter: 600; batch classifier loss: 0.530881\n",
      "epoch 8; iter: 800; batch classifier loss: 0.446462\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.425030\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.373138\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.355115\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.419568\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.391740\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.413557\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.394187\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.503671\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.417421\n",
      "epoch 9; iter: 0; batch classifier loss: 0.466043\n",
      "epoch 9; iter: 200; batch classifier loss: 0.390589\n",
      "epoch 9; iter: 400; batch classifier loss: 0.364631\n",
      "epoch 9; iter: 600; batch classifier loss: 0.451420\n",
      "epoch 9; iter: 800; batch classifier loss: 0.413597\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.366148\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.396962\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.477637\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.359291\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.484575\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.329426\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.509560\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.404125\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.324083\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464844\n",
      "epoch 10; iter: 200; batch classifier loss: 0.415615\n",
      "epoch 10; iter: 400; batch classifier loss: 0.469730\n",
      "epoch 10; iter: 600; batch classifier loss: 0.367404\n",
      "epoch 10; iter: 800; batch classifier loss: 0.389259\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.400039\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.435521\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.503036\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.438562\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.455036\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.410419\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.384035\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.447699\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.428797\n",
      "epoch 11; iter: 0; batch classifier loss: 0.393619\n",
      "epoch 11; iter: 200; batch classifier loss: 0.383720\n",
      "epoch 11; iter: 400; batch classifier loss: 0.409052\n",
      "epoch 11; iter: 600; batch classifier loss: 0.401465\n",
      "epoch 11; iter: 800; batch classifier loss: 0.455307\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.461197\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.365220\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.404887\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.444559\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.428948\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.447186\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.436384\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.445481\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.478855\n",
      "epoch 12; iter: 0; batch classifier loss: 0.352026\n",
      "epoch 12; iter: 200; batch classifier loss: 0.395896\n",
      "epoch 12; iter: 400; batch classifier loss: 0.496917\n",
      "epoch 12; iter: 600; batch classifier loss: 0.363425\n",
      "epoch 12; iter: 800; batch classifier loss: 0.544807\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.349779\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.466858\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.411150\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.384277\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.381669\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.400106\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.395408\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.394778\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.350344\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448593\n",
      "epoch 13; iter: 200; batch classifier loss: 0.385735\n",
      "epoch 13; iter: 400; batch classifier loss: 0.438232\n",
      "epoch 13; iter: 600; batch classifier loss: 0.576535\n",
      "epoch 13; iter: 800; batch classifier loss: 0.424879\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.381341\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.440806\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.353941\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.392942\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.485483\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.469137\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.402333\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.380419\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.446635\n",
      "epoch 14; iter: 0; batch classifier loss: 0.408354\n",
      "epoch 14; iter: 200; batch classifier loss: 0.495762\n",
      "epoch 14; iter: 400; batch classifier loss: 0.440521\n",
      "epoch 14; iter: 600; batch classifier loss: 0.391650\n",
      "epoch 14; iter: 800; batch classifier loss: 0.406001\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.384071\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.487384\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.311870\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.412201\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.351608\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.463351\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.380462\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.436248\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.473776\n",
      "epoch 15; iter: 0; batch classifier loss: 0.410673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 200; batch classifier loss: 0.406288\n",
      "epoch 15; iter: 400; batch classifier loss: 0.413045\n",
      "epoch 15; iter: 600; batch classifier loss: 0.467877\n",
      "epoch 15; iter: 800; batch classifier loss: 0.419047\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.419981\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.362282\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.403779\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.446328\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.484207\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.454470\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.455483\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.381006\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.442132\n",
      "epoch 16; iter: 0; batch classifier loss: 0.413285\n",
      "epoch 16; iter: 200; batch classifier loss: 0.367501\n",
      "epoch 16; iter: 400; batch classifier loss: 0.403952\n",
      "epoch 16; iter: 600; batch classifier loss: 0.346506\n",
      "epoch 16; iter: 800; batch classifier loss: 0.448935\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.455172\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.417412\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.479717\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.399097\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.409951\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.378996\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.427797\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.461897\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.472435\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348480\n",
      "epoch 17; iter: 200; batch classifier loss: 0.346428\n",
      "epoch 17; iter: 400; batch classifier loss: 0.350023\n",
      "epoch 17; iter: 600; batch classifier loss: 0.416603\n",
      "epoch 17; iter: 800; batch classifier loss: 0.453317\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.349650\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.411031\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.412296\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.441928\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.442192\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.380427\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.434141\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.378530\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.389404\n",
      "epoch 18; iter: 0; batch classifier loss: 0.339440\n",
      "epoch 18; iter: 200; batch classifier loss: 0.435966\n",
      "epoch 18; iter: 400; batch classifier loss: 0.472259\n",
      "epoch 18; iter: 600; batch classifier loss: 0.403449\n",
      "epoch 18; iter: 800; batch classifier loss: 0.358274\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.415533\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.415280\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.457247\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.439253\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.409744\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.428882\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.361233\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.453495\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.384141\n",
      "epoch 19; iter: 0; batch classifier loss: 0.510241\n",
      "epoch 19; iter: 200; batch classifier loss: 0.403955\n",
      "epoch 19; iter: 400; batch classifier loss: 0.441697\n",
      "epoch 19; iter: 600; batch classifier loss: 0.411353\n",
      "epoch 19; iter: 800; batch classifier loss: 0.438673\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.310693\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.395351\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.460420\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.419374\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.383080\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.337510\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.419444\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.423915\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.454270\n",
      "epoch 20; iter: 0; batch classifier loss: 0.466640\n",
      "epoch 20; iter: 200; batch classifier loss: 0.389053\n",
      "epoch 20; iter: 400; batch classifier loss: 0.485730\n",
      "epoch 20; iter: 600; batch classifier loss: 0.470730\n",
      "epoch 20; iter: 800; batch classifier loss: 0.396822\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.386842\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.504682\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.446840\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.397979\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.418129\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.379906\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.367997\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.396574\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.354991\n",
      "epoch 21; iter: 0; batch classifier loss: 0.455251\n",
      "epoch 21; iter: 200; batch classifier loss: 0.397464\n",
      "epoch 21; iter: 400; batch classifier loss: 0.404622\n",
      "epoch 21; iter: 600; batch classifier loss: 0.343759\n",
      "epoch 21; iter: 800; batch classifier loss: 0.359494\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.394050\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.455614\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.382714\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.448776\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.457374\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.400204\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.360721\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.408940\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.403393\n",
      "epoch 22; iter: 0; batch classifier loss: 0.366268\n",
      "epoch 22; iter: 200; batch classifier loss: 0.500384\n",
      "epoch 22; iter: 400; batch classifier loss: 0.444497\n",
      "epoch 22; iter: 600; batch classifier loss: 0.449720\n",
      "epoch 22; iter: 800; batch classifier loss: 0.411705\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.417185\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.313401\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.480628\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.423650\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.385344\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.378167\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.436717\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.411093\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.404412\n",
      "epoch 23; iter: 0; batch classifier loss: 0.433979\n",
      "epoch 23; iter: 200; batch classifier loss: 0.344967\n",
      "epoch 23; iter: 400; batch classifier loss: 0.487648\n",
      "epoch 23; iter: 600; batch classifier loss: 0.417753\n",
      "epoch 23; iter: 800; batch classifier loss: 0.428469\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.493280\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.451790\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.383283\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.453140\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.392138\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.418190\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.365827\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.326188\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.540304\n",
      "epoch 24; iter: 0; batch classifier loss: 0.362976\n",
      "epoch 24; iter: 200; batch classifier loss: 0.435616\n",
      "epoch 24; iter: 400; batch classifier loss: 0.351428\n",
      "epoch 24; iter: 600; batch classifier loss: 0.435195\n",
      "epoch 24; iter: 800; batch classifier loss: 0.425723\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.334966\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.416708\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.476092\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.388398\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.546992\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.450277\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.482232\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.454842\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.503022\n",
      "epoch 25; iter: 0; batch classifier loss: 0.351321\n",
      "epoch 25; iter: 200; batch classifier loss: 0.405526\n",
      "epoch 25; iter: 400; batch classifier loss: 0.354919\n",
      "epoch 25; iter: 600; batch classifier loss: 0.477717\n",
      "epoch 25; iter: 800; batch classifier loss: 0.333088\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.393503\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.427853\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.386545\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.413670\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.362120\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.358421\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.349550\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.358339\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.390025\n",
      "epoch 26; iter: 0; batch classifier loss: 0.451117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 200; batch classifier loss: 0.367003\n",
      "epoch 26; iter: 400; batch classifier loss: 0.373849\n",
      "epoch 26; iter: 600; batch classifier loss: 0.429318\n",
      "epoch 26; iter: 800; batch classifier loss: 0.332039\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.482721\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.516629\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.409090\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.460607\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.395852\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.419717\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.330262\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.446132\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.445422\n",
      "epoch 27; iter: 0; batch classifier loss: 0.383184\n",
      "epoch 27; iter: 200; batch classifier loss: 0.475377\n",
      "epoch 27; iter: 400; batch classifier loss: 0.400733\n",
      "epoch 27; iter: 600; batch classifier loss: 0.409323\n",
      "epoch 27; iter: 800; batch classifier loss: 0.496859\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.449163\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.361574\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.395906\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.465974\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.414163\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.448637\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.540348\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.405013\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.463046\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450612\n",
      "epoch 28; iter: 200; batch classifier loss: 0.402811\n",
      "epoch 28; iter: 400; batch classifier loss: 0.375133\n",
      "epoch 28; iter: 600; batch classifier loss: 0.454535\n",
      "epoch 28; iter: 800; batch classifier loss: 0.420799\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.461142\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.433370\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.309729\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.468180\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.450610\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.353656\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.375966\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.399466\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.411596\n",
      "epoch 29; iter: 0; batch classifier loss: 0.411727\n",
      "epoch 29; iter: 200; batch classifier loss: 0.421583\n",
      "epoch 29; iter: 400; batch classifier loss: 0.403961\n",
      "epoch 29; iter: 600; batch classifier loss: 0.422104\n",
      "epoch 29; iter: 800; batch classifier loss: 0.441777\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.413417\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.449127\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.364080\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.447285\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.347287\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.410618\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.409244\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.452486\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.377293\n",
      "epoch 30; iter: 0; batch classifier loss: 0.372653\n",
      "epoch 30; iter: 200; batch classifier loss: 0.429937\n",
      "epoch 30; iter: 400; batch classifier loss: 0.374335\n",
      "epoch 30; iter: 600; batch classifier loss: 0.437941\n",
      "epoch 30; iter: 800; batch classifier loss: 0.428091\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.407024\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.418086\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.411518\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.404600\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.368223\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.454898\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.431273\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.397577\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.440484\n",
      "epoch 31; iter: 0; batch classifier loss: 0.404674\n",
      "epoch 31; iter: 200; batch classifier loss: 0.397829\n",
      "epoch 31; iter: 400; batch classifier loss: 0.381716\n",
      "epoch 31; iter: 600; batch classifier loss: 0.339403\n",
      "epoch 31; iter: 800; batch classifier loss: 0.397919\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.509901\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.426282\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.396060\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.428583\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.380249\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.526053\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.461555\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.413774\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.395565\n",
      "epoch 32; iter: 0; batch classifier loss: 0.414915\n",
      "epoch 32; iter: 200; batch classifier loss: 0.464442\n",
      "epoch 32; iter: 400; batch classifier loss: 0.382324\n",
      "epoch 32; iter: 600; batch classifier loss: 0.439710\n",
      "epoch 32; iter: 800; batch classifier loss: 0.481461\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.442934\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.423654\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.416327\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.468597\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.407358\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.376482\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.462905\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.416493\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.432081\n",
      "epoch 33; iter: 0; batch classifier loss: 0.358085\n",
      "epoch 33; iter: 200; batch classifier loss: 0.398261\n",
      "epoch 33; iter: 400; batch classifier loss: 0.399201\n",
      "epoch 33; iter: 600; batch classifier loss: 0.343022\n",
      "epoch 33; iter: 800; batch classifier loss: 0.436828\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.499561\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.449351\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.375044\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.465586\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.377336\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.496830\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.347400\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.382839\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.351062\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430965\n",
      "epoch 34; iter: 200; batch classifier loss: 0.427511\n",
      "epoch 34; iter: 400; batch classifier loss: 0.420828\n",
      "epoch 34; iter: 600; batch classifier loss: 0.432473\n",
      "epoch 34; iter: 800; batch classifier loss: 0.487285\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.503205\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.387865\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.401140\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.480860\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.414599\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.461654\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.485305\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.397416\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.486486\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429404\n",
      "epoch 35; iter: 200; batch classifier loss: 0.355282\n",
      "epoch 35; iter: 400; batch classifier loss: 0.393218\n",
      "epoch 35; iter: 600; batch classifier loss: 0.391625\n",
      "epoch 35; iter: 800; batch classifier loss: 0.413591\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.352871\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.428936\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.350556\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.388980\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.409477\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.339653\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.398758\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.395673\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.408340\n",
      "epoch 36; iter: 0; batch classifier loss: 0.557694\n",
      "epoch 36; iter: 200; batch classifier loss: 0.325128\n",
      "epoch 36; iter: 400; batch classifier loss: 0.430538\n",
      "epoch 36; iter: 600; batch classifier loss: 0.409913\n",
      "epoch 36; iter: 800; batch classifier loss: 0.400540\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.424939\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.365728\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.387311\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.403813\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.400190\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.373095\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.441242\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.355104\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.372769\n",
      "epoch 37; iter: 0; batch classifier loss: 0.296577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37; iter: 200; batch classifier loss: 0.413645\n",
      "epoch 37; iter: 400; batch classifier loss: 0.369915\n",
      "epoch 37; iter: 600; batch classifier loss: 0.432700\n",
      "epoch 37; iter: 800; batch classifier loss: 0.429983\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.466478\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.320563\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.408354\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.364656\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.471067\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.430074\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.359911\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.346597\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.376711\n",
      "epoch 38; iter: 0; batch classifier loss: 0.421745\n",
      "epoch 38; iter: 200; batch classifier loss: 0.373904\n",
      "epoch 38; iter: 400; batch classifier loss: 0.573124\n",
      "epoch 38; iter: 600; batch classifier loss: 0.466495\n",
      "epoch 38; iter: 800; batch classifier loss: 0.497201\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.348829\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.498603\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.455226\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.434157\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.369687\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.493491\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.403091\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.314893\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.394823\n",
      "epoch 39; iter: 0; batch classifier loss: 0.513429\n",
      "epoch 39; iter: 200; batch classifier loss: 0.366115\n",
      "epoch 39; iter: 400; batch classifier loss: 0.453455\n",
      "epoch 39; iter: 600; batch classifier loss: 0.394228\n",
      "epoch 39; iter: 800; batch classifier loss: 0.384697\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.424714\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.369537\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.336913\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.367244\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.412344\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.382269\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.382078\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.475946\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.456079\n",
      "epoch 40; iter: 0; batch classifier loss: 0.407587\n",
      "epoch 40; iter: 200; batch classifier loss: 0.474177\n",
      "epoch 40; iter: 400; batch classifier loss: 0.420826\n",
      "epoch 40; iter: 600; batch classifier loss: 0.413161\n",
      "epoch 40; iter: 800; batch classifier loss: 0.411733\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.419579\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.444115\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.419922\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.509427\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.405316\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.403922\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.401567\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.463105\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.439145\n",
      "epoch 41; iter: 0; batch classifier loss: 0.390197\n",
      "epoch 41; iter: 200; batch classifier loss: 0.466731\n",
      "epoch 41; iter: 400; batch classifier loss: 0.498813\n",
      "epoch 41; iter: 600; batch classifier loss: 0.337549\n",
      "epoch 41; iter: 800; batch classifier loss: 0.433598\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.402617\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.392034\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.410308\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.386091\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.405116\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.410001\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.314763\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.371901\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.352429\n",
      "epoch 42; iter: 0; batch classifier loss: 0.355496\n",
      "epoch 42; iter: 200; batch classifier loss: 0.426572\n",
      "epoch 42; iter: 400; batch classifier loss: 0.437245\n",
      "epoch 42; iter: 600; batch classifier loss: 0.344441\n",
      "epoch 42; iter: 800; batch classifier loss: 0.422786\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.441942\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.426337\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.344158\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.380102\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.394625\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.408175\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.396150\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.397939\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.445896\n",
      "epoch 43; iter: 0; batch classifier loss: 0.374094\n",
      "epoch 43; iter: 200; batch classifier loss: 0.411986\n",
      "epoch 43; iter: 400; batch classifier loss: 0.428633\n",
      "epoch 43; iter: 600; batch classifier loss: 0.410307\n",
      "epoch 43; iter: 800; batch classifier loss: 0.416237\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.352976\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.428454\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.391266\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.462712\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.437622\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.515764\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.516861\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.382478\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.381341\n",
      "epoch 44; iter: 0; batch classifier loss: 0.405190\n",
      "epoch 44; iter: 200; batch classifier loss: 0.409570\n",
      "epoch 44; iter: 400; batch classifier loss: 0.424967\n",
      "epoch 44; iter: 600; batch classifier loss: 0.378297\n",
      "epoch 44; iter: 800; batch classifier loss: 0.406788\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.403324\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.441285\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.400100\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.452765\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.384135\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.460636\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.376838\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.426992\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.392561\n",
      "epoch 45; iter: 0; batch classifier loss: 0.473140\n",
      "epoch 45; iter: 200; batch classifier loss: 0.418399\n",
      "epoch 45; iter: 400; batch classifier loss: 0.441091\n",
      "epoch 45; iter: 600; batch classifier loss: 0.385859\n",
      "epoch 45; iter: 800; batch classifier loss: 0.393542\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.358863\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.427594\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.297062\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.457483\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.422176\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.511130\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.352723\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.369450\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.343743\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430633\n",
      "epoch 46; iter: 200; batch classifier loss: 0.413799\n",
      "epoch 46; iter: 400; batch classifier loss: 0.383295\n",
      "epoch 46; iter: 600; batch classifier loss: 0.354156\n",
      "epoch 46; iter: 800; batch classifier loss: 0.513402\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.355076\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.416651\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.341944\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.453756\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.444522\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.434839\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.417800\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.371670\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.405476\n",
      "epoch 47; iter: 0; batch classifier loss: 0.436142\n",
      "epoch 47; iter: 200; batch classifier loss: 0.404863\n",
      "epoch 47; iter: 400; batch classifier loss: 0.347470\n",
      "epoch 47; iter: 600; batch classifier loss: 0.474521\n",
      "epoch 47; iter: 800; batch classifier loss: 0.502106\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.452330\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.479040\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.311694\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.440680\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.410866\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.373536\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.355314\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.451616\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.354205\n",
      "epoch 48; iter: 0; batch classifier loss: 0.371247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 200; batch classifier loss: 0.444619\n",
      "epoch 48; iter: 400; batch classifier loss: 0.391177\n",
      "epoch 48; iter: 600; batch classifier loss: 0.424921\n",
      "epoch 48; iter: 800; batch classifier loss: 0.353354\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.389366\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.400340\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.446997\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.454603\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.377014\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.371271\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.427252\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.461984\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.452838\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419067\n",
      "epoch 49; iter: 200; batch classifier loss: 0.460124\n",
      "epoch 49; iter: 400; batch classifier loss: 0.453294\n",
      "epoch 49; iter: 600; batch classifier loss: 0.433464\n",
      "epoch 49; iter: 800; batch classifier loss: 0.405971\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.453698\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.320060\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.382914\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.376663\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.489001\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.490132\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.446626\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.394612\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.392868\n",
      "epoch 0; iter: 0; batch classifier loss: 0.692337; batch adversarial loss: 1.005258\n",
      "epoch 0; iter: 200; batch classifier loss: 1.283069; batch adversarial loss: 1.023080\n",
      "epoch 1; iter: 0; batch classifier loss: 1.360341; batch adversarial loss: 0.925220\n",
      "epoch 1; iter: 200; batch classifier loss: 1.575615; batch adversarial loss: 0.687637\n",
      "epoch 2; iter: 0; batch classifier loss: 1.387084; batch adversarial loss: 0.630356\n",
      "epoch 2; iter: 200; batch classifier loss: 0.492171; batch adversarial loss: 0.532834\n",
      "epoch 3; iter: 0; batch classifier loss: 0.384830; batch adversarial loss: 0.516978\n",
      "epoch 3; iter: 200; batch classifier loss: 0.433904; batch adversarial loss: 0.488474\n",
      "epoch 4; iter: 0; batch classifier loss: 0.403637; batch adversarial loss: 0.465121\n",
      "epoch 4; iter: 200; batch classifier loss: 0.453069; batch adversarial loss: 0.479643\n",
      "epoch 5; iter: 0; batch classifier loss: 0.428390; batch adversarial loss: 0.471970\n",
      "epoch 5; iter: 200; batch classifier loss: 0.465331; batch adversarial loss: 0.431264\n",
      "epoch 6; iter: 0; batch classifier loss: 0.375692; batch adversarial loss: 0.441343\n",
      "epoch 6; iter: 200; batch classifier loss: 0.446693; batch adversarial loss: 0.440453\n",
      "epoch 7; iter: 0; batch classifier loss: 0.493549; batch adversarial loss: 0.448022\n",
      "epoch 7; iter: 200; batch classifier loss: 0.427536; batch adversarial loss: 0.434968\n",
      "epoch 8; iter: 0; batch classifier loss: 0.491722; batch adversarial loss: 0.408415\n",
      "epoch 8; iter: 200; batch classifier loss: 0.376934; batch adversarial loss: 0.423010\n",
      "epoch 9; iter: 0; batch classifier loss: 0.442881; batch adversarial loss: 0.357952\n",
      "epoch 9; iter: 200; batch classifier loss: 0.375423; batch adversarial loss: 0.384486\n",
      "epoch 10; iter: 0; batch classifier loss: 0.372559; batch adversarial loss: 0.501248\n",
      "epoch 10; iter: 200; batch classifier loss: 0.440061; batch adversarial loss: 0.467744\n",
      "epoch 11; iter: 0; batch classifier loss: 0.429613; batch adversarial loss: 0.397483\n",
      "epoch 11; iter: 200; batch classifier loss: 0.346954; batch adversarial loss: 0.314480\n",
      "epoch 12; iter: 0; batch classifier loss: 0.490597; batch adversarial loss: 0.361937\n",
      "epoch 12; iter: 200; batch classifier loss: 0.495524; batch adversarial loss: 0.460246\n",
      "epoch 13; iter: 0; batch classifier loss: 0.456636; batch adversarial loss: 0.394124\n",
      "epoch 13; iter: 200; batch classifier loss: 0.420764; batch adversarial loss: 0.441558\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469112; batch adversarial loss: 0.563469\n",
      "epoch 14; iter: 200; batch classifier loss: 0.441123; batch adversarial loss: 0.403248\n",
      "epoch 15; iter: 0; batch classifier loss: 0.384895; batch adversarial loss: 0.433317\n",
      "epoch 15; iter: 200; batch classifier loss: 0.539141; batch adversarial loss: 0.352386\n",
      "epoch 16; iter: 0; batch classifier loss: 0.385277; batch adversarial loss: 0.413688\n",
      "epoch 16; iter: 200; batch classifier loss: 0.380149; batch adversarial loss: 0.408307\n",
      "epoch 17; iter: 0; batch classifier loss: 0.556687; batch adversarial loss: 0.351224\n",
      "epoch 17; iter: 200; batch classifier loss: 0.367869; batch adversarial loss: 0.560587\n",
      "epoch 18; iter: 0; batch classifier loss: 0.452985; batch adversarial loss: 0.436306\n",
      "epoch 18; iter: 200; batch classifier loss: 0.520456; batch adversarial loss: 0.347620\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482743; batch adversarial loss: 0.458214\n",
      "epoch 19; iter: 200; batch classifier loss: 0.458967; batch adversarial loss: 0.376309\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491029; batch adversarial loss: 0.403587\n",
      "epoch 20; iter: 200; batch classifier loss: 0.418456; batch adversarial loss: 0.486209\n",
      "epoch 21; iter: 0; batch classifier loss: 0.395698; batch adversarial loss: 0.402256\n",
      "epoch 21; iter: 200; batch classifier loss: 0.482296; batch adversarial loss: 0.383826\n",
      "epoch 22; iter: 0; batch classifier loss: 0.451453; batch adversarial loss: 0.386993\n",
      "epoch 22; iter: 200; batch classifier loss: 0.395799; batch adversarial loss: 0.447467\n",
      "epoch 23; iter: 0; batch classifier loss: 0.465372; batch adversarial loss: 0.391615\n",
      "epoch 23; iter: 200; batch classifier loss: 0.495408; batch adversarial loss: 0.338646\n",
      "epoch 24; iter: 0; batch classifier loss: 0.462996; batch adversarial loss: 0.458574\n",
      "epoch 24; iter: 200; batch classifier loss: 0.429915; batch adversarial loss: 0.355590\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474124; batch adversarial loss: 0.349627\n",
      "epoch 25; iter: 200; batch classifier loss: 0.370902; batch adversarial loss: 0.437698\n",
      "epoch 26; iter: 0; batch classifier loss: 0.350691; batch adversarial loss: 0.418171\n",
      "epoch 26; iter: 200; batch classifier loss: 0.399245; batch adversarial loss: 0.385646\n",
      "epoch 27; iter: 0; batch classifier loss: 0.443674; batch adversarial loss: 0.466660\n",
      "epoch 27; iter: 200; batch classifier loss: 0.478971; batch adversarial loss: 0.314850\n",
      "epoch 28; iter: 0; batch classifier loss: 0.425930; batch adversarial loss: 0.553594\n",
      "epoch 28; iter: 200; batch classifier loss: 0.446843; batch adversarial loss: 0.360857\n",
      "epoch 29; iter: 0; batch classifier loss: 0.384690; batch adversarial loss: 0.445229\n",
      "epoch 29; iter: 200; batch classifier loss: 0.424636; batch adversarial loss: 0.393635\n",
      "epoch 30; iter: 0; batch classifier loss: 0.448042; batch adversarial loss: 0.329327\n",
      "epoch 30; iter: 200; batch classifier loss: 0.452948; batch adversarial loss: 0.365746\n",
      "epoch 31; iter: 0; batch classifier loss: 0.337490; batch adversarial loss: 0.459618\n",
      "epoch 31; iter: 200; batch classifier loss: 0.402439; batch adversarial loss: 0.414147\n",
      "epoch 32; iter: 0; batch classifier loss: 0.448600; batch adversarial loss: 0.367133\n",
      "epoch 32; iter: 200; batch classifier loss: 0.549381; batch adversarial loss: 0.512040\n",
      "epoch 33; iter: 0; batch classifier loss: 0.450175; batch adversarial loss: 0.516064\n",
      "epoch 33; iter: 200; batch classifier loss: 0.368211; batch adversarial loss: 0.382544\n",
      "epoch 34; iter: 0; batch classifier loss: 0.392989; batch adversarial loss: 0.374708\n",
      "epoch 34; iter: 200; batch classifier loss: 0.415928; batch adversarial loss: 0.400588\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429530; batch adversarial loss: 0.396881\n",
      "epoch 35; iter: 200; batch classifier loss: 0.350264; batch adversarial loss: 0.495799\n",
      "epoch 36; iter: 0; batch classifier loss: 0.283219; batch adversarial loss: 0.459262\n",
      "epoch 36; iter: 200; batch classifier loss: 0.393652; batch adversarial loss: 0.468231\n",
      "epoch 37; iter: 0; batch classifier loss: 0.381129; batch adversarial loss: 0.384246\n",
      "epoch 37; iter: 200; batch classifier loss: 0.415485; batch adversarial loss: 0.417317\n",
      "epoch 38; iter: 0; batch classifier loss: 0.448420; batch adversarial loss: 0.397260\n",
      "epoch 38; iter: 200; batch classifier loss: 0.421430; batch adversarial loss: 0.369839\n",
      "epoch 39; iter: 0; batch classifier loss: 0.404628; batch adversarial loss: 0.471998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 200; batch classifier loss: 0.482216; batch adversarial loss: 0.489484\n",
      "epoch 40; iter: 0; batch classifier loss: 0.370423; batch adversarial loss: 0.385828\n",
      "epoch 40; iter: 200; batch classifier loss: 0.417765; batch adversarial loss: 0.612171\n",
      "epoch 41; iter: 0; batch classifier loss: 0.450519; batch adversarial loss: 0.400489\n",
      "epoch 41; iter: 200; batch classifier loss: 0.398507; batch adversarial loss: 0.420313\n",
      "epoch 42; iter: 0; batch classifier loss: 0.370194; batch adversarial loss: 0.420471\n",
      "epoch 42; iter: 200; batch classifier loss: 0.419890; batch adversarial loss: 0.328151\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414278; batch adversarial loss: 0.376140\n",
      "epoch 43; iter: 200; batch classifier loss: 0.411210; batch adversarial loss: 0.380550\n",
      "epoch 44; iter: 0; batch classifier loss: 0.513007; batch adversarial loss: 0.465409\n",
      "epoch 44; iter: 200; batch classifier loss: 0.371366; batch adversarial loss: 0.559352\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417269; batch adversarial loss: 0.318706\n",
      "epoch 45; iter: 200; batch classifier loss: 0.382458; batch adversarial loss: 0.397670\n",
      "epoch 46; iter: 0; batch classifier loss: 0.367464; batch adversarial loss: 0.427932\n",
      "epoch 46; iter: 200; batch classifier loss: 0.356651; batch adversarial loss: 0.370099\n",
      "epoch 47; iter: 0; batch classifier loss: 0.478605; batch adversarial loss: 0.492489\n",
      "epoch 47; iter: 200; batch classifier loss: 0.474662; batch adversarial loss: 0.355521\n",
      "epoch 48; iter: 0; batch classifier loss: 0.442826; batch adversarial loss: 0.472015\n",
      "epoch 48; iter: 200; batch classifier loss: 0.473407; batch adversarial loss: 0.491733\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450628; batch adversarial loss: 0.457560\n",
      "epoch 49; iter: 200; batch classifier loss: 0.473416; batch adversarial loss: 0.392567\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676601\n",
      "epoch 0; iter: 200; batch classifier loss: 0.467202\n",
      "epoch 1; iter: 0; batch classifier loss: 0.417137\n",
      "epoch 1; iter: 200; batch classifier loss: 0.470769\n",
      "epoch 2; iter: 0; batch classifier loss: 0.331156\n",
      "epoch 2; iter: 200; batch classifier loss: 0.352245\n",
      "epoch 3; iter: 0; batch classifier loss: 0.356797\n",
      "epoch 3; iter: 200; batch classifier loss: 0.364874\n",
      "epoch 4; iter: 0; batch classifier loss: 0.427363\n",
      "epoch 4; iter: 200; batch classifier loss: 0.497485\n",
      "epoch 5; iter: 0; batch classifier loss: 0.385150\n",
      "epoch 5; iter: 200; batch classifier loss: 0.430224\n",
      "epoch 6; iter: 0; batch classifier loss: 0.359974\n",
      "epoch 6; iter: 200; batch classifier loss: 0.480418\n",
      "epoch 7; iter: 0; batch classifier loss: 0.397916\n",
      "epoch 7; iter: 200; batch classifier loss: 0.438590\n",
      "epoch 8; iter: 0; batch classifier loss: 0.447578\n",
      "epoch 8; iter: 200; batch classifier loss: 0.345595\n",
      "epoch 9; iter: 0; batch classifier loss: 0.361508\n",
      "epoch 9; iter: 200; batch classifier loss: 0.365735\n",
      "epoch 10; iter: 0; batch classifier loss: 0.424644\n",
      "epoch 10; iter: 200; batch classifier loss: 0.446077\n",
      "epoch 11; iter: 0; batch classifier loss: 0.404542\n",
      "epoch 11; iter: 200; batch classifier loss: 0.467891\n",
      "epoch 12; iter: 0; batch classifier loss: 0.435953\n",
      "epoch 12; iter: 200; batch classifier loss: 0.360940\n",
      "epoch 13; iter: 0; batch classifier loss: 0.467603\n",
      "epoch 13; iter: 200; batch classifier loss: 0.511509\n",
      "epoch 14; iter: 0; batch classifier loss: 0.345878\n",
      "epoch 14; iter: 200; batch classifier loss: 0.489389\n",
      "epoch 15; iter: 0; batch classifier loss: 0.418501\n",
      "epoch 15; iter: 200; batch classifier loss: 0.371362\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387483\n",
      "epoch 16; iter: 200; batch classifier loss: 0.345777\n",
      "epoch 17; iter: 0; batch classifier loss: 0.424842\n",
      "epoch 17; iter: 200; batch classifier loss: 0.412655\n",
      "epoch 18; iter: 0; batch classifier loss: 0.441972\n",
      "epoch 18; iter: 200; batch classifier loss: 0.416127\n",
      "epoch 19; iter: 0; batch classifier loss: 0.408383\n",
      "epoch 19; iter: 200; batch classifier loss: 0.385744\n",
      "epoch 20; iter: 0; batch classifier loss: 0.321458\n",
      "epoch 20; iter: 200; batch classifier loss: 0.406979\n",
      "epoch 21; iter: 0; batch classifier loss: 0.415306\n",
      "epoch 21; iter: 200; batch classifier loss: 0.420227\n",
      "epoch 22; iter: 0; batch classifier loss: 0.381355\n",
      "epoch 22; iter: 200; batch classifier loss: 0.416016\n",
      "epoch 23; iter: 0; batch classifier loss: 0.412288\n",
      "epoch 23; iter: 200; batch classifier loss: 0.428577\n",
      "epoch 24; iter: 0; batch classifier loss: 0.348623\n",
      "epoch 24; iter: 200; batch classifier loss: 0.449345\n",
      "epoch 25; iter: 0; batch classifier loss: 0.466105\n",
      "epoch 25; iter: 200; batch classifier loss: 0.402261\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484255\n",
      "epoch 26; iter: 200; batch classifier loss: 0.427445\n",
      "epoch 27; iter: 0; batch classifier loss: 0.429993\n",
      "epoch 27; iter: 200; batch classifier loss: 0.399103\n",
      "epoch 28; iter: 0; batch classifier loss: 0.443228\n",
      "epoch 28; iter: 200; batch classifier loss: 0.489863\n",
      "epoch 29; iter: 0; batch classifier loss: 0.409686\n",
      "epoch 29; iter: 200; batch classifier loss: 0.422045\n",
      "epoch 30; iter: 0; batch classifier loss: 0.441441\n",
      "epoch 30; iter: 200; batch classifier loss: 0.385400\n",
      "epoch 31; iter: 0; batch classifier loss: 0.458035\n",
      "epoch 31; iter: 200; batch classifier loss: 0.463250\n",
      "epoch 32; iter: 0; batch classifier loss: 0.358337\n",
      "epoch 32; iter: 200; batch classifier loss: 0.366640\n",
      "epoch 33; iter: 0; batch classifier loss: 0.464804\n",
      "epoch 33; iter: 200; batch classifier loss: 0.430129\n",
      "epoch 34; iter: 0; batch classifier loss: 0.432389\n",
      "epoch 34; iter: 200; batch classifier loss: 0.432923\n",
      "epoch 35; iter: 0; batch classifier loss: 0.363206\n",
      "epoch 35; iter: 200; batch classifier loss: 0.406393\n",
      "epoch 36; iter: 0; batch classifier loss: 0.373737\n",
      "epoch 36; iter: 200; batch classifier loss: 0.406516\n",
      "epoch 37; iter: 0; batch classifier loss: 0.360178\n",
      "epoch 37; iter: 200; batch classifier loss: 0.415283\n",
      "epoch 38; iter: 0; batch classifier loss: 0.446859\n",
      "epoch 38; iter: 200; batch classifier loss: 0.379648\n",
      "epoch 39; iter: 0; batch classifier loss: 0.499205\n",
      "epoch 39; iter: 200; batch classifier loss: 0.384894\n",
      "epoch 40; iter: 0; batch classifier loss: 0.460122\n",
      "epoch 40; iter: 200; batch classifier loss: 0.422125\n",
      "epoch 41; iter: 0; batch classifier loss: 0.397128\n",
      "epoch 41; iter: 200; batch classifier loss: 0.358663\n",
      "epoch 42; iter: 0; batch classifier loss: 0.334643\n",
      "epoch 42; iter: 200; batch classifier loss: 0.439876\n",
      "epoch 43; iter: 0; batch classifier loss: 0.380297\n",
      "epoch 43; iter: 200; batch classifier loss: 0.393761\n",
      "epoch 44; iter: 0; batch classifier loss: 0.399825\n",
      "epoch 44; iter: 200; batch classifier loss: 0.416314\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463138\n",
      "epoch 45; iter: 200; batch classifier loss: 0.490451\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430027\n",
      "epoch 46; iter: 200; batch classifier loss: 0.393881\n",
      "epoch 47; iter: 0; batch classifier loss: 0.496673\n",
      "epoch 47; iter: 200; batch classifier loss: 0.418052\n",
      "epoch 48; iter: 0; batch classifier loss: 0.405240\n",
      "epoch 48; iter: 200; batch classifier loss: 0.382173\n",
      "epoch 49; iter: 0; batch classifier loss: 0.383484\n",
      "epoch 49; iter: 200; batch classifier loss: 0.375584\n",
      "run = 4\n",
      "epoch 0; iter: 0; batch classifier loss: 0.794576; batch adversarial loss: 0.730403\n",
      "epoch 0; iter: 200; batch classifier loss: 0.469139; batch adversarial loss: 0.626072\n",
      "epoch 0; iter: 400; batch classifier loss: 0.415084; batch adversarial loss: 0.578214\n",
      "epoch 0; iter: 600; batch classifier loss: 0.474388; batch adversarial loss: 0.499635\n",
      "epoch 0; iter: 800; batch classifier loss: 0.415104; batch adversarial loss: 0.525800\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.418224; batch adversarial loss: 0.487151\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.459509; batch adversarial loss: 0.507211\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.393272; batch adversarial loss: 0.418190\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.459221; batch adversarial loss: 0.509117\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.440906; batch adversarial loss: 0.382553\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.446377; batch adversarial loss: 0.443331\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.344803; batch adversarial loss: 0.386066\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.473245; batch adversarial loss: 0.485705\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.446441; batch adversarial loss: 0.450255\n",
      "epoch 1; iter: 0; batch classifier loss: 0.390221; batch adversarial loss: 0.448337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1; iter: 200; batch classifier loss: 0.426672; batch adversarial loss: 0.424114\n",
      "epoch 1; iter: 400; batch classifier loss: 0.367762; batch adversarial loss: 0.397407\n",
      "epoch 1; iter: 600; batch classifier loss: 0.352379; batch adversarial loss: 0.421751\n",
      "epoch 1; iter: 800; batch classifier loss: 0.494046; batch adversarial loss: 0.421116\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.377862; batch adversarial loss: 0.445888\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.497947; batch adversarial loss: 0.408085\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.401004; batch adversarial loss: 0.407014\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.429395; batch adversarial loss: 0.459209\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.372541; batch adversarial loss: 0.407901\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.493234; batch adversarial loss: 0.513341\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.347469; batch adversarial loss: 0.379792\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.419074; batch adversarial loss: 0.487159\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.376941; batch adversarial loss: 0.502374\n",
      "epoch 2; iter: 0; batch classifier loss: 0.284550; batch adversarial loss: 0.473658\n",
      "epoch 2; iter: 200; batch classifier loss: 0.414128; batch adversarial loss: 0.432164\n",
      "epoch 2; iter: 400; batch classifier loss: 0.367139; batch adversarial loss: 0.378288\n",
      "epoch 2; iter: 600; batch classifier loss: 0.473640; batch adversarial loss: 0.351147\n",
      "epoch 2; iter: 800; batch classifier loss: 0.444126; batch adversarial loss: 0.392937\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.431535; batch adversarial loss: 0.405719\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.266912; batch adversarial loss: 0.433940\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.379984; batch adversarial loss: 0.336340\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.313805; batch adversarial loss: 0.474774\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.437793; batch adversarial loss: 0.473518\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.398854; batch adversarial loss: 0.446592\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.458921; batch adversarial loss: 0.324246\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.424779; batch adversarial loss: 0.389899\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.495652; batch adversarial loss: 0.447992\n",
      "epoch 3; iter: 0; batch classifier loss: 0.356991; batch adversarial loss: 0.408748\n",
      "epoch 3; iter: 200; batch classifier loss: 0.446753; batch adversarial loss: 0.540027\n",
      "epoch 3; iter: 400; batch classifier loss: 0.433179; batch adversarial loss: 0.505461\n",
      "epoch 3; iter: 600; batch classifier loss: 0.442414; batch adversarial loss: 0.540753\n",
      "epoch 3; iter: 800; batch classifier loss: 0.397930; batch adversarial loss: 0.392888\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.420093; batch adversarial loss: 0.420516\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.473515; batch adversarial loss: 0.433207\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.365680; batch adversarial loss: 0.391142\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.435128; batch adversarial loss: 0.392000\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.408981; batch adversarial loss: 0.418785\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.367936; batch adversarial loss: 0.407753\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.440817; batch adversarial loss: 0.406432\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.409593; batch adversarial loss: 0.380886\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.491485; batch adversarial loss: 0.473167\n",
      "epoch 4; iter: 0; batch classifier loss: 0.377168; batch adversarial loss: 0.403403\n",
      "epoch 4; iter: 200; batch classifier loss: 0.286784; batch adversarial loss: 0.377941\n",
      "epoch 4; iter: 400; batch classifier loss: 0.501129; batch adversarial loss: 0.393019\n",
      "epoch 4; iter: 600; batch classifier loss: 0.344828; batch adversarial loss: 0.367643\n",
      "epoch 4; iter: 800; batch classifier loss: 0.523559; batch adversarial loss: 0.407611\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.388564; batch adversarial loss: 0.474783\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.376091; batch adversarial loss: 0.476117\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.415884; batch adversarial loss: 0.323406\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.412233; batch adversarial loss: 0.472961\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.381922; batch adversarial loss: 0.472364\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.376859; batch adversarial loss: 0.363910\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.451381; batch adversarial loss: 0.407771\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.366921; batch adversarial loss: 0.472725\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.492523; batch adversarial loss: 0.431596\n",
      "epoch 5; iter: 0; batch classifier loss: 0.409085; batch adversarial loss: 0.434753\n",
      "epoch 5; iter: 200; batch classifier loss: 0.413785; batch adversarial loss: 0.446365\n",
      "epoch 5; iter: 400; batch classifier loss: 0.344680; batch adversarial loss: 0.471153\n",
      "epoch 5; iter: 600; batch classifier loss: 0.363744; batch adversarial loss: 0.433411\n",
      "epoch 5; iter: 800; batch classifier loss: 0.400425; batch adversarial loss: 0.354248\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.410984; batch adversarial loss: 0.298108\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.374911; batch adversarial loss: 0.352582\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.467213; batch adversarial loss: 0.434713\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.375136; batch adversarial loss: 0.432876\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.441731; batch adversarial loss: 0.421097\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.445956; batch adversarial loss: 0.421397\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.510499; batch adversarial loss: 0.337154\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.356004; batch adversarial loss: 0.514511\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.367465; batch adversarial loss: 0.447277\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564700; batch adversarial loss: 0.376852\n",
      "epoch 6; iter: 200; batch classifier loss: 0.447641; batch adversarial loss: 0.405586\n",
      "epoch 6; iter: 400; batch classifier loss: 0.360050; batch adversarial loss: 0.378559\n",
      "epoch 6; iter: 600; batch classifier loss: 0.336227; batch adversarial loss: 0.300362\n",
      "epoch 6; iter: 800; batch classifier loss: 0.362275; batch adversarial loss: 0.526258\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.343668; batch adversarial loss: 0.378202\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.353929; batch adversarial loss: 0.403938\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.449884; batch adversarial loss: 0.381034\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.434514; batch adversarial loss: 0.416219\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.480585; batch adversarial loss: 0.379055\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.372427; batch adversarial loss: 0.435582\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.400114; batch adversarial loss: 0.431913\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.431998; batch adversarial loss: 0.352492\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.462625; batch adversarial loss: 0.407912\n",
      "epoch 7; iter: 0; batch classifier loss: 0.414987; batch adversarial loss: 0.377639\n",
      "epoch 7; iter: 200; batch classifier loss: 0.397545; batch adversarial loss: 0.404614\n",
      "epoch 7; iter: 400; batch classifier loss: 0.332274; batch adversarial loss: 0.378926\n",
      "epoch 7; iter: 600; batch classifier loss: 0.386872; batch adversarial loss: 0.462849\n",
      "epoch 7; iter: 800; batch classifier loss: 0.413695; batch adversarial loss: 0.364136\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.370551; batch adversarial loss: 0.473927\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.368261; batch adversarial loss: 0.420053\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.435152; batch adversarial loss: 0.351906\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.387669; batch adversarial loss: 0.377764\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.535790; batch adversarial loss: 0.364940\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.381156; batch adversarial loss: 0.368307\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.461588; batch adversarial loss: 0.471532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7; iter: 2400; batch classifier loss: 0.378294; batch adversarial loss: 0.445693\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.387184; batch adversarial loss: 0.377555\n",
      "epoch 8; iter: 0; batch classifier loss: 0.542832; batch adversarial loss: 0.431323\n",
      "epoch 8; iter: 200; batch classifier loss: 0.435986; batch adversarial loss: 0.446452\n",
      "epoch 8; iter: 400; batch classifier loss: 0.445017; batch adversarial loss: 0.486953\n",
      "epoch 8; iter: 600; batch classifier loss: 0.344341; batch adversarial loss: 0.379055\n",
      "epoch 8; iter: 800; batch classifier loss: 0.303035; batch adversarial loss: 0.503024\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.521380; batch adversarial loss: 0.364843\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.346676; batch adversarial loss: 0.613466\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.388200; batch adversarial loss: 0.393741\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.449247; batch adversarial loss: 0.362429\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.447408; batch adversarial loss: 0.350100\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.418118; batch adversarial loss: 0.473894\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.479861; batch adversarial loss: 0.446792\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.432171; batch adversarial loss: 0.312008\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.333881; batch adversarial loss: 0.543644\n",
      "epoch 9; iter: 0; batch classifier loss: 0.401846; batch adversarial loss: 0.404697\n",
      "epoch 9; iter: 200; batch classifier loss: 0.475606; batch adversarial loss: 0.421085\n",
      "epoch 9; iter: 400; batch classifier loss: 0.420686; batch adversarial loss: 0.477454\n",
      "epoch 9; iter: 600; batch classifier loss: 0.407266; batch adversarial loss: 0.407301\n",
      "epoch 9; iter: 800; batch classifier loss: 0.408158; batch adversarial loss: 0.488355\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.446693; batch adversarial loss: 0.435804\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.376052; batch adversarial loss: 0.450230\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.344945; batch adversarial loss: 0.352772\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.499758; batch adversarial loss: 0.391049\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.391774; batch adversarial loss: 0.405944\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.344454; batch adversarial loss: 0.462082\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.371773; batch adversarial loss: 0.364578\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.468539; batch adversarial loss: 0.460703\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.364227; batch adversarial loss: 0.474583\n",
      "epoch 10; iter: 0; batch classifier loss: 0.400475; batch adversarial loss: 0.489143\n",
      "epoch 10; iter: 200; batch classifier loss: 0.366871; batch adversarial loss: 0.378863\n",
      "epoch 10; iter: 400; batch classifier loss: 0.450878; batch adversarial loss: 0.297431\n",
      "epoch 10; iter: 600; batch classifier loss: 0.501659; batch adversarial loss: 0.400062\n",
      "epoch 10; iter: 800; batch classifier loss: 0.431633; batch adversarial loss: 0.395327\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.358897; batch adversarial loss: 0.401297\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.402494; batch adversarial loss: 0.419651\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.511061; batch adversarial loss: 0.324821\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.410374; batch adversarial loss: 0.421043\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.362594; batch adversarial loss: 0.472264\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.477711; batch adversarial loss: 0.572499\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.466520; batch adversarial loss: 0.419630\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.392952; batch adversarial loss: 0.377276\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.450454; batch adversarial loss: 0.512795\n",
      "epoch 11; iter: 0; batch classifier loss: 0.370725; batch adversarial loss: 0.487773\n",
      "epoch 11; iter: 200; batch classifier loss: 0.430349; batch adversarial loss: 0.348634\n",
      "epoch 11; iter: 400; batch classifier loss: 0.352546; batch adversarial loss: 0.407506\n",
      "epoch 11; iter: 600; batch classifier loss: 0.412433; batch adversarial loss: 0.423016\n",
      "epoch 11; iter: 800; batch classifier loss: 0.383035; batch adversarial loss: 0.379787\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.464706; batch adversarial loss: 0.347656\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.366338; batch adversarial loss: 0.434362\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.409206; batch adversarial loss: 0.366979\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.502850; batch adversarial loss: 0.392064\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.368504; batch adversarial loss: 0.379575\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.486513; batch adversarial loss: 0.379342\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.383171; batch adversarial loss: 0.347747\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.404602; batch adversarial loss: 0.351871\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.475391; batch adversarial loss: 0.405280\n",
      "epoch 12; iter: 0; batch classifier loss: 0.509256; batch adversarial loss: 0.554710\n",
      "epoch 12; iter: 200; batch classifier loss: 0.425039; batch adversarial loss: 0.460748\n",
      "epoch 12; iter: 400; batch classifier loss: 0.455705; batch adversarial loss: 0.366255\n",
      "epoch 12; iter: 600; batch classifier loss: 0.363838; batch adversarial loss: 0.377887\n",
      "epoch 12; iter: 800; batch classifier loss: 0.354745; batch adversarial loss: 0.470978\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.481502; batch adversarial loss: 0.435569\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.468448; batch adversarial loss: 0.433194\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.367976; batch adversarial loss: 0.420382\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.370563; batch adversarial loss: 0.338564\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.429124; batch adversarial loss: 0.430681\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.338363; batch adversarial loss: 0.393452\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.469072; batch adversarial loss: 0.488669\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.402910; batch adversarial loss: 0.432605\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.421540; batch adversarial loss: 0.368649\n",
      "epoch 13; iter: 0; batch classifier loss: 0.423094; batch adversarial loss: 0.409515\n",
      "epoch 13; iter: 200; batch classifier loss: 0.446559; batch adversarial loss: 0.431415\n",
      "epoch 13; iter: 400; batch classifier loss: 0.348153; batch adversarial loss: 0.443166\n",
      "epoch 13; iter: 600; batch classifier loss: 0.403767; batch adversarial loss: 0.472777\n",
      "epoch 13; iter: 800; batch classifier loss: 0.430615; batch adversarial loss: 0.435413\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.390796; batch adversarial loss: 0.366596\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.392140; batch adversarial loss: 0.393135\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.474017; batch adversarial loss: 0.350656\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.325150; batch adversarial loss: 0.364234\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.433415; batch adversarial loss: 0.395288\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.531541; batch adversarial loss: 0.375896\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.313567; batch adversarial loss: 0.517035\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.434939; batch adversarial loss: 0.282604\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.404169; batch adversarial loss: 0.554901\n",
      "epoch 14; iter: 0; batch classifier loss: 0.363774; batch adversarial loss: 0.364956\n",
      "epoch 14; iter: 200; batch classifier loss: 0.475449; batch adversarial loss: 0.365485\n",
      "epoch 14; iter: 400; batch classifier loss: 0.382576; batch adversarial loss: 0.409990\n",
      "epoch 14; iter: 600; batch classifier loss: 0.337199; batch adversarial loss: 0.347060\n",
      "epoch 14; iter: 800; batch classifier loss: 0.447966; batch adversarial loss: 0.502613\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.482034; batch adversarial loss: 0.406057\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.485458; batch adversarial loss: 0.432744\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.411730; batch adversarial loss: 0.406603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14; iter: 1600; batch classifier loss: 0.360930; batch adversarial loss: 0.459819\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.435641; batch adversarial loss: 0.420558\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.385460; batch adversarial loss: 0.433060\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.427588; batch adversarial loss: 0.463785\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.392866; batch adversarial loss: 0.364058\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.415701; batch adversarial loss: 0.474410\n",
      "epoch 15; iter: 0; batch classifier loss: 0.375473; batch adversarial loss: 0.488508\n",
      "epoch 15; iter: 200; batch classifier loss: 0.475091; batch adversarial loss: 0.393986\n",
      "epoch 15; iter: 400; batch classifier loss: 0.391482; batch adversarial loss: 0.434698\n",
      "epoch 15; iter: 600; batch classifier loss: 0.408719; batch adversarial loss: 0.416820\n",
      "epoch 15; iter: 800; batch classifier loss: 0.473324; batch adversarial loss: 0.352710\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.388485; batch adversarial loss: 0.447231\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.396725; batch adversarial loss: 0.392835\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.373251; batch adversarial loss: 0.396077\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.359602; batch adversarial loss: 0.408407\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.400509; batch adversarial loss: 0.392086\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.529889; batch adversarial loss: 0.353143\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.440093; batch adversarial loss: 0.336553\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.429168; batch adversarial loss: 0.486453\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.418974; batch adversarial loss: 0.351352\n",
      "epoch 16; iter: 0; batch classifier loss: 0.372172; batch adversarial loss: 0.445785\n",
      "epoch 16; iter: 200; batch classifier loss: 0.385925; batch adversarial loss: 0.527761\n",
      "epoch 16; iter: 400; batch classifier loss: 0.415501; batch adversarial loss: 0.377829\n",
      "epoch 16; iter: 600; batch classifier loss: 0.412867; batch adversarial loss: 0.392168\n",
      "epoch 16; iter: 800; batch classifier loss: 0.273327; batch adversarial loss: 0.403724\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.398591; batch adversarial loss: 0.461750\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.485448; batch adversarial loss: 0.420537\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.416050; batch adversarial loss: 0.378303\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.408024; batch adversarial loss: 0.366615\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.522064; batch adversarial loss: 0.365408\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.508280; batch adversarial loss: 0.422623\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.441046; batch adversarial loss: 0.487283\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.425171; batch adversarial loss: 0.378625\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.454229; batch adversarial loss: 0.381038\n",
      "epoch 17; iter: 0; batch classifier loss: 0.308580; batch adversarial loss: 0.420121\n",
      "epoch 17; iter: 200; batch classifier loss: 0.384117; batch adversarial loss: 0.407440\n",
      "epoch 17; iter: 400; batch classifier loss: 0.435358; batch adversarial loss: 0.324045\n",
      "epoch 17; iter: 600; batch classifier loss: 0.355822; batch adversarial loss: 0.404763\n",
      "epoch 17; iter: 800; batch classifier loss: 0.453839; batch adversarial loss: 0.312429\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.370819; batch adversarial loss: 0.367444\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.365139; batch adversarial loss: 0.351225\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.399131; batch adversarial loss: 0.422492\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.431450; batch adversarial loss: 0.473614\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.381478; batch adversarial loss: 0.241959\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.384314; batch adversarial loss: 0.461801\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.443432; batch adversarial loss: 0.405688\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.384608; batch adversarial loss: 0.419688\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.487196; batch adversarial loss: 0.460960\n",
      "epoch 18; iter: 0; batch classifier loss: 0.363598; batch adversarial loss: 0.502071\n",
      "epoch 18; iter: 200; batch classifier loss: 0.329925; batch adversarial loss: 0.407079\n",
      "epoch 18; iter: 400; batch classifier loss: 0.368198; batch adversarial loss: 0.448385\n",
      "epoch 18; iter: 600; batch classifier loss: 0.381598; batch adversarial loss: 0.489652\n",
      "epoch 18; iter: 800; batch classifier loss: 0.376337; batch adversarial loss: 0.461263\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.484157; batch adversarial loss: 0.446695\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.448044; batch adversarial loss: 0.461232\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.392253; batch adversarial loss: 0.376195\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.402387; batch adversarial loss: 0.461537\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.386049; batch adversarial loss: 0.498792\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.353922; batch adversarial loss: 0.312368\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.359465; batch adversarial loss: 0.503222\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.434249; batch adversarial loss: 0.339053\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.405492; batch adversarial loss: 0.459554\n",
      "epoch 19; iter: 0; batch classifier loss: 0.332810; batch adversarial loss: 0.353196\n",
      "epoch 19; iter: 200; batch classifier loss: 0.400604; batch adversarial loss: 0.513679\n",
      "epoch 19; iter: 400; batch classifier loss: 0.561073; batch adversarial loss: 0.422124\n",
      "epoch 19; iter: 600; batch classifier loss: 0.436128; batch adversarial loss: 0.338514\n",
      "epoch 19; iter: 800; batch classifier loss: 0.475675; batch adversarial loss: 0.391061\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.428961; batch adversarial loss: 0.404213\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.378973; batch adversarial loss: 0.459545\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.395879; batch adversarial loss: 0.406442\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.399970; batch adversarial loss: 0.354043\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.540077; batch adversarial loss: 0.269985\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.455643; batch adversarial loss: 0.365303\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.449902; batch adversarial loss: 0.462301\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.452592; batch adversarial loss: 0.350205\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.462359; batch adversarial loss: 0.502492\n",
      "epoch 20; iter: 0; batch classifier loss: 0.433806; batch adversarial loss: 0.447588\n",
      "epoch 20; iter: 200; batch classifier loss: 0.479786; batch adversarial loss: 0.419700\n",
      "epoch 20; iter: 400; batch classifier loss: 0.402815; batch adversarial loss: 0.503469\n",
      "epoch 20; iter: 600; batch classifier loss: 0.403599; batch adversarial loss: 0.461090\n",
      "epoch 20; iter: 800; batch classifier loss: 0.404693; batch adversarial loss: 0.528318\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.429975; batch adversarial loss: 0.446902\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.387876; batch adversarial loss: 0.476568\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.384522; batch adversarial loss: 0.449614\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.409315; batch adversarial loss: 0.472976\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.377770; batch adversarial loss: 0.552404\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.403350; batch adversarial loss: 0.354908\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.393598; batch adversarial loss: 0.365846\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.332975; batch adversarial loss: 0.530624\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.497850; batch adversarial loss: 0.393087\n",
      "epoch 21; iter: 0; batch classifier loss: 0.454238; batch adversarial loss: 0.474030\n",
      "epoch 21; iter: 200; batch classifier loss: 0.434212; batch adversarial loss: 0.365504\n",
      "epoch 21; iter: 400; batch classifier loss: 0.448163; batch adversarial loss: 0.448923\n",
      "epoch 21; iter: 600; batch classifier loss: 0.463299; batch adversarial loss: 0.448834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 800; batch classifier loss: 0.419520; batch adversarial loss: 0.461156\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.345377; batch adversarial loss: 0.458204\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.420361; batch adversarial loss: 0.420485\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.422176; batch adversarial loss: 0.487756\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.441196; batch adversarial loss: 0.404574\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.470594; batch adversarial loss: 0.393900\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.393984; batch adversarial loss: 0.444373\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.424001; batch adversarial loss: 0.432191\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.393419; batch adversarial loss: 0.433306\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.397178; batch adversarial loss: 0.339642\n",
      "epoch 22; iter: 0; batch classifier loss: 0.502547; batch adversarial loss: 0.352891\n",
      "epoch 22; iter: 200; batch classifier loss: 0.417947; batch adversarial loss: 0.380840\n",
      "epoch 22; iter: 400; batch classifier loss: 0.401852; batch adversarial loss: 0.471051\n",
      "epoch 22; iter: 600; batch classifier loss: 0.469634; batch adversarial loss: 0.407017\n",
      "epoch 22; iter: 800; batch classifier loss: 0.409893; batch adversarial loss: 0.350893\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.364770; batch adversarial loss: 0.408401\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.436824; batch adversarial loss: 0.391863\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.482709; batch adversarial loss: 0.502872\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.454605; batch adversarial loss: 0.474121\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.429361; batch adversarial loss: 0.434219\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.302479; batch adversarial loss: 0.393885\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.417668; batch adversarial loss: 0.404321\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.339497; batch adversarial loss: 0.433663\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.398176; batch adversarial loss: 0.376926\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443014; batch adversarial loss: 0.392135\n",
      "epoch 23; iter: 200; batch classifier loss: 0.447623; batch adversarial loss: 0.352198\n",
      "epoch 23; iter: 400; batch classifier loss: 0.384726; batch adversarial loss: 0.405564\n",
      "epoch 23; iter: 600; batch classifier loss: 0.500534; batch adversarial loss: 0.351052\n",
      "epoch 23; iter: 800; batch classifier loss: 0.428373; batch adversarial loss: 0.462816\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.324270; batch adversarial loss: 0.421909\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.452197; batch adversarial loss: 0.394718\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.451655; batch adversarial loss: 0.485876\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.419197; batch adversarial loss: 0.504684\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.412633; batch adversarial loss: 0.458796\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.472818; batch adversarial loss: 0.352215\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.463353; batch adversarial loss: 0.307288\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.411120; batch adversarial loss: 0.476163\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.315370; batch adversarial loss: 0.431706\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465944; batch adversarial loss: 0.473351\n",
      "epoch 24; iter: 200; batch classifier loss: 0.456068; batch adversarial loss: 0.421883\n",
      "epoch 24; iter: 400; batch classifier loss: 0.469359; batch adversarial loss: 0.404490\n",
      "epoch 24; iter: 600; batch classifier loss: 0.436731; batch adversarial loss: 0.394211\n",
      "epoch 24; iter: 800; batch classifier loss: 0.312822; batch adversarial loss: 0.430864\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.379408; batch adversarial loss: 0.433507\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.425788; batch adversarial loss: 0.500246\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.358894; batch adversarial loss: 0.420728\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.374483; batch adversarial loss: 0.351896\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.377081; batch adversarial loss: 0.459561\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.414169; batch adversarial loss: 0.406859\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.398594; batch adversarial loss: 0.393117\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.439847; batch adversarial loss: 0.420250\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.388179; batch adversarial loss: 0.431818\n",
      "epoch 25; iter: 0; batch classifier loss: 0.469982; batch adversarial loss: 0.377528\n",
      "epoch 25; iter: 200; batch classifier loss: 0.461646; batch adversarial loss: 0.431476\n",
      "epoch 25; iter: 400; batch classifier loss: 0.456176; batch adversarial loss: 0.490035\n",
      "epoch 25; iter: 600; batch classifier loss: 0.365082; batch adversarial loss: 0.408540\n",
      "epoch 25; iter: 800; batch classifier loss: 0.489614; batch adversarial loss: 0.472972\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.405751; batch adversarial loss: 0.461894\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.353146; batch adversarial loss: 0.434758\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.346852; batch adversarial loss: 0.595321\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.535033; batch adversarial loss: 0.364066\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.380464; batch adversarial loss: 0.381205\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.385362; batch adversarial loss: 0.448876\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.441511; batch adversarial loss: 0.419874\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.379711; batch adversarial loss: 0.446220\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.435460; batch adversarial loss: 0.403891\n",
      "epoch 26; iter: 0; batch classifier loss: 0.399579; batch adversarial loss: 0.420819\n",
      "epoch 26; iter: 200; batch classifier loss: 0.381726; batch adversarial loss: 0.450124\n",
      "epoch 26; iter: 400; batch classifier loss: 0.414167; batch adversarial loss: 0.542748\n",
      "epoch 26; iter: 600; batch classifier loss: 0.344317; batch adversarial loss: 0.340349\n",
      "epoch 26; iter: 800; batch classifier loss: 0.443215; batch adversarial loss: 0.433690\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.493568; batch adversarial loss: 0.433963\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.503408; batch adversarial loss: 0.432929\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.430212; batch adversarial loss: 0.502272\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.413123; batch adversarial loss: 0.405000\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.474265; batch adversarial loss: 0.420534\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.544932; batch adversarial loss: 0.511274\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.406857; batch adversarial loss: 0.380959\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.339716; batch adversarial loss: 0.456942\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.293107; batch adversarial loss: 0.433206\n",
      "epoch 27; iter: 0; batch classifier loss: 0.359241; batch adversarial loss: 0.445792\n",
      "epoch 27; iter: 200; batch classifier loss: 0.463161; batch adversarial loss: 0.461366\n",
      "epoch 27; iter: 400; batch classifier loss: 0.421423; batch adversarial loss: 0.377835\n",
      "epoch 27; iter: 600; batch classifier loss: 0.336941; batch adversarial loss: 0.405859\n",
      "epoch 27; iter: 800; batch classifier loss: 0.426255; batch adversarial loss: 0.430909\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.366156; batch adversarial loss: 0.391480\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.432330; batch adversarial loss: 0.365950\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.357812; batch adversarial loss: 0.404324\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.393618; batch adversarial loss: 0.352422\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.458012; batch adversarial loss: 0.379123\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.421310; batch adversarial loss: 0.406264\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.435874; batch adversarial loss: 0.377200\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.399461; batch adversarial loss: 0.378992\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.400743; batch adversarial loss: 0.366608\n",
      "epoch 28; iter: 0; batch classifier loss: 0.459363; batch adversarial loss: 0.282777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 200; batch classifier loss: 0.378152; batch adversarial loss: 0.434685\n",
      "epoch 28; iter: 400; batch classifier loss: 0.479340; batch adversarial loss: 0.391535\n",
      "epoch 28; iter: 600; batch classifier loss: 0.348086; batch adversarial loss: 0.433655\n",
      "epoch 28; iter: 800; batch classifier loss: 0.388943; batch adversarial loss: 0.471273\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.461716; batch adversarial loss: 0.491949\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.373649; batch adversarial loss: 0.470763\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.490386; batch adversarial loss: 0.403081\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.445708; batch adversarial loss: 0.418556\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.447184; batch adversarial loss: 0.405611\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.376754; batch adversarial loss: 0.377140\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.468320; batch adversarial loss: 0.353255\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.410103; batch adversarial loss: 0.528229\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.378369; batch adversarial loss: 0.433824\n",
      "epoch 29; iter: 0; batch classifier loss: 0.419276; batch adversarial loss: 0.434273\n",
      "epoch 29; iter: 200; batch classifier loss: 0.479190; batch adversarial loss: 0.432118\n",
      "epoch 29; iter: 400; batch classifier loss: 0.394676; batch adversarial loss: 0.475421\n",
      "epoch 29; iter: 600; batch classifier loss: 0.396556; batch adversarial loss: 0.417728\n",
      "epoch 29; iter: 800; batch classifier loss: 0.307239; batch adversarial loss: 0.392307\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.408271; batch adversarial loss: 0.393290\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.464783; batch adversarial loss: 0.408262\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.441082; batch adversarial loss: 0.405912\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.412470; batch adversarial loss: 0.390120\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.387764; batch adversarial loss: 0.488442\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.363523; batch adversarial loss: 0.394807\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.436927; batch adversarial loss: 0.418224\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.389163; batch adversarial loss: 0.377715\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.402326; batch adversarial loss: 0.365457\n",
      "epoch 30; iter: 0; batch classifier loss: 0.381519; batch adversarial loss: 0.393587\n",
      "epoch 30; iter: 200; batch classifier loss: 0.381171; batch adversarial loss: 0.448967\n",
      "epoch 30; iter: 400; batch classifier loss: 0.378998; batch adversarial loss: 0.433515\n",
      "epoch 30; iter: 600; batch classifier loss: 0.378562; batch adversarial loss: 0.389592\n",
      "epoch 30; iter: 800; batch classifier loss: 0.519057; batch adversarial loss: 0.516026\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.415630; batch adversarial loss: 0.392649\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.388154; batch adversarial loss: 0.474901\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.357093; batch adversarial loss: 0.366054\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.463296; batch adversarial loss: 0.338713\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.343133; batch adversarial loss: 0.406693\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.422629; batch adversarial loss: 0.477291\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.448908; batch adversarial loss: 0.366174\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.442447; batch adversarial loss: 0.421933\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.483495; batch adversarial loss: 0.376509\n",
      "epoch 31; iter: 0; batch classifier loss: 0.429747; batch adversarial loss: 0.432478\n",
      "epoch 31; iter: 200; batch classifier loss: 0.514190; batch adversarial loss: 0.457750\n",
      "epoch 31; iter: 400; batch classifier loss: 0.368307; batch adversarial loss: 0.447449\n",
      "epoch 31; iter: 600; batch classifier loss: 0.492136; batch adversarial loss: 0.420544\n",
      "epoch 31; iter: 800; batch classifier loss: 0.457761; batch adversarial loss: 0.489814\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.495713; batch adversarial loss: 0.515164\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.481876; batch adversarial loss: 0.430529\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.410863; batch adversarial loss: 0.352316\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.406996; batch adversarial loss: 0.487991\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.412036; batch adversarial loss: 0.515073\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.494037; batch adversarial loss: 0.336758\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.427620; batch adversarial loss: 0.460658\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.377816; batch adversarial loss: 0.324381\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.415974; batch adversarial loss: 0.380198\n",
      "epoch 32; iter: 0; batch classifier loss: 0.362278; batch adversarial loss: 0.420404\n",
      "epoch 32; iter: 200; batch classifier loss: 0.360691; batch adversarial loss: 0.390954\n",
      "epoch 32; iter: 400; batch classifier loss: 0.438036; batch adversarial loss: 0.447963\n",
      "epoch 32; iter: 600; batch classifier loss: 0.427606; batch adversarial loss: 0.338407\n",
      "epoch 32; iter: 800; batch classifier loss: 0.418891; batch adversarial loss: 0.433733\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.350613; batch adversarial loss: 0.405466\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.480390; batch adversarial loss: 0.352440\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.423378; batch adversarial loss: 0.489395\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.396485; batch adversarial loss: 0.460551\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.370667; batch adversarial loss: 0.295363\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.474260; batch adversarial loss: 0.491050\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.422178; batch adversarial loss: 0.471003\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.435562; batch adversarial loss: 0.500549\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.507918; batch adversarial loss: 0.473444\n",
      "epoch 33; iter: 0; batch classifier loss: 0.384886; batch adversarial loss: 0.351598\n",
      "epoch 33; iter: 200; batch classifier loss: 0.384287; batch adversarial loss: 0.419549\n",
      "epoch 33; iter: 400; batch classifier loss: 0.377219; batch adversarial loss: 0.477729\n",
      "epoch 33; iter: 600; batch classifier loss: 0.392512; batch adversarial loss: 0.446785\n",
      "epoch 33; iter: 800; batch classifier loss: 0.490362; batch adversarial loss: 0.449470\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.371201; batch adversarial loss: 0.408948\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.433657; batch adversarial loss: 0.442989\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.405579; batch adversarial loss: 0.366446\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.438618; batch adversarial loss: 0.447714\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.463024; batch adversarial loss: 0.375867\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.380712; batch adversarial loss: 0.393858\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.407090; batch adversarial loss: 0.338638\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.439117; batch adversarial loss: 0.434343\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.430559; batch adversarial loss: 0.379875\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426830; batch adversarial loss: 0.419572\n",
      "epoch 34; iter: 200; batch classifier loss: 0.381731; batch adversarial loss: 0.433140\n",
      "epoch 34; iter: 400; batch classifier loss: 0.354050; batch adversarial loss: 0.460234\n",
      "epoch 34; iter: 600; batch classifier loss: 0.343483; batch adversarial loss: 0.322869\n",
      "epoch 34; iter: 800; batch classifier loss: 0.339501; batch adversarial loss: 0.420048\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.423980; batch adversarial loss: 0.364882\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.488583; batch adversarial loss: 0.487764\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.434306; batch adversarial loss: 0.349188\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.392858; batch adversarial loss: 0.336616\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.435130; batch adversarial loss: 0.476040\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.335049; batch adversarial loss: 0.416978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 2200; batch classifier loss: 0.412302; batch adversarial loss: 0.395233\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.452893; batch adversarial loss: 0.422177\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.343458; batch adversarial loss: 0.378650\n",
      "epoch 35; iter: 0; batch classifier loss: 0.485976; batch adversarial loss: 0.394909\n",
      "epoch 35; iter: 200; batch classifier loss: 0.390359; batch adversarial loss: 0.366058\n",
      "epoch 35; iter: 400; batch classifier loss: 0.352663; batch adversarial loss: 0.365740\n",
      "epoch 35; iter: 600; batch classifier loss: 0.450199; batch adversarial loss: 0.422693\n",
      "epoch 35; iter: 800; batch classifier loss: 0.330256; batch adversarial loss: 0.378371\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.381891; batch adversarial loss: 0.323572\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.431899; batch adversarial loss: 0.461371\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.405992; batch adversarial loss: 0.473645\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.416376; batch adversarial loss: 0.447876\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.392422; batch adversarial loss: 0.419479\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.465946; batch adversarial loss: 0.471316\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.387014; batch adversarial loss: 0.420064\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.441944; batch adversarial loss: 0.459351\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.413453; batch adversarial loss: 0.406011\n",
      "epoch 36; iter: 0; batch classifier loss: 0.360522; batch adversarial loss: 0.448376\n",
      "epoch 36; iter: 200; batch classifier loss: 0.450202; batch adversarial loss: 0.364929\n",
      "epoch 36; iter: 400; batch classifier loss: 0.448867; batch adversarial loss: 0.433441\n",
      "epoch 36; iter: 600; batch classifier loss: 0.512235; batch adversarial loss: 0.404605\n",
      "epoch 36; iter: 800; batch classifier loss: 0.471032; batch adversarial loss: 0.350182\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.383043; batch adversarial loss: 0.489146\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.442001; batch adversarial loss: 0.336979\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.334425; batch adversarial loss: 0.391345\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.500971; batch adversarial loss: 0.433732\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.440788; batch adversarial loss: 0.390185\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.434399; batch adversarial loss: 0.470951\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.421586; batch adversarial loss: 0.448056\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.345894; batch adversarial loss: 0.473109\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.407137; batch adversarial loss: 0.392133\n",
      "epoch 37; iter: 0; batch classifier loss: 0.410816; batch adversarial loss: 0.419241\n",
      "epoch 37; iter: 200; batch classifier loss: 0.426342; batch adversarial loss: 0.406603\n",
      "epoch 37; iter: 400; batch classifier loss: 0.411076; batch adversarial loss: 0.420980\n",
      "epoch 37; iter: 600; batch classifier loss: 0.397026; batch adversarial loss: 0.404646\n",
      "epoch 37; iter: 800; batch classifier loss: 0.418807; batch adversarial loss: 0.460240\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.389510; batch adversarial loss: 0.404898\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.395349; batch adversarial loss: 0.409697\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.376585; batch adversarial loss: 0.431410\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.436126; batch adversarial loss: 0.476200\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.428907; batch adversarial loss: 0.515648\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.439309; batch adversarial loss: 0.432461\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.424480; batch adversarial loss: 0.366260\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.375576; batch adversarial loss: 0.459400\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.371815; batch adversarial loss: 0.419944\n",
      "epoch 38; iter: 0; batch classifier loss: 0.482207; batch adversarial loss: 0.366273\n",
      "epoch 38; iter: 200; batch classifier loss: 0.366196; batch adversarial loss: 0.419673\n",
      "epoch 38; iter: 400; batch classifier loss: 0.335718; batch adversarial loss: 0.394725\n",
      "epoch 38; iter: 600; batch classifier loss: 0.398139; batch adversarial loss: 0.408357\n",
      "epoch 38; iter: 800; batch classifier loss: 0.406857; batch adversarial loss: 0.322771\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.471253; batch adversarial loss: 0.393386\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.410464; batch adversarial loss: 0.463054\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.490203; batch adversarial loss: 0.403654\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.400146; batch adversarial loss: 0.461448\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.439655; batch adversarial loss: 0.394341\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.407136; batch adversarial loss: 0.405036\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.406147; batch adversarial loss: 0.461818\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.384797; batch adversarial loss: 0.403714\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.407444; batch adversarial loss: 0.448592\n",
      "epoch 39; iter: 0; batch classifier loss: 0.448943; batch adversarial loss: 0.351365\n",
      "epoch 39; iter: 200; batch classifier loss: 0.403463; batch adversarial loss: 0.389814\n",
      "epoch 39; iter: 400; batch classifier loss: 0.323397; batch adversarial loss: 0.420342\n",
      "epoch 39; iter: 600; batch classifier loss: 0.406570; batch adversarial loss: 0.405578\n",
      "epoch 39; iter: 800; batch classifier loss: 0.354304; batch adversarial loss: 0.366347\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.418763; batch adversarial loss: 0.310399\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.335848; batch adversarial loss: 0.419677\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.497089; batch adversarial loss: 0.421023\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.442330; batch adversarial loss: 0.476440\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.456300; batch adversarial loss: 0.457249\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.405433; batch adversarial loss: 0.432181\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.463288; batch adversarial loss: 0.462307\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.405006; batch adversarial loss: 0.540449\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.409232; batch adversarial loss: 0.462372\n",
      "epoch 40; iter: 0; batch classifier loss: 0.371572; batch adversarial loss: 0.421386\n",
      "epoch 40; iter: 200; batch classifier loss: 0.425612; batch adversarial loss: 0.395049\n",
      "epoch 40; iter: 400; batch classifier loss: 0.398093; batch adversarial loss: 0.491364\n",
      "epoch 40; iter: 600; batch classifier loss: 0.440001; batch adversarial loss: 0.363121\n",
      "epoch 40; iter: 800; batch classifier loss: 0.344984; batch adversarial loss: 0.338100\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.413603; batch adversarial loss: 0.448847\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.417578; batch adversarial loss: 0.431111\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.592742; batch adversarial loss: 0.390851\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.407699; batch adversarial loss: 0.338468\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.378171; batch adversarial loss: 0.516024\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.354894; batch adversarial loss: 0.362286\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.427608; batch adversarial loss: 0.392377\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.458815; batch adversarial loss: 0.435569\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.322360; batch adversarial loss: 0.377414\n",
      "epoch 41; iter: 0; batch classifier loss: 0.460098; batch adversarial loss: 0.353058\n",
      "epoch 41; iter: 200; batch classifier loss: 0.427256; batch adversarial loss: 0.445813\n",
      "epoch 41; iter: 400; batch classifier loss: 0.428467; batch adversarial loss: 0.432685\n",
      "epoch 41; iter: 600; batch classifier loss: 0.375085; batch adversarial loss: 0.489825\n",
      "epoch 41; iter: 800; batch classifier loss: 0.456345; batch adversarial loss: 0.396820\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.519026; batch adversarial loss: 0.461939\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.385267; batch adversarial loss: 0.379875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 1400; batch classifier loss: 0.403863; batch adversarial loss: 0.366153\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.472434; batch adversarial loss: 0.450839\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.394086; batch adversarial loss: 0.447643\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.412405; batch adversarial loss: 0.487364\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.403218; batch adversarial loss: 0.421379\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.392841; batch adversarial loss: 0.430492\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.400519; batch adversarial loss: 0.419924\n",
      "epoch 42; iter: 0; batch classifier loss: 0.384213; batch adversarial loss: 0.473142\n",
      "epoch 42; iter: 200; batch classifier loss: 0.426069; batch adversarial loss: 0.461311\n",
      "epoch 42; iter: 400; batch classifier loss: 0.418864; batch adversarial loss: 0.394322\n",
      "epoch 42; iter: 600; batch classifier loss: 0.506739; batch adversarial loss: 0.527702\n",
      "epoch 42; iter: 800; batch classifier loss: 0.419333; batch adversarial loss: 0.377508\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.328317; batch adversarial loss: 0.406081\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.406155; batch adversarial loss: 0.392702\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.435989; batch adversarial loss: 0.405785\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.476293; batch adversarial loss: 0.404149\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.429237; batch adversarial loss: 0.430546\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.414482; batch adversarial loss: 0.433994\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.451094; batch adversarial loss: 0.378005\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.540506; batch adversarial loss: 0.364967\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.459271; batch adversarial loss: 0.380462\n",
      "epoch 43; iter: 0; batch classifier loss: 0.470490; batch adversarial loss: 0.502604\n",
      "epoch 43; iter: 200; batch classifier loss: 0.404852; batch adversarial loss: 0.340133\n",
      "epoch 43; iter: 400; batch classifier loss: 0.403637; batch adversarial loss: 0.484575\n",
      "epoch 43; iter: 600; batch classifier loss: 0.400149; batch adversarial loss: 0.294997\n",
      "epoch 43; iter: 800; batch classifier loss: 0.446312; batch adversarial loss: 0.487914\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.425249; batch adversarial loss: 0.392703\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.391688; batch adversarial loss: 0.392007\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.469613; batch adversarial loss: 0.404976\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.422648; batch adversarial loss: 0.326060\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.427076; batch adversarial loss: 0.447008\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.434312; batch adversarial loss: 0.488777\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.416970; batch adversarial loss: 0.395359\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.507414; batch adversarial loss: 0.379599\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.407131; batch adversarial loss: 0.408884\n",
      "epoch 44; iter: 0; batch classifier loss: 0.476859; batch adversarial loss: 0.406505\n",
      "epoch 44; iter: 200; batch classifier loss: 0.374192; batch adversarial loss: 0.446809\n",
      "epoch 44; iter: 400; batch classifier loss: 0.410351; batch adversarial loss: 0.352554\n",
      "epoch 44; iter: 600; batch classifier loss: 0.387009; batch adversarial loss: 0.337639\n",
      "epoch 44; iter: 800; batch classifier loss: 0.365377; batch adversarial loss: 0.487511\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.405769; batch adversarial loss: 0.462229\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.410769; batch adversarial loss: 0.406171\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.403878; batch adversarial loss: 0.407371\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.505596; batch adversarial loss: 0.474962\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.428045; batch adversarial loss: 0.460343\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.403234; batch adversarial loss: 0.378219\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.443208; batch adversarial loss: 0.349686\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.395133; batch adversarial loss: 0.431846\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.469540; batch adversarial loss: 0.546268\n",
      "epoch 45; iter: 0; batch classifier loss: 0.426101; batch adversarial loss: 0.486904\n",
      "epoch 45; iter: 200; batch classifier loss: 0.326823; batch adversarial loss: 0.489525\n",
      "epoch 45; iter: 400; batch classifier loss: 0.388377; batch adversarial loss: 0.406549\n",
      "epoch 45; iter: 600; batch classifier loss: 0.451044; batch adversarial loss: 0.351075\n",
      "epoch 45; iter: 800; batch classifier loss: 0.401721; batch adversarial loss: 0.458741\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.328809; batch adversarial loss: 0.404663\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.407119; batch adversarial loss: 0.434014\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.413493; batch adversarial loss: 0.516071\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.373758; batch adversarial loss: 0.420726\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.483557; batch adversarial loss: 0.488235\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.423578; batch adversarial loss: 0.351851\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.420190; batch adversarial loss: 0.394421\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.411294; batch adversarial loss: 0.405057\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.475916; batch adversarial loss: 0.391172\n",
      "epoch 46; iter: 0; batch classifier loss: 0.384200; batch adversarial loss: 0.339403\n",
      "epoch 46; iter: 200; batch classifier loss: 0.362668; batch adversarial loss: 0.530979\n",
      "epoch 46; iter: 400; batch classifier loss: 0.409939; batch adversarial loss: 0.483202\n",
      "epoch 46; iter: 600; batch classifier loss: 0.457139; batch adversarial loss: 0.380377\n",
      "epoch 46; iter: 800; batch classifier loss: 0.430420; batch adversarial loss: 0.353501\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.439519; batch adversarial loss: 0.477514\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.436653; batch adversarial loss: 0.391718\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.455199; batch adversarial loss: 0.352671\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.316415; batch adversarial loss: 0.352835\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.474083; batch adversarial loss: 0.431318\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.418064; batch adversarial loss: 0.420024\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.353953; batch adversarial loss: 0.422121\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.474129; batch adversarial loss: 0.365631\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.510448; batch adversarial loss: 0.444451\n",
      "epoch 47; iter: 0; batch classifier loss: 0.520282; batch adversarial loss: 0.431299\n",
      "epoch 47; iter: 200; batch classifier loss: 0.327005; batch adversarial loss: 0.433557\n",
      "epoch 47; iter: 400; batch classifier loss: 0.392831; batch adversarial loss: 0.544266\n",
      "epoch 47; iter: 600; batch classifier loss: 0.402128; batch adversarial loss: 0.406794\n",
      "epoch 47; iter: 800; batch classifier loss: 0.552327; batch adversarial loss: 0.408874\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.436750; batch adversarial loss: 0.422185\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.399780; batch adversarial loss: 0.376840\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.480099; batch adversarial loss: 0.501841\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.431344; batch adversarial loss: 0.472329\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.469119; batch adversarial loss: 0.349834\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.445596; batch adversarial loss: 0.380732\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.393654; batch adversarial loss: 0.475188\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.387206; batch adversarial loss: 0.461504\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.443157; batch adversarial loss: 0.419985\n",
      "epoch 48; iter: 0; batch classifier loss: 0.500112; batch adversarial loss: 0.488105\n",
      "epoch 48; iter: 200; batch classifier loss: 0.424922; batch adversarial loss: 0.489137\n",
      "epoch 48; iter: 400; batch classifier loss: 0.412369; batch adversarial loss: 0.421277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 600; batch classifier loss: 0.393609; batch adversarial loss: 0.420500\n",
      "epoch 48; iter: 800; batch classifier loss: 0.335269; batch adversarial loss: 0.377174\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.369084; batch adversarial loss: 0.363320\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.417930; batch adversarial loss: 0.473399\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.480798; batch adversarial loss: 0.488158\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.401420; batch adversarial loss: 0.390887\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.460921; batch adversarial loss: 0.421284\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.412784; batch adversarial loss: 0.391387\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.510155; batch adversarial loss: 0.417833\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.334681; batch adversarial loss: 0.376982\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.440566; batch adversarial loss: 0.404648\n",
      "epoch 49; iter: 0; batch classifier loss: 0.398658; batch adversarial loss: 0.392597\n",
      "epoch 49; iter: 200; batch classifier loss: 0.440910; batch adversarial loss: 0.487445\n",
      "epoch 49; iter: 400; batch classifier loss: 0.357719; batch adversarial loss: 0.421382\n",
      "epoch 49; iter: 600; batch classifier loss: 0.395543; batch adversarial loss: 0.364366\n",
      "epoch 49; iter: 800; batch classifier loss: 0.384342; batch adversarial loss: 0.270044\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.464754; batch adversarial loss: 0.516552\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.378558; batch adversarial loss: 0.337565\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.345566; batch adversarial loss: 0.405089\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.442470; batch adversarial loss: 0.447228\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.402578; batch adversarial loss: 0.406808\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.348543; batch adversarial loss: 0.448926\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.339043; batch adversarial loss: 0.435904\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.327904; batch adversarial loss: 0.473673\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.490390; batch adversarial loss: 0.408286\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675117\n",
      "epoch 0; iter: 200; batch classifier loss: 0.452198\n",
      "epoch 0; iter: 400; batch classifier loss: 0.454908\n",
      "epoch 0; iter: 600; batch classifier loss: 0.408099\n",
      "epoch 0; iter: 800; batch classifier loss: 0.294596\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.507748\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.301553\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.407356\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.420374\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.468319\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.415154\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.333291\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.369191\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.412099\n",
      "epoch 1; iter: 0; batch classifier loss: 0.379675\n",
      "epoch 1; iter: 200; batch classifier loss: 0.316567\n",
      "epoch 1; iter: 400; batch classifier loss: 0.464538\n",
      "epoch 1; iter: 600; batch classifier loss: 0.448071\n",
      "epoch 1; iter: 800; batch classifier loss: 0.369997\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.418753\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.381668\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.493673\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.473259\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.423266\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.429946\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.431331\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.367595\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.377098\n",
      "epoch 2; iter: 0; batch classifier loss: 0.428724\n",
      "epoch 2; iter: 200; batch classifier loss: 0.437070\n",
      "epoch 2; iter: 400; batch classifier loss: 0.397772\n",
      "epoch 2; iter: 600; batch classifier loss: 0.398016\n",
      "epoch 2; iter: 800; batch classifier loss: 0.387461\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.444119\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.458641\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.413245\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.448676\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.350233\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.498181\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.363325\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.348691\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.380857\n",
      "epoch 3; iter: 0; batch classifier loss: 0.372254\n",
      "epoch 3; iter: 200; batch classifier loss: 0.427411\n",
      "epoch 3; iter: 400; batch classifier loss: 0.452849\n",
      "epoch 3; iter: 600; batch classifier loss: 0.377304\n",
      "epoch 3; iter: 800; batch classifier loss: 0.415103\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.396547\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.410237\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.409793\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.522800\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.342279\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.403267\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.472361\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.395774\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.455975\n",
      "epoch 4; iter: 0; batch classifier loss: 0.363464\n",
      "epoch 4; iter: 200; batch classifier loss: 0.462301\n",
      "epoch 4; iter: 400; batch classifier loss: 0.381874\n",
      "epoch 4; iter: 600; batch classifier loss: 0.423130\n",
      "epoch 4; iter: 800; batch classifier loss: 0.415218\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.380765\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.422473\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.453765\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.358642\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.459941\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.423367\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.485947\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.394392\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.369043\n",
      "epoch 5; iter: 0; batch classifier loss: 0.435285\n",
      "epoch 5; iter: 200; batch classifier loss: 0.440307\n",
      "epoch 5; iter: 400; batch classifier loss: 0.449957\n",
      "epoch 5; iter: 600; batch classifier loss: 0.406038\n",
      "epoch 5; iter: 800; batch classifier loss: 0.441125\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.434018\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.524325\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.337228\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.351798\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.534178\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.435369\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.405566\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.421557\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.433951\n",
      "epoch 6; iter: 0; batch classifier loss: 0.491940\n",
      "epoch 6; iter: 200; batch classifier loss: 0.419545\n",
      "epoch 6; iter: 400; batch classifier loss: 0.366807\n",
      "epoch 6; iter: 600; batch classifier loss: 0.421794\n",
      "epoch 6; iter: 800; batch classifier loss: 0.376574\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.405674\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.415967\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.328798\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.395890\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.477230\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.419109\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.409915\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.405311\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.406002\n",
      "epoch 7; iter: 0; batch classifier loss: 0.369816\n",
      "epoch 7; iter: 200; batch classifier loss: 0.375192\n",
      "epoch 7; iter: 400; batch classifier loss: 0.454070\n",
      "epoch 7; iter: 600; batch classifier loss: 0.369679\n",
      "epoch 7; iter: 800; batch classifier loss: 0.385708\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.455236\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.384649\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.397962\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.347821\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.411904\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.469297\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.426578\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.428227\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.388199\n",
      "epoch 8; iter: 0; batch classifier loss: 0.450799\n",
      "epoch 8; iter: 200; batch classifier loss: 0.495972\n",
      "epoch 8; iter: 400; batch classifier loss: 0.326455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 600; batch classifier loss: 0.440842\n",
      "epoch 8; iter: 800; batch classifier loss: 0.549227\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.375419\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.484012\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.460309\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.439485\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.322197\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.444040\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.409643\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.431363\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.410229\n",
      "epoch 9; iter: 0; batch classifier loss: 0.456564\n",
      "epoch 9; iter: 200; batch classifier loss: 0.478618\n",
      "epoch 9; iter: 400; batch classifier loss: 0.377491\n",
      "epoch 9; iter: 600; batch classifier loss: 0.437353\n",
      "epoch 9; iter: 800; batch classifier loss: 0.358337\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.396564\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.410556\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.453748\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.392691\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.437031\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.456905\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.490856\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.422280\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.414852\n",
      "epoch 10; iter: 0; batch classifier loss: 0.455909\n",
      "epoch 10; iter: 200; batch classifier loss: 0.401697\n",
      "epoch 10; iter: 400; batch classifier loss: 0.493837\n",
      "epoch 10; iter: 600; batch classifier loss: 0.393412\n",
      "epoch 10; iter: 800; batch classifier loss: 0.465388\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.402869\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.480536\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.383620\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.447926\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.369496\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.339215\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.505620\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.288099\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.428829\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537757\n",
      "epoch 11; iter: 200; batch classifier loss: 0.329410\n",
      "epoch 11; iter: 400; batch classifier loss: 0.371811\n",
      "epoch 11; iter: 600; batch classifier loss: 0.366603\n",
      "epoch 11; iter: 800; batch classifier loss: 0.478106\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.445786\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.475916\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.376231\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.416655\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.473957\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.433498\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.457797\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.382353\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.367666\n",
      "epoch 12; iter: 0; batch classifier loss: 0.402599\n",
      "epoch 12; iter: 200; batch classifier loss: 0.376351\n",
      "epoch 12; iter: 400; batch classifier loss: 0.434903\n",
      "epoch 12; iter: 600; batch classifier loss: 0.404708\n",
      "epoch 12; iter: 800; batch classifier loss: 0.474461\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.355453\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.466788\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.482372\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.445443\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.477011\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.434343\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.447691\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.395588\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.503600\n",
      "epoch 13; iter: 0; batch classifier loss: 0.545381\n",
      "epoch 13; iter: 200; batch classifier loss: 0.406954\n",
      "epoch 13; iter: 400; batch classifier loss: 0.432610\n",
      "epoch 13; iter: 600; batch classifier loss: 0.516551\n",
      "epoch 13; iter: 800; batch classifier loss: 0.359610\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.439146\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.370598\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.462543\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.370366\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.444759\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.440640\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.435091\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.371921\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.401629\n",
      "epoch 14; iter: 0; batch classifier loss: 0.435528\n",
      "epoch 14; iter: 200; batch classifier loss: 0.339630\n",
      "epoch 14; iter: 400; batch classifier loss: 0.406036\n",
      "epoch 14; iter: 600; batch classifier loss: 0.463959\n",
      "epoch 14; iter: 800; batch classifier loss: 0.428872\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.325317\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.400979\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.460954\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.395282\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.413513\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.333479\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.403646\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.447208\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.440909\n",
      "epoch 15; iter: 0; batch classifier loss: 0.446830\n",
      "epoch 15; iter: 200; batch classifier loss: 0.481504\n",
      "epoch 15; iter: 400; batch classifier loss: 0.460126\n",
      "epoch 15; iter: 600; batch classifier loss: 0.439674\n",
      "epoch 15; iter: 800; batch classifier loss: 0.387134\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.462903\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.491331\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.406567\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.448606\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.499148\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.342032\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.436330\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.442848\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.341563\n",
      "epoch 16; iter: 0; batch classifier loss: 0.539157\n",
      "epoch 16; iter: 200; batch classifier loss: 0.457414\n",
      "epoch 16; iter: 400; batch classifier loss: 0.390378\n",
      "epoch 16; iter: 600; batch classifier loss: 0.425038\n",
      "epoch 16; iter: 800; batch classifier loss: 0.391646\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.440712\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.450279\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.420677\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.390587\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.400723\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.468118\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.447505\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.318681\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.478311\n",
      "epoch 17; iter: 0; batch classifier loss: 0.500761\n",
      "epoch 17; iter: 200; batch classifier loss: 0.436094\n",
      "epoch 17; iter: 400; batch classifier loss: 0.353476\n",
      "epoch 17; iter: 600; batch classifier loss: 0.379007\n",
      "epoch 17; iter: 800; batch classifier loss: 0.397954\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.434289\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.455057\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.451418\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.454078\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.456897\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.409617\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.301750\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.422783\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.538931\n",
      "epoch 18; iter: 0; batch classifier loss: 0.468264\n",
      "epoch 18; iter: 200; batch classifier loss: 0.395466\n",
      "epoch 18; iter: 400; batch classifier loss: 0.435533\n",
      "epoch 18; iter: 600; batch classifier loss: 0.422691\n",
      "epoch 18; iter: 800; batch classifier loss: 0.357022\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.498520\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.427418\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.394146\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.450087\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.417836\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.423155\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.406973\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.386238\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.398649\n",
      "epoch 19; iter: 0; batch classifier loss: 0.358293\n",
      "epoch 19; iter: 200; batch classifier loss: 0.413772\n",
      "epoch 19; iter: 400; batch classifier loss: 0.412123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19; iter: 600; batch classifier loss: 0.488403\n",
      "epoch 19; iter: 800; batch classifier loss: 0.476316\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.406689\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.412112\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.438132\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.468237\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.420763\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.405894\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.378547\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.410368\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.417859\n",
      "epoch 20; iter: 0; batch classifier loss: 0.394523\n",
      "epoch 20; iter: 200; batch classifier loss: 0.350242\n",
      "epoch 20; iter: 400; batch classifier loss: 0.459345\n",
      "epoch 20; iter: 600; batch classifier loss: 0.436480\n",
      "epoch 20; iter: 800; batch classifier loss: 0.433689\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.506859\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.292707\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.367925\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.425682\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.428629\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.445498\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.400353\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.533698\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.386888\n",
      "epoch 21; iter: 0; batch classifier loss: 0.430389\n",
      "epoch 21; iter: 200; batch classifier loss: 0.365770\n",
      "epoch 21; iter: 400; batch classifier loss: 0.397942\n",
      "epoch 21; iter: 600; batch classifier loss: 0.445130\n",
      "epoch 21; iter: 800; batch classifier loss: 0.465789\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.433252\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.388269\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.427188\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.453534\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.409483\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.414490\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.617259\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.449461\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.357908\n",
      "epoch 22; iter: 0; batch classifier loss: 0.398144\n",
      "epoch 22; iter: 200; batch classifier loss: 0.430541\n",
      "epoch 22; iter: 400; batch classifier loss: 0.437284\n",
      "epoch 22; iter: 600; batch classifier loss: 0.474592\n",
      "epoch 22; iter: 800; batch classifier loss: 0.378179\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.474104\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.482126\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.382858\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.333315\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.449553\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.498472\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.335599\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.387685\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.453547\n",
      "epoch 23; iter: 0; batch classifier loss: 0.392477\n",
      "epoch 23; iter: 200; batch classifier loss: 0.395841\n",
      "epoch 23; iter: 400; batch classifier loss: 0.391954\n",
      "epoch 23; iter: 600; batch classifier loss: 0.453030\n",
      "epoch 23; iter: 800; batch classifier loss: 0.431708\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.343520\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.370414\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.422789\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.422387\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.465637\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.361859\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.469065\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.438257\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.422826\n",
      "epoch 24; iter: 0; batch classifier loss: 0.462848\n",
      "epoch 24; iter: 200; batch classifier loss: 0.394616\n",
      "epoch 24; iter: 400; batch classifier loss: 0.494354\n",
      "epoch 24; iter: 600; batch classifier loss: 0.540650\n",
      "epoch 24; iter: 800; batch classifier loss: 0.423141\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.440475\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.336799\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.427069\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.427457\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.380813\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.468115\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.354811\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.470355\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.412220\n",
      "epoch 25; iter: 0; batch classifier loss: 0.384334\n",
      "epoch 25; iter: 200; batch classifier loss: 0.388249\n",
      "epoch 25; iter: 400; batch classifier loss: 0.375039\n",
      "epoch 25; iter: 600; batch classifier loss: 0.425355\n",
      "epoch 25; iter: 800; batch classifier loss: 0.419714\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.419835\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.398734\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.467671\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.329639\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.358436\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.489299\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.375436\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.373274\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.411243\n",
      "epoch 26; iter: 0; batch classifier loss: 0.412858\n",
      "epoch 26; iter: 200; batch classifier loss: 0.413134\n",
      "epoch 26; iter: 400; batch classifier loss: 0.535181\n",
      "epoch 26; iter: 600; batch classifier loss: 0.362334\n",
      "epoch 26; iter: 800; batch classifier loss: 0.433096\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.466649\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.469747\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.393522\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.394595\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.370992\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.416593\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.425516\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.421618\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.381756\n",
      "epoch 27; iter: 0; batch classifier loss: 0.335958\n",
      "epoch 27; iter: 200; batch classifier loss: 0.475506\n",
      "epoch 27; iter: 400; batch classifier loss: 0.384750\n",
      "epoch 27; iter: 600; batch classifier loss: 0.341445\n",
      "epoch 27; iter: 800; batch classifier loss: 0.387135\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.310850\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.429104\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.338496\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.399828\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.386515\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.404585\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.372768\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.362684\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.447993\n",
      "epoch 28; iter: 0; batch classifier loss: 0.399466\n",
      "epoch 28; iter: 200; batch classifier loss: 0.403081\n",
      "epoch 28; iter: 400; batch classifier loss: 0.483433\n",
      "epoch 28; iter: 600; batch classifier loss: 0.439513\n",
      "epoch 28; iter: 800; batch classifier loss: 0.430989\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.542783\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.411096\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.406637\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.420920\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.345356\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.420946\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.420193\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.392216\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.398547\n",
      "epoch 29; iter: 0; batch classifier loss: 0.392541\n",
      "epoch 29; iter: 200; batch classifier loss: 0.334142\n",
      "epoch 29; iter: 400; batch classifier loss: 0.302176\n",
      "epoch 29; iter: 600; batch classifier loss: 0.434777\n",
      "epoch 29; iter: 800; batch classifier loss: 0.433877\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.436119\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.403472\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.337460\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.461698\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.444475\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.485185\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.403318\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.336412\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.367165\n",
      "epoch 30; iter: 0; batch classifier loss: 0.376007\n",
      "epoch 30; iter: 200; batch classifier loss: 0.446454\n",
      "epoch 30; iter: 400; batch classifier loss: 0.455038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 600; batch classifier loss: 0.458503\n",
      "epoch 30; iter: 800; batch classifier loss: 0.443069\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.420524\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.380066\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.367959\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.366320\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.399896\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.412299\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.331084\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.410001\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.398753\n",
      "epoch 31; iter: 0; batch classifier loss: 0.442429\n",
      "epoch 31; iter: 200; batch classifier loss: 0.433355\n",
      "epoch 31; iter: 400; batch classifier loss: 0.470529\n",
      "epoch 31; iter: 600; batch classifier loss: 0.448952\n",
      "epoch 31; iter: 800; batch classifier loss: 0.364250\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.374061\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.382711\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.435612\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.444667\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.444690\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.442020\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.426186\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.323440\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.441227\n",
      "epoch 32; iter: 0; batch classifier loss: 0.393978\n",
      "epoch 32; iter: 200; batch classifier loss: 0.414287\n",
      "epoch 32; iter: 400; batch classifier loss: 0.433053\n",
      "epoch 32; iter: 600; batch classifier loss: 0.526648\n",
      "epoch 32; iter: 800; batch classifier loss: 0.417862\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.362391\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.421098\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.436259\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.397449\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.441178\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.351669\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.374470\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.467627\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.461177\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432676\n",
      "epoch 33; iter: 200; batch classifier loss: 0.310871\n",
      "epoch 33; iter: 400; batch classifier loss: 0.419746\n",
      "epoch 33; iter: 600; batch classifier loss: 0.446166\n",
      "epoch 33; iter: 800; batch classifier loss: 0.404919\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.378814\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.378522\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.425294\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.465301\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.413049\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.356156\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.462171\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.444451\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.461445\n",
      "epoch 34; iter: 0; batch classifier loss: 0.299056\n",
      "epoch 34; iter: 200; batch classifier loss: 0.427143\n",
      "epoch 34; iter: 400; batch classifier loss: 0.400952\n",
      "epoch 34; iter: 600; batch classifier loss: 0.404555\n",
      "epoch 34; iter: 800; batch classifier loss: 0.400367\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.378258\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.472769\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.407098\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.304523\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.422071\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.344258\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.403183\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.382555\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.470925\n",
      "epoch 35; iter: 0; batch classifier loss: 0.437888\n",
      "epoch 35; iter: 200; batch classifier loss: 0.389469\n",
      "epoch 35; iter: 400; batch classifier loss: 0.420590\n",
      "epoch 35; iter: 600; batch classifier loss: 0.322504\n",
      "epoch 35; iter: 800; batch classifier loss: 0.406497\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.461973\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.348047\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.382474\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.432243\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.461073\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.405787\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.356850\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.416259\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.372373\n",
      "epoch 36; iter: 0; batch classifier loss: 0.461499\n",
      "epoch 36; iter: 200; batch classifier loss: 0.360956\n",
      "epoch 36; iter: 400; batch classifier loss: 0.350456\n",
      "epoch 36; iter: 600; batch classifier loss: 0.414990\n",
      "epoch 36; iter: 800; batch classifier loss: 0.466177\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.372378\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.388861\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.452435\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.456006\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.388970\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.416820\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.401965\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.507679\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.448436\n",
      "epoch 37; iter: 0; batch classifier loss: 0.388291\n",
      "epoch 37; iter: 200; batch classifier loss: 0.373143\n",
      "epoch 37; iter: 400; batch classifier loss: 0.400983\n",
      "epoch 37; iter: 600; batch classifier loss: 0.445709\n",
      "epoch 37; iter: 800; batch classifier loss: 0.385447\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.383138\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.393498\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.419241\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.348997\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.436784\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.458722\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.398337\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.408218\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.399104\n",
      "epoch 38; iter: 0; batch classifier loss: 0.358962\n",
      "epoch 38; iter: 200; batch classifier loss: 0.436740\n",
      "epoch 38; iter: 400; batch classifier loss: 0.460775\n",
      "epoch 38; iter: 600; batch classifier loss: 0.407698\n",
      "epoch 38; iter: 800; batch classifier loss: 0.433974\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.436898\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.392945\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.392415\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.351210\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.331197\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.371154\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.382437\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.444804\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.384819\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430359\n",
      "epoch 39; iter: 200; batch classifier loss: 0.442166\n",
      "epoch 39; iter: 400; batch classifier loss: 0.324998\n",
      "epoch 39; iter: 600; batch classifier loss: 0.328505\n",
      "epoch 39; iter: 800; batch classifier loss: 0.398547\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.497757\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.377815\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.465675\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.357561\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.381919\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.412618\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.465607\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.415749\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.409917\n",
      "epoch 40; iter: 0; batch classifier loss: 0.508862\n",
      "epoch 40; iter: 200; batch classifier loss: 0.339242\n",
      "epoch 40; iter: 400; batch classifier loss: 0.437415\n",
      "epoch 40; iter: 600; batch classifier loss: 0.376198\n",
      "epoch 40; iter: 800; batch classifier loss: 0.398426\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.376019\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.363235\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.402077\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.422556\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.473179\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.365493\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.319652\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.425545\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.347476\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410422\n",
      "epoch 41; iter: 200; batch classifier loss: 0.433649\n",
      "epoch 41; iter: 400; batch classifier loss: 0.469842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 600; batch classifier loss: 0.363901\n",
      "epoch 41; iter: 800; batch classifier loss: 0.406215\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.514498\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.441933\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.373886\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.370702\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.414930\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.519066\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.537202\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.432930\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.426078\n",
      "epoch 42; iter: 0; batch classifier loss: 0.419162\n",
      "epoch 42; iter: 200; batch classifier loss: 0.409062\n",
      "epoch 42; iter: 400; batch classifier loss: 0.445181\n",
      "epoch 42; iter: 600; batch classifier loss: 0.409917\n",
      "epoch 42; iter: 800; batch classifier loss: 0.416642\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.392224\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.401885\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.358767\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.487167\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.339112\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.404345\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.499327\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.480669\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.369011\n",
      "epoch 43; iter: 0; batch classifier loss: 0.396919\n",
      "epoch 43; iter: 200; batch classifier loss: 0.435747\n",
      "epoch 43; iter: 400; batch classifier loss: 0.375167\n",
      "epoch 43; iter: 600; batch classifier loss: 0.390310\n",
      "epoch 43; iter: 800; batch classifier loss: 0.324121\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.396147\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.450653\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.465323\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.406561\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.420057\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.465649\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.372007\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.348208\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.406087\n",
      "epoch 44; iter: 0; batch classifier loss: 0.468571\n",
      "epoch 44; iter: 200; batch classifier loss: 0.452814\n",
      "epoch 44; iter: 400; batch classifier loss: 0.451723\n",
      "epoch 44; iter: 600; batch classifier loss: 0.431120\n",
      "epoch 44; iter: 800; batch classifier loss: 0.424056\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.353342\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.362694\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.508671\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.389359\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.455616\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.397676\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.328472\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.450493\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.357943\n",
      "epoch 45; iter: 0; batch classifier loss: 0.403898\n",
      "epoch 45; iter: 200; batch classifier loss: 0.396760\n",
      "epoch 45; iter: 400; batch classifier loss: 0.358695\n",
      "epoch 45; iter: 600; batch classifier loss: 0.463225\n",
      "epoch 45; iter: 800; batch classifier loss: 0.433395\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.437471\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.383251\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.429509\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.368627\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.494848\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.450620\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.397018\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.454927\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.407997\n",
      "epoch 46; iter: 0; batch classifier loss: 0.453909\n",
      "epoch 46; iter: 200; batch classifier loss: 0.418046\n",
      "epoch 46; iter: 400; batch classifier loss: 0.354411\n",
      "epoch 46; iter: 600; batch classifier loss: 0.516012\n",
      "epoch 46; iter: 800; batch classifier loss: 0.505619\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.397552\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.421310\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.387604\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.357398\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.468850\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.369964\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.444973\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.501182\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.448583\n",
      "epoch 47; iter: 0; batch classifier loss: 0.365603\n",
      "epoch 47; iter: 200; batch classifier loss: 0.463045\n",
      "epoch 47; iter: 400; batch classifier loss: 0.436537\n",
      "epoch 47; iter: 600; batch classifier loss: 0.414920\n",
      "epoch 47; iter: 800; batch classifier loss: 0.480664\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.389900\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.445252\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.390293\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.364933\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.423205\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.412883\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.394617\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.384334\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.388532\n",
      "epoch 48; iter: 0; batch classifier loss: 0.403675\n",
      "epoch 48; iter: 200; batch classifier loss: 0.417605\n",
      "epoch 48; iter: 400; batch classifier loss: 0.365103\n",
      "epoch 48; iter: 600; batch classifier loss: 0.448531\n",
      "epoch 48; iter: 800; batch classifier loss: 0.376637\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.469372\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.371757\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.430120\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.375915\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.383692\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.398622\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.479981\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.464978\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.366568\n",
      "epoch 49; iter: 0; batch classifier loss: 0.335920\n",
      "epoch 49; iter: 200; batch classifier loss: 0.402586\n",
      "epoch 49; iter: 400; batch classifier loss: 0.362664\n",
      "epoch 49; iter: 600; batch classifier loss: 0.367778\n",
      "epoch 49; iter: 800; batch classifier loss: 0.519981\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.461390\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.409847\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.317793\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.379106\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.455844\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.390352\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.397945\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.393326\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.474110\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698962; batch adversarial loss: 0.574076\n",
      "epoch 0; iter: 200; batch classifier loss: 0.520816; batch adversarial loss: 0.600422\n",
      "epoch 1; iter: 0; batch classifier loss: 0.469610; batch adversarial loss: 0.586997\n",
      "epoch 1; iter: 200; batch classifier loss: 0.412813; batch adversarial loss: 0.572232\n",
      "epoch 2; iter: 0; batch classifier loss: 0.382718; batch adversarial loss: 0.534201\n",
      "epoch 2; iter: 200; batch classifier loss: 0.524996; batch adversarial loss: 0.503368\n",
      "epoch 3; iter: 0; batch classifier loss: 0.522919; batch adversarial loss: 0.536570\n",
      "epoch 3; iter: 200; batch classifier loss: 0.429766; batch adversarial loss: 0.482170\n",
      "epoch 4; iter: 0; batch classifier loss: 0.518472; batch adversarial loss: 0.458510\n",
      "epoch 4; iter: 200; batch classifier loss: 0.512948; batch adversarial loss: 0.462107\n",
      "epoch 5; iter: 0; batch classifier loss: 0.415802; batch adversarial loss: 0.431589\n",
      "epoch 5; iter: 200; batch classifier loss: 0.524091; batch adversarial loss: 0.506650\n",
      "epoch 6; iter: 0; batch classifier loss: 0.463283; batch adversarial loss: 0.376479\n",
      "epoch 6; iter: 200; batch classifier loss: 0.478160; batch adversarial loss: 0.457010\n",
      "epoch 7; iter: 0; batch classifier loss: 0.503992; batch adversarial loss: 0.483025\n",
      "epoch 7; iter: 200; batch classifier loss: 0.399287; batch adversarial loss: 0.473429\n",
      "epoch 8; iter: 0; batch classifier loss: 0.446642; batch adversarial loss: 0.450801\n",
      "epoch 8; iter: 200; batch classifier loss: 0.390168; batch adversarial loss: 0.472668\n",
      "epoch 9; iter: 0; batch classifier loss: 0.449476; batch adversarial loss: 0.458880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 200; batch classifier loss: 0.294267; batch adversarial loss: 0.417629\n",
      "epoch 10; iter: 0; batch classifier loss: 0.500882; batch adversarial loss: 0.405409\n",
      "epoch 10; iter: 200; batch classifier loss: 0.472532; batch adversarial loss: 0.443059\n",
      "epoch 11; iter: 0; batch classifier loss: 0.407538; batch adversarial loss: 0.401024\n",
      "epoch 11; iter: 200; batch classifier loss: 0.431160; batch adversarial loss: 0.432530\n",
      "epoch 12; iter: 0; batch classifier loss: 0.431251; batch adversarial loss: 0.352161\n",
      "epoch 12; iter: 200; batch classifier loss: 0.379336; batch adversarial loss: 0.489623\n",
      "epoch 13; iter: 0; batch classifier loss: 0.504260; batch adversarial loss: 0.424735\n",
      "epoch 13; iter: 200; batch classifier loss: 0.430253; batch adversarial loss: 0.311171\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469361; batch adversarial loss: 0.417626\n",
      "epoch 14; iter: 200; batch classifier loss: 0.394006; batch adversarial loss: 0.453837\n",
      "epoch 15; iter: 0; batch classifier loss: 0.417296; batch adversarial loss: 0.471827\n",
      "epoch 15; iter: 200; batch classifier loss: 0.348714; batch adversarial loss: 0.473335\n",
      "epoch 16; iter: 0; batch classifier loss: 0.419434; batch adversarial loss: 0.495598\n",
      "epoch 16; iter: 200; batch classifier loss: 0.411488; batch adversarial loss: 0.452120\n",
      "epoch 17; iter: 0; batch classifier loss: 0.431375; batch adversarial loss: 0.489941\n",
      "epoch 17; iter: 200; batch classifier loss: 0.453466; batch adversarial loss: 0.369266\n",
      "epoch 18; iter: 0; batch classifier loss: 0.419752; batch adversarial loss: 0.324573\n",
      "epoch 18; iter: 200; batch classifier loss: 0.450500; batch adversarial loss: 0.411717\n",
      "epoch 19; iter: 0; batch classifier loss: 0.393409; batch adversarial loss: 0.304547\n",
      "epoch 19; iter: 200; batch classifier loss: 0.416081; batch adversarial loss: 0.394769\n",
      "epoch 20; iter: 0; batch classifier loss: 0.403388; batch adversarial loss: 0.435816\n",
      "epoch 20; iter: 200; batch classifier loss: 0.383612; batch adversarial loss: 0.356964\n",
      "epoch 21; iter: 0; batch classifier loss: 0.521067; batch adversarial loss: 0.407690\n",
      "epoch 21; iter: 200; batch classifier loss: 0.464042; batch adversarial loss: 0.395207\n",
      "epoch 22; iter: 0; batch classifier loss: 0.395936; batch adversarial loss: 0.402691\n",
      "epoch 22; iter: 200; batch classifier loss: 0.467405; batch adversarial loss: 0.378126\n",
      "epoch 23; iter: 0; batch classifier loss: 0.352440; batch adversarial loss: 0.487825\n",
      "epoch 23; iter: 200; batch classifier loss: 0.402132; batch adversarial loss: 0.415017\n",
      "epoch 24; iter: 0; batch classifier loss: 0.555053; batch adversarial loss: 0.375891\n",
      "epoch 24; iter: 200; batch classifier loss: 0.434893; batch adversarial loss: 0.362559\n",
      "epoch 25; iter: 0; batch classifier loss: 0.418452; batch adversarial loss: 0.446563\n",
      "epoch 25; iter: 200; batch classifier loss: 0.347496; batch adversarial loss: 0.395175\n",
      "epoch 26; iter: 0; batch classifier loss: 0.372615; batch adversarial loss: 0.428585\n",
      "epoch 26; iter: 200; batch classifier loss: 0.443350; batch adversarial loss: 0.351432\n",
      "epoch 27; iter: 0; batch classifier loss: 0.449020; batch adversarial loss: 0.378621\n",
      "epoch 27; iter: 200; batch classifier loss: 0.396717; batch adversarial loss: 0.357639\n",
      "epoch 28; iter: 0; batch classifier loss: 0.344677; batch adversarial loss: 0.480134\n",
      "epoch 28; iter: 200; batch classifier loss: 0.419363; batch adversarial loss: 0.407796\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452250; batch adversarial loss: 0.389014\n",
      "epoch 29; iter: 200; batch classifier loss: 0.467886; batch adversarial loss: 0.424530\n",
      "epoch 30; iter: 0; batch classifier loss: 0.344964; batch adversarial loss: 0.358778\n",
      "epoch 30; iter: 200; batch classifier loss: 0.424037; batch adversarial loss: 0.443578\n",
      "epoch 31; iter: 0; batch classifier loss: 0.471622; batch adversarial loss: 0.403684\n",
      "epoch 31; iter: 200; batch classifier loss: 0.519531; batch adversarial loss: 0.336244\n",
      "epoch 32; iter: 0; batch classifier loss: 0.516989; batch adversarial loss: 0.454980\n",
      "epoch 32; iter: 200; batch classifier loss: 0.455619; batch adversarial loss: 0.441715\n",
      "epoch 33; iter: 0; batch classifier loss: 0.384207; batch adversarial loss: 0.397712\n",
      "epoch 33; iter: 200; batch classifier loss: 0.392139; batch adversarial loss: 0.431534\n",
      "epoch 34; iter: 0; batch classifier loss: 0.350105; batch adversarial loss: 0.391437\n",
      "epoch 34; iter: 200; batch classifier loss: 0.428396; batch adversarial loss: 0.520527\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429776; batch adversarial loss: 0.403998\n",
      "epoch 35; iter: 200; batch classifier loss: 0.438072; batch adversarial loss: 0.425982\n",
      "epoch 36; iter: 0; batch classifier loss: 0.387920; batch adversarial loss: 0.447325\n",
      "epoch 36; iter: 200; batch classifier loss: 0.415280; batch adversarial loss: 0.356692\n",
      "epoch 37; iter: 0; batch classifier loss: 0.408261; batch adversarial loss: 0.497732\n",
      "epoch 37; iter: 200; batch classifier loss: 0.341188; batch adversarial loss: 0.422951\n",
      "epoch 38; iter: 0; batch classifier loss: 0.419513; batch adversarial loss: 0.461856\n",
      "epoch 38; iter: 200; batch classifier loss: 0.266608; batch adversarial loss: 0.418121\n",
      "epoch 39; iter: 0; batch classifier loss: 0.380436; batch adversarial loss: 0.488634\n",
      "epoch 39; iter: 200; batch classifier loss: 0.451531; batch adversarial loss: 0.512694\n",
      "epoch 40; iter: 0; batch classifier loss: 0.397045; batch adversarial loss: 0.443122\n",
      "epoch 40; iter: 200; batch classifier loss: 0.479577; batch adversarial loss: 0.350852\n",
      "epoch 41; iter: 0; batch classifier loss: 0.327929; batch adversarial loss: 0.501321\n",
      "epoch 41; iter: 200; batch classifier loss: 0.397021; batch adversarial loss: 0.422939\n",
      "epoch 42; iter: 0; batch classifier loss: 0.403646; batch adversarial loss: 0.352966\n",
      "epoch 42; iter: 200; batch classifier loss: 0.398180; batch adversarial loss: 0.358518\n",
      "epoch 43; iter: 0; batch classifier loss: 0.419141; batch adversarial loss: 0.487992\n",
      "epoch 43; iter: 200; batch classifier loss: 0.356211; batch adversarial loss: 0.534972\n",
      "epoch 44; iter: 0; batch classifier loss: 0.446871; batch adversarial loss: 0.430133\n",
      "epoch 44; iter: 200; batch classifier loss: 0.354835; batch adversarial loss: 0.355304\n",
      "epoch 45; iter: 0; batch classifier loss: 0.389045; batch adversarial loss: 0.343979\n",
      "epoch 45; iter: 200; batch classifier loss: 0.463072; batch adversarial loss: 0.415124\n",
      "epoch 46; iter: 0; batch classifier loss: 0.328257; batch adversarial loss: 0.403064\n",
      "epoch 46; iter: 200; batch classifier loss: 0.386427; batch adversarial loss: 0.430568\n",
      "epoch 47; iter: 0; batch classifier loss: 0.435888; batch adversarial loss: 0.482925\n",
      "epoch 47; iter: 200; batch classifier loss: 0.406990; batch adversarial loss: 0.418684\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370233; batch adversarial loss: 0.432350\n",
      "epoch 48; iter: 200; batch classifier loss: 0.461819; batch adversarial loss: 0.431297\n",
      "epoch 49; iter: 0; batch classifier loss: 0.438025; batch adversarial loss: 0.457565\n",
      "epoch 49; iter: 200; batch classifier loss: 0.386325; batch adversarial loss: 0.446650\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726290\n",
      "epoch 0; iter: 200; batch classifier loss: 0.384140\n",
      "epoch 1; iter: 0; batch classifier loss: 0.380557\n",
      "epoch 1; iter: 200; batch classifier loss: 0.391270\n",
      "epoch 2; iter: 0; batch classifier loss: 0.458631\n",
      "epoch 2; iter: 200; batch classifier loss: 0.444712\n",
      "epoch 3; iter: 0; batch classifier loss: 0.326962\n",
      "epoch 3; iter: 200; batch classifier loss: 0.389777\n",
      "epoch 4; iter: 0; batch classifier loss: 0.423588\n",
      "epoch 4; iter: 200; batch classifier loss: 0.377363\n",
      "epoch 5; iter: 0; batch classifier loss: 0.438160\n",
      "epoch 5; iter: 200; batch classifier loss: 0.381345\n",
      "epoch 6; iter: 0; batch classifier loss: 0.503974\n",
      "epoch 6; iter: 200; batch classifier loss: 0.470727\n",
      "epoch 7; iter: 0; batch classifier loss: 0.352837\n",
      "epoch 7; iter: 200; batch classifier loss: 0.348645\n",
      "epoch 8; iter: 0; batch classifier loss: 0.404981\n",
      "epoch 8; iter: 200; batch classifier loss: 0.434670\n",
      "epoch 9; iter: 0; batch classifier loss: 0.438150\n",
      "epoch 9; iter: 200; batch classifier loss: 0.501248\n",
      "epoch 10; iter: 0; batch classifier loss: 0.355024\n",
      "epoch 10; iter: 200; batch classifier loss: 0.373485\n",
      "epoch 11; iter: 0; batch classifier loss: 0.435636\n",
      "epoch 11; iter: 200; batch classifier loss: 0.420519\n",
      "epoch 12; iter: 0; batch classifier loss: 0.455795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 200; batch classifier loss: 0.381193\n",
      "epoch 13; iter: 0; batch classifier loss: 0.446340\n",
      "epoch 13; iter: 200; batch classifier loss: 0.411402\n",
      "epoch 14; iter: 0; batch classifier loss: 0.395578\n",
      "epoch 14; iter: 200; batch classifier loss: 0.473478\n",
      "epoch 15; iter: 0; batch classifier loss: 0.337440\n",
      "epoch 15; iter: 200; batch classifier loss: 0.396565\n",
      "epoch 16; iter: 0; batch classifier loss: 0.378225\n",
      "epoch 16; iter: 200; batch classifier loss: 0.464350\n",
      "epoch 17; iter: 0; batch classifier loss: 0.401117\n",
      "epoch 17; iter: 200; batch classifier loss: 0.505622\n",
      "epoch 18; iter: 0; batch classifier loss: 0.430265\n",
      "epoch 18; iter: 200; batch classifier loss: 0.382589\n",
      "epoch 19; iter: 0; batch classifier loss: 0.378249\n",
      "epoch 19; iter: 200; batch classifier loss: 0.428712\n",
      "epoch 20; iter: 0; batch classifier loss: 0.396214\n",
      "epoch 20; iter: 200; batch classifier loss: 0.451330\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495908\n",
      "epoch 21; iter: 200; batch classifier loss: 0.453868\n",
      "epoch 22; iter: 0; batch classifier loss: 0.442871\n",
      "epoch 22; iter: 200; batch classifier loss: 0.364517\n",
      "epoch 23; iter: 0; batch classifier loss: 0.373251\n",
      "epoch 23; iter: 200; batch classifier loss: 0.450389\n",
      "epoch 24; iter: 0; batch classifier loss: 0.377892\n",
      "epoch 24; iter: 200; batch classifier loss: 0.345523\n",
      "epoch 25; iter: 0; batch classifier loss: 0.444904\n",
      "epoch 25; iter: 200; batch classifier loss: 0.370242\n",
      "epoch 26; iter: 0; batch classifier loss: 0.423323\n",
      "epoch 26; iter: 200; batch classifier loss: 0.453366\n",
      "epoch 27; iter: 0; batch classifier loss: 0.427211\n",
      "epoch 27; iter: 200; batch classifier loss: 0.450444\n",
      "epoch 28; iter: 0; batch classifier loss: 0.407745\n",
      "epoch 28; iter: 200; batch classifier loss: 0.464379\n",
      "epoch 29; iter: 0; batch classifier loss: 0.316642\n",
      "epoch 29; iter: 200; batch classifier loss: 0.396404\n",
      "epoch 30; iter: 0; batch classifier loss: 0.398719\n",
      "epoch 30; iter: 200; batch classifier loss: 0.513688\n",
      "epoch 31; iter: 0; batch classifier loss: 0.378282\n",
      "epoch 31; iter: 200; batch classifier loss: 0.426632\n",
      "epoch 32; iter: 0; batch classifier loss: 0.428112\n",
      "epoch 32; iter: 200; batch classifier loss: 0.396269\n",
      "epoch 33; iter: 0; batch classifier loss: 0.383683\n",
      "epoch 33; iter: 200; batch classifier loss: 0.356494\n",
      "epoch 34; iter: 0; batch classifier loss: 0.434527\n",
      "epoch 34; iter: 200; batch classifier loss: 0.388170\n",
      "epoch 35; iter: 0; batch classifier loss: 0.425911\n",
      "epoch 35; iter: 200; batch classifier loss: 0.432669\n",
      "epoch 36; iter: 0; batch classifier loss: 0.451851\n",
      "epoch 36; iter: 200; batch classifier loss: 0.335435\n",
      "epoch 37; iter: 0; batch classifier loss: 0.363972\n",
      "epoch 37; iter: 200; batch classifier loss: 0.405223\n",
      "epoch 38; iter: 0; batch classifier loss: 0.371265\n",
      "epoch 38; iter: 200; batch classifier loss: 0.365730\n",
      "epoch 39; iter: 0; batch classifier loss: 0.423519\n",
      "epoch 39; iter: 200; batch classifier loss: 0.380734\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459559\n",
      "epoch 40; iter: 200; batch classifier loss: 0.401868\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417222\n",
      "epoch 41; iter: 200; batch classifier loss: 0.450494\n",
      "epoch 42; iter: 0; batch classifier loss: 0.380521\n",
      "epoch 42; iter: 200; batch classifier loss: 0.444995\n",
      "epoch 43; iter: 0; batch classifier loss: 0.408201\n",
      "epoch 43; iter: 200; batch classifier loss: 0.399434\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412834\n",
      "epoch 44; iter: 200; batch classifier loss: 0.428481\n",
      "epoch 45; iter: 0; batch classifier loss: 0.378454\n",
      "epoch 45; iter: 200; batch classifier loss: 0.394900\n",
      "epoch 46; iter: 0; batch classifier loss: 0.411515\n",
      "epoch 46; iter: 200; batch classifier loss: 0.353904\n",
      "epoch 47; iter: 0; batch classifier loss: 0.475558\n",
      "epoch 47; iter: 200; batch classifier loss: 0.389629\n",
      "epoch 48; iter: 0; batch classifier loss: 0.323883\n",
      "epoch 48; iter: 200; batch classifier loss: 0.409158\n",
      "epoch 49; iter: 0; batch classifier loss: 0.330929\n",
      "epoch 49; iter: 200; batch classifier loss: 0.403862\n",
      "run = 5\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672627; batch adversarial loss: 0.564852\n",
      "epoch 0; iter: 200; batch classifier loss: 0.491340; batch adversarial loss: 0.634123\n",
      "epoch 0; iter: 400; batch classifier loss: 0.475709; batch adversarial loss: 0.572122\n",
      "epoch 0; iter: 600; batch classifier loss: 0.438120; batch adversarial loss: 0.585866\n",
      "epoch 0; iter: 800; batch classifier loss: 0.496035; batch adversarial loss: 0.494028\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.413435; batch adversarial loss: 0.439515\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.445692; batch adversarial loss: 0.466783\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.496279; batch adversarial loss: 0.417071\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.458342; batch adversarial loss: 0.442306\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.484987; batch adversarial loss: 0.441336\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.456598; batch adversarial loss: 0.485294\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.413089; batch adversarial loss: 0.415026\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.457285; batch adversarial loss: 0.379830\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.442875; batch adversarial loss: 0.352102\n",
      "epoch 1; iter: 0; batch classifier loss: 0.361205; batch adversarial loss: 0.399765\n",
      "epoch 1; iter: 200; batch classifier loss: 0.364989; batch adversarial loss: 0.372899\n",
      "epoch 1; iter: 400; batch classifier loss: 0.380624; batch adversarial loss: 0.358608\n",
      "epoch 1; iter: 600; batch classifier loss: 0.416618; batch adversarial loss: 0.433685\n",
      "epoch 1; iter: 800; batch classifier loss: 0.440709; batch adversarial loss: 0.446640\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.308791; batch adversarial loss: 0.436359\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.448808; batch adversarial loss: 0.392471\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.414291; batch adversarial loss: 0.420560\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.397273; batch adversarial loss: 0.446472\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.408823; batch adversarial loss: 0.419809\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.498626; batch adversarial loss: 0.459485\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.375446; batch adversarial loss: 0.420458\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.390416; batch adversarial loss: 0.376603\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.368682; batch adversarial loss: 0.416813\n",
      "epoch 2; iter: 0; batch classifier loss: 0.366312; batch adversarial loss: 0.379323\n",
      "epoch 2; iter: 200; batch classifier loss: 0.458232; batch adversarial loss: 0.446152\n",
      "epoch 2; iter: 400; batch classifier loss: 0.365465; batch adversarial loss: 0.327771\n",
      "epoch 2; iter: 600; batch classifier loss: 0.481265; batch adversarial loss: 0.363495\n",
      "epoch 2; iter: 800; batch classifier loss: 0.494199; batch adversarial loss: 0.489512\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.326580; batch adversarial loss: 0.444676\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.396561; batch adversarial loss: 0.460277\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.441808; batch adversarial loss: 0.483444\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.498724; batch adversarial loss: 0.459819\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.527636; batch adversarial loss: 0.402054\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.372827; batch adversarial loss: 0.475684\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.460458; batch adversarial loss: 0.485320\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.441541; batch adversarial loss: 0.407162\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.407881; batch adversarial loss: 0.393171\n",
      "epoch 3; iter: 0; batch classifier loss: 0.447746; batch adversarial loss: 0.406451\n",
      "epoch 3; iter: 200; batch classifier loss: 0.438137; batch adversarial loss: 0.380129\n",
      "epoch 3; iter: 400; batch classifier loss: 0.465009; batch adversarial loss: 0.526683\n",
      "epoch 3; iter: 600; batch classifier loss: 0.459852; batch adversarial loss: 0.437443\n",
      "epoch 3; iter: 800; batch classifier loss: 0.456870; batch adversarial loss: 0.445349\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.478724; batch adversarial loss: 0.339417\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.390902; batch adversarial loss: 0.432606\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.387505; batch adversarial loss: 0.351574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 1600; batch classifier loss: 0.412614; batch adversarial loss: 0.391686\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.508578; batch adversarial loss: 0.446558\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.457282; batch adversarial loss: 0.445275\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.377737; batch adversarial loss: 0.407156\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.450464; batch adversarial loss: 0.434008\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.397640; batch adversarial loss: 0.378349\n",
      "epoch 4; iter: 0; batch classifier loss: 0.369209; batch adversarial loss: 0.404277\n",
      "epoch 4; iter: 200; batch classifier loss: 0.354221; batch adversarial loss: 0.407248\n",
      "epoch 4; iter: 400; batch classifier loss: 0.441486; batch adversarial loss: 0.379210\n",
      "epoch 4; iter: 600; batch classifier loss: 0.389741; batch adversarial loss: 0.364708\n",
      "epoch 4; iter: 800; batch classifier loss: 0.539223; batch adversarial loss: 0.446224\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.418558; batch adversarial loss: 0.452182\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.360021; batch adversarial loss: 0.377476\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.447792; batch adversarial loss: 0.448237\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.483156; batch adversarial loss: 0.435896\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.436552; batch adversarial loss: 0.485791\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.403360; batch adversarial loss: 0.477604\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.428234; batch adversarial loss: 0.403949\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.468774; batch adversarial loss: 0.432859\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.393618; batch adversarial loss: 0.417849\n",
      "epoch 5; iter: 0; batch classifier loss: 0.355948; batch adversarial loss: 0.338267\n",
      "epoch 5; iter: 200; batch classifier loss: 0.337774; batch adversarial loss: 0.554344\n",
      "epoch 5; iter: 400; batch classifier loss: 0.409162; batch adversarial loss: 0.485465\n",
      "epoch 5; iter: 600; batch classifier loss: 0.418312; batch adversarial loss: 0.421152\n",
      "epoch 5; iter: 800; batch classifier loss: 0.427768; batch adversarial loss: 0.459381\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.358951; batch adversarial loss: 0.380785\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.400146; batch adversarial loss: 0.433336\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.467841; batch adversarial loss: 0.338266\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.392065; batch adversarial loss: 0.433968\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.383809; batch adversarial loss: 0.392209\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.455464; batch adversarial loss: 0.489089\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.350092; batch adversarial loss: 0.500608\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.418792; batch adversarial loss: 0.407837\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.325946; batch adversarial loss: 0.432209\n",
      "epoch 6; iter: 0; batch classifier loss: 0.466568; batch adversarial loss: 0.338957\n",
      "epoch 6; iter: 200; batch classifier loss: 0.436664; batch adversarial loss: 0.462274\n",
      "epoch 6; iter: 400; batch classifier loss: 0.277268; batch adversarial loss: 0.311187\n",
      "epoch 6; iter: 600; batch classifier loss: 0.409770; batch adversarial loss: 0.409670\n",
      "epoch 6; iter: 800; batch classifier loss: 0.387271; batch adversarial loss: 0.435527\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.382648; batch adversarial loss: 0.502322\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.402923; batch adversarial loss: 0.391152\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.365653; batch adversarial loss: 0.336348\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.401732; batch adversarial loss: 0.337662\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.408436; batch adversarial loss: 0.474969\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.405078; batch adversarial loss: 0.460060\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.410358; batch adversarial loss: 0.365524\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.546882; batch adversarial loss: 0.422574\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.390351; batch adversarial loss: 0.435979\n",
      "epoch 7; iter: 0; batch classifier loss: 0.446506; batch adversarial loss: 0.377290\n",
      "epoch 7; iter: 200; batch classifier loss: 0.472387; batch adversarial loss: 0.430340\n",
      "epoch 7; iter: 400; batch classifier loss: 0.407345; batch adversarial loss: 0.404805\n",
      "epoch 7; iter: 600; batch classifier loss: 0.344688; batch adversarial loss: 0.376692\n",
      "epoch 7; iter: 800; batch classifier loss: 0.352463; batch adversarial loss: 0.339256\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.338344; batch adversarial loss: 0.461956\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.349489; batch adversarial loss: 0.350315\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.447575; batch adversarial loss: 0.420376\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.416371; batch adversarial loss: 0.353165\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.506489; batch adversarial loss: 0.446818\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.424550; batch adversarial loss: 0.379126\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.498807; batch adversarial loss: 0.351523\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.397632; batch adversarial loss: 0.406582\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.403159; batch adversarial loss: 0.337690\n",
      "epoch 8; iter: 0; batch classifier loss: 0.381595; batch adversarial loss: 0.405213\n",
      "epoch 8; iter: 200; batch classifier loss: 0.370885; batch adversarial loss: 0.502018\n",
      "epoch 8; iter: 400; batch classifier loss: 0.425439; batch adversarial loss: 0.449876\n",
      "epoch 8; iter: 600; batch classifier loss: 0.566621; batch adversarial loss: 0.461283\n",
      "epoch 8; iter: 800; batch classifier loss: 0.427174; batch adversarial loss: 0.516279\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.366060; batch adversarial loss: 0.379246\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.507378; batch adversarial loss: 0.463675\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.405570; batch adversarial loss: 0.391298\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.330680; batch adversarial loss: 0.461574\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.405431; batch adversarial loss: 0.461604\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.422998; batch adversarial loss: 0.420741\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.435469; batch adversarial loss: 0.419797\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.390105; batch adversarial loss: 0.353569\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.394089; batch adversarial loss: 0.422211\n",
      "epoch 9; iter: 0; batch classifier loss: 0.375678; batch adversarial loss: 0.404246\n",
      "epoch 9; iter: 200; batch classifier loss: 0.393140; batch adversarial loss: 0.488667\n",
      "epoch 9; iter: 400; batch classifier loss: 0.349483; batch adversarial loss: 0.488550\n",
      "epoch 9; iter: 600; batch classifier loss: 0.429155; batch adversarial loss: 0.336676\n",
      "epoch 9; iter: 800; batch classifier loss: 0.425622; batch adversarial loss: 0.502022\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.398912; batch adversarial loss: 0.485542\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.478532; batch adversarial loss: 0.311640\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.446060; batch adversarial loss: 0.363885\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.386172; batch adversarial loss: 0.323257\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.394338; batch adversarial loss: 0.390256\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.338352; batch adversarial loss: 0.392945\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.454938; batch adversarial loss: 0.461722\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.409649; batch adversarial loss: 0.351051\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.483784; batch adversarial loss: 0.379238\n",
      "epoch 10; iter: 0; batch classifier loss: 0.413663; batch adversarial loss: 0.473675\n",
      "epoch 10; iter: 200; batch classifier loss: 0.426100; batch adversarial loss: 0.404278\n",
      "epoch 10; iter: 400; batch classifier loss: 0.445609; batch adversarial loss: 0.419999\n",
      "epoch 10; iter: 600; batch classifier loss: 0.359658; batch adversarial loss: 0.393186\n",
      "epoch 10; iter: 800; batch classifier loss: 0.357387; batch adversarial loss: 0.461881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 1000; batch classifier loss: 0.393993; batch adversarial loss: 0.489036\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.522371; batch adversarial loss: 0.379567\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.377307; batch adversarial loss: 0.421602\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.452408; batch adversarial loss: 0.393179\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.382849; batch adversarial loss: 0.390586\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.394565; batch adversarial loss: 0.432594\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.368431; batch adversarial loss: 0.376100\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.385002; batch adversarial loss: 0.395066\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.352421; batch adversarial loss: 0.459602\n",
      "epoch 11; iter: 0; batch classifier loss: 0.472696; batch adversarial loss: 0.475458\n",
      "epoch 11; iter: 200; batch classifier loss: 0.401237; batch adversarial loss: 0.434055\n",
      "epoch 11; iter: 400; batch classifier loss: 0.446894; batch adversarial loss: 0.407539\n",
      "epoch 11; iter: 600; batch classifier loss: 0.402583; batch adversarial loss: 0.487118\n",
      "epoch 11; iter: 800; batch classifier loss: 0.346106; batch adversarial loss: 0.390205\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.473518; batch adversarial loss: 0.435151\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.458897; batch adversarial loss: 0.353192\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.291653; batch adversarial loss: 0.376467\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.354594; batch adversarial loss: 0.530608\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.455266; batch adversarial loss: 0.434633\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.404921; batch adversarial loss: 0.459095\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.441871; batch adversarial loss: 0.393415\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.353489; batch adversarial loss: 0.366038\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.455460; batch adversarial loss: 0.420990\n",
      "epoch 12; iter: 0; batch classifier loss: 0.427456; batch adversarial loss: 0.461365\n",
      "epoch 12; iter: 200; batch classifier loss: 0.380145; batch adversarial loss: 0.420763\n",
      "epoch 12; iter: 400; batch classifier loss: 0.487533; batch adversarial loss: 0.435032\n",
      "epoch 12; iter: 600; batch classifier loss: 0.474963; batch adversarial loss: 0.393841\n",
      "epoch 12; iter: 800; batch classifier loss: 0.417308; batch adversarial loss: 0.365300\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.433845; batch adversarial loss: 0.378724\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.396267; batch adversarial loss: 0.434159\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.468534; batch adversarial loss: 0.391865\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.410649; batch adversarial loss: 0.431695\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.494561; batch adversarial loss: 0.459447\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.407833; batch adversarial loss: 0.464348\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.437899; batch adversarial loss: 0.541987\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.455638; batch adversarial loss: 0.380861\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.413714; batch adversarial loss: 0.388941\n",
      "epoch 13; iter: 0; batch classifier loss: 0.400670; batch adversarial loss: 0.461196\n",
      "epoch 13; iter: 200; batch classifier loss: 0.362532; batch adversarial loss: 0.353007\n",
      "epoch 13; iter: 400; batch classifier loss: 0.450751; batch adversarial loss: 0.502416\n",
      "epoch 13; iter: 600; batch classifier loss: 0.486711; batch adversarial loss: 0.450158\n",
      "epoch 13; iter: 800; batch classifier loss: 0.476803; batch adversarial loss: 0.408657\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.371950; batch adversarial loss: 0.448125\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.494337; batch adversarial loss: 0.406340\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.396031; batch adversarial loss: 0.516902\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.461281; batch adversarial loss: 0.348161\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.495393; batch adversarial loss: 0.347752\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.374992; batch adversarial loss: 0.381016\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.429376; batch adversarial loss: 0.475171\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.440929; batch adversarial loss: 0.474949\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.479820; batch adversarial loss: 0.309620\n",
      "epoch 14; iter: 0; batch classifier loss: 0.397132; batch adversarial loss: 0.367801\n",
      "epoch 14; iter: 200; batch classifier loss: 0.581232; batch adversarial loss: 0.337303\n",
      "epoch 14; iter: 400; batch classifier loss: 0.386245; batch adversarial loss: 0.405367\n",
      "epoch 14; iter: 600; batch classifier loss: 0.463618; batch adversarial loss: 0.431454\n",
      "epoch 14; iter: 800; batch classifier loss: 0.443684; batch adversarial loss: 0.434564\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.402697; batch adversarial loss: 0.377804\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.363078; batch adversarial loss: 0.405343\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.428106; batch adversarial loss: 0.350902\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.516684; batch adversarial loss: 0.340064\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.454321; batch adversarial loss: 0.461485\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.390675; batch adversarial loss: 0.448106\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.484686; batch adversarial loss: 0.284500\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.407987; batch adversarial loss: 0.445050\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.429816; batch adversarial loss: 0.529447\n",
      "epoch 15; iter: 0; batch classifier loss: 0.414687; batch adversarial loss: 0.446876\n",
      "epoch 15; iter: 200; batch classifier loss: 0.420020; batch adversarial loss: 0.392664\n",
      "epoch 15; iter: 400; batch classifier loss: 0.435821; batch adversarial loss: 0.405398\n",
      "epoch 15; iter: 600; batch classifier loss: 0.469909; batch adversarial loss: 0.408032\n",
      "epoch 15; iter: 800; batch classifier loss: 0.477390; batch adversarial loss: 0.419224\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.434138; batch adversarial loss: 0.362760\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.369188; batch adversarial loss: 0.516636\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.391496; batch adversarial loss: 0.432558\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.421801; batch adversarial loss: 0.380221\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.476536; batch adversarial loss: 0.419119\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.410728; batch adversarial loss: 0.529566\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.395896; batch adversarial loss: 0.463106\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.432142; batch adversarial loss: 0.394929\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.363720; batch adversarial loss: 0.463187\n",
      "epoch 16; iter: 0; batch classifier loss: 0.496690; batch adversarial loss: 0.435067\n",
      "epoch 16; iter: 200; batch classifier loss: 0.448949; batch adversarial loss: 0.459845\n",
      "epoch 16; iter: 400; batch classifier loss: 0.505488; batch adversarial loss: 0.406978\n",
      "epoch 16; iter: 600; batch classifier loss: 0.387122; batch adversarial loss: 0.420415\n",
      "epoch 16; iter: 800; batch classifier loss: 0.398178; batch adversarial loss: 0.560204\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.382742; batch adversarial loss: 0.418505\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.336606; batch adversarial loss: 0.393901\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.459400; batch adversarial loss: 0.407651\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.408381; batch adversarial loss: 0.390533\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.417657; batch adversarial loss: 0.389841\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.499869; batch adversarial loss: 0.460782\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.362395; batch adversarial loss: 0.391378\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.442312; batch adversarial loss: 0.405377\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.426386; batch adversarial loss: 0.394695\n",
      "epoch 17; iter: 0; batch classifier loss: 0.397617; batch adversarial loss: 0.529131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 200; batch classifier loss: 0.409756; batch adversarial loss: 0.352407\n",
      "epoch 17; iter: 400; batch classifier loss: 0.393216; batch adversarial loss: 0.475452\n",
      "epoch 17; iter: 600; batch classifier loss: 0.455097; batch adversarial loss: 0.435866\n",
      "epoch 17; iter: 800; batch classifier loss: 0.458259; batch adversarial loss: 0.431465\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.550892; batch adversarial loss: 0.408026\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.397166; batch adversarial loss: 0.447799\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.406338; batch adversarial loss: 0.420141\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.525746; batch adversarial loss: 0.556201\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.396496; batch adversarial loss: 0.391815\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.469769; batch adversarial loss: 0.337000\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.440645; batch adversarial loss: 0.501985\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.393189; batch adversarial loss: 0.487202\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.441322; batch adversarial loss: 0.447377\n",
      "epoch 18; iter: 0; batch classifier loss: 0.414864; batch adversarial loss: 0.365494\n",
      "epoch 18; iter: 200; batch classifier loss: 0.365540; batch adversarial loss: 0.461612\n",
      "epoch 18; iter: 400; batch classifier loss: 0.428781; batch adversarial loss: 0.393251\n",
      "epoch 18; iter: 600; batch classifier loss: 0.379750; batch adversarial loss: 0.420296\n",
      "epoch 18; iter: 800; batch classifier loss: 0.365709; batch adversarial loss: 0.379386\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.400884; batch adversarial loss: 0.393068\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.408853; batch adversarial loss: 0.405422\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.370364; batch adversarial loss: 0.365990\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.602467; batch adversarial loss: 0.380111\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.436147; batch adversarial loss: 0.475509\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.496847; batch adversarial loss: 0.354426\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.482462; batch adversarial loss: 0.461270\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.442928; batch adversarial loss: 0.474916\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.421149; batch adversarial loss: 0.475898\n",
      "epoch 19; iter: 0; batch classifier loss: 0.396501; batch adversarial loss: 0.407943\n",
      "epoch 19; iter: 200; batch classifier loss: 0.387945; batch adversarial loss: 0.378311\n",
      "epoch 19; iter: 400; batch classifier loss: 0.484062; batch adversarial loss: 0.475047\n",
      "epoch 19; iter: 600; batch classifier loss: 0.515417; batch adversarial loss: 0.448745\n",
      "epoch 19; iter: 800; batch classifier loss: 0.452185; batch adversarial loss: 0.392222\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.390168; batch adversarial loss: 0.421448\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.391651; batch adversarial loss: 0.379619\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.413987; batch adversarial loss: 0.448871\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.441127; batch adversarial loss: 0.392033\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.422240; batch adversarial loss: 0.432639\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.460342; batch adversarial loss: 0.324253\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.478460; batch adversarial loss: 0.364112\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.447963; batch adversarial loss: 0.582772\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.434922; batch adversarial loss: 0.434312\n",
      "epoch 20; iter: 0; batch classifier loss: 0.398293; batch adversarial loss: 0.419672\n",
      "epoch 20; iter: 200; batch classifier loss: 0.458937; batch adversarial loss: 0.392073\n",
      "epoch 20; iter: 400; batch classifier loss: 0.419773; batch adversarial loss: 0.419073\n",
      "epoch 20; iter: 600; batch classifier loss: 0.401915; batch adversarial loss: 0.350828\n",
      "epoch 20; iter: 800; batch classifier loss: 0.402272; batch adversarial loss: 0.406930\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.475070; batch adversarial loss: 0.366629\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.514137; batch adversarial loss: 0.473852\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.345436; batch adversarial loss: 0.434703\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.312968; batch adversarial loss: 0.335550\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.387625; batch adversarial loss: 0.458406\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.453725; batch adversarial loss: 0.406152\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.539154; batch adversarial loss: 0.390940\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.376990; batch adversarial loss: 0.487462\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.417839; batch adversarial loss: 0.463008\n",
      "epoch 21; iter: 0; batch classifier loss: 0.456534; batch adversarial loss: 0.433697\n",
      "epoch 21; iter: 200; batch classifier loss: 0.412928; batch adversarial loss: 0.406186\n",
      "epoch 21; iter: 400; batch classifier loss: 0.386616; batch adversarial loss: 0.380116\n",
      "epoch 21; iter: 600; batch classifier loss: 0.455070; batch adversarial loss: 0.379503\n",
      "epoch 21; iter: 800; batch classifier loss: 0.378957; batch adversarial loss: 0.352727\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.417229; batch adversarial loss: 0.501746\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.457124; batch adversarial loss: 0.392936\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.381003; batch adversarial loss: 0.460157\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.361685; batch adversarial loss: 0.363970\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.423215; batch adversarial loss: 0.529664\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.403710; batch adversarial loss: 0.392452\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.396373; batch adversarial loss: 0.449142\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.418532; batch adversarial loss: 0.486201\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.414513; batch adversarial loss: 0.311145\n",
      "epoch 22; iter: 0; batch classifier loss: 0.360364; batch adversarial loss: 0.406603\n",
      "epoch 22; iter: 200; batch classifier loss: 0.320268; batch adversarial loss: 0.352073\n",
      "epoch 22; iter: 400; batch classifier loss: 0.360872; batch adversarial loss: 0.310247\n",
      "epoch 22; iter: 600; batch classifier loss: 0.405059; batch adversarial loss: 0.431915\n",
      "epoch 22; iter: 800; batch classifier loss: 0.395033; batch adversarial loss: 0.352238\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.430463; batch adversarial loss: 0.365227\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.434989; batch adversarial loss: 0.448469\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.408362; batch adversarial loss: 0.365288\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.366528; batch adversarial loss: 0.392911\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.436545; batch adversarial loss: 0.365936\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.440215; batch adversarial loss: 0.531234\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.395951; batch adversarial loss: 0.378076\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.493135; batch adversarial loss: 0.365647\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.457949; batch adversarial loss: 0.391899\n",
      "epoch 23; iter: 0; batch classifier loss: 0.420205; batch adversarial loss: 0.391130\n",
      "epoch 23; iter: 200; batch classifier loss: 0.345928; batch adversarial loss: 0.475021\n",
      "epoch 23; iter: 400; batch classifier loss: 0.443478; batch adversarial loss: 0.489292\n",
      "epoch 23; iter: 600; batch classifier loss: 0.378043; batch adversarial loss: 0.515798\n",
      "epoch 23; iter: 800; batch classifier loss: 0.394564; batch adversarial loss: 0.364778\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.450710; batch adversarial loss: 0.488691\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.371057; batch adversarial loss: 0.380688\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.391378; batch adversarial loss: 0.473092\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.397836; batch adversarial loss: 0.420722\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.394560; batch adversarial loss: 0.432232\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.442785; batch adversarial loss: 0.406990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 2200; batch classifier loss: 0.348924; batch adversarial loss: 0.352631\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.418382; batch adversarial loss: 0.405965\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.445844; batch adversarial loss: 0.393147\n",
      "epoch 24; iter: 0; batch classifier loss: 0.428930; batch adversarial loss: 0.255082\n",
      "epoch 24; iter: 200; batch classifier loss: 0.411209; batch adversarial loss: 0.365934\n",
      "epoch 24; iter: 400; batch classifier loss: 0.360792; batch adversarial loss: 0.485602\n",
      "epoch 24; iter: 600; batch classifier loss: 0.330672; batch adversarial loss: 0.351522\n",
      "epoch 24; iter: 800; batch classifier loss: 0.446609; batch adversarial loss: 0.436050\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.573279; batch adversarial loss: 0.404330\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.436310; batch adversarial loss: 0.420958\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.363099; batch adversarial loss: 0.366279\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.401897; batch adversarial loss: 0.394495\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.328568; batch adversarial loss: 0.419329\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.422018; batch adversarial loss: 0.432761\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.404147; batch adversarial loss: 0.488435\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.407813; batch adversarial loss: 0.379134\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.380722; batch adversarial loss: 0.461178\n",
      "epoch 25; iter: 0; batch classifier loss: 0.401803; batch adversarial loss: 0.380670\n",
      "epoch 25; iter: 200; batch classifier loss: 0.369468; batch adversarial loss: 0.431424\n",
      "epoch 25; iter: 400; batch classifier loss: 0.369389; batch adversarial loss: 0.366266\n",
      "epoch 25; iter: 600; batch classifier loss: 0.347064; batch adversarial loss: 0.448351\n",
      "epoch 25; iter: 800; batch classifier loss: 0.477140; batch adversarial loss: 0.447414\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.409429; batch adversarial loss: 0.420364\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.373287; batch adversarial loss: 0.365561\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.408401; batch adversarial loss: 0.553887\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.508812; batch adversarial loss: 0.352820\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.417138; batch adversarial loss: 0.433612\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.422771; batch adversarial loss: 0.489387\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.489551; batch adversarial loss: 0.487910\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.482914; batch adversarial loss: 0.406395\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.493655; batch adversarial loss: 0.378676\n",
      "epoch 26; iter: 0; batch classifier loss: 0.361338; batch adversarial loss: 0.310945\n",
      "epoch 26; iter: 200; batch classifier loss: 0.457600; batch adversarial loss: 0.350680\n",
      "epoch 26; iter: 400; batch classifier loss: 0.424979; batch adversarial loss: 0.435310\n",
      "epoch 26; iter: 600; batch classifier loss: 0.530418; batch adversarial loss: 0.379848\n",
      "epoch 26; iter: 800; batch classifier loss: 0.438920; batch adversarial loss: 0.488671\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.405296; batch adversarial loss: 0.378326\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.372348; batch adversarial loss: 0.404884\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.460550; batch adversarial loss: 0.379326\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.451627; batch adversarial loss: 0.434046\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.437442; batch adversarial loss: 0.390898\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.443472; batch adversarial loss: 0.378083\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.420088; batch adversarial loss: 0.392984\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.401394; batch adversarial loss: 0.502485\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.495809; batch adversarial loss: 0.325624\n",
      "epoch 27; iter: 0; batch classifier loss: 0.372510; batch adversarial loss: 0.404775\n",
      "epoch 27; iter: 200; batch classifier loss: 0.497413; batch adversarial loss: 0.434178\n",
      "epoch 27; iter: 400; batch classifier loss: 0.368999; batch adversarial loss: 0.391249\n",
      "epoch 27; iter: 600; batch classifier loss: 0.399204; batch adversarial loss: 0.324460\n",
      "epoch 27; iter: 800; batch classifier loss: 0.342827; batch adversarial loss: 0.475592\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.425567; batch adversarial loss: 0.403846\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.439091; batch adversarial loss: 0.460671\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.349079; batch adversarial loss: 0.282401\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.433511; batch adversarial loss: 0.462954\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.406008; batch adversarial loss: 0.363479\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.391597; batch adversarial loss: 0.447726\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.524451; batch adversarial loss: 0.392596\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.533467; batch adversarial loss: 0.447239\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.423680; batch adversarial loss: 0.433925\n",
      "epoch 28; iter: 0; batch classifier loss: 0.334106; batch adversarial loss: 0.433094\n",
      "epoch 28; iter: 200; batch classifier loss: 0.452508; batch adversarial loss: 0.365667\n",
      "epoch 28; iter: 400; batch classifier loss: 0.395152; batch adversarial loss: 0.335778\n",
      "epoch 28; iter: 600; batch classifier loss: 0.420881; batch adversarial loss: 0.407106\n",
      "epoch 28; iter: 800; batch classifier loss: 0.329528; batch adversarial loss: 0.434403\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.404222; batch adversarial loss: 0.529305\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.362705; batch adversarial loss: 0.407671\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.433204; batch adversarial loss: 0.473583\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.434329; batch adversarial loss: 0.364956\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.374927; batch adversarial loss: 0.309794\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.479628; batch adversarial loss: 0.349784\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.437285; batch adversarial loss: 0.311267\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.408029; batch adversarial loss: 0.406938\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.466944; batch adversarial loss: 0.378455\n",
      "epoch 29; iter: 0; batch classifier loss: 0.441971; batch adversarial loss: 0.324777\n",
      "epoch 29; iter: 200; batch classifier loss: 0.501554; batch adversarial loss: 0.392761\n",
      "epoch 29; iter: 400; batch classifier loss: 0.385547; batch adversarial loss: 0.487954\n",
      "epoch 29; iter: 600; batch classifier loss: 0.427319; batch adversarial loss: 0.489191\n",
      "epoch 29; iter: 800; batch classifier loss: 0.512539; batch adversarial loss: 0.296376\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.393103; batch adversarial loss: 0.378418\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.374915; batch adversarial loss: 0.324070\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.331543; batch adversarial loss: 0.364152\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.453622; batch adversarial loss: 0.324405\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.370118; batch adversarial loss: 0.376375\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.395232; batch adversarial loss: 0.446527\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.386984; batch adversarial loss: 0.393128\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.528017; batch adversarial loss: 0.364735\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.481538; batch adversarial loss: 0.420174\n",
      "epoch 30; iter: 0; batch classifier loss: 0.476280; batch adversarial loss: 0.406562\n",
      "epoch 30; iter: 200; batch classifier loss: 0.391354; batch adversarial loss: 0.476507\n",
      "epoch 30; iter: 400; batch classifier loss: 0.444071; batch adversarial loss: 0.406130\n",
      "epoch 30; iter: 600; batch classifier loss: 0.445859; batch adversarial loss: 0.461404\n",
      "epoch 30; iter: 800; batch classifier loss: 0.484783; batch adversarial loss: 0.405759\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.363336; batch adversarial loss: 0.407673\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.435837; batch adversarial loss: 0.349149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30; iter: 1400; batch classifier loss: 0.401183; batch adversarial loss: 0.502943\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.396506; batch adversarial loss: 0.448028\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.524855; batch adversarial loss: 0.502573\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.409324; batch adversarial loss: 0.433553\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.405267; batch adversarial loss: 0.323208\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.352275; batch adversarial loss: 0.420719\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.444998; batch adversarial loss: 0.404641\n",
      "epoch 31; iter: 0; batch classifier loss: 0.427532; batch adversarial loss: 0.475087\n",
      "epoch 31; iter: 200; batch classifier loss: 0.471403; batch adversarial loss: 0.322465\n",
      "epoch 31; iter: 400; batch classifier loss: 0.411364; batch adversarial loss: 0.391956\n",
      "epoch 31; iter: 600; batch classifier loss: 0.479381; batch adversarial loss: 0.502817\n",
      "epoch 31; iter: 800; batch classifier loss: 0.429249; batch adversarial loss: 0.363898\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.407946; batch adversarial loss: 0.433807\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.413968; batch adversarial loss: 0.541597\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.374184; batch adversarial loss: 0.420214\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.456656; batch adversarial loss: 0.462438\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.481874; batch adversarial loss: 0.310472\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.464882; batch adversarial loss: 0.460432\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.432727; batch adversarial loss: 0.309209\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.358942; batch adversarial loss: 0.421394\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.411358; batch adversarial loss: 0.353176\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459374; batch adversarial loss: 0.505895\n",
      "epoch 32; iter: 200; batch classifier loss: 0.447991; batch adversarial loss: 0.460766\n",
      "epoch 32; iter: 400; batch classifier loss: 0.389658; batch adversarial loss: 0.379260\n",
      "epoch 32; iter: 600; batch classifier loss: 0.425886; batch adversarial loss: 0.432860\n",
      "epoch 32; iter: 800; batch classifier loss: 0.357253; batch adversarial loss: 0.448720\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.388325; batch adversarial loss: 0.419404\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.471460; batch adversarial loss: 0.460467\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.455294; batch adversarial loss: 0.447469\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.396230; batch adversarial loss: 0.406933\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.451777; batch adversarial loss: 0.448592\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.401726; batch adversarial loss: 0.351198\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.382594; batch adversarial loss: 0.449441\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.438077; batch adversarial loss: 0.336021\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.453518; batch adversarial loss: 0.474828\n",
      "epoch 33; iter: 0; batch classifier loss: 0.437743; batch adversarial loss: 0.417326\n",
      "epoch 33; iter: 200; batch classifier loss: 0.397860; batch adversarial loss: 0.419752\n",
      "epoch 33; iter: 400; batch classifier loss: 0.395917; batch adversarial loss: 0.502973\n",
      "epoch 33; iter: 600; batch classifier loss: 0.393130; batch adversarial loss: 0.377805\n",
      "epoch 33; iter: 800; batch classifier loss: 0.419690; batch adversarial loss: 0.363831\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.358242; batch adversarial loss: 0.449066\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.376724; batch adversarial loss: 0.433717\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.427258; batch adversarial loss: 0.377921\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.406125; batch adversarial loss: 0.570760\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.381421; batch adversarial loss: 0.586150\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.485010; batch adversarial loss: 0.351162\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.418298; batch adversarial loss: 0.421139\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.436585; batch adversarial loss: 0.419805\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.405465; batch adversarial loss: 0.458402\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447787; batch adversarial loss: 0.474305\n",
      "epoch 34; iter: 200; batch classifier loss: 0.426734; batch adversarial loss: 0.409026\n",
      "epoch 34; iter: 400; batch classifier loss: 0.382580; batch adversarial loss: 0.475225\n",
      "epoch 34; iter: 600; batch classifier loss: 0.448688; batch adversarial loss: 0.311047\n",
      "epoch 34; iter: 800; batch classifier loss: 0.430824; batch adversarial loss: 0.476778\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.407571; batch adversarial loss: 0.379329\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.312919; batch adversarial loss: 0.406657\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.374285; batch adversarial loss: 0.433640\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.339746; batch adversarial loss: 0.432914\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.402533; batch adversarial loss: 0.323190\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.441284; batch adversarial loss: 0.420285\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.432594; batch adversarial loss: 0.377953\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.447196; batch adversarial loss: 0.461376\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.584775; batch adversarial loss: 0.503932\n",
      "epoch 35; iter: 0; batch classifier loss: 0.484293; batch adversarial loss: 0.487487\n",
      "epoch 35; iter: 200; batch classifier loss: 0.396944; batch adversarial loss: 0.432345\n",
      "epoch 35; iter: 400; batch classifier loss: 0.511462; batch adversarial loss: 0.325719\n",
      "epoch 35; iter: 600; batch classifier loss: 0.380684; batch adversarial loss: 0.435087\n",
      "epoch 35; iter: 800; batch classifier loss: 0.361186; batch adversarial loss: 0.473457\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.398496; batch adversarial loss: 0.405299\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.477732; batch adversarial loss: 0.405571\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.397931; batch adversarial loss: 0.336452\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.372330; batch adversarial loss: 0.338050\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.318693; batch adversarial loss: 0.391862\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.482921; batch adversarial loss: 0.321366\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.493691; batch adversarial loss: 0.502341\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.431501; batch adversarial loss: 0.529991\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.421343; batch adversarial loss: 0.460569\n",
      "epoch 36; iter: 0; batch classifier loss: 0.349230; batch adversarial loss: 0.419578\n",
      "epoch 36; iter: 200; batch classifier loss: 0.481290; batch adversarial loss: 0.365760\n",
      "epoch 36; iter: 400; batch classifier loss: 0.413357; batch adversarial loss: 0.407964\n",
      "epoch 36; iter: 600; batch classifier loss: 0.343469; batch adversarial loss: 0.335826\n",
      "epoch 36; iter: 800; batch classifier loss: 0.358510; batch adversarial loss: 0.449098\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.458100; batch adversarial loss: 0.457156\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.376528; batch adversarial loss: 0.352174\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.441474; batch adversarial loss: 0.352040\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.432359; batch adversarial loss: 0.375982\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.398973; batch adversarial loss: 0.350664\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.510003; batch adversarial loss: 0.431882\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.444226; batch adversarial loss: 0.418783\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.426127; batch adversarial loss: 0.487720\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.380064; batch adversarial loss: 0.419950\n",
      "epoch 37; iter: 0; batch classifier loss: 0.355507; batch adversarial loss: 0.352656\n",
      "epoch 37; iter: 200; batch classifier loss: 0.516311; batch adversarial loss: 0.381330\n",
      "epoch 37; iter: 400; batch classifier loss: 0.478583; batch adversarial loss: 0.419180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37; iter: 600; batch classifier loss: 0.466236; batch adversarial loss: 0.406269\n",
      "epoch 37; iter: 800; batch classifier loss: 0.481477; batch adversarial loss: 0.462746\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.382874; batch adversarial loss: 0.404840\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.360759; batch adversarial loss: 0.475817\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.370864; batch adversarial loss: 0.501446\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.400580; batch adversarial loss: 0.461240\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.397821; batch adversarial loss: 0.516265\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.420968; batch adversarial loss: 0.350030\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.398142; batch adversarial loss: 0.433141\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.515347; batch adversarial loss: 0.421815\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.437955; batch adversarial loss: 0.554876\n",
      "epoch 38; iter: 0; batch classifier loss: 0.390120; batch adversarial loss: 0.420044\n",
      "epoch 38; iter: 200; batch classifier loss: 0.332339; batch adversarial loss: 0.447299\n",
      "epoch 38; iter: 400; batch classifier loss: 0.453508; batch adversarial loss: 0.502892\n",
      "epoch 38; iter: 600; batch classifier loss: 0.407571; batch adversarial loss: 0.418386\n",
      "epoch 38; iter: 800; batch classifier loss: 0.435054; batch adversarial loss: 0.434774\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.356714; batch adversarial loss: 0.463553\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.455166; batch adversarial loss: 0.504967\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.409920; batch adversarial loss: 0.448651\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.423417; batch adversarial loss: 0.420078\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.373796; batch adversarial loss: 0.310597\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.463680; batch adversarial loss: 0.417177\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.407131; batch adversarial loss: 0.378660\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.353838; batch adversarial loss: 0.434611\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.413851; batch adversarial loss: 0.309810\n",
      "epoch 39; iter: 0; batch classifier loss: 0.353632; batch adversarial loss: 0.420426\n",
      "epoch 39; iter: 200; batch classifier loss: 0.432817; batch adversarial loss: 0.323582\n",
      "epoch 39; iter: 400; batch classifier loss: 0.447991; batch adversarial loss: 0.379521\n",
      "epoch 39; iter: 600; batch classifier loss: 0.413618; batch adversarial loss: 0.335714\n",
      "epoch 39; iter: 800; batch classifier loss: 0.409581; batch adversarial loss: 0.461108\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.512425; batch adversarial loss: 0.488623\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.421678; batch adversarial loss: 0.474118\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.447833; batch adversarial loss: 0.486963\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.360685; batch adversarial loss: 0.448585\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.436309; batch adversarial loss: 0.420222\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.435793; batch adversarial loss: 0.323433\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.324422; batch adversarial loss: 0.363630\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.380379; batch adversarial loss: 0.420080\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.390459; batch adversarial loss: 0.461703\n",
      "epoch 40; iter: 0; batch classifier loss: 0.477811; batch adversarial loss: 0.349939\n",
      "epoch 40; iter: 200; batch classifier loss: 0.399658; batch adversarial loss: 0.543313\n",
      "epoch 40; iter: 400; batch classifier loss: 0.497036; batch adversarial loss: 0.407414\n",
      "epoch 40; iter: 600; batch classifier loss: 0.371954; batch adversarial loss: 0.407857\n",
      "epoch 40; iter: 800; batch classifier loss: 0.391672; batch adversarial loss: 0.448512\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.520940; batch adversarial loss: 0.419015\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.430472; batch adversarial loss: 0.311112\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.510705; batch adversarial loss: 0.474223\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.380273; batch adversarial loss: 0.434217\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.419265; batch adversarial loss: 0.324639\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.475854; batch adversarial loss: 0.417921\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.458978; batch adversarial loss: 0.325190\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.451575; batch adversarial loss: 0.378568\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.420911; batch adversarial loss: 0.377847\n",
      "epoch 41; iter: 0; batch classifier loss: 0.421820; batch adversarial loss: 0.394065\n",
      "epoch 41; iter: 200; batch classifier loss: 0.447960; batch adversarial loss: 0.294829\n",
      "epoch 41; iter: 400; batch classifier loss: 0.430742; batch adversarial loss: 0.419729\n",
      "epoch 41; iter: 600; batch classifier loss: 0.502470; batch adversarial loss: 0.405443\n",
      "epoch 41; iter: 800; batch classifier loss: 0.398608; batch adversarial loss: 0.392761\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.505939; batch adversarial loss: 0.420685\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.486394; batch adversarial loss: 0.404573\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.359637; batch adversarial loss: 0.461634\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.395533; batch adversarial loss: 0.448118\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.464396; batch adversarial loss: 0.476538\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.390238; batch adversarial loss: 0.403824\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.397018; batch adversarial loss: 0.446171\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.388192; batch adversarial loss: 0.366986\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.444358; batch adversarial loss: 0.351221\n",
      "epoch 42; iter: 0; batch classifier loss: 0.347132; batch adversarial loss: 0.446196\n",
      "epoch 42; iter: 200; batch classifier loss: 0.412582; batch adversarial loss: 0.350617\n",
      "epoch 42; iter: 400; batch classifier loss: 0.402751; batch adversarial loss: 0.379113\n",
      "epoch 42; iter: 600; batch classifier loss: 0.407064; batch adversarial loss: 0.503807\n",
      "epoch 42; iter: 800; batch classifier loss: 0.520002; batch adversarial loss: 0.378424\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.457492; batch adversarial loss: 0.476026\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.437147; batch adversarial loss: 0.434105\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.377618; batch adversarial loss: 0.544826\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.341219; batch adversarial loss: 0.392072\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.349705; batch adversarial loss: 0.350667\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.498116; batch adversarial loss: 0.458960\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.378969; batch adversarial loss: 0.433074\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.442457; batch adversarial loss: 0.407459\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.397407; batch adversarial loss: 0.394080\n",
      "epoch 43; iter: 0; batch classifier loss: 0.376844; batch adversarial loss: 0.294756\n",
      "epoch 43; iter: 200; batch classifier loss: 0.423382; batch adversarial loss: 0.556705\n",
      "epoch 43; iter: 400; batch classifier loss: 0.491636; batch adversarial loss: 0.392097\n",
      "epoch 43; iter: 600; batch classifier loss: 0.441273; batch adversarial loss: 0.323872\n",
      "epoch 43; iter: 800; batch classifier loss: 0.374801; batch adversarial loss: 0.459479\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.405526; batch adversarial loss: 0.379403\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.329179; batch adversarial loss: 0.461355\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.398805; batch adversarial loss: 0.448390\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.416312; batch adversarial loss: 0.406593\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.450493; batch adversarial loss: 0.461222\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.406101; batch adversarial loss: 0.543888\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.324148; batch adversarial loss: 0.447128\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.423929; batch adversarial loss: 0.459424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43; iter: 2600; batch classifier loss: 0.418869; batch adversarial loss: 0.434097\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414209; batch adversarial loss: 0.390659\n",
      "epoch 44; iter: 200; batch classifier loss: 0.376829; batch adversarial loss: 0.462257\n",
      "epoch 44; iter: 400; batch classifier loss: 0.340818; batch adversarial loss: 0.403950\n",
      "epoch 44; iter: 600; batch classifier loss: 0.476697; batch adversarial loss: 0.543529\n",
      "epoch 44; iter: 800; batch classifier loss: 0.375934; batch adversarial loss: 0.406937\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.383629; batch adversarial loss: 0.460601\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.419469; batch adversarial loss: 0.338022\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.433416; batch adversarial loss: 0.490134\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.422416; batch adversarial loss: 0.448563\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.322611; batch adversarial loss: 0.570813\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.409419; batch adversarial loss: 0.350620\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.541709; batch adversarial loss: 0.459156\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.422211; batch adversarial loss: 0.430838\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.524742; batch adversarial loss: 0.324828\n",
      "epoch 45; iter: 0; batch classifier loss: 0.374252; batch adversarial loss: 0.447051\n",
      "epoch 45; iter: 200; batch classifier loss: 0.441745; batch adversarial loss: 0.391292\n",
      "epoch 45; iter: 400; batch classifier loss: 0.484113; batch adversarial loss: 0.433535\n",
      "epoch 45; iter: 600; batch classifier loss: 0.376842; batch adversarial loss: 0.461553\n",
      "epoch 45; iter: 800; batch classifier loss: 0.356527; batch adversarial loss: 0.364606\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.420776; batch adversarial loss: 0.434535\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.455377; batch adversarial loss: 0.434901\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.404522; batch adversarial loss: 0.365964\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.426188; batch adversarial loss: 0.351696\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.375637; batch adversarial loss: 0.337036\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.382143; batch adversarial loss: 0.489165\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.404881; batch adversarial loss: 0.393737\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.365010; batch adversarial loss: 0.364939\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.383296; batch adversarial loss: 0.462883\n",
      "epoch 46; iter: 0; batch classifier loss: 0.390853; batch adversarial loss: 0.448037\n",
      "epoch 46; iter: 200; batch classifier loss: 0.419002; batch adversarial loss: 0.433968\n",
      "epoch 46; iter: 400; batch classifier loss: 0.397532; batch adversarial loss: 0.350910\n",
      "epoch 46; iter: 600; batch classifier loss: 0.453300; batch adversarial loss: 0.461210\n",
      "epoch 46; iter: 800; batch classifier loss: 0.535005; batch adversarial loss: 0.393008\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.426115; batch adversarial loss: 0.366501\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.481258; batch adversarial loss: 0.433727\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.421687; batch adversarial loss: 0.419094\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.429930; batch adversarial loss: 0.392756\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.403722; batch adversarial loss: 0.432239\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.456859; batch adversarial loss: 0.392668\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.439796; batch adversarial loss: 0.378398\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.420152; batch adversarial loss: 0.528699\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.372394; batch adversarial loss: 0.419125\n",
      "epoch 47; iter: 0; batch classifier loss: 0.330438; batch adversarial loss: 0.419628\n",
      "epoch 47; iter: 200; batch classifier loss: 0.465031; batch adversarial loss: 0.475317\n",
      "epoch 47; iter: 400; batch classifier loss: 0.382088; batch adversarial loss: 0.447356\n",
      "epoch 47; iter: 600; batch classifier loss: 0.422700; batch adversarial loss: 0.435974\n",
      "epoch 47; iter: 800; batch classifier loss: 0.389284; batch adversarial loss: 0.421566\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.404383; batch adversarial loss: 0.365768\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.367095; batch adversarial loss: 0.350799\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.518755; batch adversarial loss: 0.418505\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.463664; batch adversarial loss: 0.405842\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.437384; batch adversarial loss: 0.446973\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.414614; batch adversarial loss: 0.378764\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.397517; batch adversarial loss: 0.476526\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.333402; batch adversarial loss: 0.324350\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.368524; batch adversarial loss: 0.475254\n",
      "epoch 48; iter: 0; batch classifier loss: 0.518492; batch adversarial loss: 0.377227\n",
      "epoch 48; iter: 200; batch classifier loss: 0.360478; batch adversarial loss: 0.486530\n",
      "epoch 48; iter: 400; batch classifier loss: 0.502652; batch adversarial loss: 0.380253\n",
      "epoch 48; iter: 600; batch classifier loss: 0.481732; batch adversarial loss: 0.448105\n",
      "epoch 48; iter: 800; batch classifier loss: 0.340176; batch adversarial loss: 0.461787\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.361312; batch adversarial loss: 0.540390\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.391526; batch adversarial loss: 0.420461\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.458200; batch adversarial loss: 0.378650\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.416746; batch adversarial loss: 0.406604\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.373840; batch adversarial loss: 0.448143\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.417564; batch adversarial loss: 0.350367\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.422396; batch adversarial loss: 0.448479\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.401470; batch adversarial loss: 0.513995\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.393641; batch adversarial loss: 0.433536\n",
      "epoch 49; iter: 0; batch classifier loss: 0.412842; batch adversarial loss: 0.446472\n",
      "epoch 49; iter: 200; batch classifier loss: 0.479170; batch adversarial loss: 0.433327\n",
      "epoch 49; iter: 400; batch classifier loss: 0.297130; batch adversarial loss: 0.416833\n",
      "epoch 49; iter: 600; batch classifier loss: 0.359870; batch adversarial loss: 0.282977\n",
      "epoch 49; iter: 800; batch classifier loss: 0.443424; batch adversarial loss: 0.435016\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.361980; batch adversarial loss: 0.350917\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.431566; batch adversarial loss: 0.460376\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.405078; batch adversarial loss: 0.309620\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.464561; batch adversarial loss: 0.502053\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.378678; batch adversarial loss: 0.407165\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.447328; batch adversarial loss: 0.351358\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.417197; batch adversarial loss: 0.393019\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.327694; batch adversarial loss: 0.434138\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.367699; batch adversarial loss: 0.420533\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696093\n",
      "epoch 0; iter: 200; batch classifier loss: 0.466490\n",
      "epoch 0; iter: 400; batch classifier loss: 0.414836\n",
      "epoch 0; iter: 600; batch classifier loss: 0.440145\n",
      "epoch 0; iter: 800; batch classifier loss: 0.370602\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.455308\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.450349\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.404667\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.477544\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.369765\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.418715\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.448187\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.483764\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.436186\n",
      "epoch 1; iter: 0; batch classifier loss: 0.357721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1; iter: 200; batch classifier loss: 0.472887\n",
      "epoch 1; iter: 400; batch classifier loss: 0.457459\n",
      "epoch 1; iter: 600; batch classifier loss: 0.471318\n",
      "epoch 1; iter: 800; batch classifier loss: 0.441592\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.453420\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.394811\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.428049\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.430602\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.457196\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.463172\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.506366\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.519234\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.337421\n",
      "epoch 2; iter: 0; batch classifier loss: 0.396517\n",
      "epoch 2; iter: 200; batch classifier loss: 0.445009\n",
      "epoch 2; iter: 400; batch classifier loss: 0.454464\n",
      "epoch 2; iter: 600; batch classifier loss: 0.429644\n",
      "epoch 2; iter: 800; batch classifier loss: 0.419915\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.507155\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.423553\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.478966\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.409244\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.398299\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.491586\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.415017\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.421604\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.329195\n",
      "epoch 3; iter: 0; batch classifier loss: 0.359896\n",
      "epoch 3; iter: 200; batch classifier loss: 0.331287\n",
      "epoch 3; iter: 400; batch classifier loss: 0.399142\n",
      "epoch 3; iter: 600; batch classifier loss: 0.384029\n",
      "epoch 3; iter: 800; batch classifier loss: 0.397094\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.317037\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.369868\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.383440\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.435497\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.458592\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.437973\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.399297\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.480533\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.452613\n",
      "epoch 4; iter: 0; batch classifier loss: 0.397898\n",
      "epoch 4; iter: 200; batch classifier loss: 0.447818\n",
      "epoch 4; iter: 400; batch classifier loss: 0.362557\n",
      "epoch 4; iter: 600; batch classifier loss: 0.389035\n",
      "epoch 4; iter: 800; batch classifier loss: 0.416542\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.392285\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.367057\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.432705\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.427418\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.434532\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.395618\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.378468\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.406547\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.414164\n",
      "epoch 5; iter: 0; batch classifier loss: 0.433292\n",
      "epoch 5; iter: 200; batch classifier loss: 0.486385\n",
      "epoch 5; iter: 400; batch classifier loss: 0.440403\n",
      "epoch 5; iter: 600; batch classifier loss: 0.420656\n",
      "epoch 5; iter: 800; batch classifier loss: 0.397152\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.451805\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.455812\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.449436\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.421102\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.310945\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.354898\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.343200\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.465069\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.363318\n",
      "epoch 6; iter: 0; batch classifier loss: 0.454518\n",
      "epoch 6; iter: 200; batch classifier loss: 0.428854\n",
      "epoch 6; iter: 400; batch classifier loss: 0.348717\n",
      "epoch 6; iter: 600; batch classifier loss: 0.482771\n",
      "epoch 6; iter: 800; batch classifier loss: 0.399751\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.389302\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.367352\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.382848\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.410429\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.393536\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.486799\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.442065\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.377410\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.429031\n",
      "epoch 7; iter: 0; batch classifier loss: 0.369936\n",
      "epoch 7; iter: 200; batch classifier loss: 0.309402\n",
      "epoch 7; iter: 400; batch classifier loss: 0.406455\n",
      "epoch 7; iter: 600; batch classifier loss: 0.475647\n",
      "epoch 7; iter: 800; batch classifier loss: 0.394362\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.491102\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.434823\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.358137\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.336731\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.424356\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.432226\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.396540\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.450482\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.442751\n",
      "epoch 8; iter: 0; batch classifier loss: 0.435751\n",
      "epoch 8; iter: 200; batch classifier loss: 0.384169\n",
      "epoch 8; iter: 400; batch classifier loss: 0.385936\n",
      "epoch 8; iter: 600; batch classifier loss: 0.349708\n",
      "epoch 8; iter: 800; batch classifier loss: 0.390203\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.460156\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.361518\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.398498\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.452512\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.480478\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.411822\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.509117\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.412132\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.420816\n",
      "epoch 9; iter: 0; batch classifier loss: 0.340367\n",
      "epoch 9; iter: 200; batch classifier loss: 0.410725\n",
      "epoch 9; iter: 400; batch classifier loss: 0.473805\n",
      "epoch 9; iter: 600; batch classifier loss: 0.432743\n",
      "epoch 9; iter: 800; batch classifier loss: 0.424411\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.341611\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.425769\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.399948\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.390484\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.374161\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.413737\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.501039\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.426522\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.457195\n",
      "epoch 10; iter: 0; batch classifier loss: 0.471154\n",
      "epoch 10; iter: 200; batch classifier loss: 0.344468\n",
      "epoch 10; iter: 400; batch classifier loss: 0.430585\n",
      "epoch 10; iter: 600; batch classifier loss: 0.424134\n",
      "epoch 10; iter: 800; batch classifier loss: 0.319375\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.443346\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.392640\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.379462\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.476067\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.413570\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.395289\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.495755\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.428147\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.429703\n",
      "epoch 11; iter: 0; batch classifier loss: 0.364421\n",
      "epoch 11; iter: 200; batch classifier loss: 0.471863\n",
      "epoch 11; iter: 400; batch classifier loss: 0.464952\n",
      "epoch 11; iter: 600; batch classifier loss: 0.374741\n",
      "epoch 11; iter: 800; batch classifier loss: 0.454944\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.379673\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.454927\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.377822\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.395137\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.350579\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.381280\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.441345\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.410993\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.374385\n",
      "epoch 12; iter: 0; batch classifier loss: 0.348618\n",
      "epoch 12; iter: 200; batch classifier loss: 0.470410\n",
      "epoch 12; iter: 400; batch classifier loss: 0.352655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 600; batch classifier loss: 0.366700\n",
      "epoch 12; iter: 800; batch classifier loss: 0.343610\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.392269\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.320826\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.460968\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.430013\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.467563\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.378475\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.443182\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.454349\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.358636\n",
      "epoch 13; iter: 0; batch classifier loss: 0.445914\n",
      "epoch 13; iter: 200; batch classifier loss: 0.369811\n",
      "epoch 13; iter: 400; batch classifier loss: 0.419605\n",
      "epoch 13; iter: 600; batch classifier loss: 0.512292\n",
      "epoch 13; iter: 800; batch classifier loss: 0.417883\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.447283\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.409705\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.411083\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.388556\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.440742\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.334269\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.433244\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.436488\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.472938\n",
      "epoch 14; iter: 0; batch classifier loss: 0.421271\n",
      "epoch 14; iter: 200; batch classifier loss: 0.454500\n",
      "epoch 14; iter: 400; batch classifier loss: 0.404199\n",
      "epoch 14; iter: 600; batch classifier loss: 0.456447\n",
      "epoch 14; iter: 800; batch classifier loss: 0.458413\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.427177\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.396494\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.401288\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.428659\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.410056\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.402770\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.380142\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.474323\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.491760\n",
      "epoch 15; iter: 0; batch classifier loss: 0.428646\n",
      "epoch 15; iter: 200; batch classifier loss: 0.418294\n",
      "epoch 15; iter: 400; batch classifier loss: 0.322095\n",
      "epoch 15; iter: 600; batch classifier loss: 0.436261\n",
      "epoch 15; iter: 800; batch classifier loss: 0.367931\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.377928\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.412666\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.349201\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.434164\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.372512\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.468189\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.353003\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.398214\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.440097\n",
      "epoch 16; iter: 0; batch classifier loss: 0.438793\n",
      "epoch 16; iter: 200; batch classifier loss: 0.457945\n",
      "epoch 16; iter: 400; batch classifier loss: 0.362698\n",
      "epoch 16; iter: 600; batch classifier loss: 0.323402\n",
      "epoch 16; iter: 800; batch classifier loss: 0.439589\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.300354\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.347172\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.453841\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.395087\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.471271\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.425385\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.494502\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.400915\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.474353\n",
      "epoch 17; iter: 0; batch classifier loss: 0.443706\n",
      "epoch 17; iter: 200; batch classifier loss: 0.374216\n",
      "epoch 17; iter: 400; batch classifier loss: 0.461125\n",
      "epoch 17; iter: 600; batch classifier loss: 0.443120\n",
      "epoch 17; iter: 800; batch classifier loss: 0.400024\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.510352\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.465392\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.373239\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.459788\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.453718\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.355736\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.454170\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.349870\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.486053\n",
      "epoch 18; iter: 0; batch classifier loss: 0.429646\n",
      "epoch 18; iter: 200; batch classifier loss: 0.400583\n",
      "epoch 18; iter: 400; batch classifier loss: 0.391766\n",
      "epoch 18; iter: 600; batch classifier loss: 0.443586\n",
      "epoch 18; iter: 800; batch classifier loss: 0.295284\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.303467\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.501016\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.403404\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.399154\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.353733\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.380861\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.451548\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.370008\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.462996\n",
      "epoch 19; iter: 0; batch classifier loss: 0.419239\n",
      "epoch 19; iter: 200; batch classifier loss: 0.417387\n",
      "epoch 19; iter: 400; batch classifier loss: 0.387276\n",
      "epoch 19; iter: 600; batch classifier loss: 0.386756\n",
      "epoch 19; iter: 800; batch classifier loss: 0.351947\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.360474\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.346734\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.430759\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.471137\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.383308\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.419326\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.370714\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.381428\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.440157\n",
      "epoch 20; iter: 0; batch classifier loss: 0.377659\n",
      "epoch 20; iter: 200; batch classifier loss: 0.418828\n",
      "epoch 20; iter: 400; batch classifier loss: 0.394089\n",
      "epoch 20; iter: 600; batch classifier loss: 0.395396\n",
      "epoch 20; iter: 800; batch classifier loss: 0.439009\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.445520\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.521291\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.431934\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.436370\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.367364\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.363334\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.444805\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.430638\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.457166\n",
      "epoch 21; iter: 0; batch classifier loss: 0.374368\n",
      "epoch 21; iter: 200; batch classifier loss: 0.465981\n",
      "epoch 21; iter: 400; batch classifier loss: 0.294941\n",
      "epoch 21; iter: 600; batch classifier loss: 0.419284\n",
      "epoch 21; iter: 800; batch classifier loss: 0.409475\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.407181\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.369959\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.436690\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.333918\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.432970\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.457025\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.509650\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.362033\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.358115\n",
      "epoch 22; iter: 0; batch classifier loss: 0.394809\n",
      "epoch 22; iter: 200; batch classifier loss: 0.353752\n",
      "epoch 22; iter: 400; batch classifier loss: 0.494086\n",
      "epoch 22; iter: 600; batch classifier loss: 0.394177\n",
      "epoch 22; iter: 800; batch classifier loss: 0.366675\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.367114\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.487289\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.442970\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.479875\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.392124\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.358716\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.389508\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.411512\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.440486\n",
      "epoch 23; iter: 0; batch classifier loss: 0.443699\n",
      "epoch 23; iter: 200; batch classifier loss: 0.412878\n",
      "epoch 23; iter: 400; batch classifier loss: 0.427721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23; iter: 600; batch classifier loss: 0.353797\n",
      "epoch 23; iter: 800; batch classifier loss: 0.351880\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.454943\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.403354\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.453742\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.361039\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.362727\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.386326\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.481018\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.421253\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.428378\n",
      "epoch 24; iter: 0; batch classifier loss: 0.373776\n",
      "epoch 24; iter: 200; batch classifier loss: 0.388621\n",
      "epoch 24; iter: 400; batch classifier loss: 0.339902\n",
      "epoch 24; iter: 600; batch classifier loss: 0.505018\n",
      "epoch 24; iter: 800; batch classifier loss: 0.398095\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.529029\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.456411\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.409700\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.352996\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.376606\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.450184\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.503386\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.416758\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.442238\n",
      "epoch 25; iter: 0; batch classifier loss: 0.486919\n",
      "epoch 25; iter: 200; batch classifier loss: 0.401641\n",
      "epoch 25; iter: 400; batch classifier loss: 0.468647\n",
      "epoch 25; iter: 600; batch classifier loss: 0.393790\n",
      "epoch 25; iter: 800; batch classifier loss: 0.456648\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.351645\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.439694\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.409193\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.459016\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.383553\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.420690\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.496299\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.456316\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.393584\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440852\n",
      "epoch 26; iter: 200; batch classifier loss: 0.355447\n",
      "epoch 26; iter: 400; batch classifier loss: 0.478583\n",
      "epoch 26; iter: 600; batch classifier loss: 0.369133\n",
      "epoch 26; iter: 800; batch classifier loss: 0.432479\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.440475\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.352917\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.441011\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.390144\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.499654\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.455750\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.320598\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.518116\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.455697\n",
      "epoch 27; iter: 0; batch classifier loss: 0.446130\n",
      "epoch 27; iter: 200; batch classifier loss: 0.422609\n",
      "epoch 27; iter: 400; batch classifier loss: 0.422338\n",
      "epoch 27; iter: 600; batch classifier loss: 0.460305\n",
      "epoch 27; iter: 800; batch classifier loss: 0.421710\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.387870\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.392432\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.468110\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.414541\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.481245\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.366676\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.353900\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.433149\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.377695\n",
      "epoch 28; iter: 0; batch classifier loss: 0.523629\n",
      "epoch 28; iter: 200; batch classifier loss: 0.402437\n",
      "epoch 28; iter: 400; batch classifier loss: 0.374851\n",
      "epoch 28; iter: 600; batch classifier loss: 0.408573\n",
      "epoch 28; iter: 800; batch classifier loss: 0.373951\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.338958\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.415018\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.395785\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.437448\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.479238\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.429037\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.475623\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.447939\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.387596\n",
      "epoch 29; iter: 0; batch classifier loss: 0.368417\n",
      "epoch 29; iter: 200; batch classifier loss: 0.463599\n",
      "epoch 29; iter: 400; batch classifier loss: 0.465655\n",
      "epoch 29; iter: 600; batch classifier loss: 0.460879\n",
      "epoch 29; iter: 800; batch classifier loss: 0.404880\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.334285\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.445308\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.418836\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.377492\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.395731\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.316226\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.407290\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.419369\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.406673\n",
      "epoch 30; iter: 0; batch classifier loss: 0.351056\n",
      "epoch 30; iter: 200; batch classifier loss: 0.420817\n",
      "epoch 30; iter: 400; batch classifier loss: 0.431613\n",
      "epoch 30; iter: 600; batch classifier loss: 0.408933\n",
      "epoch 30; iter: 800; batch classifier loss: 0.371926\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.408985\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.352115\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.366923\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.377368\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.427087\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.357026\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.396289\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.366901\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.372154\n",
      "epoch 31; iter: 0; batch classifier loss: 0.360812\n",
      "epoch 31; iter: 200; batch classifier loss: 0.430514\n",
      "epoch 31; iter: 400; batch classifier loss: 0.353622\n",
      "epoch 31; iter: 600; batch classifier loss: 0.315706\n",
      "epoch 31; iter: 800; batch classifier loss: 0.348140\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.441390\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.372878\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.461543\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.494853\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.442804\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.348985\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.424279\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.459069\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.411959\n",
      "epoch 32; iter: 0; batch classifier loss: 0.388676\n",
      "epoch 32; iter: 200; batch classifier loss: 0.358514\n",
      "epoch 32; iter: 400; batch classifier loss: 0.391177\n",
      "epoch 32; iter: 600; batch classifier loss: 0.404089\n",
      "epoch 32; iter: 800; batch classifier loss: 0.379727\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.348693\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.396520\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.455516\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.366248\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.451171\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.403179\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.440437\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.397511\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.455819\n",
      "epoch 33; iter: 0; batch classifier loss: 0.404973\n",
      "epoch 33; iter: 200; batch classifier loss: 0.343787\n",
      "epoch 33; iter: 400; batch classifier loss: 0.411548\n",
      "epoch 33; iter: 600; batch classifier loss: 0.401781\n",
      "epoch 33; iter: 800; batch classifier loss: 0.395468\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.441743\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.376792\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.437266\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.449138\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.344327\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.407997\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.439604\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.450490\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.399895\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459530\n",
      "epoch 34; iter: 200; batch classifier loss: 0.403830\n",
      "epoch 34; iter: 400; batch classifier loss: 0.405558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34; iter: 600; batch classifier loss: 0.444821\n",
      "epoch 34; iter: 800; batch classifier loss: 0.357696\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.466678\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.407482\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.414769\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.400051\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.359117\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.403685\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.509118\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.500569\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.424384\n",
      "epoch 35; iter: 0; batch classifier loss: 0.368429\n",
      "epoch 35; iter: 200; batch classifier loss: 0.347385\n",
      "epoch 35; iter: 400; batch classifier loss: 0.413184\n",
      "epoch 35; iter: 600; batch classifier loss: 0.460371\n",
      "epoch 35; iter: 800; batch classifier loss: 0.389907\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.379863\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.372679\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.491454\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.445558\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.386668\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.332938\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.483069\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.514647\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.316584\n",
      "epoch 36; iter: 0; batch classifier loss: 0.368636\n",
      "epoch 36; iter: 200; batch classifier loss: 0.477406\n",
      "epoch 36; iter: 400; batch classifier loss: 0.396526\n",
      "epoch 36; iter: 600; batch classifier loss: 0.393682\n",
      "epoch 36; iter: 800; batch classifier loss: 0.375683\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.378436\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.457320\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.302404\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.410323\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.449173\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.456255\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.414084\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.327141\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.358718\n",
      "epoch 37; iter: 0; batch classifier loss: 0.400833\n",
      "epoch 37; iter: 200; batch classifier loss: 0.462056\n",
      "epoch 37; iter: 400; batch classifier loss: 0.340739\n",
      "epoch 37; iter: 600; batch classifier loss: 0.482675\n",
      "epoch 37; iter: 800; batch classifier loss: 0.456527\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.488898\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.455005\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.478101\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.429902\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.465087\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.365719\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.368350\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.398302\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.456782\n",
      "epoch 38; iter: 0; batch classifier loss: 0.413407\n",
      "epoch 38; iter: 200; batch classifier loss: 0.313531\n",
      "epoch 38; iter: 400; batch classifier loss: 0.520177\n",
      "epoch 38; iter: 600; batch classifier loss: 0.523474\n",
      "epoch 38; iter: 800; batch classifier loss: 0.399504\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.481354\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.439828\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.338335\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.478166\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.380413\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.394525\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.417026\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.378666\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.364130\n",
      "epoch 39; iter: 0; batch classifier loss: 0.485891\n",
      "epoch 39; iter: 200; batch classifier loss: 0.387821\n",
      "epoch 39; iter: 400; batch classifier loss: 0.476796\n",
      "epoch 39; iter: 600; batch classifier loss: 0.379567\n",
      "epoch 39; iter: 800; batch classifier loss: 0.406574\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.359806\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.400862\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.400066\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.390244\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.415834\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.515180\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.344588\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.348282\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.456752\n",
      "epoch 40; iter: 0; batch classifier loss: 0.405228\n",
      "epoch 40; iter: 200; batch classifier loss: 0.455335\n",
      "epoch 40; iter: 400; batch classifier loss: 0.391478\n",
      "epoch 40; iter: 600; batch classifier loss: 0.437983\n",
      "epoch 40; iter: 800; batch classifier loss: 0.369456\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.368420\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.477246\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.314322\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.418187\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.393055\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.343519\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.444368\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.396954\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.515035\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438256\n",
      "epoch 41; iter: 200; batch classifier loss: 0.463212\n",
      "epoch 41; iter: 400; batch classifier loss: 0.403916\n",
      "epoch 41; iter: 600; batch classifier loss: 0.471091\n",
      "epoch 41; iter: 800; batch classifier loss: 0.446528\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.501624\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.394166\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.328528\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.428273\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.421032\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.339213\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.416773\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.394486\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.329206\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449294\n",
      "epoch 42; iter: 200; batch classifier loss: 0.406755\n",
      "epoch 42; iter: 400; batch classifier loss: 0.355665\n",
      "epoch 42; iter: 600; batch classifier loss: 0.445017\n",
      "epoch 42; iter: 800; batch classifier loss: 0.514788\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.432884\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.428222\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.473941\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.455471\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.458706\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.363996\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.460050\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.421630\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.417478\n",
      "epoch 43; iter: 0; batch classifier loss: 0.397639\n",
      "epoch 43; iter: 200; batch classifier loss: 0.373910\n",
      "epoch 43; iter: 400; batch classifier loss: 0.330496\n",
      "epoch 43; iter: 600; batch classifier loss: 0.424959\n",
      "epoch 43; iter: 800; batch classifier loss: 0.390263\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.388226\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.418654\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.342902\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.449775\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.344693\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.343462\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.458778\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.445323\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.384067\n",
      "epoch 44; iter: 0; batch classifier loss: 0.444237\n",
      "epoch 44; iter: 200; batch classifier loss: 0.399940\n",
      "epoch 44; iter: 400; batch classifier loss: 0.378571\n",
      "epoch 44; iter: 600; batch classifier loss: 0.319404\n",
      "epoch 44; iter: 800; batch classifier loss: 0.347389\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.482394\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.368032\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.434472\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.411080\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.402125\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.371148\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.400265\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.384177\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.399702\n",
      "epoch 45; iter: 0; batch classifier loss: 0.350029\n",
      "epoch 45; iter: 200; batch classifier loss: 0.453506\n",
      "epoch 45; iter: 400; batch classifier loss: 0.376883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 600; batch classifier loss: 0.388585\n",
      "epoch 45; iter: 800; batch classifier loss: 0.384711\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.432983\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.470714\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.397467\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.416404\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.380377\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.390949\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.395196\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.492291\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.351997\n",
      "epoch 46; iter: 0; batch classifier loss: 0.376364\n",
      "epoch 46; iter: 200; batch classifier loss: 0.431156\n",
      "epoch 46; iter: 400; batch classifier loss: 0.420484\n",
      "epoch 46; iter: 600; batch classifier loss: 0.457020\n",
      "epoch 46; iter: 800; batch classifier loss: 0.356948\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.398185\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.333829\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.406388\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.468686\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.482963\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.594383\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.397432\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.468859\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.342528\n",
      "epoch 47; iter: 0; batch classifier loss: 0.333271\n",
      "epoch 47; iter: 200; batch classifier loss: 0.498066\n",
      "epoch 47; iter: 400; batch classifier loss: 0.455197\n",
      "epoch 47; iter: 600; batch classifier loss: 0.352896\n",
      "epoch 47; iter: 800; batch classifier loss: 0.453482\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.400493\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.432970\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.330681\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.420617\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.388456\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.494036\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.341984\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.402140\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.493171\n",
      "epoch 48; iter: 0; batch classifier loss: 0.393379\n",
      "epoch 48; iter: 200; batch classifier loss: 0.394324\n",
      "epoch 48; iter: 400; batch classifier loss: 0.409659\n",
      "epoch 48; iter: 600; batch classifier loss: 0.366290\n",
      "epoch 48; iter: 800; batch classifier loss: 0.409876\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.479853\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.421475\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.354526\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.512495\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.380395\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.413921\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.424044\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.351304\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.466212\n",
      "epoch 49; iter: 0; batch classifier loss: 0.439752\n",
      "epoch 49; iter: 200; batch classifier loss: 0.398271\n",
      "epoch 49; iter: 400; batch classifier loss: 0.395700\n",
      "epoch 49; iter: 600; batch classifier loss: 0.461866\n",
      "epoch 49; iter: 800; batch classifier loss: 0.437766\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.377047\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.392185\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.431762\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.410291\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.401425\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.469166\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.396294\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.472211\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.446519\n",
      "epoch 0; iter: 0; batch classifier loss: 0.655095; batch adversarial loss: 0.707232\n",
      "epoch 0; iter: 200; batch classifier loss: 0.430628; batch adversarial loss: 0.629125\n",
      "epoch 1; iter: 0; batch classifier loss: 0.436246; batch adversarial loss: 0.624563\n",
      "epoch 1; iter: 200; batch classifier loss: 0.382062; batch adversarial loss: 0.522833\n",
      "epoch 2; iter: 0; batch classifier loss: 0.514084; batch adversarial loss: 0.557030\n",
      "epoch 2; iter: 200; batch classifier loss: 0.471014; batch adversarial loss: 0.537575\n",
      "epoch 3; iter: 0; batch classifier loss: 0.485284; batch adversarial loss: 0.514624\n",
      "epoch 3; iter: 200; batch classifier loss: 0.517010; batch adversarial loss: 0.503326\n",
      "epoch 4; iter: 0; batch classifier loss: 0.429834; batch adversarial loss: 0.514111\n",
      "epoch 4; iter: 200; batch classifier loss: 0.454049; batch adversarial loss: 0.451087\n",
      "epoch 5; iter: 0; batch classifier loss: 0.414099; batch adversarial loss: 0.554358\n",
      "epoch 5; iter: 200; batch classifier loss: 0.551631; batch adversarial loss: 0.413934\n",
      "epoch 6; iter: 0; batch classifier loss: 0.414908; batch adversarial loss: 0.413055\n",
      "epoch 6; iter: 200; batch classifier loss: 0.408146; batch adversarial loss: 0.452187\n",
      "epoch 7; iter: 0; batch classifier loss: 0.441349; batch adversarial loss: 0.526943\n",
      "epoch 7; iter: 200; batch classifier loss: 0.398162; batch adversarial loss: 0.437766\n",
      "epoch 8; iter: 0; batch classifier loss: 0.459763; batch adversarial loss: 0.423027\n",
      "epoch 8; iter: 200; batch classifier loss: 0.445979; batch adversarial loss: 0.421377\n",
      "epoch 9; iter: 0; batch classifier loss: 0.435258; batch adversarial loss: 0.377599\n",
      "epoch 9; iter: 200; batch classifier loss: 0.426423; batch adversarial loss: 0.506369\n",
      "epoch 10; iter: 0; batch classifier loss: 0.367704; batch adversarial loss: 0.380152\n",
      "epoch 10; iter: 200; batch classifier loss: 0.430004; batch adversarial loss: 0.435730\n",
      "epoch 11; iter: 0; batch classifier loss: 0.462003; batch adversarial loss: 0.450067\n",
      "epoch 11; iter: 200; batch classifier loss: 0.466658; batch adversarial loss: 0.360053\n",
      "epoch 12; iter: 0; batch classifier loss: 0.497019; batch adversarial loss: 0.440449\n",
      "epoch 12; iter: 200; batch classifier loss: 0.422238; batch adversarial loss: 0.449830\n",
      "epoch 13; iter: 0; batch classifier loss: 0.392344; batch adversarial loss: 0.450853\n",
      "epoch 13; iter: 200; batch classifier loss: 0.357329; batch adversarial loss: 0.404668\n",
      "epoch 14; iter: 0; batch classifier loss: 0.428320; batch adversarial loss: 0.400979\n",
      "epoch 14; iter: 200; batch classifier loss: 0.415545; batch adversarial loss: 0.403226\n",
      "epoch 15; iter: 0; batch classifier loss: 0.385173; batch adversarial loss: 0.340948\n",
      "epoch 15; iter: 200; batch classifier loss: 0.450238; batch adversarial loss: 0.370894\n",
      "epoch 16; iter: 0; batch classifier loss: 0.506492; batch adversarial loss: 0.454368\n",
      "epoch 16; iter: 200; batch classifier loss: 0.380218; batch adversarial loss: 0.325262\n",
      "epoch 17; iter: 0; batch classifier loss: 0.426527; batch adversarial loss: 0.381155\n",
      "epoch 17; iter: 200; batch classifier loss: 0.398302; batch adversarial loss: 0.405012\n",
      "epoch 18; iter: 0; batch classifier loss: 0.330989; batch adversarial loss: 0.469056\n",
      "epoch 18; iter: 200; batch classifier loss: 0.412649; batch adversarial loss: 0.436771\n",
      "epoch 19; iter: 0; batch classifier loss: 0.384818; batch adversarial loss: 0.341264\n",
      "epoch 19; iter: 200; batch classifier loss: 0.397738; batch adversarial loss: 0.340633\n",
      "epoch 20; iter: 0; batch classifier loss: 0.435181; batch adversarial loss: 0.478318\n",
      "epoch 20; iter: 200; batch classifier loss: 0.454637; batch adversarial loss: 0.295621\n",
      "epoch 21; iter: 0; batch classifier loss: 0.346777; batch adversarial loss: 0.411434\n",
      "epoch 21; iter: 200; batch classifier loss: 0.476942; batch adversarial loss: 0.300079\n",
      "epoch 22; iter: 0; batch classifier loss: 0.418015; batch adversarial loss: 0.371383\n",
      "epoch 22; iter: 200; batch classifier loss: 0.407008; batch adversarial loss: 0.410012\n",
      "epoch 23; iter: 0; batch classifier loss: 0.386271; batch adversarial loss: 0.594655\n",
      "epoch 23; iter: 200; batch classifier loss: 0.455136; batch adversarial loss: 0.308619\n",
      "epoch 24; iter: 0; batch classifier loss: 0.415243; batch adversarial loss: 0.436439\n",
      "epoch 24; iter: 200; batch classifier loss: 0.368211; batch adversarial loss: 0.466888\n",
      "epoch 25; iter: 0; batch classifier loss: 0.439470; batch adversarial loss: 0.374449\n",
      "epoch 25; iter: 200; batch classifier loss: 0.413148; batch adversarial loss: 0.452681\n",
      "epoch 26; iter: 0; batch classifier loss: 0.301813; batch adversarial loss: 0.425604\n",
      "epoch 26; iter: 200; batch classifier loss: 0.410989; batch adversarial loss: 0.439872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 0; batch classifier loss: 0.475928; batch adversarial loss: 0.359793\n",
      "epoch 27; iter: 200; batch classifier loss: 0.369321; batch adversarial loss: 0.413730\n",
      "epoch 28; iter: 0; batch classifier loss: 0.446312; batch adversarial loss: 0.386766\n",
      "epoch 28; iter: 200; batch classifier loss: 0.459787; batch adversarial loss: 0.466087\n",
      "epoch 29; iter: 0; batch classifier loss: 0.408498; batch adversarial loss: 0.471456\n",
      "epoch 29; iter: 200; batch classifier loss: 0.599405; batch adversarial loss: 0.516961\n",
      "epoch 30; iter: 0; batch classifier loss: 0.328561; batch adversarial loss: 0.505643\n",
      "epoch 30; iter: 200; batch classifier loss: 0.443848; batch adversarial loss: 0.468811\n",
      "epoch 31; iter: 0; batch classifier loss: 0.425914; batch adversarial loss: 0.452885\n",
      "epoch 31; iter: 200; batch classifier loss: 0.463077; batch adversarial loss: 0.506257\n",
      "epoch 32; iter: 0; batch classifier loss: 0.339487; batch adversarial loss: 0.372264\n",
      "epoch 32; iter: 200; batch classifier loss: 0.403459; batch adversarial loss: 0.453754\n",
      "epoch 33; iter: 0; batch classifier loss: 0.385800; batch adversarial loss: 0.343086\n",
      "epoch 33; iter: 200; batch classifier loss: 0.375350; batch adversarial loss: 0.405456\n",
      "epoch 34; iter: 0; batch classifier loss: 0.418717; batch adversarial loss: 0.497077\n",
      "epoch 34; iter: 200; batch classifier loss: 0.409230; batch adversarial loss: 0.326006\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442340; batch adversarial loss: 0.356746\n",
      "epoch 35; iter: 200; batch classifier loss: 0.438280; batch adversarial loss: 0.448763\n",
      "epoch 36; iter: 0; batch classifier loss: 0.380055; batch adversarial loss: 0.363450\n",
      "epoch 36; iter: 200; batch classifier loss: 0.445951; batch adversarial loss: 0.306762\n",
      "epoch 37; iter: 0; batch classifier loss: 0.344811; batch adversarial loss: 0.547347\n",
      "epoch 37; iter: 200; batch classifier loss: 0.425053; batch adversarial loss: 0.461793\n",
      "epoch 38; iter: 0; batch classifier loss: 0.472221; batch adversarial loss: 0.444519\n",
      "epoch 38; iter: 200; batch classifier loss: 0.408366; batch adversarial loss: 0.396962\n",
      "epoch 39; iter: 0; batch classifier loss: 0.396160; batch adversarial loss: 0.502196\n",
      "epoch 39; iter: 200; batch classifier loss: 0.385429; batch adversarial loss: 0.429568\n",
      "epoch 40; iter: 0; batch classifier loss: 0.394249; batch adversarial loss: 0.480969\n",
      "epoch 40; iter: 200; batch classifier loss: 0.395619; batch adversarial loss: 0.380594\n",
      "epoch 41; iter: 0; batch classifier loss: 0.382404; batch adversarial loss: 0.442282\n",
      "epoch 41; iter: 200; batch classifier loss: 0.452629; batch adversarial loss: 0.331450\n",
      "epoch 42; iter: 0; batch classifier loss: 0.357375; batch adversarial loss: 0.431269\n",
      "epoch 42; iter: 200; batch classifier loss: 0.403073; batch adversarial loss: 0.387907\n",
      "epoch 43; iter: 0; batch classifier loss: 0.339963; batch adversarial loss: 0.402297\n",
      "epoch 43; iter: 200; batch classifier loss: 0.439390; batch adversarial loss: 0.389623\n",
      "epoch 44; iter: 0; batch classifier loss: 0.397150; batch adversarial loss: 0.409452\n",
      "epoch 44; iter: 200; batch classifier loss: 0.366526; batch adversarial loss: 0.458806\n",
      "epoch 45; iter: 0; batch classifier loss: 0.401429; batch adversarial loss: 0.425013\n",
      "epoch 45; iter: 200; batch classifier loss: 0.397815; batch adversarial loss: 0.392973\n",
      "epoch 46; iter: 0; batch classifier loss: 0.470142; batch adversarial loss: 0.360511\n",
      "epoch 46; iter: 200; batch classifier loss: 0.341903; batch adversarial loss: 0.484535\n",
      "epoch 47; iter: 0; batch classifier loss: 0.416227; batch adversarial loss: 0.345536\n",
      "epoch 47; iter: 200; batch classifier loss: 0.469552; batch adversarial loss: 0.301316\n",
      "epoch 48; iter: 0; batch classifier loss: 0.390308; batch adversarial loss: 0.364073\n",
      "epoch 48; iter: 200; batch classifier loss: 0.414780; batch adversarial loss: 0.373189\n",
      "epoch 49; iter: 0; batch classifier loss: 0.378964; batch adversarial loss: 0.372121\n",
      "epoch 49; iter: 200; batch classifier loss: 0.433269; batch adversarial loss: 0.354350\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694290\n",
      "epoch 0; iter: 200; batch classifier loss: 0.442954\n",
      "epoch 1; iter: 0; batch classifier loss: 0.503744\n",
      "epoch 1; iter: 200; batch classifier loss: 0.476468\n",
      "epoch 2; iter: 0; batch classifier loss: 0.561514\n",
      "epoch 2; iter: 200; batch classifier loss: 0.451109\n",
      "epoch 3; iter: 0; batch classifier loss: 0.451708\n",
      "epoch 3; iter: 200; batch classifier loss: 0.414559\n",
      "epoch 4; iter: 0; batch classifier loss: 0.406492\n",
      "epoch 4; iter: 200; batch classifier loss: 0.484540\n",
      "epoch 5; iter: 0; batch classifier loss: 0.433785\n",
      "epoch 5; iter: 200; batch classifier loss: 0.491046\n",
      "epoch 6; iter: 0; batch classifier loss: 0.392978\n",
      "epoch 6; iter: 200; batch classifier loss: 0.508364\n",
      "epoch 7; iter: 0; batch classifier loss: 0.463994\n",
      "epoch 7; iter: 200; batch classifier loss: 0.510054\n",
      "epoch 8; iter: 0; batch classifier loss: 0.402958\n",
      "epoch 8; iter: 200; batch classifier loss: 0.444524\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434232\n",
      "epoch 9; iter: 200; batch classifier loss: 0.393632\n",
      "epoch 10; iter: 0; batch classifier loss: 0.450928\n",
      "epoch 10; iter: 200; batch classifier loss: 0.428971\n",
      "epoch 11; iter: 0; batch classifier loss: 0.520423\n",
      "epoch 11; iter: 200; batch classifier loss: 0.385294\n",
      "epoch 12; iter: 0; batch classifier loss: 0.418574\n",
      "epoch 12; iter: 200; batch classifier loss: 0.441243\n",
      "epoch 13; iter: 0; batch classifier loss: 0.405875\n",
      "epoch 13; iter: 200; batch classifier loss: 0.495646\n",
      "epoch 14; iter: 0; batch classifier loss: 0.396794\n",
      "epoch 14; iter: 200; batch classifier loss: 0.352712\n",
      "epoch 15; iter: 0; batch classifier loss: 0.330089\n",
      "epoch 15; iter: 200; batch classifier loss: 0.468902\n",
      "epoch 16; iter: 0; batch classifier loss: 0.447442\n",
      "epoch 16; iter: 200; batch classifier loss: 0.436477\n",
      "epoch 17; iter: 0; batch classifier loss: 0.366305\n",
      "epoch 17; iter: 200; batch classifier loss: 0.538517\n",
      "epoch 18; iter: 0; batch classifier loss: 0.429811\n",
      "epoch 18; iter: 200; batch classifier loss: 0.407578\n",
      "epoch 19; iter: 0; batch classifier loss: 0.520059\n",
      "epoch 19; iter: 200; batch classifier loss: 0.374035\n",
      "epoch 20; iter: 0; batch classifier loss: 0.433706\n",
      "epoch 20; iter: 200; batch classifier loss: 0.362319\n",
      "epoch 21; iter: 0; batch classifier loss: 0.408348\n",
      "epoch 21; iter: 200; batch classifier loss: 0.466181\n",
      "epoch 22; iter: 0; batch classifier loss: 0.387524\n",
      "epoch 22; iter: 200; batch classifier loss: 0.455426\n",
      "epoch 23; iter: 0; batch classifier loss: 0.441473\n",
      "epoch 23; iter: 200; batch classifier loss: 0.342119\n",
      "epoch 24; iter: 0; batch classifier loss: 0.505695\n",
      "epoch 24; iter: 200; batch classifier loss: 0.332777\n",
      "epoch 25; iter: 0; batch classifier loss: 0.420369\n",
      "epoch 25; iter: 200; batch classifier loss: 0.418513\n",
      "epoch 26; iter: 0; batch classifier loss: 0.423780\n",
      "epoch 26; iter: 200; batch classifier loss: 0.409949\n",
      "epoch 27; iter: 0; batch classifier loss: 0.354182\n",
      "epoch 27; iter: 200; batch classifier loss: 0.436759\n",
      "epoch 28; iter: 0; batch classifier loss: 0.413210\n",
      "epoch 28; iter: 200; batch classifier loss: 0.375704\n",
      "epoch 29; iter: 0; batch classifier loss: 0.352573\n",
      "epoch 29; iter: 200; batch classifier loss: 0.399968\n",
      "epoch 30; iter: 0; batch classifier loss: 0.443282\n",
      "epoch 30; iter: 200; batch classifier loss: 0.420320\n",
      "epoch 31; iter: 0; batch classifier loss: 0.445163\n",
      "epoch 31; iter: 200; batch classifier loss: 0.372099\n",
      "epoch 32; iter: 0; batch classifier loss: 0.327436\n",
      "epoch 32; iter: 200; batch classifier loss: 0.397774\n",
      "epoch 33; iter: 0; batch classifier loss: 0.350195\n",
      "epoch 33; iter: 200; batch classifier loss: 0.485762\n",
      "epoch 34; iter: 0; batch classifier loss: 0.423308\n",
      "epoch 34; iter: 200; batch classifier loss: 0.363945\n",
      "epoch 35; iter: 0; batch classifier loss: 0.382623\n",
      "epoch 35; iter: 200; batch classifier loss: 0.366757\n",
      "epoch 36; iter: 0; batch classifier loss: 0.528140\n",
      "epoch 36; iter: 200; batch classifier loss: 0.348432\n",
      "epoch 37; iter: 0; batch classifier loss: 0.409505\n",
      "epoch 37; iter: 200; batch classifier loss: 0.419002\n",
      "epoch 38; iter: 0; batch classifier loss: 0.387366\n",
      "epoch 38; iter: 200; batch classifier loss: 0.382085\n",
      "epoch 39; iter: 0; batch classifier loss: 0.437622\n",
      "epoch 39; iter: 200; batch classifier loss: 0.443054\n",
      "epoch 40; iter: 0; batch classifier loss: 0.446622\n",
      "epoch 40; iter: 200; batch classifier loss: 0.409027\n",
      "epoch 41; iter: 0; batch classifier loss: 0.418878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41; iter: 200; batch classifier loss: 0.376795\n",
      "epoch 42; iter: 0; batch classifier loss: 0.427573\n",
      "epoch 42; iter: 200; batch classifier loss: 0.468623\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414282\n",
      "epoch 43; iter: 200; batch classifier loss: 0.409048\n",
      "epoch 44; iter: 0; batch classifier loss: 0.395061\n",
      "epoch 44; iter: 200; batch classifier loss: 0.362834\n",
      "epoch 45; iter: 0; batch classifier loss: 0.483470\n",
      "epoch 45; iter: 200; batch classifier loss: 0.426596\n",
      "epoch 46; iter: 0; batch classifier loss: 0.419387\n",
      "epoch 46; iter: 200; batch classifier loss: 0.412200\n",
      "epoch 47; iter: 0; batch classifier loss: 0.476867\n",
      "epoch 47; iter: 200; batch classifier loss: 0.392815\n",
      "epoch 48; iter: 0; batch classifier loss: 0.435010\n",
      "epoch 48; iter: 200; batch classifier loss: 0.458151\n",
      "epoch 49; iter: 0; batch classifier loss: 0.397593\n",
      "epoch 49; iter: 200; batch classifier loss: 0.380089\n",
      "run = 6\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683530; batch adversarial loss: 0.855915\n",
      "epoch 0; iter: 200; batch classifier loss: 1.207313; batch adversarial loss: 0.915226\n",
      "epoch 0; iter: 400; batch classifier loss: 0.892127; batch adversarial loss: 0.705618\n",
      "epoch 0; iter: 600; batch classifier loss: 0.417085; batch adversarial loss: 0.544026\n",
      "epoch 0; iter: 800; batch classifier loss: 0.450473; batch adversarial loss: 0.528869\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.422471; batch adversarial loss: 0.529333\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.447950; batch adversarial loss: 0.474982\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.357266; batch adversarial loss: 0.552361\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.409448; batch adversarial loss: 0.537176\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.427035; batch adversarial loss: 0.395943\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.392271; batch adversarial loss: 0.392269\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.580203; batch adversarial loss: 0.526194\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.429718; batch adversarial loss: 0.442244\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.483635; batch adversarial loss: 0.330773\n",
      "epoch 1; iter: 0; batch classifier loss: 0.416656; batch adversarial loss: 0.442215\n",
      "epoch 1; iter: 200; batch classifier loss: 0.384825; batch adversarial loss: 0.509617\n",
      "epoch 1; iter: 400; batch classifier loss: 0.392753; batch adversarial loss: 0.433856\n",
      "epoch 1; iter: 600; batch classifier loss: 0.396140; batch adversarial loss: 0.353631\n",
      "epoch 1; iter: 800; batch classifier loss: 0.357422; batch adversarial loss: 0.458762\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.455954; batch adversarial loss: 0.410390\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.427996; batch adversarial loss: 0.445535\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.432958; batch adversarial loss: 0.344519\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.330866; batch adversarial loss: 0.392210\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.463519; batch adversarial loss: 0.487564\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.442079; batch adversarial loss: 0.432785\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.408607; batch adversarial loss: 0.542617\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.453266; batch adversarial loss: 0.351949\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.478819; batch adversarial loss: 0.472201\n",
      "epoch 2; iter: 0; batch classifier loss: 0.406315; batch adversarial loss: 0.368472\n",
      "epoch 2; iter: 200; batch classifier loss: 0.346665; batch adversarial loss: 0.501070\n",
      "epoch 2; iter: 400; batch classifier loss: 0.422266; batch adversarial loss: 0.407095\n",
      "epoch 2; iter: 600; batch classifier loss: 0.481010; batch adversarial loss: 0.597347\n",
      "epoch 2; iter: 800; batch classifier loss: 0.405771; batch adversarial loss: 0.351761\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.431957; batch adversarial loss: 0.392779\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.437996; batch adversarial loss: 0.392652\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.372745; batch adversarial loss: 0.338316\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.413001; batch adversarial loss: 0.418826\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.489507; batch adversarial loss: 0.365831\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.361227; batch adversarial loss: 0.433084\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.376527; batch adversarial loss: 0.435253\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.381053; batch adversarial loss: 0.323275\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.423122; batch adversarial loss: 0.365224\n",
      "epoch 3; iter: 0; batch classifier loss: 0.473747; batch adversarial loss: 0.488881\n",
      "epoch 3; iter: 200; batch classifier loss: 0.353898; batch adversarial loss: 0.476561\n",
      "epoch 3; iter: 400; batch classifier loss: 0.433698; batch adversarial loss: 0.368751\n",
      "epoch 3; iter: 600; batch classifier loss: 0.416891; batch adversarial loss: 0.269127\n",
      "epoch 3; iter: 800; batch classifier loss: 0.397863; batch adversarial loss: 0.395193\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.405170; batch adversarial loss: 0.443375\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.432259; batch adversarial loss: 0.530650\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.407046; batch adversarial loss: 0.460829\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.497407; batch adversarial loss: 0.430497\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.481497; batch adversarial loss: 0.434062\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.398801; batch adversarial loss: 0.362830\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.418906; batch adversarial loss: 0.474984\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.379876; batch adversarial loss: 0.437300\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.402288; batch adversarial loss: 0.408575\n",
      "epoch 4; iter: 0; batch classifier loss: 0.407804; batch adversarial loss: 0.326547\n",
      "epoch 4; iter: 200; batch classifier loss: 0.474618; batch adversarial loss: 0.495132\n",
      "epoch 4; iter: 400; batch classifier loss: 0.358280; batch adversarial loss: 0.367110\n",
      "epoch 4; iter: 600; batch classifier loss: 0.443780; batch adversarial loss: 0.349625\n",
      "epoch 4; iter: 800; batch classifier loss: 0.399283; batch adversarial loss: 0.432151\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.437618; batch adversarial loss: 0.526750\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.440329; batch adversarial loss: 0.517637\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.318034; batch adversarial loss: 0.381159\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.416234; batch adversarial loss: 0.506578\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.484270; batch adversarial loss: 0.507591\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.390980; batch adversarial loss: 0.449494\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.413001; batch adversarial loss: 0.421622\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.422526; batch adversarial loss: 0.544773\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.412418; batch adversarial loss: 0.441415\n",
      "epoch 5; iter: 0; batch classifier loss: 0.459003; batch adversarial loss: 0.429540\n",
      "epoch 5; iter: 200; batch classifier loss: 0.474513; batch adversarial loss: 0.294659\n",
      "epoch 5; iter: 400; batch classifier loss: 0.420096; batch adversarial loss: 0.497413\n",
      "epoch 5; iter: 600; batch classifier loss: 0.452062; batch adversarial loss: 0.465139\n",
      "epoch 5; iter: 800; batch classifier loss: 0.432806; batch adversarial loss: 0.442899\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.404941; batch adversarial loss: 0.463040\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.414603; batch adversarial loss: 0.463584\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.431878; batch adversarial loss: 0.425648\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.431962; batch adversarial loss: 0.421780\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.421143; batch adversarial loss: 0.473529\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.374673; batch adversarial loss: 0.387565\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.412239; batch adversarial loss: 0.417935\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.461056; batch adversarial loss: 0.316746\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.419115; batch adversarial loss: 0.380752\n",
      "epoch 6; iter: 0; batch classifier loss: 0.418697; batch adversarial loss: 0.366335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 200; batch classifier loss: 0.459740; batch adversarial loss: 0.450940\n",
      "epoch 6; iter: 400; batch classifier loss: 0.425156; batch adversarial loss: 0.471698\n",
      "epoch 6; iter: 600; batch classifier loss: 0.307139; batch adversarial loss: 0.373924\n",
      "epoch 6; iter: 800; batch classifier loss: 0.412943; batch adversarial loss: 0.365472\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.357325; batch adversarial loss: 0.444722\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.439417; batch adversarial loss: 0.351213\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.410800; batch adversarial loss: 0.448160\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.471508; batch adversarial loss: 0.432846\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.510282; batch adversarial loss: 0.431436\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.353841; batch adversarial loss: 0.308570\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.374721; batch adversarial loss: 0.335741\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.337937; batch adversarial loss: 0.390182\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.445541; batch adversarial loss: 0.444694\n",
      "epoch 7; iter: 0; batch classifier loss: 0.474019; batch adversarial loss: 0.455231\n",
      "epoch 7; iter: 200; batch classifier loss: 0.487469; batch adversarial loss: 0.338938\n",
      "epoch 7; iter: 400; batch classifier loss: 0.475557; batch adversarial loss: 0.358752\n",
      "epoch 7; iter: 600; batch classifier loss: 0.399496; batch adversarial loss: 0.406569\n",
      "epoch 7; iter: 800; batch classifier loss: 0.364342; batch adversarial loss: 0.449430\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.327221; batch adversarial loss: 0.393043\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.426159; batch adversarial loss: 0.541491\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.427271; batch adversarial loss: 0.434790\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.450356; batch adversarial loss: 0.379029\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.377419; batch adversarial loss: 0.432197\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.403721; batch adversarial loss: 0.365676\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.458723; batch adversarial loss: 0.505502\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.378444; batch adversarial loss: 0.493404\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.435559; batch adversarial loss: 0.435533\n",
      "epoch 8; iter: 0; batch classifier loss: 0.428762; batch adversarial loss: 0.445056\n",
      "epoch 8; iter: 200; batch classifier loss: 0.341748; batch adversarial loss: 0.547353\n",
      "epoch 8; iter: 400; batch classifier loss: 0.435529; batch adversarial loss: 0.407183\n",
      "epoch 8; iter: 600; batch classifier loss: 0.331425; batch adversarial loss: 0.403241\n",
      "epoch 8; iter: 800; batch classifier loss: 0.386858; batch adversarial loss: 0.444028\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.428753; batch adversarial loss: 0.447639\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.363481; batch adversarial loss: 0.441915\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.436242; batch adversarial loss: 0.391023\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.440908; batch adversarial loss: 0.455558\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.305071; batch adversarial loss: 0.435337\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.401055; batch adversarial loss: 0.434771\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.443766; batch adversarial loss: 0.502535\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.390779; batch adversarial loss: 0.337896\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.353155; batch adversarial loss: 0.429616\n",
      "epoch 9; iter: 0; batch classifier loss: 0.371360; batch adversarial loss: 0.500580\n",
      "epoch 9; iter: 200; batch classifier loss: 0.427295; batch adversarial loss: 0.483329\n",
      "epoch 9; iter: 400; batch classifier loss: 0.395737; batch adversarial loss: 0.406089\n",
      "epoch 9; iter: 600; batch classifier loss: 0.460816; batch adversarial loss: 0.462337\n",
      "epoch 9; iter: 800; batch classifier loss: 0.341905; batch adversarial loss: 0.485687\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.386095; batch adversarial loss: 0.433325\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.369202; batch adversarial loss: 0.384363\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.377860; batch adversarial loss: 0.426604\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.375540; batch adversarial loss: 0.474375\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.411322; batch adversarial loss: 0.362609\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.388011; batch adversarial loss: 0.383011\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.449289; batch adversarial loss: 0.461343\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.377632; batch adversarial loss: 0.391927\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.412369; batch adversarial loss: 0.379931\n",
      "epoch 10; iter: 0; batch classifier loss: 0.367638; batch adversarial loss: 0.377977\n",
      "epoch 10; iter: 200; batch classifier loss: 0.400385; batch adversarial loss: 0.455214\n",
      "epoch 10; iter: 400; batch classifier loss: 0.386078; batch adversarial loss: 0.487219\n",
      "epoch 10; iter: 600; batch classifier loss: 0.513317; batch adversarial loss: 0.377741\n",
      "epoch 10; iter: 800; batch classifier loss: 0.415826; batch adversarial loss: 0.434847\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.374487; batch adversarial loss: 0.373661\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.394152; batch adversarial loss: 0.438655\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.376156; batch adversarial loss: 0.514537\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.368066; batch adversarial loss: 0.387312\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.502111; batch adversarial loss: 0.392836\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.458716; batch adversarial loss: 0.378098\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.474510; batch adversarial loss: 0.420735\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.402616; batch adversarial loss: 0.380340\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.419685; batch adversarial loss: 0.340053\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403931; batch adversarial loss: 0.469323\n",
      "epoch 11; iter: 200; batch classifier loss: 0.451820; batch adversarial loss: 0.438256\n",
      "epoch 11; iter: 400; batch classifier loss: 0.467467; batch adversarial loss: 0.532989\n",
      "epoch 11; iter: 600; batch classifier loss: 0.380779; batch adversarial loss: 0.461464\n",
      "epoch 11; iter: 800; batch classifier loss: 0.437648; batch adversarial loss: 0.477203\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.430404; batch adversarial loss: 0.427333\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.517536; batch adversarial loss: 0.421295\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.344924; batch adversarial loss: 0.376363\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.458597; batch adversarial loss: 0.352914\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.415893; batch adversarial loss: 0.378528\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.371772; batch adversarial loss: 0.442275\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.364812; batch adversarial loss: 0.464082\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.479323; batch adversarial loss: 0.407122\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.324407; batch adversarial loss: 0.479061\n",
      "epoch 12; iter: 0; batch classifier loss: 0.402189; batch adversarial loss: 0.416386\n",
      "epoch 12; iter: 200; batch classifier loss: 0.377483; batch adversarial loss: 0.397347\n",
      "epoch 12; iter: 400; batch classifier loss: 0.429378; batch adversarial loss: 0.447080\n",
      "epoch 12; iter: 600; batch classifier loss: 0.405619; batch adversarial loss: 0.514846\n",
      "epoch 12; iter: 800; batch classifier loss: 0.481742; batch adversarial loss: 0.488748\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.407029; batch adversarial loss: 0.444564\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.475538; batch adversarial loss: 0.447054\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.374199; batch adversarial loss: 0.477563\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.378115; batch adversarial loss: 0.431158\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.353883; batch adversarial loss: 0.424473\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.423637; batch adversarial loss: 0.367300\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.452317; batch adversarial loss: 0.394212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12; iter: 2400; batch classifier loss: 0.438948; batch adversarial loss: 0.414985\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.357148; batch adversarial loss: 0.286239\n",
      "epoch 13; iter: 0; batch classifier loss: 0.347439; batch adversarial loss: 0.351148\n",
      "epoch 13; iter: 200; batch classifier loss: 0.356415; batch adversarial loss: 0.524215\n",
      "epoch 13; iter: 400; batch classifier loss: 0.551534; batch adversarial loss: 0.374644\n",
      "epoch 13; iter: 600; batch classifier loss: 0.537590; batch adversarial loss: 0.350847\n",
      "epoch 13; iter: 800; batch classifier loss: 0.475459; batch adversarial loss: 0.476679\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.439535; batch adversarial loss: 0.410172\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.369602; batch adversarial loss: 0.379139\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.380231; batch adversarial loss: 0.348547\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.495949; batch adversarial loss: 0.556997\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.386840; batch adversarial loss: 0.378007\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.395178; batch adversarial loss: 0.469198\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.370693; batch adversarial loss: 0.364834\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.534562; batch adversarial loss: 0.322486\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.362307; batch adversarial loss: 0.364024\n",
      "epoch 14; iter: 0; batch classifier loss: 0.393227; batch adversarial loss: 0.435081\n",
      "epoch 14; iter: 200; batch classifier loss: 0.480950; batch adversarial loss: 0.474266\n",
      "epoch 14; iter: 400; batch classifier loss: 0.368929; batch adversarial loss: 0.434576\n",
      "epoch 14; iter: 600; batch classifier loss: 0.390906; batch adversarial loss: 0.492213\n",
      "epoch 14; iter: 800; batch classifier loss: 0.441176; batch adversarial loss: 0.369601\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.395494; batch adversarial loss: 0.431622\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.400328; batch adversarial loss: 0.405793\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.402823; batch adversarial loss: 0.512963\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.484399; batch adversarial loss: 0.463045\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.448394; batch adversarial loss: 0.483839\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.438847; batch adversarial loss: 0.337220\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.488321; batch adversarial loss: 0.420832\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.385975; batch adversarial loss: 0.285977\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.419398; batch adversarial loss: 0.419464\n",
      "epoch 15; iter: 0; batch classifier loss: 0.381054; batch adversarial loss: 0.416034\n",
      "epoch 15; iter: 200; batch classifier loss: 0.421667; batch adversarial loss: 0.440436\n",
      "epoch 15; iter: 400; batch classifier loss: 0.472450; batch adversarial loss: 0.412810\n",
      "epoch 15; iter: 600; batch classifier loss: 0.382374; batch adversarial loss: 0.421074\n",
      "epoch 15; iter: 800; batch classifier loss: 0.426030; batch adversarial loss: 0.420792\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.416757; batch adversarial loss: 0.483411\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.407634; batch adversarial loss: 0.479680\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.533823; batch adversarial loss: 0.423944\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.541611; batch adversarial loss: 0.447022\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.428660; batch adversarial loss: 0.346062\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.377282; batch adversarial loss: 0.353450\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.432184; batch adversarial loss: 0.545707\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.327113; batch adversarial loss: 0.358267\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.378531; batch adversarial loss: 0.434605\n",
      "epoch 16; iter: 0; batch classifier loss: 0.427260; batch adversarial loss: 0.309691\n",
      "epoch 16; iter: 200; batch classifier loss: 0.442360; batch adversarial loss: 0.407945\n",
      "epoch 16; iter: 400; batch classifier loss: 0.434755; batch adversarial loss: 0.431929\n",
      "epoch 16; iter: 600; batch classifier loss: 0.402196; batch adversarial loss: 0.351865\n",
      "epoch 16; iter: 800; batch classifier loss: 0.418222; batch adversarial loss: 0.406105\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.399836; batch adversarial loss: 0.395263\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.376843; batch adversarial loss: 0.496124\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.401105; batch adversarial loss: 0.472900\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.428528; batch adversarial loss: 0.402362\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.408344; batch adversarial loss: 0.388870\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.495107; batch adversarial loss: 0.350078\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.401275; batch adversarial loss: 0.488585\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.390294; batch adversarial loss: 0.427414\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.431058; batch adversarial loss: 0.334732\n",
      "epoch 17; iter: 0; batch classifier loss: 0.374252; batch adversarial loss: 0.378128\n",
      "epoch 17; iter: 200; batch classifier loss: 0.421661; batch adversarial loss: 0.294931\n",
      "epoch 17; iter: 400; batch classifier loss: 0.385490; batch adversarial loss: 0.354105\n",
      "epoch 17; iter: 600; batch classifier loss: 0.393667; batch adversarial loss: 0.409847\n",
      "epoch 17; iter: 800; batch classifier loss: 0.474586; batch adversarial loss: 0.408544\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.340377; batch adversarial loss: 0.474797\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.482606; batch adversarial loss: 0.440524\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.391413; batch adversarial loss: 0.366583\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.518815; batch adversarial loss: 0.406174\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.495265; batch adversarial loss: 0.404055\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.437489; batch adversarial loss: 0.407968\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.459991; batch adversarial loss: 0.427331\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.424775; batch adversarial loss: 0.406531\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.472752; batch adversarial loss: 0.392047\n",
      "epoch 18; iter: 0; batch classifier loss: 0.389950; batch adversarial loss: 0.435241\n",
      "epoch 18; iter: 200; batch classifier loss: 0.381136; batch adversarial loss: 0.367596\n",
      "epoch 18; iter: 400; batch classifier loss: 0.430155; batch adversarial loss: 0.439220\n",
      "epoch 18; iter: 600; batch classifier loss: 0.358360; batch adversarial loss: 0.405834\n",
      "epoch 18; iter: 800; batch classifier loss: 0.365593; batch adversarial loss: 0.516411\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.380594; batch adversarial loss: 0.268865\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.391349; batch adversarial loss: 0.364386\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.434884; batch adversarial loss: 0.378442\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.426611; batch adversarial loss: 0.408728\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.449398; batch adversarial loss: 0.522988\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.412134; batch adversarial loss: 0.422628\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.402054; batch adversarial loss: 0.460608\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.391082; batch adversarial loss: 0.391042\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.366460; batch adversarial loss: 0.366824\n",
      "epoch 19; iter: 0; batch classifier loss: 0.460621; batch adversarial loss: 0.511175\n",
      "epoch 19; iter: 200; batch classifier loss: 0.406081; batch adversarial loss: 0.365904\n",
      "epoch 19; iter: 400; batch classifier loss: 0.356866; batch adversarial loss: 0.347378\n",
      "epoch 19; iter: 600; batch classifier loss: 0.369551; batch adversarial loss: 0.402665\n",
      "epoch 19; iter: 800; batch classifier loss: 0.382049; batch adversarial loss: 0.382077\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.370314; batch adversarial loss: 0.446742\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.428853; batch adversarial loss: 0.469122\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.349665; batch adversarial loss: 0.460931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19; iter: 1600; batch classifier loss: 0.399065; batch adversarial loss: 0.487374\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.452385; batch adversarial loss: 0.521485\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.375296; batch adversarial loss: 0.356474\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.410008; batch adversarial loss: 0.517773\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.404358; batch adversarial loss: 0.365331\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.405295; batch adversarial loss: 0.392099\n",
      "epoch 20; iter: 0; batch classifier loss: 0.381669; batch adversarial loss: 0.513264\n",
      "epoch 20; iter: 200; batch classifier loss: 0.434154; batch adversarial loss: 0.323417\n",
      "epoch 20; iter: 400; batch classifier loss: 0.365004; batch adversarial loss: 0.364010\n",
      "epoch 20; iter: 600; batch classifier loss: 0.469248; batch adversarial loss: 0.345070\n",
      "epoch 20; iter: 800; batch classifier loss: 0.421345; batch adversarial loss: 0.443532\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.349352; batch adversarial loss: 0.423120\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.351778; batch adversarial loss: 0.416142\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.394687; batch adversarial loss: 0.449652\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.401841; batch adversarial loss: 0.365872\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.332065; batch adversarial loss: 0.419375\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.488768; batch adversarial loss: 0.381457\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.453956; batch adversarial loss: 0.382488\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.428227; batch adversarial loss: 0.475138\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.422673; batch adversarial loss: 0.410316\n",
      "epoch 21; iter: 0; batch classifier loss: 0.418080; batch adversarial loss: 0.362653\n",
      "epoch 21; iter: 200; batch classifier loss: 0.440092; batch adversarial loss: 0.419978\n",
      "epoch 21; iter: 400; batch classifier loss: 0.358035; batch adversarial loss: 0.492096\n",
      "epoch 21; iter: 600; batch classifier loss: 0.462553; batch adversarial loss: 0.434508\n",
      "epoch 21; iter: 800; batch classifier loss: 0.431607; batch adversarial loss: 0.488274\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.449349; batch adversarial loss: 0.384075\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.501008; batch adversarial loss: 0.415673\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.389470; batch adversarial loss: 0.437027\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.474449; batch adversarial loss: 0.501788\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.418785; batch adversarial loss: 0.508887\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.409799; batch adversarial loss: 0.417159\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.409464; batch adversarial loss: 0.531302\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.437324; batch adversarial loss: 0.404016\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.429961; batch adversarial loss: 0.405047\n",
      "epoch 22; iter: 0; batch classifier loss: 0.384469; batch adversarial loss: 0.434093\n",
      "epoch 22; iter: 200; batch classifier loss: 0.382694; batch adversarial loss: 0.417447\n",
      "epoch 22; iter: 400; batch classifier loss: 0.394153; batch adversarial loss: 0.367598\n",
      "epoch 22; iter: 600; batch classifier loss: 0.430162; batch adversarial loss: 0.352893\n",
      "epoch 22; iter: 800; batch classifier loss: 0.398671; batch adversarial loss: 0.461316\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.442940; batch adversarial loss: 0.401115\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.484835; batch adversarial loss: 0.445353\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.380239; batch adversarial loss: 0.293573\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.424464; batch adversarial loss: 0.510151\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.465858; batch adversarial loss: 0.323260\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.485628; batch adversarial loss: 0.388200\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.379796; batch adversarial loss: 0.453471\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.494785; batch adversarial loss: 0.499546\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.520362; batch adversarial loss: 0.453381\n",
      "epoch 23; iter: 0; batch classifier loss: 0.382472; batch adversarial loss: 0.379241\n",
      "epoch 23; iter: 200; batch classifier loss: 0.448506; batch adversarial loss: 0.348426\n",
      "epoch 23; iter: 400; batch classifier loss: 0.401201; batch adversarial loss: 0.410443\n",
      "epoch 23; iter: 600; batch classifier loss: 0.452335; batch adversarial loss: 0.385608\n",
      "epoch 23; iter: 800; batch classifier loss: 0.466899; batch adversarial loss: 0.434784\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.425260; batch adversarial loss: 0.449569\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.441616; batch adversarial loss: 0.532158\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.468103; batch adversarial loss: 0.462365\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.448784; batch adversarial loss: 0.461750\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.330228; batch adversarial loss: 0.478878\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.427943; batch adversarial loss: 0.383557\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.429443; batch adversarial loss: 0.406064\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.508926; batch adversarial loss: 0.397095\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.359137; batch adversarial loss: 0.547191\n",
      "epoch 24; iter: 0; batch classifier loss: 0.418443; batch adversarial loss: 0.399013\n",
      "epoch 24; iter: 200; batch classifier loss: 0.319980; batch adversarial loss: 0.337067\n",
      "epoch 24; iter: 400; batch classifier loss: 0.463740; batch adversarial loss: 0.449249\n",
      "epoch 24; iter: 600; batch classifier loss: 0.324327; batch adversarial loss: 0.366257\n",
      "epoch 24; iter: 800; batch classifier loss: 0.483730; batch adversarial loss: 0.423922\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.343231; batch adversarial loss: 0.464780\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.442050; batch adversarial loss: 0.366027\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.301882; batch adversarial loss: 0.449802\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.443868; batch adversarial loss: 0.429331\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.490211; batch adversarial loss: 0.433496\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.392962; batch adversarial loss: 0.464849\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.438599; batch adversarial loss: 0.433658\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.513761; batch adversarial loss: 0.397484\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.347019; batch adversarial loss: 0.379891\n",
      "epoch 25; iter: 0; batch classifier loss: 0.346426; batch adversarial loss: 0.417442\n",
      "epoch 25; iter: 200; batch classifier loss: 0.452303; batch adversarial loss: 0.381158\n",
      "epoch 25; iter: 400; batch classifier loss: 0.561237; batch adversarial loss: 0.417529\n",
      "epoch 25; iter: 600; batch classifier loss: 0.406741; batch adversarial loss: 0.434633\n",
      "epoch 25; iter: 800; batch classifier loss: 0.407167; batch adversarial loss: 0.337189\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.446690; batch adversarial loss: 0.367579\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.479018; batch adversarial loss: 0.421139\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.377992; batch adversarial loss: 0.363849\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.387931; batch adversarial loss: 0.464257\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.446462; batch adversarial loss: 0.296831\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.420945; batch adversarial loss: 0.447041\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.380109; batch adversarial loss: 0.379134\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.433806; batch adversarial loss: 0.461549\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.453534; batch adversarial loss: 0.435645\n",
      "epoch 26; iter: 0; batch classifier loss: 0.607984; batch adversarial loss: 0.579698\n",
      "epoch 26; iter: 200; batch classifier loss: 0.367139; batch adversarial loss: 0.355661\n",
      "epoch 26; iter: 400; batch classifier loss: 0.452211; batch adversarial loss: 0.366372\n",
      "epoch 26; iter: 600; batch classifier loss: 0.411060; batch adversarial loss: 0.394149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26; iter: 800; batch classifier loss: 0.429190; batch adversarial loss: 0.379405\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.366920; batch adversarial loss: 0.528367\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.384043; batch adversarial loss: 0.389666\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.466137; batch adversarial loss: 0.351606\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.467105; batch adversarial loss: 0.379641\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.406945; batch adversarial loss: 0.419582\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.419610; batch adversarial loss: 0.448207\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.443635; batch adversarial loss: 0.407790\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.416603; batch adversarial loss: 0.433072\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.382270; batch adversarial loss: 0.475483\n",
      "epoch 27; iter: 0; batch classifier loss: 0.326181; batch adversarial loss: 0.353421\n",
      "epoch 27; iter: 200; batch classifier loss: 0.435202; batch adversarial loss: 0.366345\n",
      "epoch 27; iter: 400; batch classifier loss: 0.390907; batch adversarial loss: 0.515136\n",
      "epoch 27; iter: 600; batch classifier loss: 0.407092; batch adversarial loss: 0.383105\n",
      "epoch 27; iter: 800; batch classifier loss: 0.422767; batch adversarial loss: 0.419722\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.327732; batch adversarial loss: 0.434139\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.421973; batch adversarial loss: 0.405297\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.403689; batch adversarial loss: 0.512858\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.401077; batch adversarial loss: 0.489714\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.323330; batch adversarial loss: 0.440640\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.387802; batch adversarial loss: 0.365217\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.387536; batch adversarial loss: 0.331931\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.412757; batch adversarial loss: 0.387056\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.427633; batch adversarial loss: 0.435983\n",
      "epoch 28; iter: 0; batch classifier loss: 0.422184; batch adversarial loss: 0.379506\n",
      "epoch 28; iter: 200; batch classifier loss: 0.413029; batch adversarial loss: 0.435713\n",
      "epoch 28; iter: 400; batch classifier loss: 0.343781; batch adversarial loss: 0.419346\n",
      "epoch 28; iter: 600; batch classifier loss: 0.408097; batch adversarial loss: 0.340176\n",
      "epoch 28; iter: 800; batch classifier loss: 0.509855; batch adversarial loss: 0.400121\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.418879; batch adversarial loss: 0.471387\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.386345; batch adversarial loss: 0.550241\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.425344; batch adversarial loss: 0.469106\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.495744; batch adversarial loss: 0.378933\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.509606; batch adversarial loss: 0.367357\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.435492; batch adversarial loss: 0.445625\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.499640; batch adversarial loss: 0.432800\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.477361; batch adversarial loss: 0.349001\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.429475; batch adversarial loss: 0.359664\n",
      "epoch 29; iter: 0; batch classifier loss: 0.434935; batch adversarial loss: 0.453230\n",
      "epoch 29; iter: 200; batch classifier loss: 0.411885; batch adversarial loss: 0.555031\n",
      "epoch 29; iter: 400; batch classifier loss: 0.372546; batch adversarial loss: 0.354570\n",
      "epoch 29; iter: 600; batch classifier loss: 0.424813; batch adversarial loss: 0.389686\n",
      "epoch 29; iter: 800; batch classifier loss: 0.578054; batch adversarial loss: 0.351620\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.312424; batch adversarial loss: 0.423974\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.495827; batch adversarial loss: 0.434554\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.436033; batch adversarial loss: 0.375935\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.449278; batch adversarial loss: 0.383780\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.519944; batch adversarial loss: 0.368684\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.490221; batch adversarial loss: 0.443195\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.422078; batch adversarial loss: 0.431032\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.451572; batch adversarial loss: 0.523446\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.429442; batch adversarial loss: 0.390786\n",
      "epoch 30; iter: 0; batch classifier loss: 0.399125; batch adversarial loss: 0.404665\n",
      "epoch 30; iter: 200; batch classifier loss: 0.525477; batch adversarial loss: 0.380381\n",
      "epoch 30; iter: 400; batch classifier loss: 0.401296; batch adversarial loss: 0.467600\n",
      "epoch 30; iter: 600; batch classifier loss: 0.423226; batch adversarial loss: 0.379642\n",
      "epoch 30; iter: 800; batch classifier loss: 0.413588; batch adversarial loss: 0.410800\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.440532; batch adversarial loss: 0.392172\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.503660; batch adversarial loss: 0.488850\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.360753; batch adversarial loss: 0.394964\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.513396; batch adversarial loss: 0.406199\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.453583; batch adversarial loss: 0.438324\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.486187; batch adversarial loss: 0.351432\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.416929; batch adversarial loss: 0.390249\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.365510; batch adversarial loss: 0.400990\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.438276; batch adversarial loss: 0.380624\n",
      "epoch 31; iter: 0; batch classifier loss: 0.389530; batch adversarial loss: 0.429152\n",
      "epoch 31; iter: 200; batch classifier loss: 0.438371; batch adversarial loss: 0.366226\n",
      "epoch 31; iter: 400; batch classifier loss: 0.393532; batch adversarial loss: 0.376339\n",
      "epoch 31; iter: 600; batch classifier loss: 0.429019; batch adversarial loss: 0.418459\n",
      "epoch 31; iter: 800; batch classifier loss: 0.541121; batch adversarial loss: 0.392194\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.458729; batch adversarial loss: 0.488023\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.426943; batch adversarial loss: 0.420636\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.461653; batch adversarial loss: 0.408642\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.418446; batch adversarial loss: 0.408582\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.369399; batch adversarial loss: 0.413997\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.493823; batch adversarial loss: 0.457110\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.471238; batch adversarial loss: 0.342067\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.452101; batch adversarial loss: 0.427744\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.421963; batch adversarial loss: 0.352857\n",
      "epoch 32; iter: 0; batch classifier loss: 0.311671; batch adversarial loss: 0.462369\n",
      "epoch 32; iter: 200; batch classifier loss: 0.440552; batch adversarial loss: 0.406627\n",
      "epoch 32; iter: 400; batch classifier loss: 0.439204; batch adversarial loss: 0.446033\n",
      "epoch 32; iter: 600; batch classifier loss: 0.387241; batch adversarial loss: 0.422215\n",
      "epoch 32; iter: 800; batch classifier loss: 0.379765; batch adversarial loss: 0.475070\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.352205; batch adversarial loss: 0.424342\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.435777; batch adversarial loss: 0.474896\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.466456; batch adversarial loss: 0.419965\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.526061; batch adversarial loss: 0.446965\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.426366; batch adversarial loss: 0.362283\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.414661; batch adversarial loss: 0.353278\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.393392; batch adversarial loss: 0.339345\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.388486; batch adversarial loss: 0.556574\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.459850; batch adversarial loss: 0.380794\n",
      "epoch 33; iter: 0; batch classifier loss: 0.420689; batch adversarial loss: 0.420969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 200; batch classifier loss: 0.433004; batch adversarial loss: 0.334052\n",
      "epoch 33; iter: 400; batch classifier loss: 0.441941; batch adversarial loss: 0.409997\n",
      "epoch 33; iter: 600; batch classifier loss: 0.391920; batch adversarial loss: 0.424237\n",
      "epoch 33; iter: 800; batch classifier loss: 0.493409; batch adversarial loss: 0.405209\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.463041; batch adversarial loss: 0.411506\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.357674; batch adversarial loss: 0.407032\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.355303; batch adversarial loss: 0.466313\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.417183; batch adversarial loss: 0.460551\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.380556; batch adversarial loss: 0.501912\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.412347; batch adversarial loss: 0.418768\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.421145; batch adversarial loss: 0.299604\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.446692; batch adversarial loss: 0.404200\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.432150; batch adversarial loss: 0.368934\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420911; batch adversarial loss: 0.380549\n",
      "epoch 34; iter: 200; batch classifier loss: 0.383646; batch adversarial loss: 0.435093\n",
      "epoch 34; iter: 400; batch classifier loss: 0.390747; batch adversarial loss: 0.478737\n",
      "epoch 34; iter: 600; batch classifier loss: 0.371168; batch adversarial loss: 0.476934\n",
      "epoch 34; iter: 800; batch classifier loss: 0.416312; batch adversarial loss: 0.443485\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.452745; batch adversarial loss: 0.447506\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.452011; batch adversarial loss: 0.443786\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.430233; batch adversarial loss: 0.460202\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.462701; batch adversarial loss: 0.370099\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.472850; batch adversarial loss: 0.296339\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.436748; batch adversarial loss: 0.491604\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.446900; batch adversarial loss: 0.366036\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.516053; batch adversarial loss: 0.380515\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.413636; batch adversarial loss: 0.406225\n",
      "epoch 35; iter: 0; batch classifier loss: 0.429954; batch adversarial loss: 0.408417\n",
      "epoch 35; iter: 200; batch classifier loss: 0.417326; batch adversarial loss: 0.429110\n",
      "epoch 35; iter: 400; batch classifier loss: 0.392132; batch adversarial loss: 0.431530\n",
      "epoch 35; iter: 600; batch classifier loss: 0.410038; batch adversarial loss: 0.375049\n",
      "epoch 35; iter: 800; batch classifier loss: 0.430981; batch adversarial loss: 0.390931\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.432725; batch adversarial loss: 0.436122\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.345385; batch adversarial loss: 0.484548\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.354076; batch adversarial loss: 0.447945\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.393045; batch adversarial loss: 0.540424\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.383392; batch adversarial loss: 0.329903\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.405407; batch adversarial loss: 0.365457\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.464103; batch adversarial loss: 0.464941\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.390244; batch adversarial loss: 0.404920\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.434419; batch adversarial loss: 0.311149\n",
      "epoch 36; iter: 0; batch classifier loss: 0.421833; batch adversarial loss: 0.517411\n",
      "epoch 36; iter: 200; batch classifier loss: 0.387863; batch adversarial loss: 0.322837\n",
      "epoch 36; iter: 400; batch classifier loss: 0.406422; batch adversarial loss: 0.483539\n",
      "epoch 36; iter: 600; batch classifier loss: 0.395948; batch adversarial loss: 0.448300\n",
      "epoch 36; iter: 800; batch classifier loss: 0.389224; batch adversarial loss: 0.434742\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.412782; batch adversarial loss: 0.421710\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.421330; batch adversarial loss: 0.403728\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.370819; batch adversarial loss: 0.434877\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.338550; batch adversarial loss: 0.338615\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.329278; batch adversarial loss: 0.379483\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.446634; batch adversarial loss: 0.380822\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.380105; batch adversarial loss: 0.354034\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.460659; batch adversarial loss: 0.392254\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.539685; batch adversarial loss: 0.565502\n",
      "epoch 37; iter: 0; batch classifier loss: 0.391833; batch adversarial loss: 0.292994\n",
      "epoch 37; iter: 200; batch classifier loss: 0.313598; batch adversarial loss: 0.377122\n",
      "epoch 37; iter: 400; batch classifier loss: 0.434792; batch adversarial loss: 0.473197\n",
      "epoch 37; iter: 600; batch classifier loss: 0.432868; batch adversarial loss: 0.360324\n",
      "epoch 37; iter: 800; batch classifier loss: 0.374588; batch adversarial loss: 0.346816\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.479947; batch adversarial loss: 0.388584\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.449860; batch adversarial loss: 0.459984\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.423317; batch adversarial loss: 0.476434\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.334248; batch adversarial loss: 0.430067\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.362440; batch adversarial loss: 0.470126\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.406628; batch adversarial loss: 0.605268\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.416490; batch adversarial loss: 0.401171\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.457112; batch adversarial loss: 0.460281\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.435246; batch adversarial loss: 0.503428\n",
      "epoch 38; iter: 0; batch classifier loss: 0.457752; batch adversarial loss: 0.372218\n",
      "epoch 38; iter: 200; batch classifier loss: 0.423957; batch adversarial loss: 0.347528\n",
      "epoch 38; iter: 400; batch classifier loss: 0.479978; batch adversarial loss: 0.377109\n",
      "epoch 38; iter: 600; batch classifier loss: 0.407798; batch adversarial loss: 0.403034\n",
      "epoch 38; iter: 800; batch classifier loss: 0.505709; batch adversarial loss: 0.326705\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.443463; batch adversarial loss: 0.351002\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.434557; batch adversarial loss: 0.345621\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.383574; batch adversarial loss: 0.352756\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.516476; batch adversarial loss: 0.443972\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.388390; batch adversarial loss: 0.491905\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.385231; batch adversarial loss: 0.363235\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.354817; batch adversarial loss: 0.324766\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.493237; batch adversarial loss: 0.565465\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.408967; batch adversarial loss: 0.513198\n",
      "epoch 39; iter: 0; batch classifier loss: 0.402535; batch adversarial loss: 0.379471\n",
      "epoch 39; iter: 200; batch classifier loss: 0.405082; batch adversarial loss: 0.377357\n",
      "epoch 39; iter: 400; batch classifier loss: 0.390744; batch adversarial loss: 0.369338\n",
      "epoch 39; iter: 600; batch classifier loss: 0.435602; batch adversarial loss: 0.368505\n",
      "epoch 39; iter: 800; batch classifier loss: 0.428829; batch adversarial loss: 0.403220\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.387844; batch adversarial loss: 0.380026\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.444166; batch adversarial loss: 0.366379\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.447222; batch adversarial loss: 0.469753\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.413662; batch adversarial loss: 0.422441\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.478243; batch adversarial loss: 0.463261\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.379314; batch adversarial loss: 0.361226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 2200; batch classifier loss: 0.476749; batch adversarial loss: 0.391664\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.436882; batch adversarial loss: 0.421036\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.353094; batch adversarial loss: 0.360228\n",
      "epoch 40; iter: 0; batch classifier loss: 0.442479; batch adversarial loss: 0.374284\n",
      "epoch 40; iter: 200; batch classifier loss: 0.376112; batch adversarial loss: 0.338857\n",
      "epoch 40; iter: 400; batch classifier loss: 0.433190; batch adversarial loss: 0.362007\n",
      "epoch 40; iter: 600; batch classifier loss: 0.359102; batch adversarial loss: 0.403986\n",
      "epoch 40; iter: 800; batch classifier loss: 0.410783; batch adversarial loss: 0.389780\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.441798; batch adversarial loss: 0.430712\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.419585; batch adversarial loss: 0.438831\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.339645; batch adversarial loss: 0.421997\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.454956; batch adversarial loss: 0.394321\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.360386; batch adversarial loss: 0.354129\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.425505; batch adversarial loss: 0.421406\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.447013; batch adversarial loss: 0.489290\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.348037; batch adversarial loss: 0.478543\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.376865; batch adversarial loss: 0.421814\n",
      "epoch 41; iter: 0; batch classifier loss: 0.377655; batch adversarial loss: 0.464054\n",
      "epoch 41; iter: 200; batch classifier loss: 0.433478; batch adversarial loss: 0.421274\n",
      "epoch 41; iter: 400; batch classifier loss: 0.439408; batch adversarial loss: 0.420880\n",
      "epoch 41; iter: 600; batch classifier loss: 0.519786; batch adversarial loss: 0.417773\n",
      "epoch 41; iter: 800; batch classifier loss: 0.362644; batch adversarial loss: 0.417109\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.339368; batch adversarial loss: 0.351190\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.484152; batch adversarial loss: 0.475406\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.403094; batch adversarial loss: 0.450386\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.394264; batch adversarial loss: 0.475445\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.502492; batch adversarial loss: 0.448293\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.369146; batch adversarial loss: 0.342082\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.537776; batch adversarial loss: 0.350081\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.443223; batch adversarial loss: 0.457782\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.331974; batch adversarial loss: 0.327178\n",
      "epoch 42; iter: 0; batch classifier loss: 0.372042; batch adversarial loss: 0.362974\n",
      "epoch 42; iter: 200; batch classifier loss: 0.400012; batch adversarial loss: 0.466534\n",
      "epoch 42; iter: 400; batch classifier loss: 0.392607; batch adversarial loss: 0.519509\n",
      "epoch 42; iter: 600; batch classifier loss: 0.469158; batch adversarial loss: 0.410638\n",
      "epoch 42; iter: 800; batch classifier loss: 0.344480; batch adversarial loss: 0.409243\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.351171; batch adversarial loss: 0.518394\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.395505; batch adversarial loss: 0.585357\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.482878; batch adversarial loss: 0.382483\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.449773; batch adversarial loss: 0.430842\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.408762; batch adversarial loss: 0.419532\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.404667; batch adversarial loss: 0.405780\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.449236; batch adversarial loss: 0.366460\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.434791; batch adversarial loss: 0.391980\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.310297; batch adversarial loss: 0.429978\n",
      "epoch 43; iter: 0; batch classifier loss: 0.432935; batch adversarial loss: 0.312304\n",
      "epoch 43; iter: 200; batch classifier loss: 0.490593; batch adversarial loss: 0.365994\n",
      "epoch 43; iter: 400; batch classifier loss: 0.450127; batch adversarial loss: 0.322048\n",
      "epoch 43; iter: 600; batch classifier loss: 0.419980; batch adversarial loss: 0.465254\n",
      "epoch 43; iter: 800; batch classifier loss: 0.369806; batch adversarial loss: 0.425627\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.434057; batch adversarial loss: 0.377411\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.463658; batch adversarial loss: 0.422408\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.463279; batch adversarial loss: 0.283865\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.509744; batch adversarial loss: 0.419000\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.385101; batch adversarial loss: 0.458910\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.441576; batch adversarial loss: 0.411040\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.444724; batch adversarial loss: 0.348100\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.452313; batch adversarial loss: 0.328468\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.526121; batch adversarial loss: 0.334716\n",
      "epoch 44; iter: 0; batch classifier loss: 0.451992; batch adversarial loss: 0.442391\n",
      "epoch 44; iter: 200; batch classifier loss: 0.534540; batch adversarial loss: 0.410539\n",
      "epoch 44; iter: 400; batch classifier loss: 0.450888; batch adversarial loss: 0.489336\n",
      "epoch 44; iter: 600; batch classifier loss: 0.348412; batch adversarial loss: 0.353177\n",
      "epoch 44; iter: 800; batch classifier loss: 0.472918; batch adversarial loss: 0.324000\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.446052; batch adversarial loss: 0.432737\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.432473; batch adversarial loss: 0.366867\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.364790; batch adversarial loss: 0.447884\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.383639; batch adversarial loss: 0.410442\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.350552; batch adversarial loss: 0.459585\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.488377; batch adversarial loss: 0.376443\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.403805; batch adversarial loss: 0.420531\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.478892; batch adversarial loss: 0.406824\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.380578; batch adversarial loss: 0.487645\n",
      "epoch 45; iter: 0; batch classifier loss: 0.403834; batch adversarial loss: 0.379394\n",
      "epoch 45; iter: 200; batch classifier loss: 0.379108; batch adversarial loss: 0.380250\n",
      "epoch 45; iter: 400; batch classifier loss: 0.486208; batch adversarial loss: 0.434374\n",
      "epoch 45; iter: 600; batch classifier loss: 0.476529; batch adversarial loss: 0.367072\n",
      "epoch 45; iter: 800; batch classifier loss: 0.393053; batch adversarial loss: 0.472941\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.439594; batch adversarial loss: 0.365239\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.458849; batch adversarial loss: 0.580869\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.375379; batch adversarial loss: 0.367638\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.427696; batch adversarial loss: 0.399961\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.361954; batch adversarial loss: 0.387185\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.376782; batch adversarial loss: 0.454617\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.438962; batch adversarial loss: 0.402849\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.395162; batch adversarial loss: 0.437770\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.399647; batch adversarial loss: 0.365819\n",
      "epoch 46; iter: 0; batch classifier loss: 0.436719; batch adversarial loss: 0.378541\n",
      "epoch 46; iter: 200; batch classifier loss: 0.467871; batch adversarial loss: 0.410571\n",
      "epoch 46; iter: 400; batch classifier loss: 0.414427; batch adversarial loss: 0.392451\n",
      "epoch 46; iter: 600; batch classifier loss: 0.455189; batch adversarial loss: 0.424996\n",
      "epoch 46; iter: 800; batch classifier loss: 0.323331; batch adversarial loss: 0.376857\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.437291; batch adversarial loss: 0.352145\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.407892; batch adversarial loss: 0.350897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46; iter: 1400; batch classifier loss: 0.492526; batch adversarial loss: 0.376774\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.450549; batch adversarial loss: 0.419774\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.334621; batch adversarial loss: 0.364574\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.434849; batch adversarial loss: 0.408291\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.490834; batch adversarial loss: 0.351000\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.422909; batch adversarial loss: 0.475458\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.448858; batch adversarial loss: 0.437334\n",
      "epoch 47; iter: 0; batch classifier loss: 0.495440; batch adversarial loss: 0.461603\n",
      "epoch 47; iter: 200; batch classifier loss: 0.402276; batch adversarial loss: 0.378856\n",
      "epoch 47; iter: 400; batch classifier loss: 0.406122; batch adversarial loss: 0.475807\n",
      "epoch 47; iter: 600; batch classifier loss: 0.398428; batch adversarial loss: 0.341881\n",
      "epoch 47; iter: 800; batch classifier loss: 0.360040; batch adversarial loss: 0.404837\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.347975; batch adversarial loss: 0.434552\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.350592; batch adversarial loss: 0.430624\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.449250; batch adversarial loss: 0.417918\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.391936; batch adversarial loss: 0.476723\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.437644; batch adversarial loss: 0.377976\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.384631; batch adversarial loss: 0.406709\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.330808; batch adversarial loss: 0.391185\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.384818; batch adversarial loss: 0.367819\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.431022; batch adversarial loss: 0.471483\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411767; batch adversarial loss: 0.524538\n",
      "epoch 48; iter: 200; batch classifier loss: 0.315612; batch adversarial loss: 0.405036\n",
      "epoch 48; iter: 400; batch classifier loss: 0.456584; batch adversarial loss: 0.391747\n",
      "epoch 48; iter: 600; batch classifier loss: 0.455226; batch adversarial loss: 0.445445\n",
      "epoch 48; iter: 800; batch classifier loss: 0.424504; batch adversarial loss: 0.379212\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.406989; batch adversarial loss: 0.567865\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.444206; batch adversarial loss: 0.511381\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.364308; batch adversarial loss: 0.476425\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.401958; batch adversarial loss: 0.376330\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.446268; batch adversarial loss: 0.378924\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.441823; batch adversarial loss: 0.367778\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.436789; batch adversarial loss: 0.423489\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.415328; batch adversarial loss: 0.367117\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.423804; batch adversarial loss: 0.415139\n",
      "epoch 49; iter: 0; batch classifier loss: 0.497653; batch adversarial loss: 0.343380\n",
      "epoch 49; iter: 200; batch classifier loss: 0.603187; batch adversarial loss: 0.457906\n",
      "epoch 49; iter: 400; batch classifier loss: 0.365731; batch adversarial loss: 0.366223\n",
      "epoch 49; iter: 600; batch classifier loss: 0.389296; batch adversarial loss: 0.337795\n",
      "epoch 49; iter: 800; batch classifier loss: 0.371484; batch adversarial loss: 0.495724\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.432166; batch adversarial loss: 0.377918\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.521620; batch adversarial loss: 0.530897\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.388695; batch adversarial loss: 0.488501\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.483508; batch adversarial loss: 0.415668\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.383974; batch adversarial loss: 0.348289\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.454674; batch adversarial loss: 0.505487\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.390923; batch adversarial loss: 0.432372\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.364075; batch adversarial loss: 0.270073\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.444687; batch adversarial loss: 0.499344\n",
      "epoch 0; iter: 0; batch classifier loss: 0.675425\n",
      "epoch 0; iter: 200; batch classifier loss: 0.375086\n",
      "epoch 0; iter: 400; batch classifier loss: 0.432977\n",
      "epoch 0; iter: 600; batch classifier loss: 0.438620\n",
      "epoch 0; iter: 800; batch classifier loss: 0.414772\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.391819\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.361688\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.418163\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.342287\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.490984\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.452586\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.442156\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.461829\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.412662\n",
      "epoch 1; iter: 0; batch classifier loss: 0.460215\n",
      "epoch 1; iter: 200; batch classifier loss: 0.390689\n",
      "epoch 1; iter: 400; batch classifier loss: 0.464724\n",
      "epoch 1; iter: 600; batch classifier loss: 0.370254\n",
      "epoch 1; iter: 800; batch classifier loss: 0.404874\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.440776\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.421456\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.345857\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.445869\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.450018\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.387765\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.424650\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.397263\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.464378\n",
      "epoch 2; iter: 0; batch classifier loss: 0.411130\n",
      "epoch 2; iter: 200; batch classifier loss: 0.384869\n",
      "epoch 2; iter: 400; batch classifier loss: 0.400974\n",
      "epoch 2; iter: 600; batch classifier loss: 0.456775\n",
      "epoch 2; iter: 800; batch classifier loss: 0.413259\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.341433\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.380112\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.335210\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.310208\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.381683\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.341984\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.457314\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.313811\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.448817\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339446\n",
      "epoch 3; iter: 200; batch classifier loss: 0.480112\n",
      "epoch 3; iter: 400; batch classifier loss: 0.399436\n",
      "epoch 3; iter: 600; batch classifier loss: 0.376188\n",
      "epoch 3; iter: 800; batch classifier loss: 0.370208\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.375767\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.440626\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.439620\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.444989\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.526920\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.480595\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.399227\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.398999\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.351408\n",
      "epoch 4; iter: 0; batch classifier loss: 0.472662\n",
      "epoch 4; iter: 200; batch classifier loss: 0.376753\n",
      "epoch 4; iter: 400; batch classifier loss: 0.296703\n",
      "epoch 4; iter: 600; batch classifier loss: 0.504872\n",
      "epoch 4; iter: 800; batch classifier loss: 0.385987\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.370315\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.309235\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.480125\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.404214\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.446262\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.453561\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.531418\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.395764\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.337902\n",
      "epoch 5; iter: 0; batch classifier loss: 0.383114\n",
      "epoch 5; iter: 200; batch classifier loss: 0.287137\n",
      "epoch 5; iter: 400; batch classifier loss: 0.459326\n",
      "epoch 5; iter: 600; batch classifier loss: 0.354965\n",
      "epoch 5; iter: 800; batch classifier loss: 0.396037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5; iter: 1000; batch classifier loss: 0.393973\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.401870\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.363726\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.441243\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.405591\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.435463\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.422729\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.378186\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.436548\n",
      "epoch 6; iter: 0; batch classifier loss: 0.391389\n",
      "epoch 6; iter: 200; batch classifier loss: 0.377222\n",
      "epoch 6; iter: 400; batch classifier loss: 0.443168\n",
      "epoch 6; iter: 600; batch classifier loss: 0.379962\n",
      "epoch 6; iter: 800; batch classifier loss: 0.470921\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.434473\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.462710\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.383970\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.421301\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.462057\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.395140\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.412448\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.499309\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.505156\n",
      "epoch 7; iter: 0; batch classifier loss: 0.438675\n",
      "epoch 7; iter: 200; batch classifier loss: 0.446499\n",
      "epoch 7; iter: 400; batch classifier loss: 0.345059\n",
      "epoch 7; iter: 600; batch classifier loss: 0.480761\n",
      "epoch 7; iter: 800; batch classifier loss: 0.362708\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.432158\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.376147\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.447898\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.363161\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.523422\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.399087\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.468219\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.395334\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.440695\n",
      "epoch 8; iter: 0; batch classifier loss: 0.453285\n",
      "epoch 8; iter: 200; batch classifier loss: 0.419394\n",
      "epoch 8; iter: 400; batch classifier loss: 0.567890\n",
      "epoch 8; iter: 600; batch classifier loss: 0.409561\n",
      "epoch 8; iter: 800; batch classifier loss: 0.489858\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.354867\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.477871\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.338780\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.404710\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.470307\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.410833\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.454844\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.426818\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.350840\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416539\n",
      "epoch 9; iter: 200; batch classifier loss: 0.342957\n",
      "epoch 9; iter: 400; batch classifier loss: 0.375527\n",
      "epoch 9; iter: 600; batch classifier loss: 0.358770\n",
      "epoch 9; iter: 800; batch classifier loss: 0.400896\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.424185\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.396723\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.344859\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.390245\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.426007\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.504002\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.359050\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.424351\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.382168\n",
      "epoch 10; iter: 0; batch classifier loss: 0.422095\n",
      "epoch 10; iter: 200; batch classifier loss: 0.387108\n",
      "epoch 10; iter: 400; batch classifier loss: 0.377650\n",
      "epoch 10; iter: 600; batch classifier loss: 0.432509\n",
      "epoch 10; iter: 800; batch classifier loss: 0.436614\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.451265\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.445680\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.420718\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.403821\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.470844\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.527087\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.495332\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.366382\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.463428\n",
      "epoch 11; iter: 0; batch classifier loss: 0.464519\n",
      "epoch 11; iter: 200; batch classifier loss: 0.388685\n",
      "epoch 11; iter: 400; batch classifier loss: 0.407860\n",
      "epoch 11; iter: 600; batch classifier loss: 0.443819\n",
      "epoch 11; iter: 800; batch classifier loss: 0.368752\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.348120\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.403206\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.417162\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.501434\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.396672\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.394063\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.389970\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.428001\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.422673\n",
      "epoch 12; iter: 0; batch classifier loss: 0.441632\n",
      "epoch 12; iter: 200; batch classifier loss: 0.430455\n",
      "epoch 12; iter: 400; batch classifier loss: 0.419453\n",
      "epoch 12; iter: 600; batch classifier loss: 0.392916\n",
      "epoch 12; iter: 800; batch classifier loss: 0.398598\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.403691\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.510078\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.463657\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.373737\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.445556\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.335313\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.358933\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.388855\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.465787\n",
      "epoch 13; iter: 0; batch classifier loss: 0.498866\n",
      "epoch 13; iter: 200; batch classifier loss: 0.425032\n",
      "epoch 13; iter: 400; batch classifier loss: 0.410798\n",
      "epoch 13; iter: 600; batch classifier loss: 0.432354\n",
      "epoch 13; iter: 800; batch classifier loss: 0.452647\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.418475\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.462175\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.452542\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.369091\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.391533\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.408622\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.368771\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.331943\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.463925\n",
      "epoch 14; iter: 0; batch classifier loss: 0.393105\n",
      "epoch 14; iter: 200; batch classifier loss: 0.342000\n",
      "epoch 14; iter: 400; batch classifier loss: 0.423140\n",
      "epoch 14; iter: 600; batch classifier loss: 0.393363\n",
      "epoch 14; iter: 800; batch classifier loss: 0.446120\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.538402\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.364466\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.504237\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.470948\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.422817\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.387865\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.498309\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.447776\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.457172\n",
      "epoch 15; iter: 0; batch classifier loss: 0.446096\n",
      "epoch 15; iter: 200; batch classifier loss: 0.400690\n",
      "epoch 15; iter: 400; batch classifier loss: 0.483786\n",
      "epoch 15; iter: 600; batch classifier loss: 0.392435\n",
      "epoch 15; iter: 800; batch classifier loss: 0.380763\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.409195\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.441508\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.433613\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.491524\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.350420\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.478126\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.372049\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.370505\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.420446\n",
      "epoch 16; iter: 0; batch classifier loss: 0.398253\n",
      "epoch 16; iter: 200; batch classifier loss: 0.474885\n",
      "epoch 16; iter: 400; batch classifier loss: 0.425196\n",
      "epoch 16; iter: 600; batch classifier loss: 0.462602\n",
      "epoch 16; iter: 800; batch classifier loss: 0.390623\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.372462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 1200; batch classifier loss: 0.426890\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.433312\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.380620\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.419668\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.423753\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.449348\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.467937\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.456013\n",
      "epoch 17; iter: 0; batch classifier loss: 0.407299\n",
      "epoch 17; iter: 200; batch classifier loss: 0.496237\n",
      "epoch 17; iter: 400; batch classifier loss: 0.427997\n",
      "epoch 17; iter: 600; batch classifier loss: 0.469486\n",
      "epoch 17; iter: 800; batch classifier loss: 0.350352\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.461016\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.411022\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.393762\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.407752\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.499509\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.418767\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.378485\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.453707\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.470371\n",
      "epoch 18; iter: 0; batch classifier loss: 0.473403\n",
      "epoch 18; iter: 200; batch classifier loss: 0.392539\n",
      "epoch 18; iter: 400; batch classifier loss: 0.337342\n",
      "epoch 18; iter: 600; batch classifier loss: 0.482590\n",
      "epoch 18; iter: 800; batch classifier loss: 0.437640\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.381642\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.493089\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.383981\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.374929\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.355062\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.386012\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.409191\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.436016\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.524833\n",
      "epoch 19; iter: 0; batch classifier loss: 0.344416\n",
      "epoch 19; iter: 200; batch classifier loss: 0.380189\n",
      "epoch 19; iter: 400; batch classifier loss: 0.510656\n",
      "epoch 19; iter: 600; batch classifier loss: 0.393302\n",
      "epoch 19; iter: 800; batch classifier loss: 0.361148\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.518025\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.391934\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.407805\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.412760\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.339593\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.357133\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.439773\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.344938\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.485459\n",
      "epoch 20; iter: 0; batch classifier loss: 0.376504\n",
      "epoch 20; iter: 200; batch classifier loss: 0.420387\n",
      "epoch 20; iter: 400; batch classifier loss: 0.460019\n",
      "epoch 20; iter: 600; batch classifier loss: 0.439497\n",
      "epoch 20; iter: 800; batch classifier loss: 0.454225\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.469792\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.366995\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.349594\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.352973\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.407667\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.428993\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.496217\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.491484\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.413779\n",
      "epoch 21; iter: 0; batch classifier loss: 0.390288\n",
      "epoch 21; iter: 200; batch classifier loss: 0.480106\n",
      "epoch 21; iter: 400; batch classifier loss: 0.386890\n",
      "epoch 21; iter: 600; batch classifier loss: 0.320489\n",
      "epoch 21; iter: 800; batch classifier loss: 0.389634\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.463717\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.412545\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.395231\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.411666\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.420024\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.440947\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.402203\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.373306\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.432278\n",
      "epoch 22; iter: 0; batch classifier loss: 0.516538\n",
      "epoch 22; iter: 200; batch classifier loss: 0.436187\n",
      "epoch 22; iter: 400; batch classifier loss: 0.358981\n",
      "epoch 22; iter: 600; batch classifier loss: 0.448752\n",
      "epoch 22; iter: 800; batch classifier loss: 0.416849\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.397744\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.385468\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.356242\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.411820\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.355201\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.490635\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.376113\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.480739\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.417229\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439515\n",
      "epoch 23; iter: 200; batch classifier loss: 0.411716\n",
      "epoch 23; iter: 400; batch classifier loss: 0.447139\n",
      "epoch 23; iter: 600; batch classifier loss: 0.397323\n",
      "epoch 23; iter: 800; batch classifier loss: 0.370476\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.425844\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.385111\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.424226\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.444352\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.438942\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.436952\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.291813\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.410909\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.433242\n",
      "epoch 24; iter: 0; batch classifier loss: 0.428933\n",
      "epoch 24; iter: 200; batch classifier loss: 0.448185\n",
      "epoch 24; iter: 400; batch classifier loss: 0.508186\n",
      "epoch 24; iter: 600; batch classifier loss: 0.466273\n",
      "epoch 24; iter: 800; batch classifier loss: 0.442219\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.461784\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.448213\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.435045\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.410476\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.509156\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.441449\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.486153\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.408042\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.404421\n",
      "epoch 25; iter: 0; batch classifier loss: 0.371890\n",
      "epoch 25; iter: 200; batch classifier loss: 0.365896\n",
      "epoch 25; iter: 400; batch classifier loss: 0.308948\n",
      "epoch 25; iter: 600; batch classifier loss: 0.436111\n",
      "epoch 25; iter: 800; batch classifier loss: 0.490039\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.416095\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.354726\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.465130\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.468451\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.364241\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.384941\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.435027\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.387735\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.420967\n",
      "epoch 26; iter: 0; batch classifier loss: 0.378567\n",
      "epoch 26; iter: 200; batch classifier loss: 0.410783\n",
      "epoch 26; iter: 400; batch classifier loss: 0.481940\n",
      "epoch 26; iter: 600; batch classifier loss: 0.451290\n",
      "epoch 26; iter: 800; batch classifier loss: 0.284900\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.352419\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.440161\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.395013\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.380592\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.463093\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.455678\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.344034\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.496381\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.431296\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460998\n",
      "epoch 27; iter: 200; batch classifier loss: 0.359807\n",
      "epoch 27; iter: 400; batch classifier loss: 0.439010\n",
      "epoch 27; iter: 600; batch classifier loss: 0.353098\n",
      "epoch 27; iter: 800; batch classifier loss: 0.358623\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.505369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 1200; batch classifier loss: 0.338369\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.431413\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.457775\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.442328\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.390629\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.431906\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.419879\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.440801\n",
      "epoch 28; iter: 0; batch classifier loss: 0.436817\n",
      "epoch 28; iter: 200; batch classifier loss: 0.474349\n",
      "epoch 28; iter: 400; batch classifier loss: 0.452503\n",
      "epoch 28; iter: 600; batch classifier loss: 0.395526\n",
      "epoch 28; iter: 800; batch classifier loss: 0.429145\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.373828\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.455853\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.560601\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.491302\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.459942\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.432462\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.378501\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.371164\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.470744\n",
      "epoch 29; iter: 0; batch classifier loss: 0.419092\n",
      "epoch 29; iter: 200; batch classifier loss: 0.432156\n",
      "epoch 29; iter: 400; batch classifier loss: 0.504268\n",
      "epoch 29; iter: 600; batch classifier loss: 0.418882\n",
      "epoch 29; iter: 800; batch classifier loss: 0.397433\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.408367\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.364021\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.443848\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.367826\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.420118\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.340491\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.430887\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.372966\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.420532\n",
      "epoch 30; iter: 0; batch classifier loss: 0.406013\n",
      "epoch 30; iter: 200; batch classifier loss: 0.448180\n",
      "epoch 30; iter: 400; batch classifier loss: 0.378594\n",
      "epoch 30; iter: 600; batch classifier loss: 0.464885\n",
      "epoch 30; iter: 800; batch classifier loss: 0.423079\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.429181\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.417888\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.336625\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.376409\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.337385\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.386705\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.376061\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.342357\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.416148\n",
      "epoch 31; iter: 0; batch classifier loss: 0.349751\n",
      "epoch 31; iter: 200; batch classifier loss: 0.346572\n",
      "epoch 31; iter: 400; batch classifier loss: 0.409840\n",
      "epoch 31; iter: 600; batch classifier loss: 0.333046\n",
      "epoch 31; iter: 800; batch classifier loss: 0.376646\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.383990\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.463328\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.433146\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.437070\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.457465\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.475549\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.408678\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.429197\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.448893\n",
      "epoch 32; iter: 0; batch classifier loss: 0.478834\n",
      "epoch 32; iter: 200; batch classifier loss: 0.392579\n",
      "epoch 32; iter: 400; batch classifier loss: 0.385323\n",
      "epoch 32; iter: 600; batch classifier loss: 0.444523\n",
      "epoch 32; iter: 800; batch classifier loss: 0.339334\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.482390\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.430061\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.437991\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.409134\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.355150\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.336919\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.358440\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.396278\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.386436\n",
      "epoch 33; iter: 0; batch classifier loss: 0.500805\n",
      "epoch 33; iter: 200; batch classifier loss: 0.447302\n",
      "epoch 33; iter: 400; batch classifier loss: 0.426138\n",
      "epoch 33; iter: 600; batch classifier loss: 0.391067\n",
      "epoch 33; iter: 800; batch classifier loss: 0.428212\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.397938\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.500438\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.470661\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.397872\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.446453\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.452069\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.419202\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.391183\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.401494\n",
      "epoch 34; iter: 0; batch classifier loss: 0.447322\n",
      "epoch 34; iter: 200; batch classifier loss: 0.427843\n",
      "epoch 34; iter: 400; batch classifier loss: 0.360440\n",
      "epoch 34; iter: 600; batch classifier loss: 0.420657\n",
      "epoch 34; iter: 800; batch classifier loss: 0.391746\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.418689\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.366292\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.484847\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.438169\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.465532\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.451356\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.426252\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.421032\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.336136\n",
      "epoch 35; iter: 0; batch classifier loss: 0.382660\n",
      "epoch 35; iter: 200; batch classifier loss: 0.427203\n",
      "epoch 35; iter: 400; batch classifier loss: 0.467007\n",
      "epoch 35; iter: 600; batch classifier loss: 0.386686\n",
      "epoch 35; iter: 800; batch classifier loss: 0.435367\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.376401\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.407155\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.404420\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.369071\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.348545\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.402649\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.453177\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.527010\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.416416\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432407\n",
      "epoch 36; iter: 200; batch classifier loss: 0.415429\n",
      "epoch 36; iter: 400; batch classifier loss: 0.370308\n",
      "epoch 36; iter: 600; batch classifier loss: 0.372479\n",
      "epoch 36; iter: 800; batch classifier loss: 0.358566\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.431482\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.459716\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.361981\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.440949\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.463166\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.427792\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.465526\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.412069\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.342260\n",
      "epoch 37; iter: 0; batch classifier loss: 0.409277\n",
      "epoch 37; iter: 200; batch classifier loss: 0.417293\n",
      "epoch 37; iter: 400; batch classifier loss: 0.331230\n",
      "epoch 37; iter: 600; batch classifier loss: 0.448704\n",
      "epoch 37; iter: 800; batch classifier loss: 0.350706\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.388011\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.408688\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.391155\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.371029\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.469269\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.449687\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.404303\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.432570\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.367120\n",
      "epoch 38; iter: 0; batch classifier loss: 0.438080\n",
      "epoch 38; iter: 200; batch classifier loss: 0.418069\n",
      "epoch 38; iter: 400; batch classifier loss: 0.331522\n",
      "epoch 38; iter: 600; batch classifier loss: 0.426750\n",
      "epoch 38; iter: 800; batch classifier loss: 0.406042\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.396974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 1200; batch classifier loss: 0.452557\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.312558\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.472957\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.374426\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.412641\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.349783\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.421222\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.359381\n",
      "epoch 39; iter: 0; batch classifier loss: 0.446333\n",
      "epoch 39; iter: 200; batch classifier loss: 0.422972\n",
      "epoch 39; iter: 400; batch classifier loss: 0.340031\n",
      "epoch 39; iter: 600; batch classifier loss: 0.452630\n",
      "epoch 39; iter: 800; batch classifier loss: 0.488531\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.392140\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.412309\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.460056\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.548263\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.347826\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.433900\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.397028\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.441888\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.442648\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411422\n",
      "epoch 40; iter: 200; batch classifier loss: 0.408329\n",
      "epoch 40; iter: 400; batch classifier loss: 0.430020\n",
      "epoch 40; iter: 600; batch classifier loss: 0.565147\n",
      "epoch 40; iter: 800; batch classifier loss: 0.448136\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.420490\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.419567\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.429884\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.465043\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.428292\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.466223\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.365649\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.431702\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.456227\n",
      "epoch 41; iter: 0; batch classifier loss: 0.514315\n",
      "epoch 41; iter: 200; batch classifier loss: 0.406804\n",
      "epoch 41; iter: 400; batch classifier loss: 0.368894\n",
      "epoch 41; iter: 600; batch classifier loss: 0.401179\n",
      "epoch 41; iter: 800; batch classifier loss: 0.486992\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.398044\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.411983\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.432084\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.381485\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.371056\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.401822\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.361679\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.346631\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.350945\n",
      "epoch 42; iter: 0; batch classifier loss: 0.375017\n",
      "epoch 42; iter: 200; batch classifier loss: 0.461217\n",
      "epoch 42; iter: 400; batch classifier loss: 0.423057\n",
      "epoch 42; iter: 600; batch classifier loss: 0.437448\n",
      "epoch 42; iter: 800; batch classifier loss: 0.510215\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.507472\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.372952\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.312430\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.426427\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.358310\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.391831\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.485437\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.437094\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.327890\n",
      "epoch 43; iter: 0; batch classifier loss: 0.374100\n",
      "epoch 43; iter: 200; batch classifier loss: 0.401994\n",
      "epoch 43; iter: 400; batch classifier loss: 0.432264\n",
      "epoch 43; iter: 600; batch classifier loss: 0.436522\n",
      "epoch 43; iter: 800; batch classifier loss: 0.394327\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.375370\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.437734\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.440284\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.402814\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.421295\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.439847\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.411236\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.414329\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.479429\n",
      "epoch 44; iter: 0; batch classifier loss: 0.351429\n",
      "epoch 44; iter: 200; batch classifier loss: 0.415713\n",
      "epoch 44; iter: 400; batch classifier loss: 0.481233\n",
      "epoch 44; iter: 600; batch classifier loss: 0.476630\n",
      "epoch 44; iter: 800; batch classifier loss: 0.348929\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.431688\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.409798\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.371764\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.407738\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.390606\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.446055\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.392236\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.398806\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.428358\n",
      "epoch 45; iter: 0; batch classifier loss: 0.395189\n",
      "epoch 45; iter: 200; batch classifier loss: 0.403454\n",
      "epoch 45; iter: 400; batch classifier loss: 0.408932\n",
      "epoch 45; iter: 600; batch classifier loss: 0.431273\n",
      "epoch 45; iter: 800; batch classifier loss: 0.401224\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.404003\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.372273\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.429772\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.425886\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.328753\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.489686\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.402805\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.466716\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.423266\n",
      "epoch 46; iter: 0; batch classifier loss: 0.372836\n",
      "epoch 46; iter: 200; batch classifier loss: 0.410408\n",
      "epoch 46; iter: 400; batch classifier loss: 0.545880\n",
      "epoch 46; iter: 600; batch classifier loss: 0.444221\n",
      "epoch 46; iter: 800; batch classifier loss: 0.435834\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.440568\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.411621\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.381631\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.410290\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.449367\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.384956\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.388702\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.502082\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.362780\n",
      "epoch 47; iter: 0; batch classifier loss: 0.333767\n",
      "epoch 47; iter: 200; batch classifier loss: 0.431384\n",
      "epoch 47; iter: 400; batch classifier loss: 0.458696\n",
      "epoch 47; iter: 600; batch classifier loss: 0.378386\n",
      "epoch 47; iter: 800; batch classifier loss: 0.425117\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.368391\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.396260\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.418460\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.482559\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.368921\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.429898\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.373711\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.415963\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.507544\n",
      "epoch 48; iter: 0; batch classifier loss: 0.414729\n",
      "epoch 48; iter: 200; batch classifier loss: 0.422424\n",
      "epoch 48; iter: 400; batch classifier loss: 0.406571\n",
      "epoch 48; iter: 600; batch classifier loss: 0.385946\n",
      "epoch 48; iter: 800; batch classifier loss: 0.455563\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.471289\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.458045\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.391302\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.455646\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.437974\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.330725\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.428754\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.387743\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.411467\n",
      "epoch 49; iter: 0; batch classifier loss: 0.391197\n",
      "epoch 49; iter: 200; batch classifier loss: 0.324293\n",
      "epoch 49; iter: 400; batch classifier loss: 0.422204\n",
      "epoch 49; iter: 600; batch classifier loss: 0.455190\n",
      "epoch 49; iter: 800; batch classifier loss: 0.419410\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.244137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49; iter: 1200; batch classifier loss: 0.522236\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.421347\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.367885\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.455164\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.426600\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.371275\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.355000\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.396587\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673173; batch adversarial loss: 0.652503\n",
      "epoch 0; iter: 200; batch classifier loss: 0.518279; batch adversarial loss: 0.604249\n",
      "epoch 1; iter: 0; batch classifier loss: 0.289601; batch adversarial loss: 0.590218\n",
      "epoch 1; iter: 200; batch classifier loss: 0.396133; batch adversarial loss: 0.549154\n",
      "epoch 2; iter: 0; batch classifier loss: 0.484407; batch adversarial loss: 0.514767\n",
      "epoch 2; iter: 200; batch classifier loss: 0.516335; batch adversarial loss: 0.545621\n",
      "epoch 3; iter: 0; batch classifier loss: 0.396189; batch adversarial loss: 0.568135\n",
      "epoch 3; iter: 200; batch classifier loss: 0.657454; batch adversarial loss: 0.455580\n",
      "epoch 4; iter: 0; batch classifier loss: 0.575685; batch adversarial loss: 0.548095\n",
      "epoch 4; iter: 200; batch classifier loss: 0.575832; batch adversarial loss: 0.470813\n",
      "epoch 5; iter: 0; batch classifier loss: 0.516590; batch adversarial loss: 0.502644\n",
      "epoch 5; iter: 200; batch classifier loss: 0.433551; batch adversarial loss: 0.420531\n",
      "epoch 6; iter: 0; batch classifier loss: 0.492492; batch adversarial loss: 0.468337\n",
      "epoch 6; iter: 200; batch classifier loss: 0.421115; batch adversarial loss: 0.430864\n",
      "epoch 7; iter: 0; batch classifier loss: 0.414216; batch adversarial loss: 0.415276\n",
      "epoch 7; iter: 200; batch classifier loss: 0.439008; batch adversarial loss: 0.451893\n",
      "epoch 8; iter: 0; batch classifier loss: 0.393967; batch adversarial loss: 0.446804\n",
      "epoch 8; iter: 200; batch classifier loss: 0.487624; batch adversarial loss: 0.413347\n",
      "epoch 9; iter: 0; batch classifier loss: 0.364446; batch adversarial loss: 0.472891\n",
      "epoch 9; iter: 200; batch classifier loss: 0.387955; batch adversarial loss: 0.431670\n",
      "epoch 10; iter: 0; batch classifier loss: 0.473770; batch adversarial loss: 0.427954\n",
      "epoch 10; iter: 200; batch classifier loss: 0.382695; batch adversarial loss: 0.429446\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539769; batch adversarial loss: 0.355067\n",
      "epoch 11; iter: 200; batch classifier loss: 0.508355; batch adversarial loss: 0.455115\n",
      "epoch 12; iter: 0; batch classifier loss: 0.435639; batch adversarial loss: 0.474867\n",
      "epoch 12; iter: 200; batch classifier loss: 0.437953; batch adversarial loss: 0.403376\n",
      "epoch 13; iter: 0; batch classifier loss: 0.408716; batch adversarial loss: 0.393521\n",
      "epoch 13; iter: 200; batch classifier loss: 0.371464; batch adversarial loss: 0.313060\n",
      "epoch 14; iter: 0; batch classifier loss: 0.355269; batch adversarial loss: 0.435734\n",
      "epoch 14; iter: 200; batch classifier loss: 0.333283; batch adversarial loss: 0.498957\n",
      "epoch 15; iter: 0; batch classifier loss: 0.431618; batch adversarial loss: 0.405151\n",
      "epoch 15; iter: 200; batch classifier loss: 0.438152; batch adversarial loss: 0.351753\n",
      "epoch 16; iter: 0; batch classifier loss: 0.329076; batch adversarial loss: 0.388556\n",
      "epoch 16; iter: 200; batch classifier loss: 0.413883; batch adversarial loss: 0.363314\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409392; batch adversarial loss: 0.426259\n",
      "epoch 17; iter: 200; batch classifier loss: 0.349354; batch adversarial loss: 0.348558\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359963; batch adversarial loss: 0.405902\n",
      "epoch 18; iter: 200; batch classifier loss: 0.450292; batch adversarial loss: 0.479833\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484246; batch adversarial loss: 0.432803\n",
      "epoch 19; iter: 200; batch classifier loss: 0.484955; batch adversarial loss: 0.424709\n",
      "epoch 20; iter: 0; batch classifier loss: 0.466745; batch adversarial loss: 0.380331\n",
      "epoch 20; iter: 200; batch classifier loss: 0.394899; batch adversarial loss: 0.457857\n",
      "epoch 21; iter: 0; batch classifier loss: 0.409500; batch adversarial loss: 0.438544\n",
      "epoch 21; iter: 200; batch classifier loss: 0.413479; batch adversarial loss: 0.440827\n",
      "epoch 22; iter: 0; batch classifier loss: 0.406503; batch adversarial loss: 0.498993\n",
      "epoch 22; iter: 200; batch classifier loss: 0.450930; batch adversarial loss: 0.448141\n",
      "epoch 23; iter: 0; batch classifier loss: 0.453102; batch adversarial loss: 0.420306\n",
      "epoch 23; iter: 200; batch classifier loss: 0.406778; batch adversarial loss: 0.401221\n",
      "epoch 24; iter: 0; batch classifier loss: 0.402528; batch adversarial loss: 0.462250\n",
      "epoch 24; iter: 200; batch classifier loss: 0.387022; batch adversarial loss: 0.466865\n",
      "epoch 25; iter: 0; batch classifier loss: 0.419357; batch adversarial loss: 0.439343\n",
      "epoch 25; iter: 200; batch classifier loss: 0.390917; batch adversarial loss: 0.410983\n",
      "epoch 26; iter: 0; batch classifier loss: 0.461658; batch adversarial loss: 0.467989\n",
      "epoch 26; iter: 200; batch classifier loss: 0.526765; batch adversarial loss: 0.465289\n",
      "epoch 27; iter: 0; batch classifier loss: 0.451594; batch adversarial loss: 0.404616\n",
      "epoch 27; iter: 200; batch classifier loss: 0.510904; batch adversarial loss: 0.339386\n",
      "epoch 28; iter: 0; batch classifier loss: 0.377835; batch adversarial loss: 0.381409\n",
      "epoch 28; iter: 200; batch classifier loss: 0.342482; batch adversarial loss: 0.466420\n",
      "epoch 29; iter: 0; batch classifier loss: 0.510935; batch adversarial loss: 0.481849\n",
      "epoch 29; iter: 200; batch classifier loss: 0.420385; batch adversarial loss: 0.438263\n",
      "epoch 30; iter: 0; batch classifier loss: 0.424570; batch adversarial loss: 0.478649\n",
      "epoch 30; iter: 200; batch classifier loss: 0.499159; batch adversarial loss: 0.416629\n",
      "epoch 31; iter: 0; batch classifier loss: 0.460276; batch adversarial loss: 0.353300\n",
      "epoch 31; iter: 200; batch classifier loss: 0.424343; batch adversarial loss: 0.446390\n",
      "epoch 32; iter: 0; batch classifier loss: 0.426010; batch adversarial loss: 0.452369\n",
      "epoch 32; iter: 200; batch classifier loss: 0.485503; batch adversarial loss: 0.405862\n",
      "epoch 33; iter: 0; batch classifier loss: 0.376933; batch adversarial loss: 0.367020\n",
      "epoch 33; iter: 200; batch classifier loss: 0.410808; batch adversarial loss: 0.342350\n",
      "epoch 34; iter: 0; batch classifier loss: 0.381793; batch adversarial loss: 0.346334\n",
      "epoch 34; iter: 200; batch classifier loss: 0.499054; batch adversarial loss: 0.410978\n",
      "epoch 35; iter: 0; batch classifier loss: 0.348894; batch adversarial loss: 0.482560\n",
      "epoch 35; iter: 200; batch classifier loss: 0.446529; batch adversarial loss: 0.404659\n",
      "epoch 36; iter: 0; batch classifier loss: 0.401087; batch adversarial loss: 0.401013\n",
      "epoch 36; iter: 200; batch classifier loss: 0.445398; batch adversarial loss: 0.367481\n",
      "epoch 37; iter: 0; batch classifier loss: 0.399802; batch adversarial loss: 0.370840\n",
      "epoch 37; iter: 200; batch classifier loss: 0.520099; batch adversarial loss: 0.348180\n",
      "epoch 38; iter: 0; batch classifier loss: 0.408799; batch adversarial loss: 0.390587\n",
      "epoch 38; iter: 200; batch classifier loss: 0.427236; batch adversarial loss: 0.446723\n",
      "epoch 39; iter: 0; batch classifier loss: 0.484530; batch adversarial loss: 0.386502\n",
      "epoch 39; iter: 200; batch classifier loss: 0.420218; batch adversarial loss: 0.397814\n",
      "epoch 40; iter: 0; batch classifier loss: 0.383791; batch adversarial loss: 0.339843\n",
      "epoch 40; iter: 200; batch classifier loss: 0.344111; batch adversarial loss: 0.460763\n",
      "epoch 41; iter: 0; batch classifier loss: 0.474390; batch adversarial loss: 0.485196\n",
      "epoch 41; iter: 200; batch classifier loss: 0.369052; batch adversarial loss: 0.469876\n",
      "epoch 42; iter: 0; batch classifier loss: 0.325191; batch adversarial loss: 0.479316\n",
      "epoch 42; iter: 200; batch classifier loss: 0.392820; batch adversarial loss: 0.542837\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414834; batch adversarial loss: 0.469667\n",
      "epoch 43; iter: 200; batch classifier loss: 0.518665; batch adversarial loss: 0.450599\n",
      "epoch 44; iter: 0; batch classifier loss: 0.331640; batch adversarial loss: 0.442453\n",
      "epoch 44; iter: 200; batch classifier loss: 0.478803; batch adversarial loss: 0.377367\n",
      "epoch 45; iter: 0; batch classifier loss: 0.534367; batch adversarial loss: 0.411419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45; iter: 200; batch classifier loss: 0.398308; batch adversarial loss: 0.469873\n",
      "epoch 46; iter: 0; batch classifier loss: 0.388457; batch adversarial loss: 0.411044\n",
      "epoch 46; iter: 200; batch classifier loss: 0.458543; batch adversarial loss: 0.484345\n",
      "epoch 47; iter: 0; batch classifier loss: 0.373478; batch adversarial loss: 0.343279\n",
      "epoch 47; iter: 200; batch classifier loss: 0.408126; batch adversarial loss: 0.364018\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418261; batch adversarial loss: 0.410998\n",
      "epoch 48; iter: 200; batch classifier loss: 0.468817; batch adversarial loss: 0.428763\n",
      "epoch 49; iter: 0; batch classifier loss: 0.448616; batch adversarial loss: 0.472633\n",
      "epoch 49; iter: 200; batch classifier loss: 0.435860; batch adversarial loss: 0.364923\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725443\n",
      "epoch 0; iter: 200; batch classifier loss: 0.391978\n",
      "epoch 1; iter: 0; batch classifier loss: 0.459378\n",
      "epoch 1; iter: 200; batch classifier loss: 0.408224\n",
      "epoch 2; iter: 0; batch classifier loss: 0.431869\n",
      "epoch 2; iter: 200; batch classifier loss: 0.327126\n",
      "epoch 3; iter: 0; batch classifier loss: 0.451484\n",
      "epoch 3; iter: 200; batch classifier loss: 0.395589\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537322\n",
      "epoch 4; iter: 200; batch classifier loss: 0.401000\n",
      "epoch 5; iter: 0; batch classifier loss: 0.338963\n",
      "epoch 5; iter: 200; batch classifier loss: 0.501924\n",
      "epoch 6; iter: 0; batch classifier loss: 0.498293\n",
      "epoch 6; iter: 200; batch classifier loss: 0.370669\n",
      "epoch 7; iter: 0; batch classifier loss: 0.408646\n",
      "epoch 7; iter: 200; batch classifier loss: 0.428639\n",
      "epoch 8; iter: 0; batch classifier loss: 0.522237\n",
      "epoch 8; iter: 200; batch classifier loss: 0.438670\n",
      "epoch 9; iter: 0; batch classifier loss: 0.450222\n",
      "epoch 9; iter: 200; batch classifier loss: 0.381306\n",
      "epoch 10; iter: 0; batch classifier loss: 0.406103\n",
      "epoch 10; iter: 200; batch classifier loss: 0.432075\n",
      "epoch 11; iter: 0; batch classifier loss: 0.426095\n",
      "epoch 11; iter: 200; batch classifier loss: 0.441923\n",
      "epoch 12; iter: 0; batch classifier loss: 0.378730\n",
      "epoch 12; iter: 200; batch classifier loss: 0.459061\n",
      "epoch 13; iter: 0; batch classifier loss: 0.487735\n",
      "epoch 13; iter: 200; batch classifier loss: 0.338601\n",
      "epoch 14; iter: 0; batch classifier loss: 0.445871\n",
      "epoch 14; iter: 200; batch classifier loss: 0.463454\n",
      "epoch 15; iter: 0; batch classifier loss: 0.453692\n",
      "epoch 15; iter: 200; batch classifier loss: 0.433277\n",
      "epoch 16; iter: 0; batch classifier loss: 0.434356\n",
      "epoch 16; iter: 200; batch classifier loss: 0.432712\n",
      "epoch 17; iter: 0; batch classifier loss: 0.398387\n",
      "epoch 17; iter: 200; batch classifier loss: 0.433530\n",
      "epoch 18; iter: 0; batch classifier loss: 0.487348\n",
      "epoch 18; iter: 200; batch classifier loss: 0.455804\n",
      "epoch 19; iter: 0; batch classifier loss: 0.334858\n",
      "epoch 19; iter: 200; batch classifier loss: 0.416915\n",
      "epoch 20; iter: 0; batch classifier loss: 0.431323\n",
      "epoch 20; iter: 200; batch classifier loss: 0.403211\n",
      "epoch 21; iter: 0; batch classifier loss: 0.416995\n",
      "epoch 21; iter: 200; batch classifier loss: 0.426821\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483765\n",
      "epoch 22; iter: 200; batch classifier loss: 0.518190\n",
      "epoch 23; iter: 0; batch classifier loss: 0.420122\n",
      "epoch 23; iter: 200; batch classifier loss: 0.416879\n",
      "epoch 24; iter: 0; batch classifier loss: 0.343170\n",
      "epoch 24; iter: 200; batch classifier loss: 0.379329\n",
      "epoch 25; iter: 0; batch classifier loss: 0.374278\n",
      "epoch 25; iter: 200; batch classifier loss: 0.475351\n",
      "epoch 26; iter: 0; batch classifier loss: 0.401434\n",
      "epoch 26; iter: 200; batch classifier loss: 0.363759\n",
      "epoch 27; iter: 0; batch classifier loss: 0.479483\n",
      "epoch 27; iter: 200; batch classifier loss: 0.424585\n",
      "epoch 28; iter: 0; batch classifier loss: 0.398803\n",
      "epoch 28; iter: 200; batch classifier loss: 0.413351\n",
      "epoch 29; iter: 0; batch classifier loss: 0.392277\n",
      "epoch 29; iter: 200; batch classifier loss: 0.388350\n",
      "epoch 30; iter: 0; batch classifier loss: 0.436000\n",
      "epoch 30; iter: 200; batch classifier loss: 0.323434\n",
      "epoch 31; iter: 0; batch classifier loss: 0.393886\n",
      "epoch 31; iter: 200; batch classifier loss: 0.401534\n",
      "epoch 32; iter: 0; batch classifier loss: 0.434302\n",
      "epoch 32; iter: 200; batch classifier loss: 0.448234\n",
      "epoch 33; iter: 0; batch classifier loss: 0.369374\n",
      "epoch 33; iter: 200; batch classifier loss: 0.475549\n",
      "epoch 34; iter: 0; batch classifier loss: 0.357766\n",
      "epoch 34; iter: 200; batch classifier loss: 0.487663\n",
      "epoch 35; iter: 0; batch classifier loss: 0.483738\n",
      "epoch 35; iter: 200; batch classifier loss: 0.428863\n",
      "epoch 36; iter: 0; batch classifier loss: 0.453635\n",
      "epoch 36; iter: 200; batch classifier loss: 0.373435\n",
      "epoch 37; iter: 0; batch classifier loss: 0.452224\n",
      "epoch 37; iter: 200; batch classifier loss: 0.396221\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409475\n",
      "epoch 38; iter: 200; batch classifier loss: 0.488542\n",
      "epoch 39; iter: 0; batch classifier loss: 0.460566\n",
      "epoch 39; iter: 200; batch classifier loss: 0.432115\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425598\n",
      "epoch 40; iter: 200; batch classifier loss: 0.434294\n",
      "epoch 41; iter: 0; batch classifier loss: 0.461829\n",
      "epoch 41; iter: 200; batch classifier loss: 0.495193\n",
      "epoch 42; iter: 0; batch classifier loss: 0.383972\n",
      "epoch 42; iter: 200; batch classifier loss: 0.445078\n",
      "epoch 43; iter: 0; batch classifier loss: 0.401651\n",
      "epoch 43; iter: 200; batch classifier loss: 0.425287\n",
      "epoch 44; iter: 0; batch classifier loss: 0.386113\n",
      "epoch 44; iter: 200; batch classifier loss: 0.455350\n",
      "epoch 45; iter: 0; batch classifier loss: 0.417073\n",
      "epoch 45; iter: 200; batch classifier loss: 0.412108\n",
      "epoch 46; iter: 0; batch classifier loss: 0.430034\n",
      "epoch 46; iter: 200; batch classifier loss: 0.414989\n",
      "epoch 47; iter: 0; batch classifier loss: 0.418133\n",
      "epoch 47; iter: 200; batch classifier loss: 0.447875\n",
      "epoch 48; iter: 0; batch classifier loss: 0.374411\n",
      "epoch 48; iter: 200; batch classifier loss: 0.426992\n",
      "epoch 49; iter: 0; batch classifier loss: 0.394613\n",
      "epoch 49; iter: 200; batch classifier loss: 0.394938\n",
      "run = 7\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686813; batch adversarial loss: 0.525182\n",
      "epoch 0; iter: 200; batch classifier loss: 0.437413; batch adversarial loss: 0.632958\n",
      "epoch 0; iter: 400; batch classifier loss: 0.494470; batch adversarial loss: 0.639546\n",
      "epoch 0; iter: 600; batch classifier loss: 0.473343; batch adversarial loss: 0.543701\n",
      "epoch 0; iter: 800; batch classifier loss: 0.562779; batch adversarial loss: 0.541288\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.464461; batch adversarial loss: 0.474401\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.491820; batch adversarial loss: 0.502269\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.428464; batch adversarial loss: 0.442798\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.436119; batch adversarial loss: 0.478560\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.429130; batch adversarial loss: 0.409816\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.436262; batch adversarial loss: 0.403007\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.496130; batch adversarial loss: 0.406425\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.455463; batch adversarial loss: 0.383366\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.358276; batch adversarial loss: 0.434978\n",
      "epoch 1; iter: 0; batch classifier loss: 0.400380; batch adversarial loss: 0.474076\n",
      "epoch 1; iter: 200; batch classifier loss: 0.401563; batch adversarial loss: 0.337887\n",
      "epoch 1; iter: 400; batch classifier loss: 0.439169; batch adversarial loss: 0.408738\n",
      "epoch 1; iter: 600; batch classifier loss: 0.545978; batch adversarial loss: 0.473379\n",
      "epoch 1; iter: 800; batch classifier loss: 0.404757; batch adversarial loss: 0.472870\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.386560; batch adversarial loss: 0.550715\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.360366; batch adversarial loss: 0.380538\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.444392; batch adversarial loss: 0.485922\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.367846; batch adversarial loss: 0.443484\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.491518; batch adversarial loss: 0.418507\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.316774; batch adversarial loss: 0.457841\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.329299; batch adversarial loss: 0.425757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1; iter: 2400; batch classifier loss: 0.354788; batch adversarial loss: 0.427555\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.389411; batch adversarial loss: 0.310404\n",
      "epoch 2; iter: 0; batch classifier loss: 0.467957; batch adversarial loss: 0.483720\n",
      "epoch 2; iter: 200; batch classifier loss: 0.387591; batch adversarial loss: 0.469764\n",
      "epoch 2; iter: 400; batch classifier loss: 0.434607; batch adversarial loss: 0.427899\n",
      "epoch 2; iter: 600; batch classifier loss: 0.467961; batch adversarial loss: 0.391513\n",
      "epoch 2; iter: 800; batch classifier loss: 0.393453; batch adversarial loss: 0.393959\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.452268; batch adversarial loss: 0.367488\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.439402; batch adversarial loss: 0.418710\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.356428; batch adversarial loss: 0.377001\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.393328; batch adversarial loss: 0.476036\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.543322; batch adversarial loss: 0.449168\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.485571; batch adversarial loss: 0.433150\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.437355; batch adversarial loss: 0.518676\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.476232; batch adversarial loss: 0.404756\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.415986; batch adversarial loss: 0.366959\n",
      "epoch 3; iter: 0; batch classifier loss: 0.361040; batch adversarial loss: 0.501100\n",
      "epoch 3; iter: 200; batch classifier loss: 0.378863; batch adversarial loss: 0.429549\n",
      "epoch 3; iter: 400; batch classifier loss: 0.372423; batch adversarial loss: 0.419029\n",
      "epoch 3; iter: 600; batch classifier loss: 0.410766; batch adversarial loss: 0.434115\n",
      "epoch 3; iter: 800; batch classifier loss: 0.546091; batch adversarial loss: 0.442116\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.411135; batch adversarial loss: 0.449563\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.376898; batch adversarial loss: 0.366243\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.438542; batch adversarial loss: 0.442450\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.374933; batch adversarial loss: 0.402016\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.421099; batch adversarial loss: 0.379944\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.458238; batch adversarial loss: 0.406807\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.447871; batch adversarial loss: 0.460853\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.388570; batch adversarial loss: 0.422550\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.439953; batch adversarial loss: 0.324245\n",
      "epoch 4; iter: 0; batch classifier loss: 0.374931; batch adversarial loss: 0.530884\n",
      "epoch 4; iter: 200; batch classifier loss: 0.409211; batch adversarial loss: 0.375826\n",
      "epoch 4; iter: 400; batch classifier loss: 0.390927; batch adversarial loss: 0.529364\n",
      "epoch 4; iter: 600; batch classifier loss: 0.368226; batch adversarial loss: 0.392422\n",
      "epoch 4; iter: 800; batch classifier loss: 0.397330; batch adversarial loss: 0.391227\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.499671; batch adversarial loss: 0.325562\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.344520; batch adversarial loss: 0.338934\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.470782; batch adversarial loss: 0.390033\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.453854; batch adversarial loss: 0.405312\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.419199; batch adversarial loss: 0.336731\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.499536; batch adversarial loss: 0.352355\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.428293; batch adversarial loss: 0.475644\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.528073; batch adversarial loss: 0.429681\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.402009; batch adversarial loss: 0.476121\n",
      "epoch 5; iter: 0; batch classifier loss: 0.368240; batch adversarial loss: 0.353040\n",
      "epoch 5; iter: 200; batch classifier loss: 0.367766; batch adversarial loss: 0.366891\n",
      "epoch 5; iter: 400; batch classifier loss: 0.342808; batch adversarial loss: 0.406439\n",
      "epoch 5; iter: 600; batch classifier loss: 0.447629; batch adversarial loss: 0.463232\n",
      "epoch 5; iter: 800; batch classifier loss: 0.394056; batch adversarial loss: 0.367809\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.396168; batch adversarial loss: 0.375463\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.475916; batch adversarial loss: 0.530291\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.439707; batch adversarial loss: 0.477880\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.439464; batch adversarial loss: 0.422515\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.496337; batch adversarial loss: 0.404468\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.338930; batch adversarial loss: 0.381870\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.400679; batch adversarial loss: 0.379458\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.349769; batch adversarial loss: 0.406448\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.355828; batch adversarial loss: 0.420520\n",
      "epoch 6; iter: 0; batch classifier loss: 0.457515; batch adversarial loss: 0.487528\n",
      "epoch 6; iter: 200; batch classifier loss: 0.453131; batch adversarial loss: 0.437073\n",
      "epoch 6; iter: 400; batch classifier loss: 0.407619; batch adversarial loss: 0.432874\n",
      "epoch 6; iter: 600; batch classifier loss: 0.485602; batch adversarial loss: 0.404560\n",
      "epoch 6; iter: 800; batch classifier loss: 0.437701; batch adversarial loss: 0.474788\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.537343; batch adversarial loss: 0.393726\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.439312; batch adversarial loss: 0.406882\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.520549; batch adversarial loss: 0.490582\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.385664; batch adversarial loss: 0.394528\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.376566; batch adversarial loss: 0.448674\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.503604; batch adversarial loss: 0.555508\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.386465; batch adversarial loss: 0.366141\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.436193; batch adversarial loss: 0.526388\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.474696; batch adversarial loss: 0.432556\n",
      "epoch 7; iter: 0; batch classifier loss: 0.452616; batch adversarial loss: 0.295625\n",
      "epoch 7; iter: 200; batch classifier loss: 0.389273; batch adversarial loss: 0.445339\n",
      "epoch 7; iter: 400; batch classifier loss: 0.407705; batch adversarial loss: 0.422973\n",
      "epoch 7; iter: 600; batch classifier loss: 0.407708; batch adversarial loss: 0.513398\n",
      "epoch 7; iter: 800; batch classifier loss: 0.383605; batch adversarial loss: 0.324418\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.402887; batch adversarial loss: 0.379875\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.400081; batch adversarial loss: 0.377821\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.447001; batch adversarial loss: 0.407796\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.476226; batch adversarial loss: 0.471316\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.415393; batch adversarial loss: 0.458076\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.441331; batch adversarial loss: 0.423705\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.427666; batch adversarial loss: 0.418565\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.407688; batch adversarial loss: 0.407999\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.389841; batch adversarial loss: 0.376270\n",
      "epoch 8; iter: 0; batch classifier loss: 0.443975; batch adversarial loss: 0.432200\n",
      "epoch 8; iter: 200; batch classifier loss: 0.398727; batch adversarial loss: 0.380430\n",
      "epoch 8; iter: 400; batch classifier loss: 0.481702; batch adversarial loss: 0.417856\n",
      "epoch 8; iter: 600; batch classifier loss: 0.470829; batch adversarial loss: 0.322786\n",
      "epoch 8; iter: 800; batch classifier loss: 0.485207; batch adversarial loss: 0.421017\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.432734; batch adversarial loss: 0.297372\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.365075; batch adversarial loss: 0.422541\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.342646; batch adversarial loss: 0.473561\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.389850; batch adversarial loss: 0.376066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8; iter: 1800; batch classifier loss: 0.494990; batch adversarial loss: 0.475350\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.350703; batch adversarial loss: 0.382755\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.372722; batch adversarial loss: 0.403586\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.393885; batch adversarial loss: 0.510314\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.340819; batch adversarial loss: 0.435150\n",
      "epoch 9; iter: 0; batch classifier loss: 0.455698; batch adversarial loss: 0.380499\n",
      "epoch 9; iter: 200; batch classifier loss: 0.423652; batch adversarial loss: 0.350772\n",
      "epoch 9; iter: 400; batch classifier loss: 0.465479; batch adversarial loss: 0.366395\n",
      "epoch 9; iter: 600; batch classifier loss: 0.404550; batch adversarial loss: 0.350250\n",
      "epoch 9; iter: 800; batch classifier loss: 0.401157; batch adversarial loss: 0.324146\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.429699; batch adversarial loss: 0.457773\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.453887; batch adversarial loss: 0.505630\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.399129; batch adversarial loss: 0.390966\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.416619; batch adversarial loss: 0.380035\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.462199; batch adversarial loss: 0.449699\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.431933; batch adversarial loss: 0.379974\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.482100; batch adversarial loss: 0.519625\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.406994; batch adversarial loss: 0.405601\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.382564; batch adversarial loss: 0.459365\n",
      "epoch 10; iter: 0; batch classifier loss: 0.439071; batch adversarial loss: 0.377921\n",
      "epoch 10; iter: 200; batch classifier loss: 0.462173; batch adversarial loss: 0.394847\n",
      "epoch 10; iter: 400; batch classifier loss: 0.453714; batch adversarial loss: 0.445135\n",
      "epoch 10; iter: 600; batch classifier loss: 0.423970; batch adversarial loss: 0.353307\n",
      "epoch 10; iter: 800; batch classifier loss: 0.391629; batch adversarial loss: 0.350034\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.440708; batch adversarial loss: 0.378496\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.310528; batch adversarial loss: 0.351968\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.417432; batch adversarial loss: 0.499808\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.479133; batch adversarial loss: 0.296514\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.492271; batch adversarial loss: 0.336654\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.392134; batch adversarial loss: 0.362525\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.401558; batch adversarial loss: 0.516478\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.450677; batch adversarial loss: 0.472159\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.394194; batch adversarial loss: 0.457728\n",
      "epoch 11; iter: 0; batch classifier loss: 0.408269; batch adversarial loss: 0.404738\n",
      "epoch 11; iter: 200; batch classifier loss: 0.538315; batch adversarial loss: 0.387796\n",
      "epoch 11; iter: 400; batch classifier loss: 0.412139; batch adversarial loss: 0.474784\n",
      "epoch 11; iter: 600; batch classifier loss: 0.360488; batch adversarial loss: 0.484253\n",
      "epoch 11; iter: 800; batch classifier loss: 0.393827; batch adversarial loss: 0.505474\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.432419; batch adversarial loss: 0.431595\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.470679; batch adversarial loss: 0.376124\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.383949; batch adversarial loss: 0.419890\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.399423; batch adversarial loss: 0.431316\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.416658; batch adversarial loss: 0.339239\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.364325; batch adversarial loss: 0.364696\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.493915; batch adversarial loss: 0.434193\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.294061; batch adversarial loss: 0.390568\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.406601; batch adversarial loss: 0.448694\n",
      "epoch 12; iter: 0; batch classifier loss: 0.367334; batch adversarial loss: 0.418698\n",
      "epoch 12; iter: 200; batch classifier loss: 0.392047; batch adversarial loss: 0.393524\n",
      "epoch 12; iter: 400; batch classifier loss: 0.413157; batch adversarial loss: 0.378873\n",
      "epoch 12; iter: 600; batch classifier loss: 0.434988; batch adversarial loss: 0.434829\n",
      "epoch 12; iter: 800; batch classifier loss: 0.508513; batch adversarial loss: 0.374657\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.483520; batch adversarial loss: 0.393850\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.409794; batch adversarial loss: 0.299511\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.394241; batch adversarial loss: 0.447499\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.432735; batch adversarial loss: 0.348130\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.382962; batch adversarial loss: 0.391677\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.463589; batch adversarial loss: 0.407270\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.364962; batch adversarial loss: 0.307029\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.440169; batch adversarial loss: 0.395522\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.360939; batch adversarial loss: 0.500986\n",
      "epoch 13; iter: 0; batch classifier loss: 0.382802; batch adversarial loss: 0.379696\n",
      "epoch 13; iter: 200; batch classifier loss: 0.331707; batch adversarial loss: 0.430594\n",
      "epoch 13; iter: 400; batch classifier loss: 0.488454; batch adversarial loss: 0.378467\n",
      "epoch 13; iter: 600; batch classifier loss: 0.445730; batch adversarial loss: 0.473416\n",
      "epoch 13; iter: 800; batch classifier loss: 0.399418; batch adversarial loss: 0.456100\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.389448; batch adversarial loss: 0.418831\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.465286; batch adversarial loss: 0.476186\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.446042; batch adversarial loss: 0.460330\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.384141; batch adversarial loss: 0.327354\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.404335; batch adversarial loss: 0.447573\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.398651; batch adversarial loss: 0.393021\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.364127; batch adversarial loss: 0.421209\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.463990; batch adversarial loss: 0.503637\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.339420; batch adversarial loss: 0.352018\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389225; batch adversarial loss: 0.392406\n",
      "epoch 14; iter: 200; batch classifier loss: 0.388007; batch adversarial loss: 0.473543\n",
      "epoch 14; iter: 400; batch classifier loss: 0.416554; batch adversarial loss: 0.441418\n",
      "epoch 14; iter: 600; batch classifier loss: 0.454605; batch adversarial loss: 0.380666\n",
      "epoch 14; iter: 800; batch classifier loss: 0.436006; batch adversarial loss: 0.431670\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.439058; batch adversarial loss: 0.523152\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.393410; batch adversarial loss: 0.473890\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.452568; batch adversarial loss: 0.365653\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.425606; batch adversarial loss: 0.390279\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.438400; batch adversarial loss: 0.397345\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.437651; batch adversarial loss: 0.427578\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.388696; batch adversarial loss: 0.368234\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.394172; batch adversarial loss: 0.458636\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.421835; batch adversarial loss: 0.321100\n",
      "epoch 15; iter: 0; batch classifier loss: 0.416151; batch adversarial loss: 0.434787\n",
      "epoch 15; iter: 200; batch classifier loss: 0.419362; batch adversarial loss: 0.435600\n",
      "epoch 15; iter: 400; batch classifier loss: 0.476748; batch adversarial loss: 0.460947\n",
      "epoch 15; iter: 600; batch classifier loss: 0.387246; batch adversarial loss: 0.407354\n",
      "epoch 15; iter: 800; batch classifier loss: 0.401455; batch adversarial loss: 0.378905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 1000; batch classifier loss: 0.331138; batch adversarial loss: 0.366674\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.367359; batch adversarial loss: 0.475417\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.331285; batch adversarial loss: 0.499981\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.502807; batch adversarial loss: 0.446987\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.421240; batch adversarial loss: 0.391599\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.392653; batch adversarial loss: 0.365088\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.468325; batch adversarial loss: 0.472773\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.357095; batch adversarial loss: 0.442355\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.385551; batch adversarial loss: 0.431413\n",
      "epoch 16; iter: 0; batch classifier loss: 0.386549; batch adversarial loss: 0.423127\n",
      "epoch 16; iter: 200; batch classifier loss: 0.394187; batch adversarial loss: 0.365122\n",
      "epoch 16; iter: 400; batch classifier loss: 0.411300; batch adversarial loss: 0.487608\n",
      "epoch 16; iter: 600; batch classifier loss: 0.536386; batch adversarial loss: 0.378171\n",
      "epoch 16; iter: 800; batch classifier loss: 0.394481; batch adversarial loss: 0.421810\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.376654; batch adversarial loss: 0.381711\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.410232; batch adversarial loss: 0.381598\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.401549; batch adversarial loss: 0.350289\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.403852; batch adversarial loss: 0.517752\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.398507; batch adversarial loss: 0.555986\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.411732; batch adversarial loss: 0.447394\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.393033; batch adversarial loss: 0.474180\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.472236; batch adversarial loss: 0.419790\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.387348; batch adversarial loss: 0.461126\n",
      "epoch 17; iter: 0; batch classifier loss: 0.416462; batch adversarial loss: 0.531601\n",
      "epoch 17; iter: 200; batch classifier loss: 0.357508; batch adversarial loss: 0.407273\n",
      "epoch 17; iter: 400; batch classifier loss: 0.386724; batch adversarial loss: 0.364557\n",
      "epoch 17; iter: 600; batch classifier loss: 0.448202; batch adversarial loss: 0.393356\n",
      "epoch 17; iter: 800; batch classifier loss: 0.384114; batch adversarial loss: 0.433988\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.428097; batch adversarial loss: 0.364638\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.396345; batch adversarial loss: 0.420922\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.323748; batch adversarial loss: 0.475329\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.392747; batch adversarial loss: 0.351724\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.543928; batch adversarial loss: 0.584567\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.506047; batch adversarial loss: 0.444000\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.450769; batch adversarial loss: 0.459993\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.385595; batch adversarial loss: 0.443689\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.355763; batch adversarial loss: 0.352353\n",
      "epoch 18; iter: 0; batch classifier loss: 0.426176; batch adversarial loss: 0.570127\n",
      "epoch 18; iter: 200; batch classifier loss: 0.400378; batch adversarial loss: 0.349872\n",
      "epoch 18; iter: 400; batch classifier loss: 0.374976; batch adversarial loss: 0.339672\n",
      "epoch 18; iter: 600; batch classifier loss: 0.357181; batch adversarial loss: 0.409002\n",
      "epoch 18; iter: 800; batch classifier loss: 0.325495; batch adversarial loss: 0.396086\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.406136; batch adversarial loss: 0.376751\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.425541; batch adversarial loss: 0.432337\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.346389; batch adversarial loss: 0.434783\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.379954; batch adversarial loss: 0.378074\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.406982; batch adversarial loss: 0.408037\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.424454; batch adversarial loss: 0.530446\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.364453; batch adversarial loss: 0.450012\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.378180; batch adversarial loss: 0.448037\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.392720; batch adversarial loss: 0.499502\n",
      "epoch 19; iter: 0; batch classifier loss: 0.448111; batch adversarial loss: 0.390561\n",
      "epoch 19; iter: 200; batch classifier loss: 0.404714; batch adversarial loss: 0.601121\n",
      "epoch 19; iter: 400; batch classifier loss: 0.458426; batch adversarial loss: 0.407747\n",
      "epoch 19; iter: 600; batch classifier loss: 0.397509; batch adversarial loss: 0.420247\n",
      "epoch 19; iter: 800; batch classifier loss: 0.419587; batch adversarial loss: 0.360632\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.357373; batch adversarial loss: 0.478736\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.447354; batch adversarial loss: 0.418256\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.449969; batch adversarial loss: 0.419110\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.391307; batch adversarial loss: 0.472254\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.431363; batch adversarial loss: 0.337910\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.467219; batch adversarial loss: 0.460469\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.504979; batch adversarial loss: 0.404818\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.412747; batch adversarial loss: 0.405098\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.485277; batch adversarial loss: 0.391246\n",
      "epoch 20; iter: 0; batch classifier loss: 0.377160; batch adversarial loss: 0.432802\n",
      "epoch 20; iter: 200; batch classifier loss: 0.406976; batch adversarial loss: 0.405367\n",
      "epoch 20; iter: 400; batch classifier loss: 0.459595; batch adversarial loss: 0.408133\n",
      "epoch 20; iter: 600; batch classifier loss: 0.425743; batch adversarial loss: 0.390251\n",
      "epoch 20; iter: 800; batch classifier loss: 0.463657; batch adversarial loss: 0.416830\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.379109; batch adversarial loss: 0.405006\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.307770; batch adversarial loss: 0.296947\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.405844; batch adversarial loss: 0.361497\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.448812; batch adversarial loss: 0.365831\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.399041; batch adversarial loss: 0.377920\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.379509; batch adversarial loss: 0.431909\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.449251; batch adversarial loss: 0.446756\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.382104; batch adversarial loss: 0.381671\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.354880; batch adversarial loss: 0.488960\n",
      "epoch 21; iter: 0; batch classifier loss: 0.421171; batch adversarial loss: 0.446456\n",
      "epoch 21; iter: 200; batch classifier loss: 0.475655; batch adversarial loss: 0.324897\n",
      "epoch 21; iter: 400; batch classifier loss: 0.427187; batch adversarial loss: 0.449500\n",
      "epoch 21; iter: 600; batch classifier loss: 0.422734; batch adversarial loss: 0.502526\n",
      "epoch 21; iter: 800; batch classifier loss: 0.340791; batch adversarial loss: 0.517120\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.403603; batch adversarial loss: 0.432446\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.387527; batch adversarial loss: 0.324474\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.368237; batch adversarial loss: 0.386860\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.382267; batch adversarial loss: 0.405292\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.419417; batch adversarial loss: 0.364988\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.446836; batch adversarial loss: 0.433835\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.446849; batch adversarial loss: 0.501429\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.354384; batch adversarial loss: 0.392683\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.402296; batch adversarial loss: 0.393833\n",
      "epoch 22; iter: 0; batch classifier loss: 0.380746; batch adversarial loss: 0.416252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 200; batch classifier loss: 0.404906; batch adversarial loss: 0.406858\n",
      "epoch 22; iter: 400; batch classifier loss: 0.455621; batch adversarial loss: 0.543674\n",
      "epoch 22; iter: 600; batch classifier loss: 0.396781; batch adversarial loss: 0.462772\n",
      "epoch 22; iter: 800; batch classifier loss: 0.488427; batch adversarial loss: 0.407783\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.413061; batch adversarial loss: 0.502887\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.433653; batch adversarial loss: 0.377523\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.437364; batch adversarial loss: 0.324899\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.483134; batch adversarial loss: 0.471778\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.401758; batch adversarial loss: 0.447064\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.363490; batch adversarial loss: 0.423366\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.431486; batch adversarial loss: 0.433759\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.457176; batch adversarial loss: 0.407951\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.502995; batch adversarial loss: 0.505785\n",
      "epoch 23; iter: 0; batch classifier loss: 0.430523; batch adversarial loss: 0.472939\n",
      "epoch 23; iter: 200; batch classifier loss: 0.390715; batch adversarial loss: 0.448670\n",
      "epoch 23; iter: 400; batch classifier loss: 0.419944; batch adversarial loss: 0.407416\n",
      "epoch 23; iter: 600; batch classifier loss: 0.381083; batch adversarial loss: 0.486431\n",
      "epoch 23; iter: 800; batch classifier loss: 0.428734; batch adversarial loss: 0.484202\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.422776; batch adversarial loss: 0.458689\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.489411; batch adversarial loss: 0.393094\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.475454; batch adversarial loss: 0.391736\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.410626; batch adversarial loss: 0.475117\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.413819; batch adversarial loss: 0.499710\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.442143; batch adversarial loss: 0.419718\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.488202; batch adversarial loss: 0.459009\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.484006; batch adversarial loss: 0.415998\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.435670; batch adversarial loss: 0.349570\n",
      "epoch 24; iter: 0; batch classifier loss: 0.456036; batch adversarial loss: 0.435100\n",
      "epoch 24; iter: 200; batch classifier loss: 0.495667; batch adversarial loss: 0.420137\n",
      "epoch 24; iter: 400; batch classifier loss: 0.476873; batch adversarial loss: 0.392653\n",
      "epoch 24; iter: 600; batch classifier loss: 0.475938; batch adversarial loss: 0.457677\n",
      "epoch 24; iter: 800; batch classifier loss: 0.459799; batch adversarial loss: 0.487341\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.393682; batch adversarial loss: 0.404802\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.402135; batch adversarial loss: 0.487461\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.364717; batch adversarial loss: 0.514130\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.373101; batch adversarial loss: 0.418236\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.421214; batch adversarial loss: 0.380575\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.400519; batch adversarial loss: 0.501490\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.421542; batch adversarial loss: 0.283696\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.498918; batch adversarial loss: 0.420066\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.389169; batch adversarial loss: 0.391097\n",
      "epoch 25; iter: 0; batch classifier loss: 0.358802; batch adversarial loss: 0.404396\n",
      "epoch 25; iter: 200; batch classifier loss: 0.445504; batch adversarial loss: 0.380108\n",
      "epoch 25; iter: 400; batch classifier loss: 0.435941; batch adversarial loss: 0.433322\n",
      "epoch 25; iter: 600; batch classifier loss: 0.461903; batch adversarial loss: 0.365155\n",
      "epoch 25; iter: 800; batch classifier loss: 0.394503; batch adversarial loss: 0.365221\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.408089; batch adversarial loss: 0.392662\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.495179; batch adversarial loss: 0.419648\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.367905; batch adversarial loss: 0.337002\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.382767; batch adversarial loss: 0.395027\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.368495; batch adversarial loss: 0.459754\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.453140; batch adversarial loss: 0.476354\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.353438; batch adversarial loss: 0.447600\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.367501; batch adversarial loss: 0.475960\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.421958; batch adversarial loss: 0.406654\n",
      "epoch 26; iter: 0; batch classifier loss: 0.404152; batch adversarial loss: 0.431186\n",
      "epoch 26; iter: 200; batch classifier loss: 0.337303; batch adversarial loss: 0.402353\n",
      "epoch 26; iter: 400; batch classifier loss: 0.432868; batch adversarial loss: 0.501325\n",
      "epoch 26; iter: 600; batch classifier loss: 0.435234; batch adversarial loss: 0.404489\n",
      "epoch 26; iter: 800; batch classifier loss: 0.377886; batch adversarial loss: 0.362614\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.539749; batch adversarial loss: 0.325641\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.387946; batch adversarial loss: 0.475328\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.447329; batch adversarial loss: 0.351230\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.390361; batch adversarial loss: 0.423577\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.390873; batch adversarial loss: 0.472456\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.441875; batch adversarial loss: 0.421186\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.375907; batch adversarial loss: 0.394785\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.347342; batch adversarial loss: 0.379128\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.378570; batch adversarial loss: 0.435865\n",
      "epoch 27; iter: 0; batch classifier loss: 0.345317; batch adversarial loss: 0.434958\n",
      "epoch 27; iter: 200; batch classifier loss: 0.494642; batch adversarial loss: 0.427105\n",
      "epoch 27; iter: 400; batch classifier loss: 0.379208; batch adversarial loss: 0.364983\n",
      "epoch 27; iter: 600; batch classifier loss: 0.398968; batch adversarial loss: 0.457223\n",
      "epoch 27; iter: 800; batch classifier loss: 0.428654; batch adversarial loss: 0.432008\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.480780; batch adversarial loss: 0.393215\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.439367; batch adversarial loss: 0.520407\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.557150; batch adversarial loss: 0.405805\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.423163; batch adversarial loss: 0.409018\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.368678; batch adversarial loss: 0.443834\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.361485; batch adversarial loss: 0.392133\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.414338; batch adversarial loss: 0.339966\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.385601; batch adversarial loss: 0.419700\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.407253; batch adversarial loss: 0.388077\n",
      "epoch 28; iter: 0; batch classifier loss: 0.364128; batch adversarial loss: 0.407213\n",
      "epoch 28; iter: 200; batch classifier loss: 0.489173; batch adversarial loss: 0.432751\n",
      "epoch 28; iter: 400; batch classifier loss: 0.360217; batch adversarial loss: 0.435724\n",
      "epoch 28; iter: 600; batch classifier loss: 0.462122; batch adversarial loss: 0.476049\n",
      "epoch 28; iter: 800; batch classifier loss: 0.361636; batch adversarial loss: 0.392007\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.493172; batch adversarial loss: 0.501459\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.436681; batch adversarial loss: 0.527936\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.433194; batch adversarial loss: 0.379497\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.442964; batch adversarial loss: 0.445374\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.457518; batch adversarial loss: 0.541183\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.403956; batch adversarial loss: 0.463870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 2200; batch classifier loss: 0.357258; batch adversarial loss: 0.378681\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.417742; batch adversarial loss: 0.542049\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.397586; batch adversarial loss: 0.429430\n",
      "epoch 29; iter: 0; batch classifier loss: 0.382998; batch adversarial loss: 0.407764\n",
      "epoch 29; iter: 200; batch classifier loss: 0.375157; batch adversarial loss: 0.419238\n",
      "epoch 29; iter: 400; batch classifier loss: 0.482666; batch adversarial loss: 0.404620\n",
      "epoch 29; iter: 600; batch classifier loss: 0.433037; batch adversarial loss: 0.364676\n",
      "epoch 29; iter: 800; batch classifier loss: 0.434718; batch adversarial loss: 0.363488\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.421105; batch adversarial loss: 0.488058\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.467303; batch adversarial loss: 0.405646\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.384100; batch adversarial loss: 0.364036\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.470214; batch adversarial loss: 0.408214\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.422104; batch adversarial loss: 0.490085\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.425406; batch adversarial loss: 0.381004\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.392609; batch adversarial loss: 0.405279\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.372061; batch adversarial loss: 0.432590\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.484049; batch adversarial loss: 0.477432\n",
      "epoch 30; iter: 0; batch classifier loss: 0.415795; batch adversarial loss: 0.368565\n",
      "epoch 30; iter: 200; batch classifier loss: 0.394844; batch adversarial loss: 0.363343\n",
      "epoch 30; iter: 400; batch classifier loss: 0.417422; batch adversarial loss: 0.408742\n",
      "epoch 30; iter: 600; batch classifier loss: 0.334772; batch adversarial loss: 0.446293\n",
      "epoch 30; iter: 800; batch classifier loss: 0.367039; batch adversarial loss: 0.409496\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.519489; batch adversarial loss: 0.514721\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.454251; batch adversarial loss: 0.420459\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.462543; batch adversarial loss: 0.460912\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.413011; batch adversarial loss: 0.431077\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.344879; batch adversarial loss: 0.353054\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.417688; batch adversarial loss: 0.529480\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.395616; batch adversarial loss: 0.337233\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.439302; batch adversarial loss: 0.437890\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.459231; batch adversarial loss: 0.432381\n",
      "epoch 31; iter: 0; batch classifier loss: 0.378188; batch adversarial loss: 0.419498\n",
      "epoch 31; iter: 200; batch classifier loss: 0.503875; batch adversarial loss: 0.569716\n",
      "epoch 31; iter: 400; batch classifier loss: 0.386854; batch adversarial loss: 0.421424\n",
      "epoch 31; iter: 600; batch classifier loss: 0.406449; batch adversarial loss: 0.531935\n",
      "epoch 31; iter: 800; batch classifier loss: 0.435067; batch adversarial loss: 0.436079\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.412993; batch adversarial loss: 0.405352\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.310014; batch adversarial loss: 0.390860\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.467211; batch adversarial loss: 0.490206\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.444034; batch adversarial loss: 0.459644\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.438212; batch adversarial loss: 0.445963\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.420278; batch adversarial loss: 0.369133\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.375346; batch adversarial loss: 0.363921\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.441847; batch adversarial loss: 0.485073\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.520280; batch adversarial loss: 0.446685\n",
      "epoch 32; iter: 0; batch classifier loss: 0.493284; batch adversarial loss: 0.516381\n",
      "epoch 32; iter: 200; batch classifier loss: 0.482444; batch adversarial loss: 0.366544\n",
      "epoch 32; iter: 400; batch classifier loss: 0.471576; batch adversarial loss: 0.436202\n",
      "epoch 32; iter: 600; batch classifier loss: 0.363450; batch adversarial loss: 0.457852\n",
      "epoch 32; iter: 800; batch classifier loss: 0.437261; batch adversarial loss: 0.460286\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.458238; batch adversarial loss: 0.431934\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.477960; batch adversarial loss: 0.489668\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.462171; batch adversarial loss: 0.421112\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.504890; batch adversarial loss: 0.415603\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.446040; batch adversarial loss: 0.395389\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.380037; batch adversarial loss: 0.390698\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.468358; batch adversarial loss: 0.498021\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.452307; batch adversarial loss: 0.391635\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.423832; batch adversarial loss: 0.420725\n",
      "epoch 33; iter: 0; batch classifier loss: 0.424222; batch adversarial loss: 0.378720\n",
      "epoch 33; iter: 200; batch classifier loss: 0.367095; batch adversarial loss: 0.446676\n",
      "epoch 33; iter: 400; batch classifier loss: 0.423988; batch adversarial loss: 0.363050\n",
      "epoch 33; iter: 600; batch classifier loss: 0.390219; batch adversarial loss: 0.395246\n",
      "epoch 33; iter: 800; batch classifier loss: 0.438386; batch adversarial loss: 0.487683\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.473421; batch adversarial loss: 0.365535\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.426141; batch adversarial loss: 0.389106\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.363557; batch adversarial loss: 0.366478\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.371826; batch adversarial loss: 0.446078\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.457697; batch adversarial loss: 0.349465\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.480142; batch adversarial loss: 0.419831\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.406976; batch adversarial loss: 0.630584\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.445833; batch adversarial loss: 0.459213\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.415393; batch adversarial loss: 0.472461\n",
      "epoch 34; iter: 0; batch classifier loss: 0.422206; batch adversarial loss: 0.414138\n",
      "epoch 34; iter: 200; batch classifier loss: 0.412429; batch adversarial loss: 0.382210\n",
      "epoch 34; iter: 400; batch classifier loss: 0.450216; batch adversarial loss: 0.340861\n",
      "epoch 34; iter: 600; batch classifier loss: 0.427812; batch adversarial loss: 0.474684\n",
      "epoch 34; iter: 800; batch classifier loss: 0.404531; batch adversarial loss: 0.417530\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.393178; batch adversarial loss: 0.434507\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.444934; batch adversarial loss: 0.468445\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.402457; batch adversarial loss: 0.365216\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.413554; batch adversarial loss: 0.405441\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.448388; batch adversarial loss: 0.377791\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.465462; batch adversarial loss: 0.445844\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.450624; batch adversarial loss: 0.448373\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.403328; batch adversarial loss: 0.420178\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.478244; batch adversarial loss: 0.454843\n",
      "epoch 35; iter: 0; batch classifier loss: 0.471721; batch adversarial loss: 0.376264\n",
      "epoch 35; iter: 200; batch classifier loss: 0.463226; batch adversarial loss: 0.463739\n",
      "epoch 35; iter: 400; batch classifier loss: 0.311590; batch adversarial loss: 0.477231\n",
      "epoch 35; iter: 600; batch classifier loss: 0.449856; batch adversarial loss: 0.419048\n",
      "epoch 35; iter: 800; batch classifier loss: 0.529261; batch adversarial loss: 0.526197\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.384706; batch adversarial loss: 0.364221\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.423973; batch adversarial loss: 0.462343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 1400; batch classifier loss: 0.478384; batch adversarial loss: 0.434832\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.359723; batch adversarial loss: 0.407025\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.392398; batch adversarial loss: 0.267822\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.394830; batch adversarial loss: 0.364502\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.395663; batch adversarial loss: 0.336537\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.372153; batch adversarial loss: 0.457052\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.412196; batch adversarial loss: 0.335713\n",
      "epoch 36; iter: 0; batch classifier loss: 0.368396; batch adversarial loss: 0.500388\n",
      "epoch 36; iter: 200; batch classifier loss: 0.412274; batch adversarial loss: 0.474279\n",
      "epoch 36; iter: 400; batch classifier loss: 0.465587; batch adversarial loss: 0.403782\n",
      "epoch 36; iter: 600; batch classifier loss: 0.387594; batch adversarial loss: 0.449074\n",
      "epoch 36; iter: 800; batch classifier loss: 0.371247; batch adversarial loss: 0.394334\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.440323; batch adversarial loss: 0.407369\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.383596; batch adversarial loss: 0.501397\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.494165; batch adversarial loss: 0.353883\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.411905; batch adversarial loss: 0.418552\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.378295; batch adversarial loss: 0.515981\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.367090; batch adversarial loss: 0.444673\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.447703; batch adversarial loss: 0.380402\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.460347; batch adversarial loss: 0.393144\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.361929; batch adversarial loss: 0.504074\n",
      "epoch 37; iter: 0; batch classifier loss: 0.386027; batch adversarial loss: 0.380022\n",
      "epoch 37; iter: 200; batch classifier loss: 0.432637; batch adversarial loss: 0.474127\n",
      "epoch 37; iter: 400; batch classifier loss: 0.435232; batch adversarial loss: 0.471905\n",
      "epoch 37; iter: 600; batch classifier loss: 0.436194; batch adversarial loss: 0.458867\n",
      "epoch 37; iter: 800; batch classifier loss: 0.391358; batch adversarial loss: 0.509670\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.468636; batch adversarial loss: 0.340292\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.502986; batch adversarial loss: 0.570657\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.470716; batch adversarial loss: 0.338209\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.581607; batch adversarial loss: 0.432121\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.405949; batch adversarial loss: 0.489347\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.363767; batch adversarial loss: 0.488575\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.398512; batch adversarial loss: 0.421648\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.379472; batch adversarial loss: 0.408135\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.359628; batch adversarial loss: 0.584217\n",
      "epoch 38; iter: 0; batch classifier loss: 0.407423; batch adversarial loss: 0.421008\n",
      "epoch 38; iter: 200; batch classifier loss: 0.359319; batch adversarial loss: 0.415926\n",
      "epoch 38; iter: 400; batch classifier loss: 0.417260; batch adversarial loss: 0.390830\n",
      "epoch 38; iter: 600; batch classifier loss: 0.395024; batch adversarial loss: 0.470042\n",
      "epoch 38; iter: 800; batch classifier loss: 0.354273; batch adversarial loss: 0.399204\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.421461; batch adversarial loss: 0.349399\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.423874; batch adversarial loss: 0.321728\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.459112; batch adversarial loss: 0.475872\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.476919; batch adversarial loss: 0.474214\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.458629; batch adversarial loss: 0.474250\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.367076; batch adversarial loss: 0.490745\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.381723; batch adversarial loss: 0.363434\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.471733; batch adversarial loss: 0.418593\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.447351; batch adversarial loss: 0.502405\n",
      "epoch 39; iter: 0; batch classifier loss: 0.504455; batch adversarial loss: 0.446205\n",
      "epoch 39; iter: 200; batch classifier loss: 0.457479; batch adversarial loss: 0.417515\n",
      "epoch 39; iter: 400; batch classifier loss: 0.492663; batch adversarial loss: 0.377295\n",
      "epoch 39; iter: 600; batch classifier loss: 0.392522; batch adversarial loss: 0.503871\n",
      "epoch 39; iter: 800; batch classifier loss: 0.443268; batch adversarial loss: 0.406922\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.476123; batch adversarial loss: 0.377240\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.455399; batch adversarial loss: 0.351987\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.407613; batch adversarial loss: 0.449461\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.364228; batch adversarial loss: 0.322903\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.418721; batch adversarial loss: 0.310565\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.414795; batch adversarial loss: 0.432827\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.423380; batch adversarial loss: 0.417729\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.477122; batch adversarial loss: 0.390601\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.407040; batch adversarial loss: 0.311352\n",
      "epoch 40; iter: 0; batch classifier loss: 0.378934; batch adversarial loss: 0.390248\n",
      "epoch 40; iter: 200; batch classifier loss: 0.395983; batch adversarial loss: 0.378280\n",
      "epoch 40; iter: 400; batch classifier loss: 0.500004; batch adversarial loss: 0.337186\n",
      "epoch 40; iter: 600; batch classifier loss: 0.470173; batch adversarial loss: 0.459971\n",
      "epoch 40; iter: 800; batch classifier loss: 0.416661; batch adversarial loss: 0.408220\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.384195; batch adversarial loss: 0.486666\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.359374; batch adversarial loss: 0.406159\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.452353; batch adversarial loss: 0.352594\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.401742; batch adversarial loss: 0.393530\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.383700; batch adversarial loss: 0.531138\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.393278; batch adversarial loss: 0.403488\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.291189; batch adversarial loss: 0.506781\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.462719; batch adversarial loss: 0.470935\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.454473; batch adversarial loss: 0.297870\n",
      "epoch 41; iter: 0; batch classifier loss: 0.404749; batch adversarial loss: 0.448189\n",
      "epoch 41; iter: 200; batch classifier loss: 0.415859; batch adversarial loss: 0.338316\n",
      "epoch 41; iter: 400; batch classifier loss: 0.404761; batch adversarial loss: 0.338876\n",
      "epoch 41; iter: 600; batch classifier loss: 0.371225; batch adversarial loss: 0.338048\n",
      "epoch 41; iter: 800; batch classifier loss: 0.432192; batch adversarial loss: 0.378090\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.374975; batch adversarial loss: 0.404388\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.421512; batch adversarial loss: 0.428105\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.421419; batch adversarial loss: 0.407807\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.509467; batch adversarial loss: 0.380615\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.504712; batch adversarial loss: 0.336743\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.466285; batch adversarial loss: 0.451711\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.460397; batch adversarial loss: 0.432441\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.363884; batch adversarial loss: 0.458691\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.436123; batch adversarial loss: 0.312665\n",
      "epoch 42; iter: 0; batch classifier loss: 0.325994; batch adversarial loss: 0.351760\n",
      "epoch 42; iter: 200; batch classifier loss: 0.459063; batch adversarial loss: 0.347534\n",
      "epoch 42; iter: 400; batch classifier loss: 0.340860; batch adversarial loss: 0.408783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 600; batch classifier loss: 0.541500; batch adversarial loss: 0.380047\n",
      "epoch 42; iter: 800; batch classifier loss: 0.404353; batch adversarial loss: 0.405691\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.360187; batch adversarial loss: 0.434752\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.511747; batch adversarial loss: 0.501994\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.449432; batch adversarial loss: 0.489688\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.500023; batch adversarial loss: 0.375473\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.454855; batch adversarial loss: 0.419039\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.426772; batch adversarial loss: 0.395396\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.476816; batch adversarial loss: 0.449712\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.451896; batch adversarial loss: 0.378868\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.468835; batch adversarial loss: 0.338531\n",
      "epoch 43; iter: 0; batch classifier loss: 0.396017; batch adversarial loss: 0.501024\n",
      "epoch 43; iter: 200; batch classifier loss: 0.421855; batch adversarial loss: 0.499562\n",
      "epoch 43; iter: 400; batch classifier loss: 0.391779; batch adversarial loss: 0.498626\n",
      "epoch 43; iter: 600; batch classifier loss: 0.428759; batch adversarial loss: 0.477295\n",
      "epoch 43; iter: 800; batch classifier loss: 0.429684; batch adversarial loss: 0.462652\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.408894; batch adversarial loss: 0.416450\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.409897; batch adversarial loss: 0.323394\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.476832; batch adversarial loss: 0.516735\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.359946; batch adversarial loss: 0.459651\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.461023; batch adversarial loss: 0.401873\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.386672; batch adversarial loss: 0.419628\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.356730; batch adversarial loss: 0.377002\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.392532; batch adversarial loss: 0.447857\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.459586; batch adversarial loss: 0.502031\n",
      "epoch 44; iter: 0; batch classifier loss: 0.556265; batch adversarial loss: 0.392157\n",
      "epoch 44; iter: 200; batch classifier loss: 0.381205; batch adversarial loss: 0.555223\n",
      "epoch 44; iter: 400; batch classifier loss: 0.384988; batch adversarial loss: 0.448285\n",
      "epoch 44; iter: 600; batch classifier loss: 0.374953; batch adversarial loss: 0.379291\n",
      "epoch 44; iter: 800; batch classifier loss: 0.452168; batch adversarial loss: 0.446409\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.427449; batch adversarial loss: 0.457412\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.482114; batch adversarial loss: 0.378714\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.367648; batch adversarial loss: 0.416940\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.454520; batch adversarial loss: 0.403952\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.365687; batch adversarial loss: 0.380788\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.416233; batch adversarial loss: 0.392152\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.420835; batch adversarial loss: 0.419283\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.355995; batch adversarial loss: 0.353105\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.387294; batch adversarial loss: 0.377706\n",
      "epoch 45; iter: 0; batch classifier loss: 0.340540; batch adversarial loss: 0.404967\n",
      "epoch 45; iter: 200; batch classifier loss: 0.389436; batch adversarial loss: 0.447261\n",
      "epoch 45; iter: 400; batch classifier loss: 0.389092; batch adversarial loss: 0.377755\n",
      "epoch 45; iter: 600; batch classifier loss: 0.496208; batch adversarial loss: 0.434938\n",
      "epoch 45; iter: 800; batch classifier loss: 0.415414; batch adversarial loss: 0.408692\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.419651; batch adversarial loss: 0.405747\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.401143; batch adversarial loss: 0.404231\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.497153; batch adversarial loss: 0.474752\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.431838; batch adversarial loss: 0.311882\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.391955; batch adversarial loss: 0.365906\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.438422; batch adversarial loss: 0.485489\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.477534; batch adversarial loss: 0.472200\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.433858; batch adversarial loss: 0.367639\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.458841; batch adversarial loss: 0.445651\n",
      "epoch 46; iter: 0; batch classifier loss: 0.460174; batch adversarial loss: 0.310624\n",
      "epoch 46; iter: 200; batch classifier loss: 0.478299; batch adversarial loss: 0.460843\n",
      "epoch 46; iter: 400; batch classifier loss: 0.413538; batch adversarial loss: 0.344922\n",
      "epoch 46; iter: 600; batch classifier loss: 0.335388; batch adversarial loss: 0.419089\n",
      "epoch 46; iter: 800; batch classifier loss: 0.472649; batch adversarial loss: 0.392147\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.392218; batch adversarial loss: 0.336791\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.309803; batch adversarial loss: 0.459227\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.452706; batch adversarial loss: 0.403173\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.421947; batch adversarial loss: 0.472422\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.499803; batch adversarial loss: 0.447961\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.406374; batch adversarial loss: 0.460691\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.399036; batch adversarial loss: 0.394780\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.506979; batch adversarial loss: 0.420271\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.497344; batch adversarial loss: 0.491878\n",
      "epoch 47; iter: 0; batch classifier loss: 0.505559; batch adversarial loss: 0.391035\n",
      "epoch 47; iter: 200; batch classifier loss: 0.377412; batch adversarial loss: 0.456698\n",
      "epoch 47; iter: 400; batch classifier loss: 0.354137; batch adversarial loss: 0.377747\n",
      "epoch 47; iter: 600; batch classifier loss: 0.389834; batch adversarial loss: 0.502255\n",
      "epoch 47; iter: 800; batch classifier loss: 0.460865; batch adversarial loss: 0.365636\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.467243; batch adversarial loss: 0.420667\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.398547; batch adversarial loss: 0.421729\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.419983; batch adversarial loss: 0.360776\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.442739; batch adversarial loss: 0.392020\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.472317; batch adversarial loss: 0.460391\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.400438; batch adversarial loss: 0.395933\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.402453; batch adversarial loss: 0.418077\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.393387; batch adversarial loss: 0.298749\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.401187; batch adversarial loss: 0.460227\n",
      "epoch 48; iter: 0; batch classifier loss: 0.430971; batch adversarial loss: 0.443523\n",
      "epoch 48; iter: 200; batch classifier loss: 0.389091; batch adversarial loss: 0.428858\n",
      "epoch 48; iter: 400; batch classifier loss: 0.464047; batch adversarial loss: 0.378096\n",
      "epoch 48; iter: 600; batch classifier loss: 0.384186; batch adversarial loss: 0.380013\n",
      "epoch 48; iter: 800; batch classifier loss: 0.373309; batch adversarial loss: 0.445034\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.401944; batch adversarial loss: 0.436473\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.391118; batch adversarial loss: 0.487548\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.375114; batch adversarial loss: 0.428715\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.390667; batch adversarial loss: 0.471266\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.399350; batch adversarial loss: 0.461053\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.353113; batch adversarial loss: 0.527668\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.358665; batch adversarial loss: 0.337102\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.432307; batch adversarial loss: 0.433671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 2600; batch classifier loss: 0.376420; batch adversarial loss: 0.381031\n",
      "epoch 49; iter: 0; batch classifier loss: 0.385014; batch adversarial loss: 0.367030\n",
      "epoch 49; iter: 200; batch classifier loss: 0.491061; batch adversarial loss: 0.430732\n",
      "epoch 49; iter: 400; batch classifier loss: 0.386304; batch adversarial loss: 0.433015\n",
      "epoch 49; iter: 600; batch classifier loss: 0.506218; batch adversarial loss: 0.557785\n",
      "epoch 49; iter: 800; batch classifier loss: 0.439802; batch adversarial loss: 0.483967\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.415947; batch adversarial loss: 0.447034\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.394397; batch adversarial loss: 0.502333\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.377673; batch adversarial loss: 0.375664\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.397397; batch adversarial loss: 0.417795\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.441315; batch adversarial loss: 0.418515\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.413254; batch adversarial loss: 0.379871\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.368557; batch adversarial loss: 0.447841\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.469358; batch adversarial loss: 0.445539\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.534252; batch adversarial loss: 0.430729\n",
      "epoch 0; iter: 0; batch classifier loss: 0.696899\n",
      "epoch 0; iter: 200; batch classifier loss: 0.391558\n",
      "epoch 0; iter: 400; batch classifier loss: 0.378596\n",
      "epoch 0; iter: 600; batch classifier loss: 0.512289\n",
      "epoch 0; iter: 800; batch classifier loss: 0.479574\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.478182\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.423982\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.399057\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.433257\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.388774\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.444000\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.379866\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.409046\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.331166\n",
      "epoch 1; iter: 0; batch classifier loss: 0.392253\n",
      "epoch 1; iter: 200; batch classifier loss: 0.446017\n",
      "epoch 1; iter: 400; batch classifier loss: 0.332778\n",
      "epoch 1; iter: 600; batch classifier loss: 0.448368\n",
      "epoch 1; iter: 800; batch classifier loss: 0.384461\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.378539\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.453636\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.482405\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.443513\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.491380\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.367682\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.424204\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.479738\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.366686\n",
      "epoch 2; iter: 0; batch classifier loss: 0.416693\n",
      "epoch 2; iter: 200; batch classifier loss: 0.425438\n",
      "epoch 2; iter: 400; batch classifier loss: 0.422519\n",
      "epoch 2; iter: 600; batch classifier loss: 0.409636\n",
      "epoch 2; iter: 800; batch classifier loss: 0.479030\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.412021\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.458348\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.337982\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.418973\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.444045\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.424753\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.358355\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.406501\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.412037\n",
      "epoch 3; iter: 0; batch classifier loss: 0.444781\n",
      "epoch 3; iter: 200; batch classifier loss: 0.404631\n",
      "epoch 3; iter: 400; batch classifier loss: 0.411724\n",
      "epoch 3; iter: 600; batch classifier loss: 0.440013\n",
      "epoch 3; iter: 800; batch classifier loss: 0.392771\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.366530\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.310585\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.420590\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.414675\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.447876\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.418503\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.454106\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.462790\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.409365\n",
      "epoch 4; iter: 0; batch classifier loss: 0.390549\n",
      "epoch 4; iter: 200; batch classifier loss: 0.560026\n",
      "epoch 4; iter: 400; batch classifier loss: 0.383600\n",
      "epoch 4; iter: 600; batch classifier loss: 0.383588\n",
      "epoch 4; iter: 800; batch classifier loss: 0.414650\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.403982\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.464494\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.419821\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.425135\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.434784\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.407143\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.440408\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.406060\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.359735\n",
      "epoch 5; iter: 0; batch classifier loss: 0.366254\n",
      "epoch 5; iter: 200; batch classifier loss: 0.414875\n",
      "epoch 5; iter: 400; batch classifier loss: 0.318125\n",
      "epoch 5; iter: 600; batch classifier loss: 0.383129\n",
      "epoch 5; iter: 800; batch classifier loss: 0.341964\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.444974\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.440608\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.391505\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.461037\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.453270\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.431014\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.431168\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.420709\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.434417\n",
      "epoch 6; iter: 0; batch classifier loss: 0.330422\n",
      "epoch 6; iter: 200; batch classifier loss: 0.433748\n",
      "epoch 6; iter: 400; batch classifier loss: 0.452751\n",
      "epoch 6; iter: 600; batch classifier loss: 0.349729\n",
      "epoch 6; iter: 800; batch classifier loss: 0.344927\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.436057\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.425943\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.384929\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.504945\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.428785\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.443616\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.365606\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.438088\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.442778\n",
      "epoch 7; iter: 0; batch classifier loss: 0.394663\n",
      "epoch 7; iter: 200; batch classifier loss: 0.472994\n",
      "epoch 7; iter: 400; batch classifier loss: 0.340215\n",
      "epoch 7; iter: 600; batch classifier loss: 0.458770\n",
      "epoch 7; iter: 800; batch classifier loss: 0.413350\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.512088\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.426881\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.387535\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.354730\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.436971\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.346865\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.432724\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.422138\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.448008\n",
      "epoch 8; iter: 0; batch classifier loss: 0.342348\n",
      "epoch 8; iter: 200; batch classifier loss: 0.330350\n",
      "epoch 8; iter: 400; batch classifier loss: 0.408425\n",
      "epoch 8; iter: 600; batch classifier loss: 0.346095\n",
      "epoch 8; iter: 800; batch classifier loss: 0.406550\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.354840\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.387850\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.403374\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.367091\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.473898\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.418644\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.450100\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.406091\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.402808\n",
      "epoch 9; iter: 0; batch classifier loss: 0.323192\n",
      "epoch 9; iter: 200; batch classifier loss: 0.450386\n",
      "epoch 9; iter: 400; batch classifier loss: 0.507152\n",
      "epoch 9; iter: 600; batch classifier loss: 0.462208\n",
      "epoch 9; iter: 800; batch classifier loss: 0.406264\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.373946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 1200; batch classifier loss: 0.434633\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.594928\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.451974\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.428603\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.469142\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.475414\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.499773\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.460585\n",
      "epoch 10; iter: 0; batch classifier loss: 0.436236\n",
      "epoch 10; iter: 200; batch classifier loss: 0.353838\n",
      "epoch 10; iter: 400; batch classifier loss: 0.423650\n",
      "epoch 10; iter: 600; batch classifier loss: 0.453506\n",
      "epoch 10; iter: 800; batch classifier loss: 0.473536\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.520711\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.417009\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.353326\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.328664\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.458112\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.399239\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.445992\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.538185\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.421269\n",
      "epoch 11; iter: 0; batch classifier loss: 0.448618\n",
      "epoch 11; iter: 200; batch classifier loss: 0.383464\n",
      "epoch 11; iter: 400; batch classifier loss: 0.500897\n",
      "epoch 11; iter: 600; batch classifier loss: 0.395370\n",
      "epoch 11; iter: 800; batch classifier loss: 0.414531\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.400631\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.420160\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.460249\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.333640\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.425808\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.361707\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.412973\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.439861\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.360142\n",
      "epoch 12; iter: 0; batch classifier loss: 0.570460\n",
      "epoch 12; iter: 200; batch classifier loss: 0.471239\n",
      "epoch 12; iter: 400; batch classifier loss: 0.344508\n",
      "epoch 12; iter: 600; batch classifier loss: 0.412332\n",
      "epoch 12; iter: 800; batch classifier loss: 0.491258\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.383933\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.458958\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.439042\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.326206\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.431698\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.408380\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.376025\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.458112\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.373960\n",
      "epoch 13; iter: 0; batch classifier loss: 0.451263\n",
      "epoch 13; iter: 200; batch classifier loss: 0.420400\n",
      "epoch 13; iter: 400; batch classifier loss: 0.412763\n",
      "epoch 13; iter: 600; batch classifier loss: 0.446527\n",
      "epoch 13; iter: 800; batch classifier loss: 0.322861\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.426553\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.414833\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.363756\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.475610\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.419516\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.346236\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.368980\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.464983\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.382484\n",
      "epoch 14; iter: 0; batch classifier loss: 0.485127\n",
      "epoch 14; iter: 200; batch classifier loss: 0.432332\n",
      "epoch 14; iter: 400; batch classifier loss: 0.428540\n",
      "epoch 14; iter: 600; batch classifier loss: 0.424722\n",
      "epoch 14; iter: 800; batch classifier loss: 0.462152\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.401327\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.512976\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.349998\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.369633\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.390353\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.382989\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.390990\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.390398\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.372574\n",
      "epoch 15; iter: 0; batch classifier loss: 0.409697\n",
      "epoch 15; iter: 200; batch classifier loss: 0.445270\n",
      "epoch 15; iter: 400; batch classifier loss: 0.416702\n",
      "epoch 15; iter: 600; batch classifier loss: 0.480667\n",
      "epoch 15; iter: 800; batch classifier loss: 0.407809\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.380331\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.331195\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.387814\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.404393\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.392647\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.431665\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.381264\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.435204\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.459017\n",
      "epoch 16; iter: 0; batch classifier loss: 0.403685\n",
      "epoch 16; iter: 200; batch classifier loss: 0.393557\n",
      "epoch 16; iter: 400; batch classifier loss: 0.383510\n",
      "epoch 16; iter: 600; batch classifier loss: 0.401363\n",
      "epoch 16; iter: 800; batch classifier loss: 0.475385\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.428181\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.435090\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.397356\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.423517\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.403458\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.445175\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.394279\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.339227\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.360626\n",
      "epoch 17; iter: 0; batch classifier loss: 0.419003\n",
      "epoch 17; iter: 200; batch classifier loss: 0.402150\n",
      "epoch 17; iter: 400; batch classifier loss: 0.404873\n",
      "epoch 17; iter: 600; batch classifier loss: 0.462218\n",
      "epoch 17; iter: 800; batch classifier loss: 0.414287\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.363299\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.332302\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.406627\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.337635\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.497472\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.365437\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.504818\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.409952\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.494929\n",
      "epoch 18; iter: 0; batch classifier loss: 0.367196\n",
      "epoch 18; iter: 200; batch classifier loss: 0.451450\n",
      "epoch 18; iter: 400; batch classifier loss: 0.469918\n",
      "epoch 18; iter: 600; batch classifier loss: 0.529996\n",
      "epoch 18; iter: 800; batch classifier loss: 0.387982\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.486993\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.402689\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.418609\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.402021\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.461866\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.389552\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.421945\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.431752\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.504900\n",
      "epoch 19; iter: 0; batch classifier loss: 0.408550\n",
      "epoch 19; iter: 200; batch classifier loss: 0.425292\n",
      "epoch 19; iter: 400; batch classifier loss: 0.386753\n",
      "epoch 19; iter: 600; batch classifier loss: 0.437653\n",
      "epoch 19; iter: 800; batch classifier loss: 0.424431\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.471881\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.350227\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.491946\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.430937\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.505190\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.350082\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.446062\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.497259\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.461199\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474567\n",
      "epoch 20; iter: 200; batch classifier loss: 0.488997\n",
      "epoch 20; iter: 400; batch classifier loss: 0.406633\n",
      "epoch 20; iter: 600; batch classifier loss: 0.527657\n",
      "epoch 20; iter: 800; batch classifier loss: 0.338903\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.465146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 1200; batch classifier loss: 0.463702\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.400628\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.402682\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.399659\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.440568\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.398607\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.476508\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.424908\n",
      "epoch 21; iter: 0; batch classifier loss: 0.462196\n",
      "epoch 21; iter: 200; batch classifier loss: 0.441731\n",
      "epoch 21; iter: 400; batch classifier loss: 0.435326\n",
      "epoch 21; iter: 600; batch classifier loss: 0.374629\n",
      "epoch 21; iter: 800; batch classifier loss: 0.404640\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.318911\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.399498\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.371220\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.441017\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.449061\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.488468\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.390455\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.409400\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.411223\n",
      "epoch 22; iter: 0; batch classifier loss: 0.440761\n",
      "epoch 22; iter: 200; batch classifier loss: 0.366247\n",
      "epoch 22; iter: 400; batch classifier loss: 0.421588\n",
      "epoch 22; iter: 600; batch classifier loss: 0.440643\n",
      "epoch 22; iter: 800; batch classifier loss: 0.349400\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.401899\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.409651\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.431662\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.432601\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.437180\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.370137\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.425272\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.342643\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.561725\n",
      "epoch 23; iter: 0; batch classifier loss: 0.458186\n",
      "epoch 23; iter: 200; batch classifier loss: 0.357502\n",
      "epoch 23; iter: 400; batch classifier loss: 0.448374\n",
      "epoch 23; iter: 600; batch classifier loss: 0.351437\n",
      "epoch 23; iter: 800; batch classifier loss: 0.399507\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.426225\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.442478\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.422959\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.507286\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.388853\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.407718\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.426085\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.396348\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.449988\n",
      "epoch 24; iter: 0; batch classifier loss: 0.403496\n",
      "epoch 24; iter: 200; batch classifier loss: 0.381215\n",
      "epoch 24; iter: 400; batch classifier loss: 0.387873\n",
      "epoch 24; iter: 600; batch classifier loss: 0.387905\n",
      "epoch 24; iter: 800; batch classifier loss: 0.496550\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.362297\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.343347\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.436288\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.400222\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.422392\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.334442\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.402356\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.358281\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.449260\n",
      "epoch 25; iter: 0; batch classifier loss: 0.505737\n",
      "epoch 25; iter: 200; batch classifier loss: 0.372001\n",
      "epoch 25; iter: 400; batch classifier loss: 0.428872\n",
      "epoch 25; iter: 600; batch classifier loss: 0.482825\n",
      "epoch 25; iter: 800; batch classifier loss: 0.331045\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.325992\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.375041\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.446051\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.388112\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.423172\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.464158\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.421824\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.445813\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.392214\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502392\n",
      "epoch 26; iter: 200; batch classifier loss: 0.523224\n",
      "epoch 26; iter: 400; batch classifier loss: 0.412873\n",
      "epoch 26; iter: 600; batch classifier loss: 0.485845\n",
      "epoch 26; iter: 800; batch classifier loss: 0.386707\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.414383\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.377027\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.505289\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.397081\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.553326\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.393738\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.476500\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.384943\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.376443\n",
      "epoch 27; iter: 0; batch classifier loss: 0.401051\n",
      "epoch 27; iter: 200; batch classifier loss: 0.469273\n",
      "epoch 27; iter: 400; batch classifier loss: 0.493426\n",
      "epoch 27; iter: 600; batch classifier loss: 0.443622\n",
      "epoch 27; iter: 800; batch classifier loss: 0.446955\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.414485\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.342783\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.389982\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.414629\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.450686\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.446758\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.472792\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.371231\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.471752\n",
      "epoch 28; iter: 0; batch classifier loss: 0.416752\n",
      "epoch 28; iter: 200; batch classifier loss: 0.429692\n",
      "epoch 28; iter: 400; batch classifier loss: 0.452567\n",
      "epoch 28; iter: 600; batch classifier loss: 0.405437\n",
      "epoch 28; iter: 800; batch classifier loss: 0.463142\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.365515\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.491236\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.385657\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.377784\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.407078\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.406906\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.480454\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.413826\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.463739\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452152\n",
      "epoch 29; iter: 200; batch classifier loss: 0.583773\n",
      "epoch 29; iter: 400; batch classifier loss: 0.445368\n",
      "epoch 29; iter: 600; batch classifier loss: 0.379993\n",
      "epoch 29; iter: 800; batch classifier loss: 0.493634\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.395951\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.422482\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.453950\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.385627\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.431883\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.458722\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.449557\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.434078\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.439405\n",
      "epoch 30; iter: 0; batch classifier loss: 0.400196\n",
      "epoch 30; iter: 200; batch classifier loss: 0.459185\n",
      "epoch 30; iter: 400; batch classifier loss: 0.396336\n",
      "epoch 30; iter: 600; batch classifier loss: 0.428984\n",
      "epoch 30; iter: 800; batch classifier loss: 0.367300\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.418949\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.451657\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.411271\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.427524\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.423016\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.426248\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.463301\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.371924\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.501005\n",
      "epoch 31; iter: 0; batch classifier loss: 0.419764\n",
      "epoch 31; iter: 200; batch classifier loss: 0.364414\n",
      "epoch 31; iter: 400; batch classifier loss: 0.452412\n",
      "epoch 31; iter: 600; batch classifier loss: 0.411104\n",
      "epoch 31; iter: 800; batch classifier loss: 0.395946\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.403863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31; iter: 1200; batch classifier loss: 0.352974\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.367559\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.468617\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.306451\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.468063\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.462996\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.420551\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.424728\n",
      "epoch 32; iter: 0; batch classifier loss: 0.343853\n",
      "epoch 32; iter: 200; batch classifier loss: 0.465194\n",
      "epoch 32; iter: 400; batch classifier loss: 0.492855\n",
      "epoch 32; iter: 600; batch classifier loss: 0.479854\n",
      "epoch 32; iter: 800; batch classifier loss: 0.427544\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.425723\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.406244\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.418850\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.449664\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.333718\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.356641\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.456279\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.427012\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.525340\n",
      "epoch 33; iter: 0; batch classifier loss: 0.399664\n",
      "epoch 33; iter: 200; batch classifier loss: 0.412567\n",
      "epoch 33; iter: 400; batch classifier loss: 0.521208\n",
      "epoch 33; iter: 600; batch classifier loss: 0.414788\n",
      "epoch 33; iter: 800; batch classifier loss: 0.419572\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.490024\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.373893\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.420488\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.404373\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.343031\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.441775\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.434825\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.377278\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.450443\n",
      "epoch 34; iter: 0; batch classifier loss: 0.442075\n",
      "epoch 34; iter: 200; batch classifier loss: 0.380712\n",
      "epoch 34; iter: 400; batch classifier loss: 0.466522\n",
      "epoch 34; iter: 600; batch classifier loss: 0.423430\n",
      "epoch 34; iter: 800; batch classifier loss: 0.358387\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.418084\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.392135\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.472598\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.372444\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.449486\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.507327\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.416799\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.331849\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.375573\n",
      "epoch 35; iter: 0; batch classifier loss: 0.387317\n",
      "epoch 35; iter: 200; batch classifier loss: 0.485436\n",
      "epoch 35; iter: 400; batch classifier loss: 0.379696\n",
      "epoch 35; iter: 600; batch classifier loss: 0.445983\n",
      "epoch 35; iter: 800; batch classifier loss: 0.462019\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.419192\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.464195\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.411044\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.470328\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.399333\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.379679\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.416120\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.403334\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.345304\n",
      "epoch 36; iter: 0; batch classifier loss: 0.464899\n",
      "epoch 36; iter: 200; batch classifier loss: 0.404140\n",
      "epoch 36; iter: 400; batch classifier loss: 0.388896\n",
      "epoch 36; iter: 600; batch classifier loss: 0.513007\n",
      "epoch 36; iter: 800; batch classifier loss: 0.424612\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.475349\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.449583\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.480097\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.518487\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.481128\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.460199\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.367153\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.469165\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.513953\n",
      "epoch 37; iter: 0; batch classifier loss: 0.449198\n",
      "epoch 37; iter: 200; batch classifier loss: 0.454450\n",
      "epoch 37; iter: 400; batch classifier loss: 0.447125\n",
      "epoch 37; iter: 600; batch classifier loss: 0.480494\n",
      "epoch 37; iter: 800; batch classifier loss: 0.508407\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.339451\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.340025\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.467559\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.331528\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.416742\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.413493\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.360581\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.417113\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.518019\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441373\n",
      "epoch 38; iter: 200; batch classifier loss: 0.487652\n",
      "epoch 38; iter: 400; batch classifier loss: 0.380486\n",
      "epoch 38; iter: 600; batch classifier loss: 0.436248\n",
      "epoch 38; iter: 800; batch classifier loss: 0.405120\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.448847\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.486259\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.439456\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.526435\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.372052\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.367424\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.427169\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.474219\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.422016\n",
      "epoch 39; iter: 0; batch classifier loss: 0.434657\n",
      "epoch 39; iter: 200; batch classifier loss: 0.428648\n",
      "epoch 39; iter: 400; batch classifier loss: 0.437226\n",
      "epoch 39; iter: 600; batch classifier loss: 0.363947\n",
      "epoch 39; iter: 800; batch classifier loss: 0.390322\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.450486\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.355941\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.322679\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.390696\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.412918\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.408378\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.460070\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.452366\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.434535\n",
      "epoch 40; iter: 0; batch classifier loss: 0.325339\n",
      "epoch 40; iter: 200; batch classifier loss: 0.510514\n",
      "epoch 40; iter: 400; batch classifier loss: 0.419341\n",
      "epoch 40; iter: 600; batch classifier loss: 0.368505\n",
      "epoch 40; iter: 800; batch classifier loss: 0.364542\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.300308\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.435269\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.480992\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.459648\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.378390\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.446162\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.395114\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.449037\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.330196\n",
      "epoch 41; iter: 0; batch classifier loss: 0.444389\n",
      "epoch 41; iter: 200; batch classifier loss: 0.418857\n",
      "epoch 41; iter: 400; batch classifier loss: 0.495762\n",
      "epoch 41; iter: 600; batch classifier loss: 0.328837\n",
      "epoch 41; iter: 800; batch classifier loss: 0.450293\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.466616\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.377286\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.385923\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.358407\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.476712\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.397614\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.380951\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.377973\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.506649\n",
      "epoch 42; iter: 0; batch classifier loss: 0.530205\n",
      "epoch 42; iter: 200; batch classifier loss: 0.344585\n",
      "epoch 42; iter: 400; batch classifier loss: 0.445143\n",
      "epoch 42; iter: 600; batch classifier loss: 0.395437\n",
      "epoch 42; iter: 800; batch classifier loss: 0.339535\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.410230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42; iter: 1200; batch classifier loss: 0.341873\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.416456\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.415434\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.384921\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.399397\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.436709\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.401298\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.426972\n",
      "epoch 43; iter: 0; batch classifier loss: 0.480089\n",
      "epoch 43; iter: 200; batch classifier loss: 0.386380\n",
      "epoch 43; iter: 400; batch classifier loss: 0.423525\n",
      "epoch 43; iter: 600; batch classifier loss: 0.497961\n",
      "epoch 43; iter: 800; batch classifier loss: 0.541335\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.497837\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.391504\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.444896\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.407139\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.368204\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.347269\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.472495\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.385323\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.440416\n",
      "epoch 44; iter: 0; batch classifier loss: 0.470135\n",
      "epoch 44; iter: 200; batch classifier loss: 0.455985\n",
      "epoch 44; iter: 400; batch classifier loss: 0.417049\n",
      "epoch 44; iter: 600; batch classifier loss: 0.490412\n",
      "epoch 44; iter: 800; batch classifier loss: 0.315739\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.442490\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.441842\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.376572\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.397680\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.406247\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.534930\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.417931\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.450203\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.317561\n",
      "epoch 45; iter: 0; batch classifier loss: 0.329564\n",
      "epoch 45; iter: 200; batch classifier loss: 0.342729\n",
      "epoch 45; iter: 400; batch classifier loss: 0.373498\n",
      "epoch 45; iter: 600; batch classifier loss: 0.380802\n",
      "epoch 45; iter: 800; batch classifier loss: 0.418327\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.342784\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.469650\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.482304\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.426884\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.385406\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.325086\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.470185\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.463794\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.357932\n",
      "epoch 46; iter: 0; batch classifier loss: 0.502829\n",
      "epoch 46; iter: 200; batch classifier loss: 0.478156\n",
      "epoch 46; iter: 400; batch classifier loss: 0.349366\n",
      "epoch 46; iter: 600; batch classifier loss: 0.372090\n",
      "epoch 46; iter: 800; batch classifier loss: 0.397163\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.357120\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.418934\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.383405\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.497867\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.439559\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.419058\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.449626\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.460400\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.383449\n",
      "epoch 47; iter: 0; batch classifier loss: 0.314095\n",
      "epoch 47; iter: 200; batch classifier loss: 0.387637\n",
      "epoch 47; iter: 400; batch classifier loss: 0.499845\n",
      "epoch 47; iter: 600; batch classifier loss: 0.338550\n",
      "epoch 47; iter: 800; batch classifier loss: 0.406532\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.393846\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.439865\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.416942\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.420467\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.399830\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.391424\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.416424\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.405541\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.381432\n",
      "epoch 48; iter: 0; batch classifier loss: 0.361463\n",
      "epoch 48; iter: 200; batch classifier loss: 0.434435\n",
      "epoch 48; iter: 400; batch classifier loss: 0.423693\n",
      "epoch 48; iter: 600; batch classifier loss: 0.520898\n",
      "epoch 48; iter: 800; batch classifier loss: 0.369882\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.454547\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.458350\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.353230\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.418250\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.416626\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.444832\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.464546\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.360350\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.328981\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400143\n",
      "epoch 49; iter: 200; batch classifier loss: 0.444164\n",
      "epoch 49; iter: 400; batch classifier loss: 0.374907\n",
      "epoch 49; iter: 600; batch classifier loss: 0.361642\n",
      "epoch 49; iter: 800; batch classifier loss: 0.396284\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.453526\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.454940\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.441834\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.430681\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.407145\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.446035\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.462078\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.368287\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.499159\n",
      "epoch 0; iter: 0; batch classifier loss: 0.749946; batch adversarial loss: 0.625008\n",
      "epoch 0; iter: 200; batch classifier loss: 0.359066; batch adversarial loss: 0.621461\n",
      "epoch 1; iter: 0; batch classifier loss: 0.510110; batch adversarial loss: 0.615090\n",
      "epoch 1; iter: 200; batch classifier loss: 0.374005; batch adversarial loss: 0.551742\n",
      "epoch 2; iter: 0; batch classifier loss: 0.518215; batch adversarial loss: 0.529462\n",
      "epoch 2; iter: 200; batch classifier loss: 0.440240; batch adversarial loss: 0.496788\n",
      "epoch 3; iter: 0; batch classifier loss: 0.483797; batch adversarial loss: 0.467059\n",
      "epoch 3; iter: 200; batch classifier loss: 0.491277; batch adversarial loss: 0.459387\n",
      "epoch 4; iter: 0; batch classifier loss: 0.443985; batch adversarial loss: 0.444418\n",
      "epoch 4; iter: 200; batch classifier loss: 0.472183; batch adversarial loss: 0.459175\n",
      "epoch 5; iter: 0; batch classifier loss: 0.355679; batch adversarial loss: 0.419921\n",
      "epoch 5; iter: 200; batch classifier loss: 0.427804; batch adversarial loss: 0.406381\n",
      "epoch 6; iter: 0; batch classifier loss: 0.441614; batch adversarial loss: 0.463706\n",
      "epoch 6; iter: 200; batch classifier loss: 0.423932; batch adversarial loss: 0.401357\n",
      "epoch 7; iter: 0; batch classifier loss: 0.387756; batch adversarial loss: 0.437574\n",
      "epoch 7; iter: 200; batch classifier loss: 0.412092; batch adversarial loss: 0.478822\n",
      "epoch 8; iter: 0; batch classifier loss: 0.392827; batch adversarial loss: 0.356224\n",
      "epoch 8; iter: 200; batch classifier loss: 0.409495; batch adversarial loss: 0.409480\n",
      "epoch 9; iter: 0; batch classifier loss: 0.475849; batch adversarial loss: 0.300528\n",
      "epoch 9; iter: 200; batch classifier loss: 0.382982; batch adversarial loss: 0.359906\n",
      "epoch 10; iter: 0; batch classifier loss: 0.439879; batch adversarial loss: 0.381048\n",
      "epoch 10; iter: 200; batch classifier loss: 0.477744; batch adversarial loss: 0.400621\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501219; batch adversarial loss: 0.398649\n",
      "epoch 11; iter: 200; batch classifier loss: 0.446460; batch adversarial loss: 0.373777\n",
      "epoch 12; iter: 0; batch classifier loss: 0.448339; batch adversarial loss: 0.403271\n",
      "epoch 12; iter: 200; batch classifier loss: 0.498075; batch adversarial loss: 0.420840\n",
      "epoch 13; iter: 0; batch classifier loss: 0.371973; batch adversarial loss: 0.394898\n",
      "epoch 13; iter: 200; batch classifier loss: 0.436925; batch adversarial loss: 0.365204\n",
      "epoch 14; iter: 0; batch classifier loss: 0.399789; batch adversarial loss: 0.413505\n",
      "epoch 14; iter: 200; batch classifier loss: 0.354792; batch adversarial loss: 0.312076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 0; batch classifier loss: 0.445109; batch adversarial loss: 0.352331\n",
      "epoch 15; iter: 200; batch classifier loss: 0.523684; batch adversarial loss: 0.371118\n",
      "epoch 16; iter: 0; batch classifier loss: 0.319725; batch adversarial loss: 0.361607\n",
      "epoch 16; iter: 200; batch classifier loss: 0.484324; batch adversarial loss: 0.495949\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507330; batch adversarial loss: 0.321262\n",
      "epoch 17; iter: 200; batch classifier loss: 0.497873; batch adversarial loss: 0.423694\n",
      "epoch 18; iter: 0; batch classifier loss: 0.414627; batch adversarial loss: 0.353507\n",
      "epoch 18; iter: 200; batch classifier loss: 0.468498; batch adversarial loss: 0.429169\n",
      "epoch 19; iter: 0; batch classifier loss: 0.411867; batch adversarial loss: 0.546688\n",
      "epoch 19; iter: 200; batch classifier loss: 0.437115; batch adversarial loss: 0.365310\n",
      "epoch 20; iter: 0; batch classifier loss: 0.430766; batch adversarial loss: 0.389592\n",
      "epoch 20; iter: 200; batch classifier loss: 0.384046; batch adversarial loss: 0.511735\n",
      "epoch 21; iter: 0; batch classifier loss: 0.390333; batch adversarial loss: 0.459022\n",
      "epoch 21; iter: 200; batch classifier loss: 0.440856; batch adversarial loss: 0.363754\n",
      "epoch 22; iter: 0; batch classifier loss: 0.438410; batch adversarial loss: 0.373700\n",
      "epoch 22; iter: 200; batch classifier loss: 0.386932; batch adversarial loss: 0.349615\n",
      "epoch 23; iter: 0; batch classifier loss: 0.488103; batch adversarial loss: 0.314559\n",
      "epoch 23; iter: 200; batch classifier loss: 0.367728; batch adversarial loss: 0.371523\n",
      "epoch 24; iter: 0; batch classifier loss: 0.448772; batch adversarial loss: 0.411237\n",
      "epoch 24; iter: 200; batch classifier loss: 0.388517; batch adversarial loss: 0.427063\n",
      "epoch 25; iter: 0; batch classifier loss: 0.372981; batch adversarial loss: 0.530520\n",
      "epoch 25; iter: 200; batch classifier loss: 0.507250; batch adversarial loss: 0.342883\n",
      "epoch 26; iter: 0; batch classifier loss: 0.469177; batch adversarial loss: 0.382008\n",
      "epoch 26; iter: 200; batch classifier loss: 0.411433; batch adversarial loss: 0.437681\n",
      "epoch 27; iter: 0; batch classifier loss: 0.412671; batch adversarial loss: 0.435151\n",
      "epoch 27; iter: 200; batch classifier loss: 0.482468; batch adversarial loss: 0.288132\n",
      "epoch 28; iter: 0; batch classifier loss: 0.476585; batch adversarial loss: 0.365155\n",
      "epoch 28; iter: 200; batch classifier loss: 0.405592; batch adversarial loss: 0.326872\n",
      "epoch 29; iter: 0; batch classifier loss: 0.448689; batch adversarial loss: 0.425974\n",
      "epoch 29; iter: 200; batch classifier loss: 0.420990; batch adversarial loss: 0.393206\n",
      "epoch 30; iter: 0; batch classifier loss: 0.444084; batch adversarial loss: 0.393472\n",
      "epoch 30; iter: 200; batch classifier loss: 0.468997; batch adversarial loss: 0.423552\n",
      "epoch 31; iter: 0; batch classifier loss: 0.492261; batch adversarial loss: 0.390330\n",
      "epoch 31; iter: 200; batch classifier loss: 0.446135; batch adversarial loss: 0.492329\n",
      "epoch 32; iter: 0; batch classifier loss: 0.381272; batch adversarial loss: 0.465521\n",
      "epoch 32; iter: 200; batch classifier loss: 0.456075; batch adversarial loss: 0.341978\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434758; batch adversarial loss: 0.513716\n",
      "epoch 33; iter: 200; batch classifier loss: 0.465368; batch adversarial loss: 0.325486\n",
      "epoch 34; iter: 0; batch classifier loss: 0.433469; batch adversarial loss: 0.451727\n",
      "epoch 34; iter: 200; batch classifier loss: 0.469452; batch adversarial loss: 0.414377\n",
      "epoch 35; iter: 0; batch classifier loss: 0.441248; batch adversarial loss: 0.430675\n",
      "epoch 35; iter: 200; batch classifier loss: 0.369315; batch adversarial loss: 0.449136\n",
      "epoch 36; iter: 0; batch classifier loss: 0.475899; batch adversarial loss: 0.498203\n",
      "epoch 36; iter: 200; batch classifier loss: 0.444348; batch adversarial loss: 0.454233\n",
      "epoch 37; iter: 0; batch classifier loss: 0.393611; batch adversarial loss: 0.356256\n",
      "epoch 37; iter: 200; batch classifier loss: 0.342703; batch adversarial loss: 0.324735\n",
      "epoch 38; iter: 0; batch classifier loss: 0.536061; batch adversarial loss: 0.474913\n",
      "epoch 38; iter: 200; batch classifier loss: 0.510945; batch adversarial loss: 0.462896\n",
      "epoch 39; iter: 0; batch classifier loss: 0.382642; batch adversarial loss: 0.425616\n",
      "epoch 39; iter: 200; batch classifier loss: 0.399253; batch adversarial loss: 0.445402\n",
      "epoch 40; iter: 0; batch classifier loss: 0.459981; batch adversarial loss: 0.453618\n",
      "epoch 40; iter: 200; batch classifier loss: 0.415879; batch adversarial loss: 0.393862\n",
      "epoch 41; iter: 0; batch classifier loss: 0.333001; batch adversarial loss: 0.404355\n",
      "epoch 41; iter: 200; batch classifier loss: 0.406905; batch adversarial loss: 0.410246\n",
      "epoch 42; iter: 0; batch classifier loss: 0.449816; batch adversarial loss: 0.363336\n",
      "epoch 42; iter: 200; batch classifier loss: 0.419743; batch adversarial loss: 0.382018\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421110; batch adversarial loss: 0.454927\n",
      "epoch 43; iter: 200; batch classifier loss: 0.405928; batch adversarial loss: 0.415125\n",
      "epoch 44; iter: 0; batch classifier loss: 0.337673; batch adversarial loss: 0.421516\n",
      "epoch 44; iter: 200; batch classifier loss: 0.423715; batch adversarial loss: 0.359535\n",
      "epoch 45; iter: 0; batch classifier loss: 0.421742; batch adversarial loss: 0.369847\n",
      "epoch 45; iter: 200; batch classifier loss: 0.359632; batch adversarial loss: 0.374066\n",
      "epoch 46; iter: 0; batch classifier loss: 0.435865; batch adversarial loss: 0.464480\n",
      "epoch 46; iter: 200; batch classifier loss: 0.425177; batch adversarial loss: 0.344099\n",
      "epoch 47; iter: 0; batch classifier loss: 0.407362; batch adversarial loss: 0.447730\n",
      "epoch 47; iter: 200; batch classifier loss: 0.431488; batch adversarial loss: 0.352035\n",
      "epoch 48; iter: 0; batch classifier loss: 0.400938; batch adversarial loss: 0.367680\n",
      "epoch 48; iter: 200; batch classifier loss: 0.458080; batch adversarial loss: 0.266159\n",
      "epoch 49; iter: 0; batch classifier loss: 0.448467; batch adversarial loss: 0.453358\n",
      "epoch 49; iter: 200; batch classifier loss: 0.370646; batch adversarial loss: 0.451255\n",
      "epoch 0; iter: 0; batch classifier loss: 0.722031\n",
      "epoch 0; iter: 200; batch classifier loss: 0.430306\n",
      "epoch 1; iter: 0; batch classifier loss: 0.447768\n",
      "epoch 1; iter: 200; batch classifier loss: 0.400737\n",
      "epoch 2; iter: 0; batch classifier loss: 0.425167\n",
      "epoch 2; iter: 200; batch classifier loss: 0.452108\n",
      "epoch 3; iter: 0; batch classifier loss: 0.418353\n",
      "epoch 3; iter: 200; batch classifier loss: 0.343498\n",
      "epoch 4; iter: 0; batch classifier loss: 0.362765\n",
      "epoch 4; iter: 200; batch classifier loss: 0.476095\n",
      "epoch 5; iter: 0; batch classifier loss: 0.474197\n",
      "epoch 5; iter: 200; batch classifier loss: 0.363440\n",
      "epoch 6; iter: 0; batch classifier loss: 0.372502\n",
      "epoch 6; iter: 200; batch classifier loss: 0.392431\n",
      "epoch 7; iter: 0; batch classifier loss: 0.462383\n",
      "epoch 7; iter: 200; batch classifier loss: 0.392521\n",
      "epoch 8; iter: 0; batch classifier loss: 0.368044\n",
      "epoch 8; iter: 200; batch classifier loss: 0.398443\n",
      "epoch 9; iter: 0; batch classifier loss: 0.387852\n",
      "epoch 9; iter: 200; batch classifier loss: 0.417007\n",
      "epoch 10; iter: 0; batch classifier loss: 0.407814\n",
      "epoch 10; iter: 200; batch classifier loss: 0.437637\n",
      "epoch 11; iter: 0; batch classifier loss: 0.419609\n",
      "epoch 11; iter: 200; batch classifier loss: 0.470205\n",
      "epoch 12; iter: 0; batch classifier loss: 0.421475\n",
      "epoch 12; iter: 200; batch classifier loss: 0.456625\n",
      "epoch 13; iter: 0; batch classifier loss: 0.433069\n",
      "epoch 13; iter: 200; batch classifier loss: 0.401818\n",
      "epoch 14; iter: 0; batch classifier loss: 0.386532\n",
      "epoch 14; iter: 200; batch classifier loss: 0.449985\n",
      "epoch 15; iter: 0; batch classifier loss: 0.379711\n",
      "epoch 15; iter: 200; batch classifier loss: 0.366153\n",
      "epoch 16; iter: 0; batch classifier loss: 0.349549\n",
      "epoch 16; iter: 200; batch classifier loss: 0.413161\n",
      "epoch 17; iter: 0; batch classifier loss: 0.424538\n",
      "epoch 17; iter: 200; batch classifier loss: 0.412529\n",
      "epoch 18; iter: 0; batch classifier loss: 0.342230\n",
      "epoch 18; iter: 200; batch classifier loss: 0.372512\n",
      "epoch 19; iter: 0; batch classifier loss: 0.365040\n",
      "epoch 19; iter: 200; batch classifier loss: 0.362714\n",
      "epoch 20; iter: 0; batch classifier loss: 0.446281\n",
      "epoch 20; iter: 200; batch classifier loss: 0.265319\n",
      "epoch 21; iter: 0; batch classifier loss: 0.431954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 200; batch classifier loss: 0.523958\n",
      "epoch 22; iter: 0; batch classifier loss: 0.425493\n",
      "epoch 22; iter: 200; batch classifier loss: 0.485297\n",
      "epoch 23; iter: 0; batch classifier loss: 0.403095\n",
      "epoch 23; iter: 200; batch classifier loss: 0.348121\n",
      "epoch 24; iter: 0; batch classifier loss: 0.412342\n",
      "epoch 24; iter: 200; batch classifier loss: 0.435705\n",
      "epoch 25; iter: 0; batch classifier loss: 0.398809\n",
      "epoch 25; iter: 200; batch classifier loss: 0.315901\n",
      "epoch 26; iter: 0; batch classifier loss: 0.489878\n",
      "epoch 26; iter: 200; batch classifier loss: 0.487713\n",
      "epoch 27; iter: 0; batch classifier loss: 0.435300\n",
      "epoch 27; iter: 200; batch classifier loss: 0.421407\n",
      "epoch 28; iter: 0; batch classifier loss: 0.306159\n",
      "epoch 28; iter: 200; batch classifier loss: 0.451785\n",
      "epoch 29; iter: 0; batch classifier loss: 0.524029\n",
      "epoch 29; iter: 200; batch classifier loss: 0.529207\n",
      "epoch 30; iter: 0; batch classifier loss: 0.419693\n",
      "epoch 30; iter: 200; batch classifier loss: 0.449781\n",
      "epoch 31; iter: 0; batch classifier loss: 0.467165\n",
      "epoch 31; iter: 200; batch classifier loss: 0.404024\n",
      "epoch 32; iter: 0; batch classifier loss: 0.367968\n",
      "epoch 32; iter: 200; batch classifier loss: 0.429115\n",
      "epoch 33; iter: 0; batch classifier loss: 0.316204\n",
      "epoch 33; iter: 200; batch classifier loss: 0.422772\n",
      "epoch 34; iter: 0; batch classifier loss: 0.418944\n",
      "epoch 34; iter: 200; batch classifier loss: 0.372694\n",
      "epoch 35; iter: 0; batch classifier loss: 0.356646\n",
      "epoch 35; iter: 200; batch classifier loss: 0.473373\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406468\n",
      "epoch 36; iter: 200; batch classifier loss: 0.520551\n",
      "epoch 37; iter: 0; batch classifier loss: 0.415730\n",
      "epoch 37; iter: 200; batch classifier loss: 0.438337\n",
      "epoch 38; iter: 0; batch classifier loss: 0.401051\n",
      "epoch 38; iter: 200; batch classifier loss: 0.366532\n",
      "epoch 39; iter: 0; batch classifier loss: 0.457385\n",
      "epoch 39; iter: 200; batch classifier loss: 0.442626\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412073\n",
      "epoch 40; iter: 200; batch classifier loss: 0.362375\n",
      "epoch 41; iter: 0; batch classifier loss: 0.417512\n",
      "epoch 41; iter: 200; batch classifier loss: 0.401855\n",
      "epoch 42; iter: 0; batch classifier loss: 0.395940\n",
      "epoch 42; iter: 200; batch classifier loss: 0.446176\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415303\n",
      "epoch 43; iter: 200; batch classifier loss: 0.510703\n",
      "epoch 44; iter: 0; batch classifier loss: 0.382888\n",
      "epoch 44; iter: 200; batch classifier loss: 0.441959\n",
      "epoch 45; iter: 0; batch classifier loss: 0.373052\n",
      "epoch 45; iter: 200; batch classifier loss: 0.435353\n",
      "epoch 46; iter: 0; batch classifier loss: 0.371848\n",
      "epoch 46; iter: 200; batch classifier loss: 0.383949\n",
      "epoch 47; iter: 0; batch classifier loss: 0.357441\n",
      "epoch 47; iter: 200; batch classifier loss: 0.438772\n",
      "epoch 48; iter: 0; batch classifier loss: 0.497114\n",
      "epoch 48; iter: 200; batch classifier loss: 0.481047\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393625\n",
      "epoch 49; iter: 200; batch classifier loss: 0.361971\n",
      "run = 8\n",
      "epoch 0; iter: 0; batch classifier loss: 0.660320; batch adversarial loss: 0.667012\n",
      "epoch 0; iter: 200; batch classifier loss: 0.416856; batch adversarial loss: 0.628713\n",
      "epoch 0; iter: 400; batch classifier loss: 0.607639; batch adversarial loss: 0.586506\n",
      "epoch 0; iter: 600; batch classifier loss: 0.439318; batch adversarial loss: 0.538353\n",
      "epoch 0; iter: 800; batch classifier loss: 0.400893; batch adversarial loss: 0.502895\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.494152; batch adversarial loss: 0.494056\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.477644; batch adversarial loss: 0.489820\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.424958; batch adversarial loss: 0.441941\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.386489; batch adversarial loss: 0.457289\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.480008; batch adversarial loss: 0.472896\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.387313; batch adversarial loss: 0.469712\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.466600; batch adversarial loss: 0.418822\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.390477; batch adversarial loss: 0.471813\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.407122; batch adversarial loss: 0.414017\n",
      "epoch 1; iter: 0; batch classifier loss: 0.414721; batch adversarial loss: 0.437889\n",
      "epoch 1; iter: 200; batch classifier loss: 0.433245; batch adversarial loss: 0.398538\n",
      "epoch 1; iter: 400; batch classifier loss: 0.438175; batch adversarial loss: 0.384057\n",
      "epoch 1; iter: 600; batch classifier loss: 0.409773; batch adversarial loss: 0.421481\n",
      "epoch 1; iter: 800; batch classifier loss: 0.462277; batch adversarial loss: 0.382359\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.389315; batch adversarial loss: 0.394826\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.429100; batch adversarial loss: 0.512850\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.418450; batch adversarial loss: 0.367556\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.479304; batch adversarial loss: 0.447271\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.306947; batch adversarial loss: 0.432743\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.481946; batch adversarial loss: 0.352849\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.432540; batch adversarial loss: 0.380541\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.360341; batch adversarial loss: 0.393638\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.465632; batch adversarial loss: 0.379579\n",
      "epoch 2; iter: 0; batch classifier loss: 0.392796; batch adversarial loss: 0.405530\n",
      "epoch 2; iter: 200; batch classifier loss: 0.372018; batch adversarial loss: 0.379551\n",
      "epoch 2; iter: 400; batch classifier loss: 0.416923; batch adversarial loss: 0.394004\n",
      "epoch 2; iter: 600; batch classifier loss: 0.367889; batch adversarial loss: 0.405539\n",
      "epoch 2; iter: 800; batch classifier loss: 0.412247; batch adversarial loss: 0.407378\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.396720; batch adversarial loss: 0.447524\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.424094; batch adversarial loss: 0.488897\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.449201; batch adversarial loss: 0.501260\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.439076; batch adversarial loss: 0.406441\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.516104; batch adversarial loss: 0.530361\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.391813; batch adversarial loss: 0.393528\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.459076; batch adversarial loss: 0.325413\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.434745; batch adversarial loss: 0.488656\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.419053; batch adversarial loss: 0.380455\n",
      "epoch 3; iter: 0; batch classifier loss: 0.437313; batch adversarial loss: 0.529693\n",
      "epoch 3; iter: 200; batch classifier loss: 0.459775; batch adversarial loss: 0.528527\n",
      "epoch 3; iter: 400; batch classifier loss: 0.347514; batch adversarial loss: 0.365798\n",
      "epoch 3; iter: 600; batch classifier loss: 0.346611; batch adversarial loss: 0.394413\n",
      "epoch 3; iter: 800; batch classifier loss: 0.433343; batch adversarial loss: 0.462861\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.384260; batch adversarial loss: 0.366403\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.444054; batch adversarial loss: 0.404866\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.422527; batch adversarial loss: 0.486101\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.407020; batch adversarial loss: 0.433840\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.359443; batch adversarial loss: 0.432766\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.346151; batch adversarial loss: 0.517534\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.371175; batch adversarial loss: 0.394935\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.315656; batch adversarial loss: 0.433193\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.385759; batch adversarial loss: 0.460357\n",
      "epoch 4; iter: 0; batch classifier loss: 0.453681; batch adversarial loss: 0.407430\n",
      "epoch 4; iter: 200; batch classifier loss: 0.394184; batch adversarial loss: 0.420204\n",
      "epoch 4; iter: 400; batch classifier loss: 0.378561; batch adversarial loss: 0.474392\n",
      "epoch 4; iter: 600; batch classifier loss: 0.374066; batch adversarial loss: 0.430970\n",
      "epoch 4; iter: 800; batch classifier loss: 0.376635; batch adversarial loss: 0.406151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4; iter: 1000; batch classifier loss: 0.427070; batch adversarial loss: 0.433899\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.377421; batch adversarial loss: 0.379418\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.372115; batch adversarial loss: 0.365063\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.396113; batch adversarial loss: 0.418009\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.435597; batch adversarial loss: 0.461563\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.456586; batch adversarial loss: 0.474691\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.350645; batch adversarial loss: 0.363198\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.449368; batch adversarial loss: 0.474375\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.345568; batch adversarial loss: 0.378167\n",
      "epoch 5; iter: 0; batch classifier loss: 0.418064; batch adversarial loss: 0.419330\n",
      "epoch 5; iter: 200; batch classifier loss: 0.381166; batch adversarial loss: 0.407324\n",
      "epoch 5; iter: 400; batch classifier loss: 0.440401; batch adversarial loss: 0.405236\n",
      "epoch 5; iter: 600; batch classifier loss: 0.414165; batch adversarial loss: 0.418078\n",
      "epoch 5; iter: 800; batch classifier loss: 0.469486; batch adversarial loss: 0.444112\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.365327; batch adversarial loss: 0.408542\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.344912; batch adversarial loss: 0.378737\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.417549; batch adversarial loss: 0.418116\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.486087; batch adversarial loss: 0.369577\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.407385; batch adversarial loss: 0.395463\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.419830; batch adversarial loss: 0.473245\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.343444; batch adversarial loss: 0.432725\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.470762; batch adversarial loss: 0.406161\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.362471; batch adversarial loss: 0.352202\n",
      "epoch 6; iter: 0; batch classifier loss: 0.421163; batch adversarial loss: 0.474981\n",
      "epoch 6; iter: 200; batch classifier loss: 0.284068; batch adversarial loss: 0.350680\n",
      "epoch 6; iter: 400; batch classifier loss: 0.389997; batch adversarial loss: 0.353405\n",
      "epoch 6; iter: 600; batch classifier loss: 0.468223; batch adversarial loss: 0.418553\n",
      "epoch 6; iter: 800; batch classifier loss: 0.381396; batch adversarial loss: 0.449018\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.497282; batch adversarial loss: 0.350475\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.467684; batch adversarial loss: 0.407005\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.436982; batch adversarial loss: 0.406386\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.369627; batch adversarial loss: 0.324280\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.398011; batch adversarial loss: 0.419855\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.394891; batch adversarial loss: 0.449029\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.430244; batch adversarial loss: 0.364834\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.460760; batch adversarial loss: 0.448072\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.368874; batch adversarial loss: 0.350718\n",
      "epoch 7; iter: 0; batch classifier loss: 0.353619; batch adversarial loss: 0.434805\n",
      "epoch 7; iter: 200; batch classifier loss: 0.484097; batch adversarial loss: 0.421780\n",
      "epoch 7; iter: 400; batch classifier loss: 0.383326; batch adversarial loss: 0.487592\n",
      "epoch 7; iter: 600; batch classifier loss: 0.467003; batch adversarial loss: 0.463076\n",
      "epoch 7; iter: 800; batch classifier loss: 0.341559; batch adversarial loss: 0.448795\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.493019; batch adversarial loss: 0.419027\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.462746; batch adversarial loss: 0.273124\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.375721; batch adversarial loss: 0.429579\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.474850; batch adversarial loss: 0.459038\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.443433; batch adversarial loss: 0.391063\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.369326; batch adversarial loss: 0.337912\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.389743; batch adversarial loss: 0.448431\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.456438; batch adversarial loss: 0.378709\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.409130; batch adversarial loss: 0.364528\n",
      "epoch 8; iter: 0; batch classifier loss: 0.464660; batch adversarial loss: 0.448928\n",
      "epoch 8; iter: 200; batch classifier loss: 0.452094; batch adversarial loss: 0.463708\n",
      "epoch 8; iter: 400; batch classifier loss: 0.447160; batch adversarial loss: 0.379103\n",
      "epoch 8; iter: 600; batch classifier loss: 0.530328; batch adversarial loss: 0.298222\n",
      "epoch 8; iter: 800; batch classifier loss: 0.401875; batch adversarial loss: 0.380044\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.400024; batch adversarial loss: 0.447076\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.405916; batch adversarial loss: 0.430945\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.514008; batch adversarial loss: 0.393168\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.433641; batch adversarial loss: 0.381536\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.489662; batch adversarial loss: 0.434523\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.384359; batch adversarial loss: 0.487383\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.432107; batch adversarial loss: 0.486721\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.387725; batch adversarial loss: 0.285918\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.412599; batch adversarial loss: 0.462994\n",
      "epoch 9; iter: 0; batch classifier loss: 0.391892; batch adversarial loss: 0.500160\n",
      "epoch 9; iter: 200; batch classifier loss: 0.449792; batch adversarial loss: 0.407113\n",
      "epoch 9; iter: 400; batch classifier loss: 0.519728; batch adversarial loss: 0.403421\n",
      "epoch 9; iter: 600; batch classifier loss: 0.423778; batch adversarial loss: 0.461708\n",
      "epoch 9; iter: 800; batch classifier loss: 0.392871; batch adversarial loss: 0.491373\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.388645; batch adversarial loss: 0.363795\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.394828; batch adversarial loss: 0.379774\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.376845; batch adversarial loss: 0.351641\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.435490; batch adversarial loss: 0.472725\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.454867; batch adversarial loss: 0.419113\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.394564; batch adversarial loss: 0.448430\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.398383; batch adversarial loss: 0.460054\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.395471; batch adversarial loss: 0.445502\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.458553; batch adversarial loss: 0.485954\n",
      "epoch 10; iter: 0; batch classifier loss: 0.440324; batch adversarial loss: 0.488252\n",
      "epoch 10; iter: 200; batch classifier loss: 0.454145; batch adversarial loss: 0.446881\n",
      "epoch 10; iter: 400; batch classifier loss: 0.419345; batch adversarial loss: 0.336379\n",
      "epoch 10; iter: 600; batch classifier loss: 0.392359; batch adversarial loss: 0.407210\n",
      "epoch 10; iter: 800; batch classifier loss: 0.398152; batch adversarial loss: 0.570190\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.353098; batch adversarial loss: 0.460193\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.401148; batch adversarial loss: 0.403874\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.474381; batch adversarial loss: 0.416944\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.450552; batch adversarial loss: 0.488177\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.465391; batch adversarial loss: 0.418495\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.529895; batch adversarial loss: 0.365650\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.362334; batch adversarial loss: 0.448026\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.403079; batch adversarial loss: 0.473876\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.436985; batch adversarial loss: 0.393759\n",
      "epoch 11; iter: 0; batch classifier loss: 0.415161; batch adversarial loss: 0.362861\n",
      "epoch 11; iter: 200; batch classifier loss: 0.382296; batch adversarial loss: 0.336134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11; iter: 400; batch classifier loss: 0.418417; batch adversarial loss: 0.404840\n",
      "epoch 11; iter: 600; batch classifier loss: 0.446076; batch adversarial loss: 0.500530\n",
      "epoch 11; iter: 800; batch classifier loss: 0.384905; batch adversarial loss: 0.283562\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.365747; batch adversarial loss: 0.407963\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.396136; batch adversarial loss: 0.513726\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.419969; batch adversarial loss: 0.407741\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.384551; batch adversarial loss: 0.379751\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.432101; batch adversarial loss: 0.541212\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.326843; batch adversarial loss: 0.433582\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.436888; batch adversarial loss: 0.393306\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.376966; batch adversarial loss: 0.406193\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.456904; batch adversarial loss: 0.378019\n",
      "epoch 12; iter: 0; batch classifier loss: 0.403303; batch adversarial loss: 0.365693\n",
      "epoch 12; iter: 200; batch classifier loss: 0.472416; batch adversarial loss: 0.486391\n",
      "epoch 12; iter: 400; batch classifier loss: 0.463090; batch adversarial loss: 0.430297\n",
      "epoch 12; iter: 600; batch classifier loss: 0.451743; batch adversarial loss: 0.351976\n",
      "epoch 12; iter: 800; batch classifier loss: 0.452050; batch adversarial loss: 0.404249\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.444487; batch adversarial loss: 0.417836\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.354643; batch adversarial loss: 0.480974\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.448291; batch adversarial loss: 0.487472\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.393295; batch adversarial loss: 0.431926\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.507759; batch adversarial loss: 0.376287\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.378604; batch adversarial loss: 0.379137\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.375137; batch adversarial loss: 0.283916\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.403544; batch adversarial loss: 0.529201\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.424370; batch adversarial loss: 0.474514\n",
      "epoch 13; iter: 0; batch classifier loss: 0.394355; batch adversarial loss: 0.392908\n",
      "epoch 13; iter: 200; batch classifier loss: 0.409169; batch adversarial loss: 0.459409\n",
      "epoch 13; iter: 400; batch classifier loss: 0.344248; batch adversarial loss: 0.417818\n",
      "epoch 13; iter: 600; batch classifier loss: 0.390377; batch adversarial loss: 0.434512\n",
      "epoch 13; iter: 800; batch classifier loss: 0.465715; batch adversarial loss: 0.489712\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.411068; batch adversarial loss: 0.432614\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.395638; batch adversarial loss: 0.417928\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.448716; batch adversarial loss: 0.351719\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.378991; batch adversarial loss: 0.513100\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.442727; batch adversarial loss: 0.528237\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.354521; batch adversarial loss: 0.336845\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.398052; batch adversarial loss: 0.381248\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.410958; batch adversarial loss: 0.474266\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.417434; batch adversarial loss: 0.365467\n",
      "epoch 14; iter: 0; batch classifier loss: 0.412591; batch adversarial loss: 0.323944\n",
      "epoch 14; iter: 200; batch classifier loss: 0.377301; batch adversarial loss: 0.433075\n",
      "epoch 14; iter: 400; batch classifier loss: 0.415763; batch adversarial loss: 0.391199\n",
      "epoch 14; iter: 600; batch classifier loss: 0.493207; batch adversarial loss: 0.393377\n",
      "epoch 14; iter: 800; batch classifier loss: 0.521328; batch adversarial loss: 0.336522\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.344531; batch adversarial loss: 0.365880\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.366598; batch adversarial loss: 0.340124\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.383554; batch adversarial loss: 0.390199\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.321465; batch adversarial loss: 0.353919\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.425241; batch adversarial loss: 0.390373\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.369098; batch adversarial loss: 0.405187\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.478793; batch adversarial loss: 0.406207\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.475616; batch adversarial loss: 0.380852\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.487974; batch adversarial loss: 0.540323\n",
      "epoch 15; iter: 0; batch classifier loss: 0.384785; batch adversarial loss: 0.461553\n",
      "epoch 15; iter: 200; batch classifier loss: 0.315523; batch adversarial loss: 0.339861\n",
      "epoch 15; iter: 400; batch classifier loss: 0.381315; batch adversarial loss: 0.377015\n",
      "epoch 15; iter: 600; batch classifier loss: 0.444038; batch adversarial loss: 0.513101\n",
      "epoch 15; iter: 800; batch classifier loss: 0.380422; batch adversarial loss: 0.449324\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.404585; batch adversarial loss: 0.416261\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.346212; batch adversarial loss: 0.515654\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.478436; batch adversarial loss: 0.433003\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.363309; batch adversarial loss: 0.380923\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.404768; batch adversarial loss: 0.474471\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.404634; batch adversarial loss: 0.392045\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.451165; batch adversarial loss: 0.379977\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.451564; batch adversarial loss: 0.474257\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.437898; batch adversarial loss: 0.364856\n",
      "epoch 16; iter: 0; batch classifier loss: 0.470349; batch adversarial loss: 0.431721\n",
      "epoch 16; iter: 200; batch classifier loss: 0.417081; batch adversarial loss: 0.457674\n",
      "epoch 16; iter: 400; batch classifier loss: 0.466615; batch adversarial loss: 0.460331\n",
      "epoch 16; iter: 600; batch classifier loss: 0.386849; batch adversarial loss: 0.391801\n",
      "epoch 16; iter: 800; batch classifier loss: 0.365863; batch adversarial loss: 0.366093\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.426798; batch adversarial loss: 0.339193\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.426854; batch adversarial loss: 0.448337\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.480424; batch adversarial loss: 0.471843\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.466240; batch adversarial loss: 0.407454\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.438770; batch adversarial loss: 0.569314\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.434220; batch adversarial loss: 0.405879\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.406731; batch adversarial loss: 0.407192\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.359832; batch adversarial loss: 0.445262\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.406118; batch adversarial loss: 0.518490\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495706; batch adversarial loss: 0.504200\n",
      "epoch 17; iter: 200; batch classifier loss: 0.329056; batch adversarial loss: 0.378426\n",
      "epoch 17; iter: 400; batch classifier loss: 0.433513; batch adversarial loss: 0.379459\n",
      "epoch 17; iter: 600; batch classifier loss: 0.440934; batch adversarial loss: 0.501627\n",
      "epoch 17; iter: 800; batch classifier loss: 0.382139; batch adversarial loss: 0.445989\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.460971; batch adversarial loss: 0.364441\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.420367; batch adversarial loss: 0.406254\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.417679; batch adversarial loss: 0.352017\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.430054; batch adversarial loss: 0.378801\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.457863; batch adversarial loss: 0.446168\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.465702; batch adversarial loss: 0.351427\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.493675; batch adversarial loss: 0.500405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 2400; batch classifier loss: 0.407253; batch adversarial loss: 0.378836\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.320285; batch adversarial loss: 0.432294\n",
      "epoch 18; iter: 0; batch classifier loss: 0.449687; batch adversarial loss: 0.380074\n",
      "epoch 18; iter: 200; batch classifier loss: 0.419562; batch adversarial loss: 0.299237\n",
      "epoch 18; iter: 400; batch classifier loss: 0.419600; batch adversarial loss: 0.553167\n",
      "epoch 18; iter: 600; batch classifier loss: 0.326313; batch adversarial loss: 0.393412\n",
      "epoch 18; iter: 800; batch classifier loss: 0.395994; batch adversarial loss: 0.446026\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.382306; batch adversarial loss: 0.515261\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.420983; batch adversarial loss: 0.474151\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.404953; batch adversarial loss: 0.352069\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.503820; batch adversarial loss: 0.406565\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.474968; batch adversarial loss: 0.393896\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.400687; batch adversarial loss: 0.392677\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.415397; batch adversarial loss: 0.430147\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.389869; batch adversarial loss: 0.311375\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.378559; batch adversarial loss: 0.366656\n",
      "epoch 19; iter: 0; batch classifier loss: 0.483722; batch adversarial loss: 0.377289\n",
      "epoch 19; iter: 200; batch classifier loss: 0.481028; batch adversarial loss: 0.363419\n",
      "epoch 19; iter: 400; batch classifier loss: 0.406684; batch adversarial loss: 0.417568\n",
      "epoch 19; iter: 600; batch classifier loss: 0.366496; batch adversarial loss: 0.487705\n",
      "epoch 19; iter: 800; batch classifier loss: 0.491139; batch adversarial loss: 0.447534\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.381870; batch adversarial loss: 0.417664\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.386325; batch adversarial loss: 0.382169\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.400106; batch adversarial loss: 0.393243\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.437562; batch adversarial loss: 0.445725\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.397229; batch adversarial loss: 0.379662\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.386819; batch adversarial loss: 0.409507\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.424599; batch adversarial loss: 0.309788\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.403878; batch adversarial loss: 0.500437\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.544271; batch adversarial loss: 0.447504\n",
      "epoch 20; iter: 0; batch classifier loss: 0.387131; batch adversarial loss: 0.421944\n",
      "epoch 20; iter: 200; batch classifier loss: 0.387352; batch adversarial loss: 0.488721\n",
      "epoch 20; iter: 400; batch classifier loss: 0.336105; batch adversarial loss: 0.365818\n",
      "epoch 20; iter: 600; batch classifier loss: 0.428450; batch adversarial loss: 0.474028\n",
      "epoch 20; iter: 800; batch classifier loss: 0.334666; batch adversarial loss: 0.350983\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.414123; batch adversarial loss: 0.403933\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.304720; batch adversarial loss: 0.484337\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.471669; batch adversarial loss: 0.444119\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.408838; batch adversarial loss: 0.364606\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.380228; batch adversarial loss: 0.446742\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.403062; batch adversarial loss: 0.435486\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.472157; batch adversarial loss: 0.377435\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.380560; batch adversarial loss: 0.433831\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.409843; batch adversarial loss: 0.405828\n",
      "epoch 21; iter: 0; batch classifier loss: 0.291573; batch adversarial loss: 0.503221\n",
      "epoch 21; iter: 200; batch classifier loss: 0.471974; batch adversarial loss: 0.405120\n",
      "epoch 21; iter: 400; batch classifier loss: 0.445837; batch adversarial loss: 0.472394\n",
      "epoch 21; iter: 600; batch classifier loss: 0.304386; batch adversarial loss: 0.419680\n",
      "epoch 21; iter: 800; batch classifier loss: 0.423376; batch adversarial loss: 0.419282\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.497163; batch adversarial loss: 0.446361\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.474233; batch adversarial loss: 0.379376\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.385255; batch adversarial loss: 0.418054\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.426217; batch adversarial loss: 0.421974\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.352036; batch adversarial loss: 0.352029\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.353042; batch adversarial loss: 0.378582\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.439088; batch adversarial loss: 0.352238\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.501202; batch adversarial loss: 0.431671\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.420085; batch adversarial loss: 0.421346\n",
      "epoch 22; iter: 0; batch classifier loss: 0.410750; batch adversarial loss: 0.435674\n",
      "epoch 22; iter: 200; batch classifier loss: 0.408718; batch adversarial loss: 0.406889\n",
      "epoch 22; iter: 400; batch classifier loss: 0.383661; batch adversarial loss: 0.393927\n",
      "epoch 22; iter: 600; batch classifier loss: 0.354585; batch adversarial loss: 0.487729\n",
      "epoch 22; iter: 800; batch classifier loss: 0.437639; batch adversarial loss: 0.447414\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.350276; batch adversarial loss: 0.310145\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.378013; batch adversarial loss: 0.403512\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.428926; batch adversarial loss: 0.393429\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.386546; batch adversarial loss: 0.446538\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.394213; batch adversarial loss: 0.393414\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.334108; batch adversarial loss: 0.474720\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.411956; batch adversarial loss: 0.418738\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.396009; batch adversarial loss: 0.432436\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.365257; batch adversarial loss: 0.421131\n",
      "epoch 23; iter: 0; batch classifier loss: 0.401604; batch adversarial loss: 0.367410\n",
      "epoch 23; iter: 200; batch classifier loss: 0.450914; batch adversarial loss: 0.475341\n",
      "epoch 23; iter: 400; batch classifier loss: 0.388842; batch adversarial loss: 0.459798\n",
      "epoch 23; iter: 600; batch classifier loss: 0.386541; batch adversarial loss: 0.474876\n",
      "epoch 23; iter: 800; batch classifier loss: 0.437954; batch adversarial loss: 0.447677\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.461322; batch adversarial loss: 0.402428\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.399463; batch adversarial loss: 0.323654\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.420630; batch adversarial loss: 0.365056\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.452889; batch adversarial loss: 0.458269\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.423937; batch adversarial loss: 0.350896\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.401797; batch adversarial loss: 0.472966\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.518642; batch adversarial loss: 0.311637\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.418713; batch adversarial loss: 0.381160\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.430628; batch adversarial loss: 0.404677\n",
      "epoch 24; iter: 0; batch classifier loss: 0.338656; batch adversarial loss: 0.447046\n",
      "epoch 24; iter: 200; batch classifier loss: 0.487931; batch adversarial loss: 0.394877\n",
      "epoch 24; iter: 400; batch classifier loss: 0.468920; batch adversarial loss: 0.446568\n",
      "epoch 24; iter: 600; batch classifier loss: 0.376286; batch adversarial loss: 0.433151\n",
      "epoch 24; iter: 800; batch classifier loss: 0.430276; batch adversarial loss: 0.446406\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.398516; batch adversarial loss: 0.541448\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.350193; batch adversarial loss: 0.391957\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.403680; batch adversarial loss: 0.418743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 1600; batch classifier loss: 0.401367; batch adversarial loss: 0.419525\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.396867; batch adversarial loss: 0.411731\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.416009; batch adversarial loss: 0.487693\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.429315; batch adversarial loss: 0.500226\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.385509; batch adversarial loss: 0.531895\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.404116; batch adversarial loss: 0.406578\n",
      "epoch 25; iter: 0; batch classifier loss: 0.454706; batch adversarial loss: 0.376103\n",
      "epoch 25; iter: 200; batch classifier loss: 0.402534; batch adversarial loss: 0.367589\n",
      "epoch 25; iter: 400; batch classifier loss: 0.454302; batch adversarial loss: 0.408500\n",
      "epoch 25; iter: 600; batch classifier loss: 0.436908; batch adversarial loss: 0.404038\n",
      "epoch 25; iter: 800; batch classifier loss: 0.483191; batch adversarial loss: 0.477715\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.433626; batch adversarial loss: 0.352604\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.446962; batch adversarial loss: 0.419539\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.412643; batch adversarial loss: 0.406640\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.421264; batch adversarial loss: 0.393178\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.432429; batch adversarial loss: 0.378102\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.426109; batch adversarial loss: 0.339188\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.346462; batch adversarial loss: 0.350613\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.428261; batch adversarial loss: 0.460285\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.316739; batch adversarial loss: 0.394420\n",
      "epoch 26; iter: 0; batch classifier loss: 0.469782; batch adversarial loss: 0.518689\n",
      "epoch 26; iter: 200; batch classifier loss: 0.509207; batch adversarial loss: 0.433902\n",
      "epoch 26; iter: 400; batch classifier loss: 0.460638; batch adversarial loss: 0.391153\n",
      "epoch 26; iter: 600; batch classifier loss: 0.448874; batch adversarial loss: 0.393476\n",
      "epoch 26; iter: 800; batch classifier loss: 0.336160; batch adversarial loss: 0.420215\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.452905; batch adversarial loss: 0.433860\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.441068; batch adversarial loss: 0.503724\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.371484; batch adversarial loss: 0.499957\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.423764; batch adversarial loss: 0.363525\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.421871; batch adversarial loss: 0.460520\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.451987; batch adversarial loss: 0.434314\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.434020; batch adversarial loss: 0.477386\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.350509; batch adversarial loss: 0.515288\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.387436; batch adversarial loss: 0.447876\n",
      "epoch 27; iter: 0; batch classifier loss: 0.573966; batch adversarial loss: 0.471748\n",
      "epoch 27; iter: 200; batch classifier loss: 0.363263; batch adversarial loss: 0.379789\n",
      "epoch 27; iter: 400; batch classifier loss: 0.403285; batch adversarial loss: 0.406610\n",
      "epoch 27; iter: 600; batch classifier loss: 0.410928; batch adversarial loss: 0.461643\n",
      "epoch 27; iter: 800; batch classifier loss: 0.381418; batch adversarial loss: 0.337614\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.516179; batch adversarial loss: 0.403256\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.257354; batch adversarial loss: 0.366164\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.411973; batch adversarial loss: 0.431200\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.491634; batch adversarial loss: 0.431971\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.390124; batch adversarial loss: 0.464640\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.462523; batch adversarial loss: 0.325323\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.409509; batch adversarial loss: 0.418639\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.344894; batch adversarial loss: 0.378569\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.319927; batch adversarial loss: 0.364856\n",
      "epoch 28; iter: 0; batch classifier loss: 0.363953; batch adversarial loss: 0.419288\n",
      "epoch 28; iter: 200; batch classifier loss: 0.525881; batch adversarial loss: 0.407069\n",
      "epoch 28; iter: 400; batch classifier loss: 0.458009; batch adversarial loss: 0.406123\n",
      "epoch 28; iter: 600; batch classifier loss: 0.415772; batch adversarial loss: 0.461102\n",
      "epoch 28; iter: 800; batch classifier loss: 0.396398; batch adversarial loss: 0.350867\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.345026; batch adversarial loss: 0.312241\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.399190; batch adversarial loss: 0.417841\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.470519; batch adversarial loss: 0.485204\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.404082; batch adversarial loss: 0.433136\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.402530; batch adversarial loss: 0.458026\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.420939; batch adversarial loss: 0.489075\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.358513; batch adversarial loss: 0.351805\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.401678; batch adversarial loss: 0.363291\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.400616; batch adversarial loss: 0.499928\n",
      "epoch 29; iter: 0; batch classifier loss: 0.408036; batch adversarial loss: 0.311444\n",
      "epoch 29; iter: 200; batch classifier loss: 0.415404; batch adversarial loss: 0.378454\n",
      "epoch 29; iter: 400; batch classifier loss: 0.374906; batch adversarial loss: 0.351172\n",
      "epoch 29; iter: 600; batch classifier loss: 0.455799; batch adversarial loss: 0.477544\n",
      "epoch 29; iter: 800; batch classifier loss: 0.431367; batch adversarial loss: 0.419854\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.414698; batch adversarial loss: 0.434145\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.430200; batch adversarial loss: 0.417075\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.408628; batch adversarial loss: 0.340544\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.425238; batch adversarial loss: 0.355145\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.373619; batch adversarial loss: 0.543118\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.506843; batch adversarial loss: 0.431389\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.382492; batch adversarial loss: 0.406404\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.406396; batch adversarial loss: 0.433538\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.387698; batch adversarial loss: 0.365336\n",
      "epoch 30; iter: 0; batch classifier loss: 0.340413; batch adversarial loss: 0.475029\n",
      "epoch 30; iter: 200; batch classifier loss: 0.450806; batch adversarial loss: 0.541098\n",
      "epoch 30; iter: 400; batch classifier loss: 0.407553; batch adversarial loss: 0.542378\n",
      "epoch 30; iter: 600; batch classifier loss: 0.449223; batch adversarial loss: 0.434215\n",
      "epoch 30; iter: 800; batch classifier loss: 0.474283; batch adversarial loss: 0.450567\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.472721; batch adversarial loss: 0.392685\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.389301; batch adversarial loss: 0.420884\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.409269; batch adversarial loss: 0.393313\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.439631; batch adversarial loss: 0.461499\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.446645; batch adversarial loss: 0.418511\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.470286; batch adversarial loss: 0.477279\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.418540; batch adversarial loss: 0.490328\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.468007; batch adversarial loss: 0.365911\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.415824; batch adversarial loss: 0.446258\n",
      "epoch 31; iter: 0; batch classifier loss: 0.443472; batch adversarial loss: 0.450700\n",
      "epoch 31; iter: 200; batch classifier loss: 0.403640; batch adversarial loss: 0.462049\n",
      "epoch 31; iter: 400; batch classifier loss: 0.437101; batch adversarial loss: 0.478036\n",
      "epoch 31; iter: 600; batch classifier loss: 0.419979; batch adversarial loss: 0.472782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31; iter: 800; batch classifier loss: 0.402765; batch adversarial loss: 0.432528\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.499530; batch adversarial loss: 0.365019\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.323654; batch adversarial loss: 0.445953\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.425693; batch adversarial loss: 0.474052\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.498810; batch adversarial loss: 0.447466\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.447537; batch adversarial loss: 0.379137\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.435784; batch adversarial loss: 0.433765\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.389571; batch adversarial loss: 0.431967\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.426321; batch adversarial loss: 0.366012\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.393037; batch adversarial loss: 0.421116\n",
      "epoch 32; iter: 0; batch classifier loss: 0.432407; batch adversarial loss: 0.381732\n",
      "epoch 32; iter: 200; batch classifier loss: 0.437275; batch adversarial loss: 0.392424\n",
      "epoch 32; iter: 400; batch classifier loss: 0.512239; batch adversarial loss: 0.475366\n",
      "epoch 32; iter: 600; batch classifier loss: 0.358710; batch adversarial loss: 0.366431\n",
      "epoch 32; iter: 800; batch classifier loss: 0.472778; batch adversarial loss: 0.405708\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.424840; batch adversarial loss: 0.459634\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.449471; batch adversarial loss: 0.420840\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.379006; batch adversarial loss: 0.395501\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.367178; batch adversarial loss: 0.391594\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.384657; batch adversarial loss: 0.403957\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.305800; batch adversarial loss: 0.445994\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.399809; batch adversarial loss: 0.476305\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.392931; batch adversarial loss: 0.432552\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.512207; batch adversarial loss: 0.416624\n",
      "epoch 33; iter: 0; batch classifier loss: 0.408445; batch adversarial loss: 0.367263\n",
      "epoch 33; iter: 200; batch classifier loss: 0.471859; batch adversarial loss: 0.395479\n",
      "epoch 33; iter: 400; batch classifier loss: 0.469689; batch adversarial loss: 0.404928\n",
      "epoch 33; iter: 600; batch classifier loss: 0.360087; batch adversarial loss: 0.406403\n",
      "epoch 33; iter: 800; batch classifier loss: 0.478635; batch adversarial loss: 0.421085\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.424067; batch adversarial loss: 0.419677\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.347128; batch adversarial loss: 0.407696\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.458061; batch adversarial loss: 0.309627\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.454024; batch adversarial loss: 0.364911\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.407102; batch adversarial loss: 0.377747\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.406281; batch adversarial loss: 0.488550\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.405701; batch adversarial loss: 0.444240\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.409866; batch adversarial loss: 0.473047\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.431599; batch adversarial loss: 0.556867\n",
      "epoch 34; iter: 0; batch classifier loss: 0.457830; batch adversarial loss: 0.391306\n",
      "epoch 34; iter: 200; batch classifier loss: 0.392061; batch adversarial loss: 0.500828\n",
      "epoch 34; iter: 400; batch classifier loss: 0.400016; batch adversarial loss: 0.447785\n",
      "epoch 34; iter: 600; batch classifier loss: 0.464066; batch adversarial loss: 0.392498\n",
      "epoch 34; iter: 800; batch classifier loss: 0.323822; batch adversarial loss: 0.447065\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.358788; batch adversarial loss: 0.377233\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.492566; batch adversarial loss: 0.434691\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.423770; batch adversarial loss: 0.447439\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.374673; batch adversarial loss: 0.451307\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.427655; batch adversarial loss: 0.367736\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.409367; batch adversarial loss: 0.434315\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.465101; batch adversarial loss: 0.353546\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.442339; batch adversarial loss: 0.435373\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.415291; batch adversarial loss: 0.434255\n",
      "epoch 35; iter: 0; batch classifier loss: 0.337414; batch adversarial loss: 0.405988\n",
      "epoch 35; iter: 200; batch classifier loss: 0.389361; batch adversarial loss: 0.310328\n",
      "epoch 35; iter: 400; batch classifier loss: 0.388763; batch adversarial loss: 0.515150\n",
      "epoch 35; iter: 600; batch classifier loss: 0.345535; batch adversarial loss: 0.392863\n",
      "epoch 35; iter: 800; batch classifier loss: 0.441932; batch adversarial loss: 0.513729\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.401683; batch adversarial loss: 0.406824\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.394770; batch adversarial loss: 0.407561\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.391863; batch adversarial loss: 0.391370\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.402873; batch adversarial loss: 0.459978\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.429220; batch adversarial loss: 0.504504\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.520776; batch adversarial loss: 0.417663\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.352868; batch adversarial loss: 0.542588\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.433623; batch adversarial loss: 0.363047\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.456639; batch adversarial loss: 0.448221\n",
      "epoch 36; iter: 0; batch classifier loss: 0.405148; batch adversarial loss: 0.489240\n",
      "epoch 36; iter: 200; batch classifier loss: 0.368361; batch adversarial loss: 0.380480\n",
      "epoch 36; iter: 400; batch classifier loss: 0.358121; batch adversarial loss: 0.448131\n",
      "epoch 36; iter: 600; batch classifier loss: 0.320834; batch adversarial loss: 0.407158\n",
      "epoch 36; iter: 800; batch classifier loss: 0.445370; batch adversarial loss: 0.379071\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.334328; batch adversarial loss: 0.378553\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.385759; batch adversarial loss: 0.476068\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.455505; batch adversarial loss: 0.365512\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.414645; batch adversarial loss: 0.431576\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.429713; batch adversarial loss: 0.324861\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.423362; batch adversarial loss: 0.446400\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.370856; batch adversarial loss: 0.420771\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.451185; batch adversarial loss: 0.445903\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.435517; batch adversarial loss: 0.351617\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416783; batch adversarial loss: 0.445974\n",
      "epoch 37; iter: 200; batch classifier loss: 0.403795; batch adversarial loss: 0.447859\n",
      "epoch 37; iter: 400; batch classifier loss: 0.366870; batch adversarial loss: 0.407849\n",
      "epoch 37; iter: 600; batch classifier loss: 0.377727; batch adversarial loss: 0.490525\n",
      "epoch 37; iter: 800; batch classifier loss: 0.433983; batch adversarial loss: 0.431943\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.467521; batch adversarial loss: 0.367000\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.432474; batch adversarial loss: 0.514707\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.457221; batch adversarial loss: 0.502784\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.415726; batch adversarial loss: 0.408894\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.436347; batch adversarial loss: 0.337541\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.494004; batch adversarial loss: 0.501826\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.415714; batch adversarial loss: 0.380868\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.389647; batch adversarial loss: 0.420555\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.391721; batch adversarial loss: 0.448085\n",
      "epoch 38; iter: 0; batch classifier loss: 0.411259; batch adversarial loss: 0.421301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38; iter: 200; batch classifier loss: 0.350558; batch adversarial loss: 0.402608\n",
      "epoch 38; iter: 400; batch classifier loss: 0.465587; batch adversarial loss: 0.351858\n",
      "epoch 38; iter: 600; batch classifier loss: 0.412042; batch adversarial loss: 0.437454\n",
      "epoch 38; iter: 800; batch classifier loss: 0.397341; batch adversarial loss: 0.404804\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.496365; batch adversarial loss: 0.421359\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.369209; batch adversarial loss: 0.420531\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.477926; batch adversarial loss: 0.405190\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.385151; batch adversarial loss: 0.403845\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.342334; batch adversarial loss: 0.366135\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.423973; batch adversarial loss: 0.517649\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.383352; batch adversarial loss: 0.391104\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.463510; batch adversarial loss: 0.432875\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.391951; batch adversarial loss: 0.458727\n",
      "epoch 39; iter: 0; batch classifier loss: 0.485130; batch adversarial loss: 0.433416\n",
      "epoch 39; iter: 200; batch classifier loss: 0.405676; batch adversarial loss: 0.448075\n",
      "epoch 39; iter: 400; batch classifier loss: 0.526958; batch adversarial loss: 0.338673\n",
      "epoch 39; iter: 600; batch classifier loss: 0.381466; batch adversarial loss: 0.459249\n",
      "epoch 39; iter: 800; batch classifier loss: 0.374881; batch adversarial loss: 0.392921\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.543133; batch adversarial loss: 0.362418\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.343303; batch adversarial loss: 0.526954\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.351458; batch adversarial loss: 0.449116\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.366301; batch adversarial loss: 0.348763\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.391317; batch adversarial loss: 0.476101\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.429870; batch adversarial loss: 0.459427\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.471520; batch adversarial loss: 0.418735\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.336897; batch adversarial loss: 0.487540\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.460608; batch adversarial loss: 0.376783\n",
      "epoch 40; iter: 0; batch classifier loss: 0.471501; batch adversarial loss: 0.432090\n",
      "epoch 40; iter: 200; batch classifier loss: 0.390054; batch adversarial loss: 0.448071\n",
      "epoch 40; iter: 400; batch classifier loss: 0.440617; batch adversarial loss: 0.418428\n",
      "epoch 40; iter: 600; batch classifier loss: 0.356674; batch adversarial loss: 0.395842\n",
      "epoch 40; iter: 800; batch classifier loss: 0.469893; batch adversarial loss: 0.366169\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.548303; batch adversarial loss: 0.418993\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.415593; batch adversarial loss: 0.485436\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.462934; batch adversarial loss: 0.516890\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.388428; batch adversarial loss: 0.408428\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.411607; batch adversarial loss: 0.435203\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.404328; batch adversarial loss: 0.392722\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.464207; batch adversarial loss: 0.404121\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.367277; batch adversarial loss: 0.394255\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.467725; batch adversarial loss: 0.431677\n",
      "epoch 41; iter: 0; batch classifier loss: 0.463700; batch adversarial loss: 0.377992\n",
      "epoch 41; iter: 200; batch classifier loss: 0.430746; batch adversarial loss: 0.391394\n",
      "epoch 41; iter: 400; batch classifier loss: 0.430363; batch adversarial loss: 0.542382\n",
      "epoch 41; iter: 600; batch classifier loss: 0.369589; batch adversarial loss: 0.446958\n",
      "epoch 41; iter: 800; batch classifier loss: 0.440727; batch adversarial loss: 0.365663\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.383773; batch adversarial loss: 0.431499\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.394082; batch adversarial loss: 0.420066\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.360483; batch adversarial loss: 0.463363\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.374601; batch adversarial loss: 0.434277\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.338040; batch adversarial loss: 0.501941\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.465361; batch adversarial loss: 0.503732\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.393978; batch adversarial loss: 0.460015\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.472825; batch adversarial loss: 0.407729\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.418493; batch adversarial loss: 0.421266\n",
      "epoch 42; iter: 0; batch classifier loss: 0.323368; batch adversarial loss: 0.488397\n",
      "epoch 42; iter: 200; batch classifier loss: 0.425528; batch adversarial loss: 0.391077\n",
      "epoch 42; iter: 400; batch classifier loss: 0.421377; batch adversarial loss: 0.337800\n",
      "epoch 42; iter: 600; batch classifier loss: 0.505051; batch adversarial loss: 0.540259\n",
      "epoch 42; iter: 800; batch classifier loss: 0.487150; batch adversarial loss: 0.381239\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.329104; batch adversarial loss: 0.435681\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.424470; batch adversarial loss: 0.434106\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.413440; batch adversarial loss: 0.433182\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.420314; batch adversarial loss: 0.432093\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.405645; batch adversarial loss: 0.365195\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.370941; batch adversarial loss: 0.310466\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.450017; batch adversarial loss: 0.448167\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.424585; batch adversarial loss: 0.391112\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.450199; batch adversarial loss: 0.365425\n",
      "epoch 43; iter: 0; batch classifier loss: 0.438446; batch adversarial loss: 0.515827\n",
      "epoch 43; iter: 200; batch classifier loss: 0.427278; batch adversarial loss: 0.473638\n",
      "epoch 43; iter: 400; batch classifier loss: 0.400640; batch adversarial loss: 0.446793\n",
      "epoch 43; iter: 600; batch classifier loss: 0.383918; batch adversarial loss: 0.516534\n",
      "epoch 43; iter: 800; batch classifier loss: 0.480287; batch adversarial loss: 0.419401\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.363997; batch adversarial loss: 0.476920\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.424204; batch adversarial loss: 0.447425\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.439700; batch adversarial loss: 0.365523\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.385049; batch adversarial loss: 0.405874\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.356858; batch adversarial loss: 0.517080\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.448806; batch adversarial loss: 0.433386\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.432283; batch adversarial loss: 0.501470\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.447447; batch adversarial loss: 0.352777\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.471404; batch adversarial loss: 0.460633\n",
      "epoch 44; iter: 0; batch classifier loss: 0.433567; batch adversarial loss: 0.476162\n",
      "epoch 44; iter: 200; batch classifier loss: 0.407233; batch adversarial loss: 0.352232\n",
      "epoch 44; iter: 400; batch classifier loss: 0.395627; batch adversarial loss: 0.363239\n",
      "epoch 44; iter: 600; batch classifier loss: 0.422300; batch adversarial loss: 0.351885\n",
      "epoch 44; iter: 800; batch classifier loss: 0.472582; batch adversarial loss: 0.404370\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.379422; batch adversarial loss: 0.378375\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.469897; batch adversarial loss: 0.406674\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.431849; batch adversarial loss: 0.444867\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.461065; batch adversarial loss: 0.406342\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.332805; batch adversarial loss: 0.433765\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.381230; batch adversarial loss: 0.336941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44; iter: 2200; batch classifier loss: 0.474710; batch adversarial loss: 0.552779\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.371002; batch adversarial loss: 0.487127\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.551767; batch adversarial loss: 0.338170\n",
      "epoch 45; iter: 0; batch classifier loss: 0.476778; batch adversarial loss: 0.446490\n",
      "epoch 45; iter: 200; batch classifier loss: 0.429821; batch adversarial loss: 0.433049\n",
      "epoch 45; iter: 400; batch classifier loss: 0.441420; batch adversarial loss: 0.446791\n",
      "epoch 45; iter: 600; batch classifier loss: 0.392867; batch adversarial loss: 0.419080\n",
      "epoch 45; iter: 800; batch classifier loss: 0.434854; batch adversarial loss: 0.528800\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.345761; batch adversarial loss: 0.405515\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.412537; batch adversarial loss: 0.433391\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.359503; batch adversarial loss: 0.420939\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.405239; batch adversarial loss: 0.364753\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.483276; batch adversarial loss: 0.391999\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.353463; batch adversarial loss: 0.392525\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.422762; batch adversarial loss: 0.459023\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.390941; batch adversarial loss: 0.432242\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.443529; batch adversarial loss: 0.391169\n",
      "epoch 46; iter: 0; batch classifier loss: 0.377200; batch adversarial loss: 0.409705\n",
      "epoch 46; iter: 200; batch classifier loss: 0.358605; batch adversarial loss: 0.387740\n",
      "epoch 46; iter: 400; batch classifier loss: 0.442332; batch adversarial loss: 0.487661\n",
      "epoch 46; iter: 600; batch classifier loss: 0.405919; batch adversarial loss: 0.394816\n",
      "epoch 46; iter: 800; batch classifier loss: 0.412717; batch adversarial loss: 0.393509\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.509860; batch adversarial loss: 0.296700\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.449035; batch adversarial loss: 0.352413\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.365700; batch adversarial loss: 0.448259\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.344292; batch adversarial loss: 0.393374\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.414836; batch adversarial loss: 0.379769\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.593663; batch adversarial loss: 0.408693\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.379404; batch adversarial loss: 0.379388\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.413754; batch adversarial loss: 0.406960\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.344608; batch adversarial loss: 0.487568\n",
      "epoch 47; iter: 0; batch classifier loss: 0.417517; batch adversarial loss: 0.375680\n",
      "epoch 47; iter: 200; batch classifier loss: 0.374766; batch adversarial loss: 0.487751\n",
      "epoch 47; iter: 400; batch classifier loss: 0.425331; batch adversarial loss: 0.462748\n",
      "epoch 47; iter: 600; batch classifier loss: 0.489051; batch adversarial loss: 0.475365\n",
      "epoch 47; iter: 800; batch classifier loss: 0.305119; batch adversarial loss: 0.379071\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.406633; batch adversarial loss: 0.394124\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.509427; batch adversarial loss: 0.421407\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.421965; batch adversarial loss: 0.418831\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.390393; batch adversarial loss: 0.363070\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.401824; batch adversarial loss: 0.405111\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.459376; batch adversarial loss: 0.432535\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.427621; batch adversarial loss: 0.405684\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.376382; batch adversarial loss: 0.311558\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.362218; batch adversarial loss: 0.310340\n",
      "epoch 48; iter: 0; batch classifier loss: 0.452216; batch adversarial loss: 0.364887\n",
      "epoch 48; iter: 200; batch classifier loss: 0.413999; batch adversarial loss: 0.366913\n",
      "epoch 48; iter: 400; batch classifier loss: 0.420510; batch adversarial loss: 0.473004\n",
      "epoch 48; iter: 600; batch classifier loss: 0.361553; batch adversarial loss: 0.339156\n",
      "epoch 48; iter: 800; batch classifier loss: 0.497196; batch adversarial loss: 0.419545\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.331720; batch adversarial loss: 0.362590\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.408823; batch adversarial loss: 0.419557\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.434813; batch adversarial loss: 0.367378\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.376144; batch adversarial loss: 0.381145\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.346248; batch adversarial loss: 0.433947\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.398104; batch adversarial loss: 0.394430\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.450463; batch adversarial loss: 0.352391\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.407941; batch adversarial loss: 0.422629\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.448308; batch adversarial loss: 0.351835\n",
      "epoch 49; iter: 0; batch classifier loss: 0.422385; batch adversarial loss: 0.338442\n",
      "epoch 49; iter: 200; batch classifier loss: 0.411568; batch adversarial loss: 0.420818\n",
      "epoch 49; iter: 400; batch classifier loss: 0.369727; batch adversarial loss: 0.364825\n",
      "epoch 49; iter: 600; batch classifier loss: 0.447979; batch adversarial loss: 0.338137\n",
      "epoch 49; iter: 800; batch classifier loss: 0.345831; batch adversarial loss: 0.446384\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.598131; batch adversarial loss: 0.408885\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.357034; batch adversarial loss: 0.434552\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.427724; batch adversarial loss: 0.587508\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.379026; batch adversarial loss: 0.378213\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.478938; batch adversarial loss: 0.379316\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.481408; batch adversarial loss: 0.311178\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.372900; batch adversarial loss: 0.352423\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.401136; batch adversarial loss: 0.380403\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.368975; batch adversarial loss: 0.446476\n",
      "epoch 0; iter: 0; batch classifier loss: 0.614588\n",
      "epoch 0; iter: 200; batch classifier loss: 0.398909\n",
      "epoch 0; iter: 400; batch classifier loss: 0.420881\n",
      "epoch 0; iter: 600; batch classifier loss: 0.471226\n",
      "epoch 0; iter: 800; batch classifier loss: 0.427585\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.430940\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.447490\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.518215\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.412502\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.456295\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.372806\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.476803\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.386200\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.392489\n",
      "epoch 1; iter: 0; batch classifier loss: 0.445101\n",
      "epoch 1; iter: 200; batch classifier loss: 0.478846\n",
      "epoch 1; iter: 400; batch classifier loss: 0.380473\n",
      "epoch 1; iter: 600; batch classifier loss: 0.361083\n",
      "epoch 1; iter: 800; batch classifier loss: 0.405888\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.392392\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.478424\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.436852\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.356294\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.364244\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.410020\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.353925\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.353760\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.361959\n",
      "epoch 2; iter: 0; batch classifier loss: 0.378337\n",
      "epoch 2; iter: 200; batch classifier loss: 0.387200\n",
      "epoch 2; iter: 400; batch classifier loss: 0.352292\n",
      "epoch 2; iter: 600; batch classifier loss: 0.474009\n",
      "epoch 2; iter: 800; batch classifier loss: 0.386983\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.505686\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.438275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 1400; batch classifier loss: 0.492402\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.309218\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.416336\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.452993\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.446558\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.408199\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.431428\n",
      "epoch 3; iter: 0; batch classifier loss: 0.410314\n",
      "epoch 3; iter: 200; batch classifier loss: 0.376158\n",
      "epoch 3; iter: 400; batch classifier loss: 0.377669\n",
      "epoch 3; iter: 600; batch classifier loss: 0.348737\n",
      "epoch 3; iter: 800; batch classifier loss: 0.364685\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.405400\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.384943\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.437516\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.479647\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.416407\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.362039\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.421430\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.449709\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.372658\n",
      "epoch 4; iter: 0; batch classifier loss: 0.498693\n",
      "epoch 4; iter: 200; batch classifier loss: 0.482151\n",
      "epoch 4; iter: 400; batch classifier loss: 0.427488\n",
      "epoch 4; iter: 600; batch classifier loss: 0.430524\n",
      "epoch 4; iter: 800; batch classifier loss: 0.421452\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.398867\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.477136\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.397883\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.355811\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.401333\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.435672\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.382979\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.524368\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.406335\n",
      "epoch 5; iter: 0; batch classifier loss: 0.438897\n",
      "epoch 5; iter: 200; batch classifier loss: 0.462876\n",
      "epoch 5; iter: 400; batch classifier loss: 0.443729\n",
      "epoch 5; iter: 600; batch classifier loss: 0.379568\n",
      "epoch 5; iter: 800; batch classifier loss: 0.432998\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.417987\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.404781\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.357605\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.427502\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.373104\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.431105\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.404632\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.391593\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.282835\n",
      "epoch 6; iter: 0; batch classifier loss: 0.401415\n",
      "epoch 6; iter: 200; batch classifier loss: 0.443250\n",
      "epoch 6; iter: 400; batch classifier loss: 0.338328\n",
      "epoch 6; iter: 600; batch classifier loss: 0.360113\n",
      "epoch 6; iter: 800; batch classifier loss: 0.507559\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.314502\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.516451\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.483953\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.446830\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.389929\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.389079\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.462863\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.384033\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.398326\n",
      "epoch 7; iter: 0; batch classifier loss: 0.447650\n",
      "epoch 7; iter: 200; batch classifier loss: 0.422339\n",
      "epoch 7; iter: 400; batch classifier loss: 0.391742\n",
      "epoch 7; iter: 600; batch classifier loss: 0.536500\n",
      "epoch 7; iter: 800; batch classifier loss: 0.427590\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.387801\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.410363\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.377401\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.467006\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.343761\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.462108\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.418038\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.375554\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.478508\n",
      "epoch 8; iter: 0; batch classifier loss: 0.435350\n",
      "epoch 8; iter: 200; batch classifier loss: 0.370052\n",
      "epoch 8; iter: 400; batch classifier loss: 0.358701\n",
      "epoch 8; iter: 600; batch classifier loss: 0.434835\n",
      "epoch 8; iter: 800; batch classifier loss: 0.490475\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.342990\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.426230\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.419993\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.373435\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.355017\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.396660\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.410859\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.397452\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.443629\n",
      "epoch 9; iter: 0; batch classifier loss: 0.338796\n",
      "epoch 9; iter: 200; batch classifier loss: 0.380372\n",
      "epoch 9; iter: 400; batch classifier loss: 0.429269\n",
      "epoch 9; iter: 600; batch classifier loss: 0.368381\n",
      "epoch 9; iter: 800; batch classifier loss: 0.378320\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.417807\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.402956\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.477485\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.449004\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.403482\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.457026\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.436139\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.419666\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.311201\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386683\n",
      "epoch 10; iter: 200; batch classifier loss: 0.426764\n",
      "epoch 10; iter: 400; batch classifier loss: 0.432251\n",
      "epoch 10; iter: 600; batch classifier loss: 0.454012\n",
      "epoch 10; iter: 800; batch classifier loss: 0.432692\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.417619\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.460507\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.443547\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.434333\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.374082\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.431649\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.458770\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.425046\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.455119\n",
      "epoch 11; iter: 0; batch classifier loss: 0.444601\n",
      "epoch 11; iter: 200; batch classifier loss: 0.412452\n",
      "epoch 11; iter: 400; batch classifier loss: 0.500964\n",
      "epoch 11; iter: 600; batch classifier loss: 0.548856\n",
      "epoch 11; iter: 800; batch classifier loss: 0.336800\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.400848\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.397272\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.455221\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.358996\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.474875\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.426312\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.464326\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.476751\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.423708\n",
      "epoch 12; iter: 0; batch classifier loss: 0.429385\n",
      "epoch 12; iter: 200; batch classifier loss: 0.486699\n",
      "epoch 12; iter: 400; batch classifier loss: 0.473820\n",
      "epoch 12; iter: 600; batch classifier loss: 0.346814\n",
      "epoch 12; iter: 800; batch classifier loss: 0.439689\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.456174\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.437667\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.445770\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.390861\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.349939\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.363066\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.411277\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.421523\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.375386\n",
      "epoch 13; iter: 0; batch classifier loss: 0.338830\n",
      "epoch 13; iter: 200; batch classifier loss: 0.428625\n",
      "epoch 13; iter: 400; batch classifier loss: 0.446093\n",
      "epoch 13; iter: 600; batch classifier loss: 0.450749\n",
      "epoch 13; iter: 800; batch classifier loss: 0.309014\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.464285\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.438576\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.459047\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.367570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13; iter: 1800; batch classifier loss: 0.429274\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.607891\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.375412\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.428821\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.403239\n",
      "epoch 14; iter: 0; batch classifier loss: 0.394646\n",
      "epoch 14; iter: 200; batch classifier loss: 0.416896\n",
      "epoch 14; iter: 400; batch classifier loss: 0.459591\n",
      "epoch 14; iter: 600; batch classifier loss: 0.441994\n",
      "epoch 14; iter: 800; batch classifier loss: 0.379745\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.441535\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.444268\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.350069\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.393176\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.414144\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.422486\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.355380\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.392090\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.472413\n",
      "epoch 15; iter: 0; batch classifier loss: 0.406744\n",
      "epoch 15; iter: 200; batch classifier loss: 0.467471\n",
      "epoch 15; iter: 400; batch classifier loss: 0.385798\n",
      "epoch 15; iter: 600; batch classifier loss: 0.452619\n",
      "epoch 15; iter: 800; batch classifier loss: 0.417797\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.443204\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.448451\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.462824\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.375079\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.530868\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.414257\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.459945\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.497773\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.382601\n",
      "epoch 16; iter: 0; batch classifier loss: 0.382438\n",
      "epoch 16; iter: 200; batch classifier loss: 0.473213\n",
      "epoch 16; iter: 400; batch classifier loss: 0.411701\n",
      "epoch 16; iter: 600; batch classifier loss: 0.419233\n",
      "epoch 16; iter: 800; batch classifier loss: 0.365904\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.398723\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.452984\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.407499\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.396347\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.392331\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.411256\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.539302\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.447145\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.425313\n",
      "epoch 17; iter: 0; batch classifier loss: 0.390541\n",
      "epoch 17; iter: 200; batch classifier loss: 0.403275\n",
      "epoch 17; iter: 400; batch classifier loss: 0.416632\n",
      "epoch 17; iter: 600; batch classifier loss: 0.417176\n",
      "epoch 17; iter: 800; batch classifier loss: 0.475841\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.396067\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.371533\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.324595\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.470580\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.464720\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.358963\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.442696\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.399320\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.445047\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492412\n",
      "epoch 18; iter: 200; batch classifier loss: 0.398584\n",
      "epoch 18; iter: 400; batch classifier loss: 0.404142\n",
      "epoch 18; iter: 600; batch classifier loss: 0.435485\n",
      "epoch 18; iter: 800; batch classifier loss: 0.380522\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.399247\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.412589\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.402928\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.409276\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.450651\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.420539\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.379522\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.441145\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.411231\n",
      "epoch 19; iter: 0; batch classifier loss: 0.389470\n",
      "epoch 19; iter: 200; batch classifier loss: 0.365110\n",
      "epoch 19; iter: 400; batch classifier loss: 0.414899\n",
      "epoch 19; iter: 600; batch classifier loss: 0.488929\n",
      "epoch 19; iter: 800; batch classifier loss: 0.498108\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.490465\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.401786\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.505558\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.437663\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.428417\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.376040\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.426706\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.430213\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.394890\n",
      "epoch 20; iter: 0; batch classifier loss: 0.378820\n",
      "epoch 20; iter: 200; batch classifier loss: 0.390896\n",
      "epoch 20; iter: 400; batch classifier loss: 0.453135\n",
      "epoch 20; iter: 600; batch classifier loss: 0.511657\n",
      "epoch 20; iter: 800; batch classifier loss: 0.498799\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.427169\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.375664\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.514897\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.356313\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.418013\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.329390\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.424191\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.388312\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.403795\n",
      "epoch 21; iter: 0; batch classifier loss: 0.353517\n",
      "epoch 21; iter: 200; batch classifier loss: 0.355339\n",
      "epoch 21; iter: 400; batch classifier loss: 0.391218\n",
      "epoch 21; iter: 600; batch classifier loss: 0.481177\n",
      "epoch 21; iter: 800; batch classifier loss: 0.363075\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.472861\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.322246\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.439752\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.426760\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.396481\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.461036\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.404988\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.437403\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.409086\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462029\n",
      "epoch 22; iter: 200; batch classifier loss: 0.413030\n",
      "epoch 22; iter: 400; batch classifier loss: 0.465172\n",
      "epoch 22; iter: 600; batch classifier loss: 0.432356\n",
      "epoch 22; iter: 800; batch classifier loss: 0.460680\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.362725\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.434171\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.407532\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.398213\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.387371\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.372626\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.457581\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.500521\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.463350\n",
      "epoch 23; iter: 0; batch classifier loss: 0.374314\n",
      "epoch 23; iter: 200; batch classifier loss: 0.319151\n",
      "epoch 23; iter: 400; batch classifier loss: 0.355598\n",
      "epoch 23; iter: 600; batch classifier loss: 0.403914\n",
      "epoch 23; iter: 800; batch classifier loss: 0.454963\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.448046\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.407552\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.398262\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.435935\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.415755\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.472262\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.389398\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.478276\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.400161\n",
      "epoch 24; iter: 0; batch classifier loss: 0.425290\n",
      "epoch 24; iter: 200; batch classifier loss: 0.421625\n",
      "epoch 24; iter: 400; batch classifier loss: 0.401565\n",
      "epoch 24; iter: 600; batch classifier loss: 0.432880\n",
      "epoch 24; iter: 800; batch classifier loss: 0.376250\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.423091\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.410996\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.422080\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.446406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24; iter: 1800; batch classifier loss: 0.472353\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.430761\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.359111\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.466940\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.356454\n",
      "epoch 25; iter: 0; batch classifier loss: 0.391906\n",
      "epoch 25; iter: 200; batch classifier loss: 0.426896\n",
      "epoch 25; iter: 400; batch classifier loss: 0.428181\n",
      "epoch 25; iter: 600; batch classifier loss: 0.399211\n",
      "epoch 25; iter: 800; batch classifier loss: 0.424175\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.408282\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.472413\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.473790\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.468169\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.377631\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.439489\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.413647\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.434614\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.345620\n",
      "epoch 26; iter: 0; batch classifier loss: 0.378248\n",
      "epoch 26; iter: 200; batch classifier loss: 0.487742\n",
      "epoch 26; iter: 400; batch classifier loss: 0.395156\n",
      "epoch 26; iter: 600; batch classifier loss: 0.429188\n",
      "epoch 26; iter: 800; batch classifier loss: 0.501406\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.345007\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.423288\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.397494\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.418594\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.380658\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.494493\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.326995\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.387194\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.492212\n",
      "epoch 27; iter: 0; batch classifier loss: 0.388784\n",
      "epoch 27; iter: 200; batch classifier loss: 0.484076\n",
      "epoch 27; iter: 400; batch classifier loss: 0.368558\n",
      "epoch 27; iter: 600; batch classifier loss: 0.452906\n",
      "epoch 27; iter: 800; batch classifier loss: 0.412969\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.393315\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.492169\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.447550\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.424095\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.404901\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.484205\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.484813\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.424014\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.405863\n",
      "epoch 28; iter: 0; batch classifier loss: 0.407749\n",
      "epoch 28; iter: 200; batch classifier loss: 0.442297\n",
      "epoch 28; iter: 400; batch classifier loss: 0.433978\n",
      "epoch 28; iter: 600; batch classifier loss: 0.413604\n",
      "epoch 28; iter: 800; batch classifier loss: 0.388053\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.473380\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.377188\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.464923\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.413260\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.394248\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.400919\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.398753\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.447515\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.443649\n",
      "epoch 29; iter: 0; batch classifier loss: 0.435059\n",
      "epoch 29; iter: 200; batch classifier loss: 0.443801\n",
      "epoch 29; iter: 400; batch classifier loss: 0.408580\n",
      "epoch 29; iter: 600; batch classifier loss: 0.356160\n",
      "epoch 29; iter: 800; batch classifier loss: 0.320901\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.392958\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.348305\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.440220\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.366504\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.424028\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.513158\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.413658\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.368580\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.376121\n",
      "epoch 30; iter: 0; batch classifier loss: 0.422872\n",
      "epoch 30; iter: 200; batch classifier loss: 0.355200\n",
      "epoch 30; iter: 400; batch classifier loss: 0.420787\n",
      "epoch 30; iter: 600; batch classifier loss: 0.405497\n",
      "epoch 30; iter: 800; batch classifier loss: 0.380225\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.383963\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.371852\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.459640\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.453307\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.385245\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.411116\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.385271\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.311122\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.396276\n",
      "epoch 31; iter: 0; batch classifier loss: 0.395560\n",
      "epoch 31; iter: 200; batch classifier loss: 0.423095\n",
      "epoch 31; iter: 400; batch classifier loss: 0.453117\n",
      "epoch 31; iter: 600; batch classifier loss: 0.462541\n",
      "epoch 31; iter: 800; batch classifier loss: 0.440392\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.508204\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.412021\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.437854\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.393973\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.384895\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.363110\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.408285\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.425424\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.430438\n",
      "epoch 32; iter: 0; batch classifier loss: 0.397317\n",
      "epoch 32; iter: 200; batch classifier loss: 0.439487\n",
      "epoch 32; iter: 400; batch classifier loss: 0.483267\n",
      "epoch 32; iter: 600; batch classifier loss: 0.365004\n",
      "epoch 32; iter: 800; batch classifier loss: 0.374701\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.443847\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.340944\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.389406\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.386283\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.371419\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.408684\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.381558\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.354366\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.557358\n",
      "epoch 33; iter: 0; batch classifier loss: 0.398117\n",
      "epoch 33; iter: 200; batch classifier loss: 0.486831\n",
      "epoch 33; iter: 400; batch classifier loss: 0.317101\n",
      "epoch 33; iter: 600; batch classifier loss: 0.492075\n",
      "epoch 33; iter: 800; batch classifier loss: 0.428324\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.444261\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.434075\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.388251\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.426667\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.400596\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.408014\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.371333\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.412118\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.371145\n",
      "epoch 34; iter: 0; batch classifier loss: 0.394745\n",
      "epoch 34; iter: 200; batch classifier loss: 0.426172\n",
      "epoch 34; iter: 400; batch classifier loss: 0.363722\n",
      "epoch 34; iter: 600; batch classifier loss: 0.438142\n",
      "epoch 34; iter: 800; batch classifier loss: 0.428360\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.517606\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.412478\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.378551\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.434313\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.421335\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.461676\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.436399\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.425642\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.426692\n",
      "epoch 35; iter: 0; batch classifier loss: 0.396830\n",
      "epoch 35; iter: 200; batch classifier loss: 0.395234\n",
      "epoch 35; iter: 400; batch classifier loss: 0.397176\n",
      "epoch 35; iter: 600; batch classifier loss: 0.403156\n",
      "epoch 35; iter: 800; batch classifier loss: 0.358447\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.485636\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.420510\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.434696\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.338186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35; iter: 1800; batch classifier loss: 0.445990\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.349136\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.489238\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.396709\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.438194\n",
      "epoch 36; iter: 0; batch classifier loss: 0.453108\n",
      "epoch 36; iter: 200; batch classifier loss: 0.409392\n",
      "epoch 36; iter: 400; batch classifier loss: 0.489308\n",
      "epoch 36; iter: 600; batch classifier loss: 0.463529\n",
      "epoch 36; iter: 800; batch classifier loss: 0.455744\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.464274\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.446481\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.493858\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.353356\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.447789\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.420711\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.366206\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.369187\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.356890\n",
      "epoch 37; iter: 0; batch classifier loss: 0.348695\n",
      "epoch 37; iter: 200; batch classifier loss: 0.357013\n",
      "epoch 37; iter: 400; batch classifier loss: 0.400223\n",
      "epoch 37; iter: 600; batch classifier loss: 0.361278\n",
      "epoch 37; iter: 800; batch classifier loss: 0.317370\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.365407\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.514319\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.448898\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.438447\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.397694\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.415992\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.449347\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.466977\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.454937\n",
      "epoch 38; iter: 0; batch classifier loss: 0.467275\n",
      "epoch 38; iter: 200; batch classifier loss: 0.490179\n",
      "epoch 38; iter: 400; batch classifier loss: 0.392074\n",
      "epoch 38; iter: 600; batch classifier loss: 0.453440\n",
      "epoch 38; iter: 800; batch classifier loss: 0.440236\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.404858\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.355998\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.352559\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.380425\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.399876\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.299904\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.383312\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.374127\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.467291\n",
      "epoch 39; iter: 0; batch classifier loss: 0.421550\n",
      "epoch 39; iter: 200; batch classifier loss: 0.490659\n",
      "epoch 39; iter: 400; batch classifier loss: 0.430000\n",
      "epoch 39; iter: 600; batch classifier loss: 0.419745\n",
      "epoch 39; iter: 800; batch classifier loss: 0.353701\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.367477\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.381151\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.439317\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.368498\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.357662\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.468454\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.411989\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.355151\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.407439\n",
      "epoch 40; iter: 0; batch classifier loss: 0.344873\n",
      "epoch 40; iter: 200; batch classifier loss: 0.419291\n",
      "epoch 40; iter: 400; batch classifier loss: 0.362537\n",
      "epoch 40; iter: 600; batch classifier loss: 0.450431\n",
      "epoch 40; iter: 800; batch classifier loss: 0.521294\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.399896\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.365926\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.418483\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.376344\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.402367\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.464442\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.452225\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.337747\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.434942\n",
      "epoch 41; iter: 0; batch classifier loss: 0.391487\n",
      "epoch 41; iter: 200; batch classifier loss: 0.428376\n",
      "epoch 41; iter: 400; batch classifier loss: 0.435196\n",
      "epoch 41; iter: 600; batch classifier loss: 0.409854\n",
      "epoch 41; iter: 800; batch classifier loss: 0.370708\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.356255\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.418033\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.414389\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.413423\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.378029\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.370448\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.449031\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.416343\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.328546\n",
      "epoch 42; iter: 0; batch classifier loss: 0.474159\n",
      "epoch 42; iter: 200; batch classifier loss: 0.395393\n",
      "epoch 42; iter: 400; batch classifier loss: 0.411867\n",
      "epoch 42; iter: 600; batch classifier loss: 0.368602\n",
      "epoch 42; iter: 800; batch classifier loss: 0.319200\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.411374\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.408133\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.373140\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.420509\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.383605\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.428305\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.319668\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.465759\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.469260\n",
      "epoch 43; iter: 0; batch classifier loss: 0.368042\n",
      "epoch 43; iter: 200; batch classifier loss: 0.446381\n",
      "epoch 43; iter: 400; batch classifier loss: 0.417738\n",
      "epoch 43; iter: 600; batch classifier loss: 0.466686\n",
      "epoch 43; iter: 800; batch classifier loss: 0.416010\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.421016\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.412064\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.430608\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.380142\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.448881\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.440050\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.417367\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.505559\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.482097\n",
      "epoch 44; iter: 0; batch classifier loss: 0.344922\n",
      "epoch 44; iter: 200; batch classifier loss: 0.399551\n",
      "epoch 44; iter: 400; batch classifier loss: 0.373467\n",
      "epoch 44; iter: 600; batch classifier loss: 0.421271\n",
      "epoch 44; iter: 800; batch classifier loss: 0.404880\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.391555\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.471611\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.437779\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.339389\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.485921\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.427855\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.413708\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.370899\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.451653\n",
      "epoch 45; iter: 0; batch classifier loss: 0.339254\n",
      "epoch 45; iter: 200; batch classifier loss: 0.369649\n",
      "epoch 45; iter: 400; batch classifier loss: 0.395347\n",
      "epoch 45; iter: 600; batch classifier loss: 0.470714\n",
      "epoch 45; iter: 800; batch classifier loss: 0.483153\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.345532\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.437949\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.388755\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.328743\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.415909\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.372305\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.329094\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.503978\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.358415\n",
      "epoch 46; iter: 0; batch classifier loss: 0.325543\n",
      "epoch 46; iter: 200; batch classifier loss: 0.453350\n",
      "epoch 46; iter: 400; batch classifier loss: 0.450038\n",
      "epoch 46; iter: 600; batch classifier loss: 0.407157\n",
      "epoch 46; iter: 800; batch classifier loss: 0.453634\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.409748\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.472283\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.356421\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.485204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46; iter: 1800; batch classifier loss: 0.445108\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.481528\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.422215\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.418015\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.458405\n",
      "epoch 47; iter: 0; batch classifier loss: 0.455670\n",
      "epoch 47; iter: 200; batch classifier loss: 0.403755\n",
      "epoch 47; iter: 400; batch classifier loss: 0.398719\n",
      "epoch 47; iter: 600; batch classifier loss: 0.386718\n",
      "epoch 47; iter: 800; batch classifier loss: 0.440512\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.481888\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.422451\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.442914\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.393256\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.407729\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.494360\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.437876\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.415558\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.347726\n",
      "epoch 48; iter: 0; batch classifier loss: 0.437705\n",
      "epoch 48; iter: 200; batch classifier loss: 0.457172\n",
      "epoch 48; iter: 400; batch classifier loss: 0.353460\n",
      "epoch 48; iter: 600; batch classifier loss: 0.436602\n",
      "epoch 48; iter: 800; batch classifier loss: 0.430407\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.357837\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.393732\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.339770\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.396183\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.443880\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.467854\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.425317\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.409649\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.408464\n",
      "epoch 49; iter: 0; batch classifier loss: 0.412645\n",
      "epoch 49; iter: 200; batch classifier loss: 0.470157\n",
      "epoch 49; iter: 400; batch classifier loss: 0.423657\n",
      "epoch 49; iter: 600; batch classifier loss: 0.371071\n",
      "epoch 49; iter: 800; batch classifier loss: 0.401369\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.331588\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.406579\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.417205\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.362297\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.374557\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.383713\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.360326\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.507620\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.461081\n",
      "epoch 0; iter: 0; batch classifier loss: 0.664373; batch adversarial loss: 0.712247\n",
      "epoch 0; iter: 200; batch classifier loss: 0.430645; batch adversarial loss: 0.617577\n",
      "epoch 1; iter: 0; batch classifier loss: 0.404944; batch adversarial loss: 0.587674\n",
      "epoch 1; iter: 200; batch classifier loss: 0.361508; batch adversarial loss: 0.560401\n",
      "epoch 2; iter: 0; batch classifier loss: 0.522235; batch adversarial loss: 0.536785\n",
      "epoch 2; iter: 200; batch classifier loss: 0.398191; batch adversarial loss: 0.531787\n",
      "epoch 3; iter: 0; batch classifier loss: 0.399915; batch adversarial loss: 0.572487\n",
      "epoch 3; iter: 200; batch classifier loss: 0.537693; batch adversarial loss: 0.473172\n",
      "epoch 4; iter: 0; batch classifier loss: 0.396100; batch adversarial loss: 0.424558\n",
      "epoch 4; iter: 200; batch classifier loss: 0.464770; batch adversarial loss: 0.530937\n",
      "epoch 5; iter: 0; batch classifier loss: 0.708700; batch adversarial loss: 0.525334\n",
      "epoch 5; iter: 200; batch classifier loss: 0.596601; batch adversarial loss: 0.458494\n",
      "epoch 6; iter: 0; batch classifier loss: 0.540942; batch adversarial loss: 0.437638\n",
      "epoch 6; iter: 200; batch classifier loss: 0.512244; batch adversarial loss: 0.449246\n",
      "epoch 7; iter: 0; batch classifier loss: 0.500459; batch adversarial loss: 0.367680\n",
      "epoch 7; iter: 200; batch classifier loss: 0.390625; batch adversarial loss: 0.419210\n",
      "epoch 8; iter: 0; batch classifier loss: 0.413689; batch adversarial loss: 0.335722\n",
      "epoch 8; iter: 200; batch classifier loss: 0.401187; batch adversarial loss: 0.439614\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488870; batch adversarial loss: 0.339925\n",
      "epoch 9; iter: 200; batch classifier loss: 0.436195; batch adversarial loss: 0.389211\n",
      "epoch 10; iter: 0; batch classifier loss: 0.371065; batch adversarial loss: 0.429220\n",
      "epoch 10; iter: 200; batch classifier loss: 0.413442; batch adversarial loss: 0.391125\n",
      "epoch 11; iter: 0; batch classifier loss: 0.389404; batch adversarial loss: 0.450972\n",
      "epoch 11; iter: 200; batch classifier loss: 0.449015; batch adversarial loss: 0.493883\n",
      "epoch 12; iter: 0; batch classifier loss: 0.424085; batch adversarial loss: 0.483644\n",
      "epoch 12; iter: 200; batch classifier loss: 0.391526; batch adversarial loss: 0.434464\n",
      "epoch 13; iter: 0; batch classifier loss: 0.445630; batch adversarial loss: 0.462345\n",
      "epoch 13; iter: 200; batch classifier loss: 0.570781; batch adversarial loss: 0.383969\n",
      "epoch 14; iter: 0; batch classifier loss: 0.379209; batch adversarial loss: 0.453245\n",
      "epoch 14; iter: 200; batch classifier loss: 0.388771; batch adversarial loss: 0.401421\n",
      "epoch 15; iter: 0; batch classifier loss: 0.532292; batch adversarial loss: 0.302301\n",
      "epoch 15; iter: 200; batch classifier loss: 0.430129; batch adversarial loss: 0.382653\n",
      "epoch 16; iter: 0; batch classifier loss: 0.374245; batch adversarial loss: 0.471827\n",
      "epoch 16; iter: 200; batch classifier loss: 0.474466; batch adversarial loss: 0.435395\n",
      "epoch 17; iter: 0; batch classifier loss: 0.410740; batch adversarial loss: 0.451326\n",
      "epoch 17; iter: 200; batch classifier loss: 0.518400; batch adversarial loss: 0.447364\n",
      "epoch 18; iter: 0; batch classifier loss: 0.403941; batch adversarial loss: 0.396555\n",
      "epoch 18; iter: 200; batch classifier loss: 0.532868; batch adversarial loss: 0.423134\n",
      "epoch 19; iter: 0; batch classifier loss: 0.396663; batch adversarial loss: 0.449381\n",
      "epoch 19; iter: 200; batch classifier loss: 0.399207; batch adversarial loss: 0.412876\n",
      "epoch 20; iter: 0; batch classifier loss: 0.407559; batch adversarial loss: 0.438304\n",
      "epoch 20; iter: 200; batch classifier loss: 0.379220; batch adversarial loss: 0.379058\n",
      "epoch 21; iter: 0; batch classifier loss: 0.450268; batch adversarial loss: 0.366774\n",
      "epoch 21; iter: 200; batch classifier loss: 0.484781; batch adversarial loss: 0.431755\n",
      "epoch 22; iter: 0; batch classifier loss: 0.334618; batch adversarial loss: 0.383805\n",
      "epoch 22; iter: 200; batch classifier loss: 0.472209; batch adversarial loss: 0.344456\n",
      "epoch 23; iter: 0; batch classifier loss: 0.456841; batch adversarial loss: 0.355019\n",
      "epoch 23; iter: 200; batch classifier loss: 0.428494; batch adversarial loss: 0.439065\n",
      "epoch 24; iter: 0; batch classifier loss: 0.362042; batch adversarial loss: 0.474116\n",
      "epoch 24; iter: 200; batch classifier loss: 0.451386; batch adversarial loss: 0.364843\n",
      "epoch 25; iter: 0; batch classifier loss: 0.375799; batch adversarial loss: 0.376963\n",
      "epoch 25; iter: 200; batch classifier loss: 0.398498; batch adversarial loss: 0.469105\n",
      "epoch 26; iter: 0; batch classifier loss: 0.448898; batch adversarial loss: 0.430742\n",
      "epoch 26; iter: 200; batch classifier loss: 0.368552; batch adversarial loss: 0.459623\n",
      "epoch 27; iter: 0; batch classifier loss: 0.399522; batch adversarial loss: 0.402084\n",
      "epoch 27; iter: 200; batch classifier loss: 0.427592; batch adversarial loss: 0.403242\n",
      "epoch 28; iter: 0; batch classifier loss: 0.450612; batch adversarial loss: 0.535777\n",
      "epoch 28; iter: 200; batch classifier loss: 0.429633; batch adversarial loss: 0.409159\n",
      "epoch 29; iter: 0; batch classifier loss: 0.386993; batch adversarial loss: 0.415270\n",
      "epoch 29; iter: 200; batch classifier loss: 0.531948; batch adversarial loss: 0.431483\n",
      "epoch 30; iter: 0; batch classifier loss: 0.406057; batch adversarial loss: 0.479073\n",
      "epoch 30; iter: 200; batch classifier loss: 0.423127; batch adversarial loss: 0.364207\n",
      "epoch 31; iter: 0; batch classifier loss: 0.353803; batch adversarial loss: 0.471696\n",
      "epoch 31; iter: 200; batch classifier loss: 0.474184; batch adversarial loss: 0.408596\n",
      "epoch 32; iter: 0; batch classifier loss: 0.463869; batch adversarial loss: 0.344321\n",
      "epoch 32; iter: 200; batch classifier loss: 0.466821; batch adversarial loss: 0.542587\n",
      "epoch 33; iter: 0; batch classifier loss: 0.413868; batch adversarial loss: 0.381874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 200; batch classifier loss: 0.399049; batch adversarial loss: 0.324759\n",
      "epoch 34; iter: 0; batch classifier loss: 0.483356; batch adversarial loss: 0.517368\n",
      "epoch 34; iter: 200; batch classifier loss: 0.442176; batch adversarial loss: 0.383642\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435638; batch adversarial loss: 0.405841\n",
      "epoch 35; iter: 200; batch classifier loss: 0.386564; batch adversarial loss: 0.382127\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441633; batch adversarial loss: 0.369330\n",
      "epoch 36; iter: 200; batch classifier loss: 0.453907; batch adversarial loss: 0.336018\n",
      "epoch 37; iter: 0; batch classifier loss: 0.423439; batch adversarial loss: 0.407023\n",
      "epoch 37; iter: 200; batch classifier loss: 0.372874; batch adversarial loss: 0.425892\n",
      "epoch 38; iter: 0; batch classifier loss: 0.448308; batch adversarial loss: 0.327597\n",
      "epoch 38; iter: 200; batch classifier loss: 0.449466; batch adversarial loss: 0.379033\n",
      "epoch 39; iter: 0; batch classifier loss: 0.383861; batch adversarial loss: 0.424759\n",
      "epoch 39; iter: 200; batch classifier loss: 0.403425; batch adversarial loss: 0.316429\n",
      "epoch 40; iter: 0; batch classifier loss: 0.444386; batch adversarial loss: 0.414489\n",
      "epoch 40; iter: 200; batch classifier loss: 0.493147; batch adversarial loss: 0.457965\n",
      "epoch 41; iter: 0; batch classifier loss: 0.465444; batch adversarial loss: 0.421043\n",
      "epoch 41; iter: 200; batch classifier loss: 0.384344; batch adversarial loss: 0.394735\n",
      "epoch 42; iter: 0; batch classifier loss: 0.473444; batch adversarial loss: 0.416092\n",
      "epoch 42; iter: 200; batch classifier loss: 0.393463; batch adversarial loss: 0.421523\n",
      "epoch 43; iter: 0; batch classifier loss: 0.391004; batch adversarial loss: 0.429720\n",
      "epoch 43; iter: 200; batch classifier loss: 0.492756; batch adversarial loss: 0.418848\n",
      "epoch 44; iter: 0; batch classifier loss: 0.463135; batch adversarial loss: 0.389325\n",
      "epoch 44; iter: 200; batch classifier loss: 0.404841; batch adversarial loss: 0.369873\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424551; batch adversarial loss: 0.357746\n",
      "epoch 45; iter: 200; batch classifier loss: 0.390379; batch adversarial loss: 0.391720\n",
      "epoch 46; iter: 0; batch classifier loss: 0.393252; batch adversarial loss: 0.424428\n",
      "epoch 46; iter: 200; batch classifier loss: 0.332618; batch adversarial loss: 0.355360\n",
      "epoch 47; iter: 0; batch classifier loss: 0.437763; batch adversarial loss: 0.413549\n",
      "epoch 47; iter: 200; batch classifier loss: 0.475397; batch adversarial loss: 0.423180\n",
      "epoch 48; iter: 0; batch classifier loss: 0.394510; batch adversarial loss: 0.371762\n",
      "epoch 48; iter: 200; batch classifier loss: 0.479715; batch adversarial loss: 0.425064\n",
      "epoch 49; iter: 0; batch classifier loss: 0.388103; batch adversarial loss: 0.476378\n",
      "epoch 49; iter: 200; batch classifier loss: 0.355803; batch adversarial loss: 0.357873\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691921\n",
      "epoch 0; iter: 200; batch classifier loss: 0.327345\n",
      "epoch 1; iter: 0; batch classifier loss: 0.387332\n",
      "epoch 1; iter: 200; batch classifier loss: 0.441686\n",
      "epoch 2; iter: 0; batch classifier loss: 0.412765\n",
      "epoch 2; iter: 200; batch classifier loss: 0.375063\n",
      "epoch 3; iter: 0; batch classifier loss: 0.434224\n",
      "epoch 3; iter: 200; batch classifier loss: 0.456777\n",
      "epoch 4; iter: 0; batch classifier loss: 0.496379\n",
      "epoch 4; iter: 200; batch classifier loss: 0.436961\n",
      "epoch 5; iter: 0; batch classifier loss: 0.446859\n",
      "epoch 5; iter: 200; batch classifier loss: 0.333544\n",
      "epoch 6; iter: 0; batch classifier loss: 0.514577\n",
      "epoch 6; iter: 200; batch classifier loss: 0.417072\n",
      "epoch 7; iter: 0; batch classifier loss: 0.401724\n",
      "epoch 7; iter: 200; batch classifier loss: 0.427391\n",
      "epoch 8; iter: 0; batch classifier loss: 0.397638\n",
      "epoch 8; iter: 200; batch classifier loss: 0.476658\n",
      "epoch 9; iter: 0; batch classifier loss: 0.356143\n",
      "epoch 9; iter: 200; batch classifier loss: 0.326629\n",
      "epoch 10; iter: 0; batch classifier loss: 0.365891\n",
      "epoch 10; iter: 200; batch classifier loss: 0.457833\n",
      "epoch 11; iter: 0; batch classifier loss: 0.491906\n",
      "epoch 11; iter: 200; batch classifier loss: 0.386361\n",
      "epoch 12; iter: 0; batch classifier loss: 0.423139\n",
      "epoch 12; iter: 200; batch classifier loss: 0.415769\n",
      "epoch 13; iter: 0; batch classifier loss: 0.412208\n",
      "epoch 13; iter: 200; batch classifier loss: 0.396328\n",
      "epoch 14; iter: 0; batch classifier loss: 0.430785\n",
      "epoch 14; iter: 200; batch classifier loss: 0.441058\n",
      "epoch 15; iter: 0; batch classifier loss: 0.400837\n",
      "epoch 15; iter: 200; batch classifier loss: 0.452657\n",
      "epoch 16; iter: 0; batch classifier loss: 0.425238\n",
      "epoch 16; iter: 200; batch classifier loss: 0.494465\n",
      "epoch 17; iter: 0; batch classifier loss: 0.371449\n",
      "epoch 17; iter: 200; batch classifier loss: 0.393655\n",
      "epoch 18; iter: 0; batch classifier loss: 0.433383\n",
      "epoch 18; iter: 200; batch classifier loss: 0.528851\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509027\n",
      "epoch 19; iter: 200; batch classifier loss: 0.381684\n",
      "epoch 20; iter: 0; batch classifier loss: 0.344107\n",
      "epoch 20; iter: 200; batch classifier loss: 0.461531\n",
      "epoch 21; iter: 0; batch classifier loss: 0.392688\n",
      "epoch 21; iter: 200; batch classifier loss: 0.385751\n",
      "epoch 22; iter: 0; batch classifier loss: 0.413905\n",
      "epoch 22; iter: 200; batch classifier loss: 0.436911\n",
      "epoch 23; iter: 0; batch classifier loss: 0.354918\n",
      "epoch 23; iter: 200; batch classifier loss: 0.372016\n",
      "epoch 24; iter: 0; batch classifier loss: 0.524956\n",
      "epoch 24; iter: 200; batch classifier loss: 0.353644\n",
      "epoch 25; iter: 0; batch classifier loss: 0.490733\n",
      "epoch 25; iter: 200; batch classifier loss: 0.406037\n",
      "epoch 26; iter: 0; batch classifier loss: 0.457882\n",
      "epoch 26; iter: 200; batch classifier loss: 0.430354\n",
      "epoch 27; iter: 0; batch classifier loss: 0.389963\n",
      "epoch 27; iter: 200; batch classifier loss: 0.436841\n",
      "epoch 28; iter: 0; batch classifier loss: 0.386603\n",
      "epoch 28; iter: 200; batch classifier loss: 0.391393\n",
      "epoch 29; iter: 0; batch classifier loss: 0.399620\n",
      "epoch 29; iter: 200; batch classifier loss: 0.408753\n",
      "epoch 30; iter: 0; batch classifier loss: 0.419816\n",
      "epoch 30; iter: 200; batch classifier loss: 0.328745\n",
      "epoch 31; iter: 0; batch classifier loss: 0.373653\n",
      "epoch 31; iter: 200; batch classifier loss: 0.383985\n",
      "epoch 32; iter: 0; batch classifier loss: 0.381469\n",
      "epoch 32; iter: 200; batch classifier loss: 0.349165\n",
      "epoch 33; iter: 0; batch classifier loss: 0.404293\n",
      "epoch 33; iter: 200; batch classifier loss: 0.551434\n",
      "epoch 34; iter: 0; batch classifier loss: 0.459425\n",
      "epoch 34; iter: 200; batch classifier loss: 0.456974\n",
      "epoch 35; iter: 0; batch classifier loss: 0.464953\n",
      "epoch 35; iter: 200; batch classifier loss: 0.424818\n",
      "epoch 36; iter: 0; batch classifier loss: 0.403338\n",
      "epoch 36; iter: 200; batch classifier loss: 0.433244\n",
      "epoch 37; iter: 0; batch classifier loss: 0.355217\n",
      "epoch 37; iter: 200; batch classifier loss: 0.473321\n",
      "epoch 38; iter: 0; batch classifier loss: 0.355936\n",
      "epoch 38; iter: 200; batch classifier loss: 0.407497\n",
      "epoch 39; iter: 0; batch classifier loss: 0.472717\n",
      "epoch 39; iter: 200; batch classifier loss: 0.457056\n",
      "epoch 40; iter: 0; batch classifier loss: 0.352334\n",
      "epoch 40; iter: 200; batch classifier loss: 0.425181\n",
      "epoch 41; iter: 0; batch classifier loss: 0.495495\n",
      "epoch 41; iter: 200; batch classifier loss: 0.468025\n",
      "epoch 42; iter: 0; batch classifier loss: 0.410693\n",
      "epoch 42; iter: 200; batch classifier loss: 0.338216\n",
      "epoch 43; iter: 0; batch classifier loss: 0.406775\n",
      "epoch 43; iter: 200; batch classifier loss: 0.448437\n",
      "epoch 44; iter: 0; batch classifier loss: 0.443142\n",
      "epoch 44; iter: 200; batch classifier loss: 0.416152\n",
      "epoch 45; iter: 0; batch classifier loss: 0.395994\n",
      "epoch 45; iter: 200; batch classifier loss: 0.487692\n",
      "epoch 46; iter: 0; batch classifier loss: 0.411096\n",
      "epoch 46; iter: 200; batch classifier loss: 0.442517\n",
      "epoch 47; iter: 0; batch classifier loss: 0.353480\n",
      "epoch 47; iter: 200; batch classifier loss: 0.472561\n",
      "epoch 48; iter: 0; batch classifier loss: 0.397847\n",
      "epoch 48; iter: 200; batch classifier loss: 0.480855\n",
      "epoch 49; iter: 0; batch classifier loss: 0.452501\n",
      "epoch 49; iter: 200; batch classifier loss: 0.424859\n",
      "run = 9\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701078; batch adversarial loss: 0.867376\n",
      "epoch 0; iter: 200; batch classifier loss: 0.554912; batch adversarial loss: 0.763529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 400; batch classifier loss: 0.440103; batch adversarial loss: 0.634559\n",
      "epoch 0; iter: 600; batch classifier loss: 0.375069; batch adversarial loss: 0.586496\n",
      "epoch 0; iter: 800; batch classifier loss: 0.420744; batch adversarial loss: 0.505882\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.423464; batch adversarial loss: 0.528645\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.364044; batch adversarial loss: 0.448830\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.533292; batch adversarial loss: 0.449391\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.372837; batch adversarial loss: 0.502327\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.435870; batch adversarial loss: 0.451551\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.437553; batch adversarial loss: 0.399526\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.449005; batch adversarial loss: 0.420064\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.415366; batch adversarial loss: 0.506007\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.398743; batch adversarial loss: 0.440970\n",
      "epoch 1; iter: 0; batch classifier loss: 0.391748; batch adversarial loss: 0.464723\n",
      "epoch 1; iter: 200; batch classifier loss: 0.399561; batch adversarial loss: 0.365534\n",
      "epoch 1; iter: 400; batch classifier loss: 0.419537; batch adversarial loss: 0.397184\n",
      "epoch 1; iter: 600; batch classifier loss: 0.432703; batch adversarial loss: 0.406732\n",
      "epoch 1; iter: 800; batch classifier loss: 0.434168; batch adversarial loss: 0.395511\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.404394; batch adversarial loss: 0.369841\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.351799; batch adversarial loss: 0.438494\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.476660; batch adversarial loss: 0.446683\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.412778; batch adversarial loss: 0.442786\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.472743; batch adversarial loss: 0.407663\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.378519; batch adversarial loss: 0.400499\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.366901; batch adversarial loss: 0.379346\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.460244; batch adversarial loss: 0.362965\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.396268; batch adversarial loss: 0.375640\n",
      "epoch 2; iter: 0; batch classifier loss: 0.447435; batch adversarial loss: 0.381630\n",
      "epoch 2; iter: 200; batch classifier loss: 0.379510; batch adversarial loss: 0.283200\n",
      "epoch 2; iter: 400; batch classifier loss: 0.496219; batch adversarial loss: 0.393736\n",
      "epoch 2; iter: 600; batch classifier loss: 0.402815; batch adversarial loss: 0.395892\n",
      "epoch 2; iter: 800; batch classifier loss: 0.462745; batch adversarial loss: 0.308881\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.361656; batch adversarial loss: 0.407478\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.500150; batch adversarial loss: 0.435696\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.350633; batch adversarial loss: 0.487145\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.459563; batch adversarial loss: 0.397987\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.407488; batch adversarial loss: 0.351666\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.404776; batch adversarial loss: 0.444320\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.490117; batch adversarial loss: 0.404012\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.457787; batch adversarial loss: 0.434948\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.354728; batch adversarial loss: 0.364098\n",
      "epoch 3; iter: 0; batch classifier loss: 0.430247; batch adversarial loss: 0.516453\n",
      "epoch 3; iter: 200; batch classifier loss: 0.363478; batch adversarial loss: 0.406679\n",
      "epoch 3; iter: 400; batch classifier loss: 0.412625; batch adversarial loss: 0.401999\n",
      "epoch 3; iter: 600; batch classifier loss: 0.436397; batch adversarial loss: 0.392110\n",
      "epoch 3; iter: 800; batch classifier loss: 0.410557; batch adversarial loss: 0.385380\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.406344; batch adversarial loss: 0.446962\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.424463; batch adversarial loss: 0.367878\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.446102; batch adversarial loss: 0.396378\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.454332; batch adversarial loss: 0.433596\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.396617; batch adversarial loss: 0.526756\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.377601; batch adversarial loss: 0.366846\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.521091; batch adversarial loss: 0.406069\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.431650; batch adversarial loss: 0.348418\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.391964; batch adversarial loss: 0.445828\n",
      "epoch 4; iter: 0; batch classifier loss: 0.354805; batch adversarial loss: 0.310170\n",
      "epoch 4; iter: 200; batch classifier loss: 0.460318; batch adversarial loss: 0.420992\n",
      "epoch 4; iter: 400; batch classifier loss: 0.444045; batch adversarial loss: 0.418580\n",
      "epoch 4; iter: 600; batch classifier loss: 0.359451; batch adversarial loss: 0.406266\n",
      "epoch 4; iter: 800; batch classifier loss: 0.417531; batch adversarial loss: 0.350669\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.307299; batch adversarial loss: 0.435507\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.383988; batch adversarial loss: 0.368868\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.437022; batch adversarial loss: 0.416683\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.392922; batch adversarial loss: 0.349189\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.461426; batch adversarial loss: 0.379683\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.446946; batch adversarial loss: 0.466801\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.400205; batch adversarial loss: 0.361893\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.363880; batch adversarial loss: 0.539820\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.444901; batch adversarial loss: 0.461785\n",
      "epoch 5; iter: 0; batch classifier loss: 0.357570; batch adversarial loss: 0.473496\n",
      "epoch 5; iter: 200; batch classifier loss: 0.405090; batch adversarial loss: 0.352117\n",
      "epoch 5; iter: 400; batch classifier loss: 0.396357; batch adversarial loss: 0.449907\n",
      "epoch 5; iter: 600; batch classifier loss: 0.430067; batch adversarial loss: 0.460725\n",
      "epoch 5; iter: 800; batch classifier loss: 0.436118; batch adversarial loss: 0.459442\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.448647; batch adversarial loss: 0.511097\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.430977; batch adversarial loss: 0.404204\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.493695; batch adversarial loss: 0.391896\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.437237; batch adversarial loss: 0.378083\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.374994; batch adversarial loss: 0.460221\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.390165; batch adversarial loss: 0.548818\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.494130; batch adversarial loss: 0.477142\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.354252; batch adversarial loss: 0.433230\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.436417; batch adversarial loss: 0.323653\n",
      "epoch 6; iter: 0; batch classifier loss: 0.403930; batch adversarial loss: 0.405147\n",
      "epoch 6; iter: 200; batch classifier loss: 0.424529; batch adversarial loss: 0.337172\n",
      "epoch 6; iter: 400; batch classifier loss: 0.504330; batch adversarial loss: 0.446308\n",
      "epoch 6; iter: 600; batch classifier loss: 0.455162; batch adversarial loss: 0.421898\n",
      "epoch 6; iter: 800; batch classifier loss: 0.348026; batch adversarial loss: 0.393604\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.322324; batch adversarial loss: 0.381682\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.384826; batch adversarial loss: 0.390250\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.379357; batch adversarial loss: 0.385267\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.461547; batch adversarial loss: 0.408123\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.410343; batch adversarial loss: 0.366396\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.441762; batch adversarial loss: 0.432200\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.451564; batch adversarial loss: 0.432447\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.431608; batch adversarial loss: 0.379090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 2600; batch classifier loss: 0.438426; batch adversarial loss: 0.321268\n",
      "epoch 7; iter: 0; batch classifier loss: 0.474523; batch adversarial loss: 0.496817\n",
      "epoch 7; iter: 200; batch classifier loss: 0.401381; batch adversarial loss: 0.457591\n",
      "epoch 7; iter: 400; batch classifier loss: 0.429182; batch adversarial loss: 0.406356\n",
      "epoch 7; iter: 600; batch classifier loss: 0.363985; batch adversarial loss: 0.502327\n",
      "epoch 7; iter: 800; batch classifier loss: 0.420683; batch adversarial loss: 0.377827\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.357094; batch adversarial loss: 0.473088\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.425956; batch adversarial loss: 0.422124\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.428326; batch adversarial loss: 0.392739\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.399566; batch adversarial loss: 0.433811\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.413029; batch adversarial loss: 0.485810\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.396293; batch adversarial loss: 0.388656\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.423631; batch adversarial loss: 0.377083\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.413796; batch adversarial loss: 0.483009\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.465228; batch adversarial loss: 0.379172\n",
      "epoch 8; iter: 0; batch classifier loss: 0.512084; batch adversarial loss: 0.309669\n",
      "epoch 8; iter: 200; batch classifier loss: 0.462755; batch adversarial loss: 0.459306\n",
      "epoch 8; iter: 400; batch classifier loss: 0.495683; batch adversarial loss: 0.431749\n",
      "epoch 8; iter: 600; batch classifier loss: 0.414628; batch adversarial loss: 0.487890\n",
      "epoch 8; iter: 800; batch classifier loss: 0.439373; batch adversarial loss: 0.510232\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.470069; batch adversarial loss: 0.540736\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.388454; batch adversarial loss: 0.378613\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.329356; batch adversarial loss: 0.365902\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.405967; batch adversarial loss: 0.417080\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.395172; batch adversarial loss: 0.396426\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.340801; batch adversarial loss: 0.405376\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.422915; batch adversarial loss: 0.462648\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.380137; batch adversarial loss: 0.326769\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.459099; batch adversarial loss: 0.421108\n",
      "epoch 9; iter: 0; batch classifier loss: 0.425771; batch adversarial loss: 0.459025\n",
      "epoch 9; iter: 200; batch classifier loss: 0.431992; batch adversarial loss: 0.366500\n",
      "epoch 9; iter: 400; batch classifier loss: 0.432762; batch adversarial loss: 0.527821\n",
      "epoch 9; iter: 600; batch classifier loss: 0.432759; batch adversarial loss: 0.392756\n",
      "epoch 9; iter: 800; batch classifier loss: 0.410026; batch adversarial loss: 0.458247\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.432972; batch adversarial loss: 0.446264\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.482737; batch adversarial loss: 0.472677\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.377047; batch adversarial loss: 0.488373\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.452188; batch adversarial loss: 0.366085\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.434660; batch adversarial loss: 0.352379\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.485040; batch adversarial loss: 0.477903\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.460493; batch adversarial loss: 0.392551\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.444978; batch adversarial loss: 0.393679\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.383303; batch adversarial loss: 0.513310\n",
      "epoch 10; iter: 0; batch classifier loss: 0.408355; batch adversarial loss: 0.393349\n",
      "epoch 10; iter: 200; batch classifier loss: 0.364795; batch adversarial loss: 0.449348\n",
      "epoch 10; iter: 400; batch classifier loss: 0.408366; batch adversarial loss: 0.377884\n",
      "epoch 10; iter: 600; batch classifier loss: 0.420389; batch adversarial loss: 0.569063\n",
      "epoch 10; iter: 800; batch classifier loss: 0.392745; batch adversarial loss: 0.436790\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.357314; batch adversarial loss: 0.501855\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.494464; batch adversarial loss: 0.335622\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.435607; batch adversarial loss: 0.351971\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.467420; batch adversarial loss: 0.420985\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.400269; batch adversarial loss: 0.488835\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.474365; batch adversarial loss: 0.406198\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.377213; batch adversarial loss: 0.472755\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.341090; batch adversarial loss: 0.379022\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.399469; batch adversarial loss: 0.432461\n",
      "epoch 11; iter: 0; batch classifier loss: 0.478850; batch adversarial loss: 0.392922\n",
      "epoch 11; iter: 200; batch classifier loss: 0.425828; batch adversarial loss: 0.393314\n",
      "epoch 11; iter: 400; batch classifier loss: 0.408609; batch adversarial loss: 0.474833\n",
      "epoch 11; iter: 600; batch classifier loss: 0.418992; batch adversarial loss: 0.430369\n",
      "epoch 11; iter: 800; batch classifier loss: 0.452848; batch adversarial loss: 0.447825\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.440524; batch adversarial loss: 0.503609\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.435950; batch adversarial loss: 0.475930\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.382152; batch adversarial loss: 0.405032\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.444248; batch adversarial loss: 0.392554\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.393670; batch adversarial loss: 0.446926\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.417710; batch adversarial loss: 0.354523\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.426282; batch adversarial loss: 0.475245\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.480326; batch adversarial loss: 0.390022\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.442391; batch adversarial loss: 0.407828\n",
      "epoch 12; iter: 0; batch classifier loss: 0.357572; batch adversarial loss: 0.560315\n",
      "epoch 12; iter: 200; batch classifier loss: 0.389388; batch adversarial loss: 0.297148\n",
      "epoch 12; iter: 400; batch classifier loss: 0.430372; batch adversarial loss: 0.363291\n",
      "epoch 12; iter: 600; batch classifier loss: 0.437447; batch adversarial loss: 0.488033\n",
      "epoch 12; iter: 800; batch classifier loss: 0.363981; batch adversarial loss: 0.447847\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.437263; batch adversarial loss: 0.381478\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.387929; batch adversarial loss: 0.433144\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.326945; batch adversarial loss: 0.242222\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.411938; batch adversarial loss: 0.445202\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.383173; batch adversarial loss: 0.434872\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.369315; batch adversarial loss: 0.476365\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.438302; batch adversarial loss: 0.417499\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.474148; batch adversarial loss: 0.349545\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.454815; batch adversarial loss: 0.504511\n",
      "epoch 13; iter: 0; batch classifier loss: 0.447466; batch adversarial loss: 0.419024\n",
      "epoch 13; iter: 200; batch classifier loss: 0.381421; batch adversarial loss: 0.394557\n",
      "epoch 13; iter: 400; batch classifier loss: 0.389099; batch adversarial loss: 0.377636\n",
      "epoch 13; iter: 600; batch classifier loss: 0.370974; batch adversarial loss: 0.433765\n",
      "epoch 13; iter: 800; batch classifier loss: 0.468353; batch adversarial loss: 0.406047\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.481874; batch adversarial loss: 0.556196\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.383000; batch adversarial loss: 0.309224\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.413033; batch adversarial loss: 0.419964\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.428820; batch adversarial loss: 0.421823\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.338067; batch adversarial loss: 0.516110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13; iter: 2000; batch classifier loss: 0.400339; batch adversarial loss: 0.404084\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.443241; batch adversarial loss: 0.435148\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.449403; batch adversarial loss: 0.402863\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.442645; batch adversarial loss: 0.365473\n",
      "epoch 14; iter: 0; batch classifier loss: 0.393056; batch adversarial loss: 0.489728\n",
      "epoch 14; iter: 200; batch classifier loss: 0.341450; batch adversarial loss: 0.433858\n",
      "epoch 14; iter: 400; batch classifier loss: 0.376340; batch adversarial loss: 0.392491\n",
      "epoch 14; iter: 600; batch classifier loss: 0.469951; batch adversarial loss: 0.461017\n",
      "epoch 14; iter: 800; batch classifier loss: 0.433258; batch adversarial loss: 0.557857\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.355952; batch adversarial loss: 0.406278\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.411041; batch adversarial loss: 0.443161\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.393258; batch adversarial loss: 0.408302\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.340932; batch adversarial loss: 0.394492\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.401589; batch adversarial loss: 0.348875\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.438614; batch adversarial loss: 0.379707\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.349849; batch adversarial loss: 0.475345\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.396611; batch adversarial loss: 0.500129\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.440186; batch adversarial loss: 0.392011\n",
      "epoch 15; iter: 0; batch classifier loss: 0.366441; batch adversarial loss: 0.542827\n",
      "epoch 15; iter: 200; batch classifier loss: 0.377279; batch adversarial loss: 0.405588\n",
      "epoch 15; iter: 400; batch classifier loss: 0.426930; batch adversarial loss: 0.544326\n",
      "epoch 15; iter: 600; batch classifier loss: 0.460804; batch adversarial loss: 0.420471\n",
      "epoch 15; iter: 800; batch classifier loss: 0.387462; batch adversarial loss: 0.447106\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.385691; batch adversarial loss: 0.448246\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.497660; batch adversarial loss: 0.431396\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.360154; batch adversarial loss: 0.487448\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.450573; batch adversarial loss: 0.379849\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.442227; batch adversarial loss: 0.379044\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.410321; batch adversarial loss: 0.432311\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.415095; batch adversarial loss: 0.459344\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.378006; batch adversarial loss: 0.434298\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.391252; batch adversarial loss: 0.390841\n",
      "epoch 16; iter: 0; batch classifier loss: 0.393825; batch adversarial loss: 0.296647\n",
      "epoch 16; iter: 200; batch classifier loss: 0.431663; batch adversarial loss: 0.516903\n",
      "epoch 16; iter: 400; batch classifier loss: 0.528810; batch adversarial loss: 0.389895\n",
      "epoch 16; iter: 600; batch classifier loss: 0.426091; batch adversarial loss: 0.378163\n",
      "epoch 16; iter: 800; batch classifier loss: 0.520948; batch adversarial loss: 0.366207\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.413181; batch adversarial loss: 0.520385\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.395948; batch adversarial loss: 0.404150\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.484151; batch adversarial loss: 0.486685\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.456629; batch adversarial loss: 0.421464\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.401013; batch adversarial loss: 0.418895\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.410908; batch adversarial loss: 0.501259\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.391276; batch adversarial loss: 0.473966\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.431439; batch adversarial loss: 0.378285\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.493625; batch adversarial loss: 0.556122\n",
      "epoch 17; iter: 0; batch classifier loss: 0.419495; batch adversarial loss: 0.528963\n",
      "epoch 17; iter: 200; batch classifier loss: 0.424170; batch adversarial loss: 0.378140\n",
      "epoch 17; iter: 400; batch classifier loss: 0.500519; batch adversarial loss: 0.487032\n",
      "epoch 17; iter: 600; batch classifier loss: 0.447750; batch adversarial loss: 0.323447\n",
      "epoch 17; iter: 800; batch classifier loss: 0.398548; batch adversarial loss: 0.292873\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.433583; batch adversarial loss: 0.461747\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.420303; batch adversarial loss: 0.406246\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.425516; batch adversarial loss: 0.479841\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.372700; batch adversarial loss: 0.351178\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.457709; batch adversarial loss: 0.460787\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.345400; batch adversarial loss: 0.361625\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.441932; batch adversarial loss: 0.462693\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.333672; batch adversarial loss: 0.364267\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.487824; batch adversarial loss: 0.475030\n",
      "epoch 18; iter: 0; batch classifier loss: 0.380797; batch adversarial loss: 0.406567\n",
      "epoch 18; iter: 200; batch classifier loss: 0.380007; batch adversarial loss: 0.337748\n",
      "epoch 18; iter: 400; batch classifier loss: 0.398247; batch adversarial loss: 0.379323\n",
      "epoch 18; iter: 600; batch classifier loss: 0.385350; batch adversarial loss: 0.447569\n",
      "epoch 18; iter: 800; batch classifier loss: 0.431619; batch adversarial loss: 0.449714\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.408572; batch adversarial loss: 0.419035\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.430895; batch adversarial loss: 0.390131\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.511790; batch adversarial loss: 0.422028\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.408380; batch adversarial loss: 0.418759\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.344081; batch adversarial loss: 0.515456\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.412940; batch adversarial loss: 0.337584\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.320746; batch adversarial loss: 0.445471\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.404539; batch adversarial loss: 0.352230\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.407542; batch adversarial loss: 0.446806\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518150; batch adversarial loss: 0.409254\n",
      "epoch 19; iter: 200; batch classifier loss: 0.366343; batch adversarial loss: 0.392053\n",
      "epoch 19; iter: 400; batch classifier loss: 0.335299; batch adversarial loss: 0.514996\n",
      "epoch 19; iter: 600; batch classifier loss: 0.421332; batch adversarial loss: 0.325576\n",
      "epoch 19; iter: 800; batch classifier loss: 0.429924; batch adversarial loss: 0.405390\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.434923; batch adversarial loss: 0.489742\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.381263; batch adversarial loss: 0.474424\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.330174; batch adversarial loss: 0.354007\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.368544; batch adversarial loss: 0.378758\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.372295; batch adversarial loss: 0.362586\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.361949; batch adversarial loss: 0.339601\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.374399; batch adversarial loss: 0.407198\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.362657; batch adversarial loss: 0.393406\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.446979; batch adversarial loss: 0.379292\n",
      "epoch 20; iter: 0; batch classifier loss: 0.455049; batch adversarial loss: 0.353423\n",
      "epoch 20; iter: 200; batch classifier loss: 0.365691; batch adversarial loss: 0.392097\n",
      "epoch 20; iter: 400; batch classifier loss: 0.401360; batch adversarial loss: 0.390609\n",
      "epoch 20; iter: 600; batch classifier loss: 0.441176; batch adversarial loss: 0.361256\n",
      "epoch 20; iter: 800; batch classifier loss: 0.462479; batch adversarial loss: 0.435178\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.491388; batch adversarial loss: 0.529311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20; iter: 1200; batch classifier loss: 0.474363; batch adversarial loss: 0.463627\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.418916; batch adversarial loss: 0.405109\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.442509; batch adversarial loss: 0.393312\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.456090; batch adversarial loss: 0.404549\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.480611; batch adversarial loss: 0.280752\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.457253; batch adversarial loss: 0.502778\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.475359; batch adversarial loss: 0.479051\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.462135; batch adversarial loss: 0.459914\n",
      "epoch 21; iter: 0; batch classifier loss: 0.449081; batch adversarial loss: 0.460803\n",
      "epoch 21; iter: 200; batch classifier loss: 0.433076; batch adversarial loss: 0.437238\n",
      "epoch 21; iter: 400; batch classifier loss: 0.481087; batch adversarial loss: 0.500489\n",
      "epoch 21; iter: 600; batch classifier loss: 0.484753; batch adversarial loss: 0.461440\n",
      "epoch 21; iter: 800; batch classifier loss: 0.347401; batch adversarial loss: 0.377474\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.466384; batch adversarial loss: 0.488163\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.356431; batch adversarial loss: 0.376745\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.388270; batch adversarial loss: 0.337459\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.439218; batch adversarial loss: 0.434068\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.462348; batch adversarial loss: 0.461965\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.392628; batch adversarial loss: 0.418974\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.321701; batch adversarial loss: 0.419686\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.423994; batch adversarial loss: 0.407107\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.474699; batch adversarial loss: 0.431743\n",
      "epoch 22; iter: 0; batch classifier loss: 0.415465; batch adversarial loss: 0.338237\n",
      "epoch 22; iter: 200; batch classifier loss: 0.398928; batch adversarial loss: 0.391886\n",
      "epoch 22; iter: 400; batch classifier loss: 0.484165; batch adversarial loss: 0.349669\n",
      "epoch 22; iter: 600; batch classifier loss: 0.453641; batch adversarial loss: 0.406668\n",
      "epoch 22; iter: 800; batch classifier loss: 0.329784; batch adversarial loss: 0.502277\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.398199; batch adversarial loss: 0.347717\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.435112; batch adversarial loss: 0.365279\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.423668; batch adversarial loss: 0.311052\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.435776; batch adversarial loss: 0.432860\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.376130; batch adversarial loss: 0.489225\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.335249; batch adversarial loss: 0.421531\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.392936; batch adversarial loss: 0.486414\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.451648; batch adversarial loss: 0.504266\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.445331; batch adversarial loss: 0.420801\n",
      "epoch 23; iter: 0; batch classifier loss: 0.480506; batch adversarial loss: 0.446950\n",
      "epoch 23; iter: 200; batch classifier loss: 0.404245; batch adversarial loss: 0.349150\n",
      "epoch 23; iter: 400; batch classifier loss: 0.429777; batch adversarial loss: 0.393200\n",
      "epoch 23; iter: 600; batch classifier loss: 0.509555; batch adversarial loss: 0.422206\n",
      "epoch 23; iter: 800; batch classifier loss: 0.488986; batch adversarial loss: 0.335053\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.475358; batch adversarial loss: 0.472638\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.460160; batch adversarial loss: 0.405661\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.361652; batch adversarial loss: 0.446292\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.385196; batch adversarial loss: 0.419049\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.460209; batch adversarial loss: 0.394054\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.422774; batch adversarial loss: 0.458692\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.469045; batch adversarial loss: 0.475798\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.383313; batch adversarial loss: 0.390784\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.452851; batch adversarial loss: 0.351972\n",
      "epoch 24; iter: 0; batch classifier loss: 0.360564; batch adversarial loss: 0.378816\n",
      "epoch 24; iter: 200; batch classifier loss: 0.425919; batch adversarial loss: 0.432081\n",
      "epoch 24; iter: 400; batch classifier loss: 0.421142; batch adversarial loss: 0.434045\n",
      "epoch 24; iter: 600; batch classifier loss: 0.341038; batch adversarial loss: 0.445239\n",
      "epoch 24; iter: 800; batch classifier loss: 0.425416; batch adversarial loss: 0.446754\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.381562; batch adversarial loss: 0.556753\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.358632; batch adversarial loss: 0.367418\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.514691; batch adversarial loss: 0.489112\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.388275; batch adversarial loss: 0.419164\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.383246; batch adversarial loss: 0.404399\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.344862; batch adversarial loss: 0.364290\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.417710; batch adversarial loss: 0.488299\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.475415; batch adversarial loss: 0.365005\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.464700; batch adversarial loss: 0.433893\n",
      "epoch 25; iter: 0; batch classifier loss: 0.474493; batch adversarial loss: 0.378712\n",
      "epoch 25; iter: 200; batch classifier loss: 0.414613; batch adversarial loss: 0.390882\n",
      "epoch 25; iter: 400; batch classifier loss: 0.391784; batch adversarial loss: 0.393029\n",
      "epoch 25; iter: 600; batch classifier loss: 0.538523; batch adversarial loss: 0.364968\n",
      "epoch 25; iter: 800; batch classifier loss: 0.399617; batch adversarial loss: 0.393844\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.375709; batch adversarial loss: 0.392351\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.390158; batch adversarial loss: 0.430668\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.344700; batch adversarial loss: 0.335599\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.307401; batch adversarial loss: 0.434565\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.410350; batch adversarial loss: 0.404327\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.487849; batch adversarial loss: 0.365169\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.471133; batch adversarial loss: 0.364110\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.475397; batch adversarial loss: 0.487138\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.476708; batch adversarial loss: 0.392268\n",
      "epoch 26; iter: 0; batch classifier loss: 0.476402; batch adversarial loss: 0.391728\n",
      "epoch 26; iter: 200; batch classifier loss: 0.387770; batch adversarial loss: 0.377343\n",
      "epoch 26; iter: 400; batch classifier loss: 0.364148; batch adversarial loss: 0.431872\n",
      "epoch 26; iter: 600; batch classifier loss: 0.367359; batch adversarial loss: 0.529793\n",
      "epoch 26; iter: 800; batch classifier loss: 0.431720; batch adversarial loss: 0.393164\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.462370; batch adversarial loss: 0.430942\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.401297; batch adversarial loss: 0.449350\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.451725; batch adversarial loss: 0.280847\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.462209; batch adversarial loss: 0.489636\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.362503; batch adversarial loss: 0.393176\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.423325; batch adversarial loss: 0.323613\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.460416; batch adversarial loss: 0.365588\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.496813; batch adversarial loss: 0.432530\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.403814; batch adversarial loss: 0.447601\n",
      "epoch 27; iter: 0; batch classifier loss: 0.319631; batch adversarial loss: 0.324577\n",
      "epoch 27; iter: 200; batch classifier loss: 0.361990; batch adversarial loss: 0.461422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27; iter: 400; batch classifier loss: 0.442262; batch adversarial loss: 0.406692\n",
      "epoch 27; iter: 600; batch classifier loss: 0.508558; batch adversarial loss: 0.434018\n",
      "epoch 27; iter: 800; batch classifier loss: 0.543566; batch adversarial loss: 0.420946\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.438663; batch adversarial loss: 0.406731\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.403864; batch adversarial loss: 0.351261\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.416420; batch adversarial loss: 0.445526\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.395157; batch adversarial loss: 0.325759\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.424658; batch adversarial loss: 0.446136\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.354503; batch adversarial loss: 0.365963\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.371762; batch adversarial loss: 0.393329\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.431641; batch adversarial loss: 0.366471\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.402360; batch adversarial loss: 0.406772\n",
      "epoch 28; iter: 0; batch classifier loss: 0.432154; batch adversarial loss: 0.435347\n",
      "epoch 28; iter: 200; batch classifier loss: 0.425517; batch adversarial loss: 0.420873\n",
      "epoch 28; iter: 400; batch classifier loss: 0.428430; batch adversarial loss: 0.434589\n",
      "epoch 28; iter: 600; batch classifier loss: 0.393608; batch adversarial loss: 0.380975\n",
      "epoch 28; iter: 800; batch classifier loss: 0.390788; batch adversarial loss: 0.421259\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.389580; batch adversarial loss: 0.336961\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.351046; batch adversarial loss: 0.407828\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.502986; batch adversarial loss: 0.325323\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.451474; batch adversarial loss: 0.464364\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.375753; batch adversarial loss: 0.406976\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.390152; batch adversarial loss: 0.435964\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.402741; batch adversarial loss: 0.323452\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.348173; batch adversarial loss: 0.489854\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.292794; batch adversarial loss: 0.380987\n",
      "epoch 29; iter: 0; batch classifier loss: 0.537158; batch adversarial loss: 0.421204\n",
      "epoch 29; iter: 200; batch classifier loss: 0.377595; batch adversarial loss: 0.378838\n",
      "epoch 29; iter: 400; batch classifier loss: 0.431391; batch adversarial loss: 0.366012\n",
      "epoch 29; iter: 600; batch classifier loss: 0.371614; batch adversarial loss: 0.445214\n",
      "epoch 29; iter: 800; batch classifier loss: 0.405215; batch adversarial loss: 0.422519\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.436754; batch adversarial loss: 0.459804\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.484549; batch adversarial loss: 0.418006\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.402279; batch adversarial loss: 0.419266\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.355543; batch adversarial loss: 0.378126\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.449177; batch adversarial loss: 0.404426\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.460652; batch adversarial loss: 0.447994\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.365641; batch adversarial loss: 0.503335\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.415843; batch adversarial loss: 0.377982\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.470968; batch adversarial loss: 0.323663\n",
      "epoch 30; iter: 0; batch classifier loss: 0.352461; batch adversarial loss: 0.365287\n",
      "epoch 30; iter: 200; batch classifier loss: 0.399349; batch adversarial loss: 0.514539\n",
      "epoch 30; iter: 400; batch classifier loss: 0.381267; batch adversarial loss: 0.322100\n",
      "epoch 30; iter: 600; batch classifier loss: 0.439203; batch adversarial loss: 0.477288\n",
      "epoch 30; iter: 800; batch classifier loss: 0.494046; batch adversarial loss: 0.407036\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.298105; batch adversarial loss: 0.351451\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.438541; batch adversarial loss: 0.433856\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.390244; batch adversarial loss: 0.447218\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.443603; batch adversarial loss: 0.430975\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.435724; batch adversarial loss: 0.419891\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.429309; batch adversarial loss: 0.353268\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.431577; batch adversarial loss: 0.433413\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.375671; batch adversarial loss: 0.336857\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.434681; batch adversarial loss: 0.474203\n",
      "epoch 31; iter: 0; batch classifier loss: 0.373828; batch adversarial loss: 0.501043\n",
      "epoch 31; iter: 200; batch classifier loss: 0.395537; batch adversarial loss: 0.377419\n",
      "epoch 31; iter: 400; batch classifier loss: 0.453898; batch adversarial loss: 0.365125\n",
      "epoch 31; iter: 600; batch classifier loss: 0.401443; batch adversarial loss: 0.404920\n",
      "epoch 31; iter: 800; batch classifier loss: 0.403650; batch adversarial loss: 0.406966\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.363462; batch adversarial loss: 0.393255\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.473870; batch adversarial loss: 0.432122\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.409781; batch adversarial loss: 0.392798\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.346393; batch adversarial loss: 0.436888\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.499876; batch adversarial loss: 0.542329\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.404799; batch adversarial loss: 0.338403\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.436336; batch adversarial loss: 0.462933\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.301126; batch adversarial loss: 0.445731\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.442331; batch adversarial loss: 0.487899\n",
      "epoch 32; iter: 0; batch classifier loss: 0.481691; batch adversarial loss: 0.418263\n",
      "epoch 32; iter: 200; batch classifier loss: 0.405672; batch adversarial loss: 0.432891\n",
      "epoch 32; iter: 400; batch classifier loss: 0.390501; batch adversarial loss: 0.489016\n",
      "epoch 32; iter: 600; batch classifier loss: 0.405066; batch adversarial loss: 0.462255\n",
      "epoch 32; iter: 800; batch classifier loss: 0.379138; batch adversarial loss: 0.326478\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.474335; batch adversarial loss: 0.378782\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.431770; batch adversarial loss: 0.501150\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.490216; batch adversarial loss: 0.446173\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.405237; batch adversarial loss: 0.394436\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.496307; batch adversarial loss: 0.477113\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.455941; batch adversarial loss: 0.392634\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.399892; batch adversarial loss: 0.461922\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.370014; batch adversarial loss: 0.339310\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.420482; batch adversarial loss: 0.406473\n",
      "epoch 33; iter: 0; batch classifier loss: 0.351394; batch adversarial loss: 0.474171\n",
      "epoch 33; iter: 200; batch classifier loss: 0.341333; batch adversarial loss: 0.498961\n",
      "epoch 33; iter: 400; batch classifier loss: 0.347655; batch adversarial loss: 0.460593\n",
      "epoch 33; iter: 600; batch classifier loss: 0.386743; batch adversarial loss: 0.407358\n",
      "epoch 33; iter: 800; batch classifier loss: 0.391587; batch adversarial loss: 0.434827\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.441451; batch adversarial loss: 0.404204\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.437141; batch adversarial loss: 0.501517\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.336889; batch adversarial loss: 0.433831\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.453947; batch adversarial loss: 0.446649\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.334552; batch adversarial loss: 0.379882\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.395369; batch adversarial loss: 0.407021\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.462503; batch adversarial loss: 0.491455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33; iter: 2400; batch classifier loss: 0.386162; batch adversarial loss: 0.311905\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.417188; batch adversarial loss: 0.405609\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451935; batch adversarial loss: 0.433499\n",
      "epoch 34; iter: 200; batch classifier loss: 0.449561; batch adversarial loss: 0.474564\n",
      "epoch 34; iter: 400; batch classifier loss: 0.434876; batch adversarial loss: 0.541990\n",
      "epoch 34; iter: 600; batch classifier loss: 0.466554; batch adversarial loss: 0.434389\n",
      "epoch 34; iter: 800; batch classifier loss: 0.353766; batch adversarial loss: 0.379836\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.400022; batch adversarial loss: 0.422149\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.458082; batch adversarial loss: 0.420799\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.388699; batch adversarial loss: 0.551870\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.387663; batch adversarial loss: 0.544376\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.495256; batch adversarial loss: 0.403602\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.437003; batch adversarial loss: 0.464224\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.428616; batch adversarial loss: 0.408247\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.397474; batch adversarial loss: 0.530553\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.413965; batch adversarial loss: 0.464337\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419770; batch adversarial loss: 0.336588\n",
      "epoch 35; iter: 200; batch classifier loss: 0.446613; batch adversarial loss: 0.445124\n",
      "epoch 35; iter: 400; batch classifier loss: 0.387075; batch adversarial loss: 0.392616\n",
      "epoch 35; iter: 600; batch classifier loss: 0.389257; batch adversarial loss: 0.364044\n",
      "epoch 35; iter: 800; batch classifier loss: 0.409701; batch adversarial loss: 0.394508\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.416838; batch adversarial loss: 0.324995\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.420724; batch adversarial loss: 0.405522\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.392976; batch adversarial loss: 0.310496\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.412509; batch adversarial loss: 0.432485\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.383911; batch adversarial loss: 0.420686\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.336172; batch adversarial loss: 0.474773\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.403441; batch adversarial loss: 0.419758\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.417011; batch adversarial loss: 0.364503\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.515817; batch adversarial loss: 0.419782\n",
      "epoch 36; iter: 0; batch classifier loss: 0.428433; batch adversarial loss: 0.460395\n",
      "epoch 36; iter: 200; batch classifier loss: 0.401744; batch adversarial loss: 0.366567\n",
      "epoch 36; iter: 400; batch classifier loss: 0.435735; batch adversarial loss: 0.336199\n",
      "epoch 36; iter: 600; batch classifier loss: 0.394833; batch adversarial loss: 0.431371\n",
      "epoch 36; iter: 800; batch classifier loss: 0.483880; batch adversarial loss: 0.389342\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.382816; batch adversarial loss: 0.434243\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.357955; batch adversarial loss: 0.408638\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.399826; batch adversarial loss: 0.448516\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.391709; batch adversarial loss: 0.351133\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.470873; batch adversarial loss: 0.269626\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.431328; batch adversarial loss: 0.406361\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.399163; batch adversarial loss: 0.419776\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.369256; batch adversarial loss: 0.462347\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.404036; batch adversarial loss: 0.420569\n",
      "epoch 37; iter: 0; batch classifier loss: 0.412009; batch adversarial loss: 0.462107\n",
      "epoch 37; iter: 200; batch classifier loss: 0.422066; batch adversarial loss: 0.350749\n",
      "epoch 37; iter: 400; batch classifier loss: 0.308244; batch adversarial loss: 0.352934\n",
      "epoch 37; iter: 600; batch classifier loss: 0.452414; batch adversarial loss: 0.529965\n",
      "epoch 37; iter: 800; batch classifier loss: 0.394882; batch adversarial loss: 0.417165\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.438996; batch adversarial loss: 0.377537\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.403276; batch adversarial loss: 0.394699\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.454741; batch adversarial loss: 0.447404\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.385271; batch adversarial loss: 0.394214\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.404313; batch adversarial loss: 0.379640\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.429756; batch adversarial loss: 0.350458\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.452224; batch adversarial loss: 0.376844\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.359699; batch adversarial loss: 0.447716\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.361750; batch adversarial loss: 0.448177\n",
      "epoch 38; iter: 0; batch classifier loss: 0.428113; batch adversarial loss: 0.512824\n",
      "epoch 38; iter: 200; batch classifier loss: 0.463374; batch adversarial loss: 0.377632\n",
      "epoch 38; iter: 400; batch classifier loss: 0.435413; batch adversarial loss: 0.337249\n",
      "epoch 38; iter: 600; batch classifier loss: 0.404334; batch adversarial loss: 0.407435\n",
      "epoch 38; iter: 800; batch classifier loss: 0.477966; batch adversarial loss: 0.445431\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.482917; batch adversarial loss: 0.463349\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.391877; batch adversarial loss: 0.473180\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.478405; batch adversarial loss: 0.422149\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.435479; batch adversarial loss: 0.392692\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.415256; batch adversarial loss: 0.323726\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.425720; batch adversarial loss: 0.392877\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.438940; batch adversarial loss: 0.351422\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.388839; batch adversarial loss: 0.394292\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.426385; batch adversarial loss: 0.364696\n",
      "epoch 39; iter: 0; batch classifier loss: 0.394498; batch adversarial loss: 0.406180\n",
      "epoch 39; iter: 200; batch classifier loss: 0.458018; batch adversarial loss: 0.337042\n",
      "epoch 39; iter: 400; batch classifier loss: 0.439317; batch adversarial loss: 0.529567\n",
      "epoch 39; iter: 600; batch classifier loss: 0.461438; batch adversarial loss: 0.444998\n",
      "epoch 39; iter: 800; batch classifier loss: 0.483501; batch adversarial loss: 0.378732\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.376200; batch adversarial loss: 0.296311\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.422005; batch adversarial loss: 0.430403\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.371001; batch adversarial loss: 0.364726\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.373992; batch adversarial loss: 0.487203\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.401939; batch adversarial loss: 0.461722\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.468180; batch adversarial loss: 0.407123\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.351081; batch adversarial loss: 0.420836\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.342555; batch adversarial loss: 0.488130\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.345054; batch adversarial loss: 0.418698\n",
      "epoch 40; iter: 0; batch classifier loss: 0.458040; batch adversarial loss: 0.391850\n",
      "epoch 40; iter: 200; batch classifier loss: 0.357258; batch adversarial loss: 0.434145\n",
      "epoch 40; iter: 400; batch classifier loss: 0.367099; batch adversarial loss: 0.434070\n",
      "epoch 40; iter: 600; batch classifier loss: 0.466445; batch adversarial loss: 0.379052\n",
      "epoch 40; iter: 800; batch classifier loss: 0.323859; batch adversarial loss: 0.434297\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.446074; batch adversarial loss: 0.418187\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.402969; batch adversarial loss: 0.353140\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.445499; batch adversarial loss: 0.489327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40; iter: 1600; batch classifier loss: 0.347500; batch adversarial loss: 0.378701\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.343800; batch adversarial loss: 0.526513\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.359171; batch adversarial loss: 0.364547\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.405141; batch adversarial loss: 0.474763\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.409116; batch adversarial loss: 0.393185\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.325527; batch adversarial loss: 0.360981\n",
      "epoch 41; iter: 0; batch classifier loss: 0.383259; batch adversarial loss: 0.529824\n",
      "epoch 41; iter: 200; batch classifier loss: 0.470730; batch adversarial loss: 0.471949\n",
      "epoch 41; iter: 400; batch classifier loss: 0.422543; batch adversarial loss: 0.409588\n",
      "epoch 41; iter: 600; batch classifier loss: 0.459478; batch adversarial loss: 0.404839\n",
      "epoch 41; iter: 800; batch classifier loss: 0.369105; batch adversarial loss: 0.487245\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.324808; batch adversarial loss: 0.435476\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.398431; batch adversarial loss: 0.431573\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.461716; batch adversarial loss: 0.391240\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.391898; batch adversarial loss: 0.406572\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.364781; batch adversarial loss: 0.406554\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.434755; batch adversarial loss: 0.378569\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.414755; batch adversarial loss: 0.474085\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.448501; batch adversarial loss: 0.365122\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.410542; batch adversarial loss: 0.435266\n",
      "epoch 42; iter: 0; batch classifier loss: 0.389835; batch adversarial loss: 0.366164\n",
      "epoch 42; iter: 200; batch classifier loss: 0.475578; batch adversarial loss: 0.462280\n",
      "epoch 42; iter: 400; batch classifier loss: 0.388683; batch adversarial loss: 0.351061\n",
      "epoch 42; iter: 600; batch classifier loss: 0.460600; batch adversarial loss: 0.419669\n",
      "epoch 42; iter: 800; batch classifier loss: 0.407443; batch adversarial loss: 0.502621\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.500899; batch adversarial loss: 0.488331\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.422620; batch adversarial loss: 0.460843\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.411438; batch adversarial loss: 0.365688\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.387607; batch adversarial loss: 0.473937\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.443454; batch adversarial loss: 0.447423\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.530434; batch adversarial loss: 0.433876\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.369246; batch adversarial loss: 0.392769\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.439878; batch adversarial loss: 0.448361\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.320278; batch adversarial loss: 0.430141\n",
      "epoch 43; iter: 0; batch classifier loss: 0.492701; batch adversarial loss: 0.433785\n",
      "epoch 43; iter: 200; batch classifier loss: 0.433260; batch adversarial loss: 0.449041\n",
      "epoch 43; iter: 400; batch classifier loss: 0.420907; batch adversarial loss: 0.501309\n",
      "epoch 43; iter: 600; batch classifier loss: 0.425180; batch adversarial loss: 0.450504\n",
      "epoch 43; iter: 800; batch classifier loss: 0.461090; batch adversarial loss: 0.353121\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.472087; batch adversarial loss: 0.380934\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.387406; batch adversarial loss: 0.557444\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.399176; batch adversarial loss: 0.420131\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.455271; batch adversarial loss: 0.432336\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.418649; batch adversarial loss: 0.393745\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.436547; batch adversarial loss: 0.419701\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.440941; batch adversarial loss: 0.406004\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.488707; batch adversarial loss: 0.392076\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.418781; batch adversarial loss: 0.352605\n",
      "epoch 44; iter: 0; batch classifier loss: 0.476261; batch adversarial loss: 0.474263\n",
      "epoch 44; iter: 200; batch classifier loss: 0.453823; batch adversarial loss: 0.338844\n",
      "epoch 44; iter: 400; batch classifier loss: 0.406659; batch adversarial loss: 0.420120\n",
      "epoch 44; iter: 600; batch classifier loss: 0.408132; batch adversarial loss: 0.490781\n",
      "epoch 44; iter: 800; batch classifier loss: 0.425273; batch adversarial loss: 0.474225\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.411579; batch adversarial loss: 0.416906\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.385933; batch adversarial loss: 0.514774\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.381537; batch adversarial loss: 0.489943\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.471786; batch adversarial loss: 0.407061\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.400458; batch adversarial loss: 0.445750\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.430219; batch adversarial loss: 0.351427\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.338103; batch adversarial loss: 0.406972\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.392841; batch adversarial loss: 0.490074\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.450327; batch adversarial loss: 0.322175\n",
      "epoch 45; iter: 0; batch classifier loss: 0.376542; batch adversarial loss: 0.433702\n",
      "epoch 45; iter: 200; batch classifier loss: 0.425156; batch adversarial loss: 0.408383\n",
      "epoch 45; iter: 400; batch classifier loss: 0.347739; batch adversarial loss: 0.324503\n",
      "epoch 45; iter: 600; batch classifier loss: 0.453750; batch adversarial loss: 0.310194\n",
      "epoch 45; iter: 800; batch classifier loss: 0.422731; batch adversarial loss: 0.352572\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.415857; batch adversarial loss: 0.405760\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.405436; batch adversarial loss: 0.395446\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.402949; batch adversarial loss: 0.401401\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.450552; batch adversarial loss: 0.282943\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.371042; batch adversarial loss: 0.379622\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.370358; batch adversarial loss: 0.445571\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.411118; batch adversarial loss: 0.529050\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.371627; batch adversarial loss: 0.462435\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.364093; batch adversarial loss: 0.477717\n",
      "epoch 46; iter: 0; batch classifier loss: 0.383762; batch adversarial loss: 0.379129\n",
      "epoch 46; iter: 200; batch classifier loss: 0.483157; batch adversarial loss: 0.393557\n",
      "epoch 46; iter: 400; batch classifier loss: 0.381642; batch adversarial loss: 0.433312\n",
      "epoch 46; iter: 600; batch classifier loss: 0.455782; batch adversarial loss: 0.451476\n",
      "epoch 46; iter: 800; batch classifier loss: 0.380418; batch adversarial loss: 0.475305\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.377056; batch adversarial loss: 0.460827\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.439958; batch adversarial loss: 0.448926\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.483346; batch adversarial loss: 0.392541\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.443352; batch adversarial loss: 0.460491\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.377999; batch adversarial loss: 0.404522\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.329630; batch adversarial loss: 0.404414\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.361242; batch adversarial loss: 0.417751\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.436938; batch adversarial loss: 0.420231\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.407436; batch adversarial loss: 0.394258\n",
      "epoch 47; iter: 0; batch classifier loss: 0.398711; batch adversarial loss: 0.393408\n",
      "epoch 47; iter: 200; batch classifier loss: 0.441227; batch adversarial loss: 0.406203\n",
      "epoch 47; iter: 400; batch classifier loss: 0.392019; batch adversarial loss: 0.475028\n",
      "epoch 47; iter: 600; batch classifier loss: 0.553448; batch adversarial loss: 0.367155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47; iter: 800; batch classifier loss: 0.416665; batch adversarial loss: 0.405412\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.449806; batch adversarial loss: 0.448553\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.450403; batch adversarial loss: 0.474396\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.507806; batch adversarial loss: 0.420902\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.366973; batch adversarial loss: 0.379924\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.402975; batch adversarial loss: 0.389815\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.469831; batch adversarial loss: 0.420794\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.475267; batch adversarial loss: 0.394137\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.439628; batch adversarial loss: 0.445626\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.513482; batch adversarial loss: 0.517853\n",
      "epoch 48; iter: 0; batch classifier loss: 0.364413; batch adversarial loss: 0.462819\n",
      "epoch 48; iter: 200; batch classifier loss: 0.441093; batch adversarial loss: 0.406324\n",
      "epoch 48; iter: 400; batch classifier loss: 0.389287; batch adversarial loss: 0.405236\n",
      "epoch 48; iter: 600; batch classifier loss: 0.335728; batch adversarial loss: 0.421694\n",
      "epoch 48; iter: 800; batch classifier loss: 0.393767; batch adversarial loss: 0.462559\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.510213; batch adversarial loss: 0.404430\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.403276; batch adversarial loss: 0.392133\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.378156; batch adversarial loss: 0.379426\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.333732; batch adversarial loss: 0.517301\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.444605; batch adversarial loss: 0.504840\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.357557; batch adversarial loss: 0.431445\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.482058; batch adversarial loss: 0.450694\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.409091; batch adversarial loss: 0.366022\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.450259; batch adversarial loss: 0.471796\n",
      "epoch 49; iter: 0; batch classifier loss: 0.341275; batch adversarial loss: 0.498966\n",
      "epoch 49; iter: 200; batch classifier loss: 0.445989; batch adversarial loss: 0.430563\n",
      "epoch 49; iter: 400; batch classifier loss: 0.429074; batch adversarial loss: 0.472119\n",
      "epoch 49; iter: 600; batch classifier loss: 0.426805; batch adversarial loss: 0.364527\n",
      "epoch 49; iter: 800; batch classifier loss: 0.454439; batch adversarial loss: 0.475418\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.409787; batch adversarial loss: 0.350054\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.454443; batch adversarial loss: 0.421479\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.419544; batch adversarial loss: 0.517325\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.367004; batch adversarial loss: 0.433076\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.357656; batch adversarial loss: 0.405763\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.453171; batch adversarial loss: 0.456712\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.444924; batch adversarial loss: 0.404417\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.395815; batch adversarial loss: 0.351153\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.371750; batch adversarial loss: 0.419984\n",
      "epoch 0; iter: 0; batch classifier loss: 0.674600\n",
      "epoch 0; iter: 200; batch classifier loss: 0.492058\n",
      "epoch 0; iter: 400; batch classifier loss: 0.506936\n",
      "epoch 0; iter: 600; batch classifier loss: 0.458709\n",
      "epoch 0; iter: 800; batch classifier loss: 0.399207\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.497621\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.430349\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.379472\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.455722\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.382722\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.378162\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.432144\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.373766\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.511836\n",
      "epoch 1; iter: 0; batch classifier loss: 0.387909\n",
      "epoch 1; iter: 200; batch classifier loss: 0.434606\n",
      "epoch 1; iter: 400; batch classifier loss: 0.428771\n",
      "epoch 1; iter: 600; batch classifier loss: 0.416700\n",
      "epoch 1; iter: 800; batch classifier loss: 0.413952\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.438806\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.381980\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.391702\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.451420\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.433796\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.454185\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.396328\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.535008\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.425899\n",
      "epoch 2; iter: 0; batch classifier loss: 0.483165\n",
      "epoch 2; iter: 200; batch classifier loss: 0.374662\n",
      "epoch 2; iter: 400; batch classifier loss: 0.381944\n",
      "epoch 2; iter: 600; batch classifier loss: 0.430019\n",
      "epoch 2; iter: 800; batch classifier loss: 0.425678\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.276396\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.414115\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.452168\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.462320\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.340176\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.384497\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.404131\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.422295\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.416277\n",
      "epoch 3; iter: 0; batch classifier loss: 0.494921\n",
      "epoch 3; iter: 200; batch classifier loss: 0.378872\n",
      "epoch 3; iter: 400; batch classifier loss: 0.367069\n",
      "epoch 3; iter: 600; batch classifier loss: 0.411891\n",
      "epoch 3; iter: 800; batch classifier loss: 0.426600\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.441689\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.411428\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.494627\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.425062\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.415369\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.494843\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.387431\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.293096\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.457200\n",
      "epoch 4; iter: 0; batch classifier loss: 0.404247\n",
      "epoch 4; iter: 200; batch classifier loss: 0.411180\n",
      "epoch 4; iter: 400; batch classifier loss: 0.393632\n",
      "epoch 4; iter: 600; batch classifier loss: 0.382943\n",
      "epoch 4; iter: 800; batch classifier loss: 0.401048\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.376633\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.393569\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.353331\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.398536\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.391318\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.407180\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.361681\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.378753\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.374087\n",
      "epoch 5; iter: 0; batch classifier loss: 0.323715\n",
      "epoch 5; iter: 200; batch classifier loss: 0.361376\n",
      "epoch 5; iter: 400; batch classifier loss: 0.406002\n",
      "epoch 5; iter: 600; batch classifier loss: 0.349737\n",
      "epoch 5; iter: 800; batch classifier loss: 0.464579\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.500512\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.466759\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.398499\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.511161\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.423827\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.429814\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.412072\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.401876\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.473786\n",
      "epoch 6; iter: 0; batch classifier loss: 0.393429\n",
      "epoch 6; iter: 200; batch classifier loss: 0.464230\n",
      "epoch 6; iter: 400; batch classifier loss: 0.378418\n",
      "epoch 6; iter: 600; batch classifier loss: 0.453736\n",
      "epoch 6; iter: 800; batch classifier loss: 0.379162\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.399036\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.385767\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.435445\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.458380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6; iter: 1800; batch classifier loss: 0.425305\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.431194\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.400827\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.471444\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.357014\n",
      "epoch 7; iter: 0; batch classifier loss: 0.421748\n",
      "epoch 7; iter: 200; batch classifier loss: 0.447445\n",
      "epoch 7; iter: 400; batch classifier loss: 0.379434\n",
      "epoch 7; iter: 600; batch classifier loss: 0.401087\n",
      "epoch 7; iter: 800; batch classifier loss: 0.448674\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.433391\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.385908\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.545793\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.471820\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.373112\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.442348\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.295118\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.416123\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.501320\n",
      "epoch 8; iter: 0; batch classifier loss: 0.391760\n",
      "epoch 8; iter: 200; batch classifier loss: 0.413198\n",
      "epoch 8; iter: 400; batch classifier loss: 0.428789\n",
      "epoch 8; iter: 600; batch classifier loss: 0.465338\n",
      "epoch 8; iter: 800; batch classifier loss: 0.477819\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.332200\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.372733\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.351125\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.466290\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.373917\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.420174\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.395788\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.363399\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.432017\n",
      "epoch 9; iter: 0; batch classifier loss: 0.459189\n",
      "epoch 9; iter: 200; batch classifier loss: 0.399589\n",
      "epoch 9; iter: 400; batch classifier loss: 0.385986\n",
      "epoch 9; iter: 600; batch classifier loss: 0.429164\n",
      "epoch 9; iter: 800; batch classifier loss: 0.377018\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.534225\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.440299\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.384321\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.416420\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.363098\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.465364\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.431033\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.390596\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.396986\n",
      "epoch 10; iter: 0; batch classifier loss: 0.347047\n",
      "epoch 10; iter: 200; batch classifier loss: 0.458494\n",
      "epoch 10; iter: 400; batch classifier loss: 0.397859\n",
      "epoch 10; iter: 600; batch classifier loss: 0.343434\n",
      "epoch 10; iter: 800; batch classifier loss: 0.412384\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.444118\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.378832\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.466023\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.269311\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.429451\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.386585\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.515690\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.457300\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.353409\n",
      "epoch 11; iter: 0; batch classifier loss: 0.501098\n",
      "epoch 11; iter: 200; batch classifier loss: 0.364475\n",
      "epoch 11; iter: 400; batch classifier loss: 0.456291\n",
      "epoch 11; iter: 600; batch classifier loss: 0.440560\n",
      "epoch 11; iter: 800; batch classifier loss: 0.433202\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.365881\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.331347\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.410088\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.306911\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.429867\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.437817\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.480913\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.455342\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.372100\n",
      "epoch 12; iter: 0; batch classifier loss: 0.337829\n",
      "epoch 12; iter: 200; batch classifier loss: 0.464604\n",
      "epoch 12; iter: 400; batch classifier loss: 0.334416\n",
      "epoch 12; iter: 600; batch classifier loss: 0.348348\n",
      "epoch 12; iter: 800; batch classifier loss: 0.439849\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.408097\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.462956\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.464879\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.493614\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.503072\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.411924\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.483706\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.435387\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.491842\n",
      "epoch 13; iter: 0; batch classifier loss: 0.348286\n",
      "epoch 13; iter: 200; batch classifier loss: 0.434832\n",
      "epoch 13; iter: 400; batch classifier loss: 0.368569\n",
      "epoch 13; iter: 600; batch classifier loss: 0.438772\n",
      "epoch 13; iter: 800; batch classifier loss: 0.417652\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.361225\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.390566\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.364461\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.441756\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.478761\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.390993\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.445063\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.358631\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.380966\n",
      "epoch 14; iter: 0; batch classifier loss: 0.368036\n",
      "epoch 14; iter: 200; batch classifier loss: 0.438276\n",
      "epoch 14; iter: 400; batch classifier loss: 0.441786\n",
      "epoch 14; iter: 600; batch classifier loss: 0.424462\n",
      "epoch 14; iter: 800; batch classifier loss: 0.389239\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.454615\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.512428\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.455787\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.464418\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.433566\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.332194\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.452841\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.363873\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.370430\n",
      "epoch 15; iter: 0; batch classifier loss: 0.368416\n",
      "epoch 15; iter: 200; batch classifier loss: 0.490505\n",
      "epoch 15; iter: 400; batch classifier loss: 0.360204\n",
      "epoch 15; iter: 600; batch classifier loss: 0.426221\n",
      "epoch 15; iter: 800; batch classifier loss: 0.340491\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.414387\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.371119\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.387482\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.430196\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.483076\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.443252\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.338398\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.460216\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.371212\n",
      "epoch 16; iter: 0; batch classifier loss: 0.427309\n",
      "epoch 16; iter: 200; batch classifier loss: 0.523310\n",
      "epoch 16; iter: 400; batch classifier loss: 0.475650\n",
      "epoch 16; iter: 600; batch classifier loss: 0.515181\n",
      "epoch 16; iter: 800; batch classifier loss: 0.380391\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.473405\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.291708\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.441728\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.334789\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.375637\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.501154\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.383362\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.380743\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.373603\n",
      "epoch 17; iter: 0; batch classifier loss: 0.404425\n",
      "epoch 17; iter: 200; batch classifier loss: 0.415953\n",
      "epoch 17; iter: 400; batch classifier loss: 0.436315\n",
      "epoch 17; iter: 600; batch classifier loss: 0.397111\n",
      "epoch 17; iter: 800; batch classifier loss: 0.388152\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.380954\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.428084\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.429597\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.477045\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.450391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17; iter: 2000; batch classifier loss: 0.449264\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.482970\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.325133\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.356162\n",
      "epoch 18; iter: 0; batch classifier loss: 0.304269\n",
      "epoch 18; iter: 200; batch classifier loss: 0.385004\n",
      "epoch 18; iter: 400; batch classifier loss: 0.383739\n",
      "epoch 18; iter: 600; batch classifier loss: 0.487728\n",
      "epoch 18; iter: 800; batch classifier loss: 0.424957\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.500557\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.380351\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.397449\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.332626\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.391363\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.416303\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.364253\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.517943\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.408700\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465280\n",
      "epoch 19; iter: 200; batch classifier loss: 0.337764\n",
      "epoch 19; iter: 400; batch classifier loss: 0.361375\n",
      "epoch 19; iter: 600; batch classifier loss: 0.432288\n",
      "epoch 19; iter: 800; batch classifier loss: 0.455159\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.394256\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.452004\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.411265\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.418352\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.422800\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.390560\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.370985\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.411459\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.391472\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491742\n",
      "epoch 20; iter: 200; batch classifier loss: 0.473825\n",
      "epoch 20; iter: 400; batch classifier loss: 0.402787\n",
      "epoch 20; iter: 600; batch classifier loss: 0.441207\n",
      "epoch 20; iter: 800; batch classifier loss: 0.366088\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.420386\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.352173\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.413931\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.514444\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.440691\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.366596\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.423067\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.429963\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.385423\n",
      "epoch 21; iter: 0; batch classifier loss: 0.403490\n",
      "epoch 21; iter: 200; batch classifier loss: 0.444959\n",
      "epoch 21; iter: 400; batch classifier loss: 0.489512\n",
      "epoch 21; iter: 600; batch classifier loss: 0.413264\n",
      "epoch 21; iter: 800; batch classifier loss: 0.407877\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.396017\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.439033\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.448387\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.418947\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.421407\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.565151\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.419550\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.411766\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.447932\n",
      "epoch 22; iter: 0; batch classifier loss: 0.381079\n",
      "epoch 22; iter: 200; batch classifier loss: 0.357456\n",
      "epoch 22; iter: 400; batch classifier loss: 0.447398\n",
      "epoch 22; iter: 600; batch classifier loss: 0.390154\n",
      "epoch 22; iter: 800; batch classifier loss: 0.434131\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.384844\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.457853\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.417235\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.375644\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.420224\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.396102\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.458665\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.462220\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.384430\n",
      "epoch 23; iter: 0; batch classifier loss: 0.483929\n",
      "epoch 23; iter: 200; batch classifier loss: 0.383013\n",
      "epoch 23; iter: 400; batch classifier loss: 0.338822\n",
      "epoch 23; iter: 600; batch classifier loss: 0.464039\n",
      "epoch 23; iter: 800; batch classifier loss: 0.429886\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.391786\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.398089\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.416567\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.413703\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.410656\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.346632\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.413768\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.387900\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.397294\n",
      "epoch 24; iter: 0; batch classifier loss: 0.443474\n",
      "epoch 24; iter: 200; batch classifier loss: 0.424157\n",
      "epoch 24; iter: 400; batch classifier loss: 0.416789\n",
      "epoch 24; iter: 600; batch classifier loss: 0.466841\n",
      "epoch 24; iter: 800; batch classifier loss: 0.408954\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.331920\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.408600\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.427836\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.408471\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.409002\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.429735\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.384136\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.398890\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.443214\n",
      "epoch 25; iter: 0; batch classifier loss: 0.386916\n",
      "epoch 25; iter: 200; batch classifier loss: 0.424975\n",
      "epoch 25; iter: 400; batch classifier loss: 0.410725\n",
      "epoch 25; iter: 600; batch classifier loss: 0.337111\n",
      "epoch 25; iter: 800; batch classifier loss: 0.438498\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.419529\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.468198\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.458986\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.465197\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.529976\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.483086\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.449154\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.470883\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.464508\n",
      "epoch 26; iter: 0; batch classifier loss: 0.435727\n",
      "epoch 26; iter: 200; batch classifier loss: 0.413765\n",
      "epoch 26; iter: 400; batch classifier loss: 0.466761\n",
      "epoch 26; iter: 600; batch classifier loss: 0.466333\n",
      "epoch 26; iter: 800; batch classifier loss: 0.511757\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.396695\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.405138\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.438869\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.345580\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.403957\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.398509\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.477914\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.501556\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.427879\n",
      "epoch 27; iter: 0; batch classifier loss: 0.379248\n",
      "epoch 27; iter: 200; batch classifier loss: 0.457170\n",
      "epoch 27; iter: 400; batch classifier loss: 0.448965\n",
      "epoch 27; iter: 600; batch classifier loss: 0.494800\n",
      "epoch 27; iter: 800; batch classifier loss: 0.466772\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.442302\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.389982\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.448102\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.478351\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.371171\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.402318\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.409198\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.383947\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.443569\n",
      "epoch 28; iter: 0; batch classifier loss: 0.397907\n",
      "epoch 28; iter: 200; batch classifier loss: 0.374517\n",
      "epoch 28; iter: 400; batch classifier loss: 0.415194\n",
      "epoch 28; iter: 600; batch classifier loss: 0.462699\n",
      "epoch 28; iter: 800; batch classifier loss: 0.435827\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.439176\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.487683\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.396408\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.462597\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.393075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28; iter: 2000; batch classifier loss: 0.419834\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.389021\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.433645\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.437820\n",
      "epoch 29; iter: 0; batch classifier loss: 0.416696\n",
      "epoch 29; iter: 200; batch classifier loss: 0.417415\n",
      "epoch 29; iter: 400; batch classifier loss: 0.382796\n",
      "epoch 29; iter: 600; batch classifier loss: 0.384912\n",
      "epoch 29; iter: 800; batch classifier loss: 0.446527\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.415525\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.402459\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.330488\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.404814\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.442584\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.465205\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.384249\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.358562\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.395461\n",
      "epoch 30; iter: 0; batch classifier loss: 0.441280\n",
      "epoch 30; iter: 200; batch classifier loss: 0.392842\n",
      "epoch 30; iter: 400; batch classifier loss: 0.433123\n",
      "epoch 30; iter: 600; batch classifier loss: 0.361081\n",
      "epoch 30; iter: 800; batch classifier loss: 0.328756\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.469500\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.419442\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.376640\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.442370\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.325191\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.459232\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.391251\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.381750\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.486443\n",
      "epoch 31; iter: 0; batch classifier loss: 0.409337\n",
      "epoch 31; iter: 200; batch classifier loss: 0.485826\n",
      "epoch 31; iter: 400; batch classifier loss: 0.539792\n",
      "epoch 31; iter: 600; batch classifier loss: 0.371420\n",
      "epoch 31; iter: 800; batch classifier loss: 0.396740\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.432776\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.354169\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.438528\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.366737\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.450779\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.388514\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.380980\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.388760\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.401283\n",
      "epoch 32; iter: 0; batch classifier loss: 0.399714\n",
      "epoch 32; iter: 200; batch classifier loss: 0.390698\n",
      "epoch 32; iter: 400; batch classifier loss: 0.461449\n",
      "epoch 32; iter: 600; batch classifier loss: 0.376461\n",
      "epoch 32; iter: 800; batch classifier loss: 0.370863\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.418030\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.354115\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.488110\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.450047\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.384614\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.343736\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.441538\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.435707\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.277001\n",
      "epoch 33; iter: 0; batch classifier loss: 0.386147\n",
      "epoch 33; iter: 200; batch classifier loss: 0.411706\n",
      "epoch 33; iter: 400; batch classifier loss: 0.401086\n",
      "epoch 33; iter: 600; batch classifier loss: 0.348725\n",
      "epoch 33; iter: 800; batch classifier loss: 0.391037\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.417796\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.427075\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.312915\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.331991\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.470274\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.445584\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.445309\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.469698\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.498498\n",
      "epoch 34; iter: 0; batch classifier loss: 0.340688\n",
      "epoch 34; iter: 200; batch classifier loss: 0.382772\n",
      "epoch 34; iter: 400; batch classifier loss: 0.448058\n",
      "epoch 34; iter: 600; batch classifier loss: 0.387033\n",
      "epoch 34; iter: 800; batch classifier loss: 0.400169\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.424619\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.391624\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.435870\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.435579\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.444396\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.508123\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.499620\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.426276\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.413746\n",
      "epoch 35; iter: 0; batch classifier loss: 0.450740\n",
      "epoch 35; iter: 200; batch classifier loss: 0.444531\n",
      "epoch 35; iter: 400; batch classifier loss: 0.341814\n",
      "epoch 35; iter: 600; batch classifier loss: 0.400257\n",
      "epoch 35; iter: 800; batch classifier loss: 0.368916\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.344615\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.433058\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.360003\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.429487\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.406710\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.341721\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.461689\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.369063\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.326560\n",
      "epoch 36; iter: 0; batch classifier loss: 0.524387\n",
      "epoch 36; iter: 200; batch classifier loss: 0.359059\n",
      "epoch 36; iter: 400; batch classifier loss: 0.408600\n",
      "epoch 36; iter: 600; batch classifier loss: 0.434903\n",
      "epoch 36; iter: 800; batch classifier loss: 0.440182\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.374756\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.427723\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.386836\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.437011\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.439973\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.385009\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.347247\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.388907\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.435399\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402606\n",
      "epoch 37; iter: 200; batch classifier loss: 0.415691\n",
      "epoch 37; iter: 400; batch classifier loss: 0.416781\n",
      "epoch 37; iter: 600; batch classifier loss: 0.420637\n",
      "epoch 37; iter: 800; batch classifier loss: 0.402709\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.519583\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.436783\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.350765\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.352991\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.371523\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.359422\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.369914\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.383772\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.447325\n",
      "epoch 38; iter: 0; batch classifier loss: 0.426346\n",
      "epoch 38; iter: 200; batch classifier loss: 0.401562\n",
      "epoch 38; iter: 400; batch classifier loss: 0.404475\n",
      "epoch 38; iter: 600; batch classifier loss: 0.389252\n",
      "epoch 38; iter: 800; batch classifier loss: 0.412684\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.369665\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.327630\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.367640\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.469204\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.389775\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.419205\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.388362\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.338453\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.468810\n",
      "epoch 39; iter: 0; batch classifier loss: 0.362035\n",
      "epoch 39; iter: 200; batch classifier loss: 0.361419\n",
      "epoch 39; iter: 400; batch classifier loss: 0.409929\n",
      "epoch 39; iter: 600; batch classifier loss: 0.479827\n",
      "epoch 39; iter: 800; batch classifier loss: 0.417470\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.391464\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.367349\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.565220\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.390934\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.449144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39; iter: 2000; batch classifier loss: 0.396158\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.460461\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.408206\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.442094\n",
      "epoch 40; iter: 0; batch classifier loss: 0.383813\n",
      "epoch 40; iter: 200; batch classifier loss: 0.429260\n",
      "epoch 40; iter: 400; batch classifier loss: 0.469240\n",
      "epoch 40; iter: 600; batch classifier loss: 0.383652\n",
      "epoch 40; iter: 800; batch classifier loss: 0.374780\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.373736\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.391745\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.493817\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.439104\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.467726\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.456609\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.562801\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.416528\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.366676\n",
      "epoch 41; iter: 0; batch classifier loss: 0.529609\n",
      "epoch 41; iter: 200; batch classifier loss: 0.526743\n",
      "epoch 41; iter: 400; batch classifier loss: 0.336868\n",
      "epoch 41; iter: 600; batch classifier loss: 0.311094\n",
      "epoch 41; iter: 800; batch classifier loss: 0.393345\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.447900\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.458887\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.425067\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.452086\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.471419\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.354682\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.390837\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.496195\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.376610\n",
      "epoch 42; iter: 0; batch classifier loss: 0.433000\n",
      "epoch 42; iter: 200; batch classifier loss: 0.293604\n",
      "epoch 42; iter: 400; batch classifier loss: 0.375629\n",
      "epoch 42; iter: 600; batch classifier loss: 0.442600\n",
      "epoch 42; iter: 800; batch classifier loss: 0.363890\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.333393\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.411734\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.476781\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.330690\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.386236\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.462668\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.494302\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.455950\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.451393\n",
      "epoch 43; iter: 0; batch classifier loss: 0.388771\n",
      "epoch 43; iter: 200; batch classifier loss: 0.402401\n",
      "epoch 43; iter: 400; batch classifier loss: 0.411681\n",
      "epoch 43; iter: 600; batch classifier loss: 0.414268\n",
      "epoch 43; iter: 800; batch classifier loss: 0.425888\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.460138\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.398137\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.403077\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.473675\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.502854\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.392827\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.410144\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.388153\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.413300\n",
      "epoch 44; iter: 0; batch classifier loss: 0.412629\n",
      "epoch 44; iter: 200; batch classifier loss: 0.331558\n",
      "epoch 44; iter: 400; batch classifier loss: 0.402852\n",
      "epoch 44; iter: 600; batch classifier loss: 0.416581\n",
      "epoch 44; iter: 800; batch classifier loss: 0.382925\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.354938\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.439017\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.404364\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.396775\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.428428\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.410434\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.385613\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.357595\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.479458\n",
      "epoch 45; iter: 0; batch classifier loss: 0.382494\n",
      "epoch 45; iter: 200; batch classifier loss: 0.421171\n",
      "epoch 45; iter: 400; batch classifier loss: 0.383106\n",
      "epoch 45; iter: 600; batch classifier loss: 0.396831\n",
      "epoch 45; iter: 800; batch classifier loss: 0.448029\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.445748\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.455448\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.417322\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.404100\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.440390\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.415011\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.420543\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.366615\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.343434\n",
      "epoch 46; iter: 0; batch classifier loss: 0.315192\n",
      "epoch 46; iter: 200; batch classifier loss: 0.418286\n",
      "epoch 46; iter: 400; batch classifier loss: 0.323059\n",
      "epoch 46; iter: 600; batch classifier loss: 0.431387\n",
      "epoch 46; iter: 800; batch classifier loss: 0.385766\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.422748\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.356586\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.411465\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.323940\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.328116\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.382674\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.435958\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.493877\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.453673\n",
      "epoch 47; iter: 0; batch classifier loss: 0.514390\n",
      "epoch 47; iter: 200; batch classifier loss: 0.454330\n",
      "epoch 47; iter: 400; batch classifier loss: 0.354416\n",
      "epoch 47; iter: 600; batch classifier loss: 0.339059\n",
      "epoch 47; iter: 800; batch classifier loss: 0.438475\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.356497\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.393575\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.395603\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.411264\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.475708\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.299832\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.448126\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.430690\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.478150\n",
      "epoch 48; iter: 0; batch classifier loss: 0.426447\n",
      "epoch 48; iter: 200; batch classifier loss: 0.381059\n",
      "epoch 48; iter: 400; batch classifier loss: 0.364703\n",
      "epoch 48; iter: 600; batch classifier loss: 0.434505\n",
      "epoch 48; iter: 800; batch classifier loss: 0.402068\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.392910\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.443065\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.399485\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.427209\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.410432\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.455526\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.380813\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.363608\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.427529\n",
      "epoch 49; iter: 0; batch classifier loss: 0.376603\n",
      "epoch 49; iter: 200; batch classifier loss: 0.488055\n",
      "epoch 49; iter: 400; batch classifier loss: 0.442317\n",
      "epoch 49; iter: 600; batch classifier loss: 0.460800\n",
      "epoch 49; iter: 800; batch classifier loss: 0.417001\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.536482\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.463236\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.386540\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.393865\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.397313\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.448715\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.541217\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.337549\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.376518\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708941; batch adversarial loss: 0.715332\n",
      "epoch 0; iter: 200; batch classifier loss: 0.316232; batch adversarial loss: 0.634963\n",
      "epoch 1; iter: 0; batch classifier loss: 0.488188; batch adversarial loss: 0.598781\n",
      "epoch 1; iter: 200; batch classifier loss: 0.427772; batch adversarial loss: 0.540570\n",
      "epoch 2; iter: 0; batch classifier loss: 0.422298; batch adversarial loss: 0.504291\n",
      "epoch 2; iter: 200; batch classifier loss: 0.462828; batch adversarial loss: 0.542322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3; iter: 0; batch classifier loss: 0.553332; batch adversarial loss: 0.478398\n",
      "epoch 3; iter: 200; batch classifier loss: 0.383461; batch adversarial loss: 0.546040\n",
      "epoch 4; iter: 0; batch classifier loss: 0.446428; batch adversarial loss: 0.476611\n",
      "epoch 4; iter: 200; batch classifier loss: 0.454603; batch adversarial loss: 0.447111\n",
      "epoch 5; iter: 0; batch classifier loss: 0.362503; batch adversarial loss: 0.475174\n",
      "epoch 5; iter: 200; batch classifier loss: 0.522141; batch adversarial loss: 0.473113\n",
      "epoch 6; iter: 0; batch classifier loss: 0.432440; batch adversarial loss: 0.432051\n",
      "epoch 6; iter: 200; batch classifier loss: 0.441553; batch adversarial loss: 0.445342\n",
      "epoch 7; iter: 0; batch classifier loss: 0.372867; batch adversarial loss: 0.413962\n",
      "epoch 7; iter: 200; batch classifier loss: 0.594580; batch adversarial loss: 0.377180\n",
      "epoch 8; iter: 0; batch classifier loss: 0.435134; batch adversarial loss: 0.435743\n",
      "epoch 8; iter: 200; batch classifier loss: 0.437340; batch adversarial loss: 0.459477\n",
      "epoch 9; iter: 0; batch classifier loss: 0.505297; batch adversarial loss: 0.388576\n",
      "epoch 9; iter: 200; batch classifier loss: 0.369510; batch adversarial loss: 0.393559\n",
      "epoch 10; iter: 0; batch classifier loss: 0.434803; batch adversarial loss: 0.374149\n",
      "epoch 10; iter: 200; batch classifier loss: 0.473687; batch adversarial loss: 0.372057\n",
      "epoch 11; iter: 0; batch classifier loss: 0.414360; batch adversarial loss: 0.494648\n",
      "epoch 11; iter: 200; batch classifier loss: 0.466621; batch adversarial loss: 0.417538\n",
      "epoch 12; iter: 0; batch classifier loss: 0.420250; batch adversarial loss: 0.415842\n",
      "epoch 12; iter: 200; batch classifier loss: 0.432155; batch adversarial loss: 0.416332\n",
      "epoch 13; iter: 0; batch classifier loss: 0.443358; batch adversarial loss: 0.409167\n",
      "epoch 13; iter: 200; batch classifier loss: 0.398345; batch adversarial loss: 0.425407\n",
      "epoch 14; iter: 0; batch classifier loss: 0.383181; batch adversarial loss: 0.430970\n",
      "epoch 14; iter: 200; batch classifier loss: 0.341708; batch adversarial loss: 0.413912\n",
      "epoch 15; iter: 0; batch classifier loss: 0.444278; batch adversarial loss: 0.439373\n",
      "epoch 15; iter: 200; batch classifier loss: 0.328298; batch adversarial loss: 0.343868\n",
      "epoch 16; iter: 0; batch classifier loss: 0.413077; batch adversarial loss: 0.392578\n",
      "epoch 16; iter: 200; batch classifier loss: 0.453522; batch adversarial loss: 0.540782\n",
      "epoch 17; iter: 0; batch classifier loss: 0.484330; batch adversarial loss: 0.257049\n",
      "epoch 17; iter: 200; batch classifier loss: 0.489114; batch adversarial loss: 0.382392\n",
      "epoch 18; iter: 0; batch classifier loss: 0.442386; batch adversarial loss: 0.413080\n",
      "epoch 18; iter: 200; batch classifier loss: 0.387863; batch adversarial loss: 0.450934\n",
      "epoch 19; iter: 0; batch classifier loss: 0.362042; batch adversarial loss: 0.397403\n",
      "epoch 19; iter: 200; batch classifier loss: 0.487175; batch adversarial loss: 0.481159\n",
      "epoch 20; iter: 0; batch classifier loss: 0.400371; batch adversarial loss: 0.402608\n",
      "epoch 20; iter: 200; batch classifier loss: 0.402279; batch adversarial loss: 0.380200\n",
      "epoch 21; iter: 0; batch classifier loss: 0.389482; batch adversarial loss: 0.565621\n",
      "epoch 21; iter: 200; batch classifier loss: 0.474980; batch adversarial loss: 0.415867\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446986; batch adversarial loss: 0.431538\n",
      "epoch 22; iter: 200; batch classifier loss: 0.411643; batch adversarial loss: 0.440825\n",
      "epoch 23; iter: 0; batch classifier loss: 0.501946; batch adversarial loss: 0.446188\n",
      "epoch 23; iter: 200; batch classifier loss: 0.413539; batch adversarial loss: 0.431857\n",
      "epoch 24; iter: 0; batch classifier loss: 0.384031; batch adversarial loss: 0.397855\n",
      "epoch 24; iter: 200; batch classifier loss: 0.443741; batch adversarial loss: 0.335519\n",
      "epoch 25; iter: 0; batch classifier loss: 0.436198; batch adversarial loss: 0.460778\n",
      "epoch 25; iter: 200; batch classifier loss: 0.481017; batch adversarial loss: 0.462999\n",
      "epoch 26; iter: 0; batch classifier loss: 0.484000; batch adversarial loss: 0.483283\n",
      "epoch 26; iter: 200; batch classifier loss: 0.353721; batch adversarial loss: 0.410641\n",
      "epoch 27; iter: 0; batch classifier loss: 0.373370; batch adversarial loss: 0.455978\n",
      "epoch 27; iter: 200; batch classifier loss: 0.365456; batch adversarial loss: 0.371046\n",
      "epoch 28; iter: 0; batch classifier loss: 0.404020; batch adversarial loss: 0.417419\n",
      "epoch 28; iter: 200; batch classifier loss: 0.360221; batch adversarial loss: 0.556913\n",
      "epoch 29; iter: 0; batch classifier loss: 0.473906; batch adversarial loss: 0.425405\n",
      "epoch 29; iter: 200; batch classifier loss: 0.465609; batch adversarial loss: 0.448291\n",
      "epoch 30; iter: 0; batch classifier loss: 0.511617; batch adversarial loss: 0.381330\n",
      "epoch 30; iter: 200; batch classifier loss: 0.491208; batch adversarial loss: 0.511377\n",
      "epoch 31; iter: 0; batch classifier loss: 0.380412; batch adversarial loss: 0.384052\n",
      "epoch 31; iter: 200; batch classifier loss: 0.372611; batch adversarial loss: 0.328871\n",
      "epoch 32; iter: 0; batch classifier loss: 0.471616; batch adversarial loss: 0.382715\n",
      "epoch 32; iter: 200; batch classifier loss: 0.415466; batch adversarial loss: 0.410755\n",
      "epoch 33; iter: 0; batch classifier loss: 0.426907; batch adversarial loss: 0.306849\n",
      "epoch 33; iter: 200; batch classifier loss: 0.422982; batch adversarial loss: 0.381748\n",
      "epoch 34; iter: 0; batch classifier loss: 0.464699; batch adversarial loss: 0.407844\n",
      "epoch 34; iter: 200; batch classifier loss: 0.357849; batch adversarial loss: 0.498829\n",
      "epoch 35; iter: 0; batch classifier loss: 0.463752; batch adversarial loss: 0.530220\n",
      "epoch 35; iter: 200; batch classifier loss: 0.500457; batch adversarial loss: 0.394302\n",
      "epoch 36; iter: 0; batch classifier loss: 0.371572; batch adversarial loss: 0.410729\n",
      "epoch 36; iter: 200; batch classifier loss: 0.494907; batch adversarial loss: 0.369246\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442104; batch adversarial loss: 0.541151\n",
      "epoch 37; iter: 200; batch classifier loss: 0.491734; batch adversarial loss: 0.357626\n",
      "epoch 38; iter: 0; batch classifier loss: 0.413189; batch adversarial loss: 0.359657\n",
      "epoch 38; iter: 200; batch classifier loss: 0.424068; batch adversarial loss: 0.329111\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436117; batch adversarial loss: 0.363356\n",
      "epoch 39; iter: 200; batch classifier loss: 0.491601; batch adversarial loss: 0.405603\n",
      "epoch 40; iter: 0; batch classifier loss: 0.395727; batch adversarial loss: 0.294513\n",
      "epoch 40; iter: 200; batch classifier loss: 0.402627; batch adversarial loss: 0.391531\n",
      "epoch 41; iter: 0; batch classifier loss: 0.438698; batch adversarial loss: 0.431199\n",
      "epoch 41; iter: 200; batch classifier loss: 0.383878; batch adversarial loss: 0.332016\n",
      "epoch 42; iter: 0; batch classifier loss: 0.453236; batch adversarial loss: 0.462601\n",
      "epoch 42; iter: 200; batch classifier loss: 0.460962; batch adversarial loss: 0.360198\n",
      "epoch 43; iter: 0; batch classifier loss: 0.322971; batch adversarial loss: 0.361398\n",
      "epoch 43; iter: 200; batch classifier loss: 0.415529; batch adversarial loss: 0.354001\n",
      "epoch 44; iter: 0; batch classifier loss: 0.457924; batch adversarial loss: 0.315547\n",
      "epoch 44; iter: 200; batch classifier loss: 0.559668; batch adversarial loss: 0.394188\n",
      "epoch 45; iter: 0; batch classifier loss: 0.398731; batch adversarial loss: 0.400911\n",
      "epoch 45; iter: 200; batch classifier loss: 0.441019; batch adversarial loss: 0.469063\n",
      "epoch 46; iter: 0; batch classifier loss: 0.339293; batch adversarial loss: 0.366409\n",
      "epoch 46; iter: 200; batch classifier loss: 0.395216; batch adversarial loss: 0.486937\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487522; batch adversarial loss: 0.379705\n",
      "epoch 47; iter: 200; batch classifier loss: 0.404744; batch adversarial loss: 0.389388\n",
      "epoch 48; iter: 0; batch classifier loss: 0.416138; batch adversarial loss: 0.334423\n",
      "epoch 48; iter: 200; batch classifier loss: 0.432786; batch adversarial loss: 0.291548\n",
      "epoch 49; iter: 0; batch classifier loss: 0.506124; batch adversarial loss: 0.446770\n",
      "epoch 49; iter: 200; batch classifier loss: 0.474976; batch adversarial loss: 0.377962\n",
      "epoch 0; iter: 0; batch classifier loss: 0.637260\n",
      "epoch 0; iter: 200; batch classifier loss: 0.457806\n",
      "epoch 1; iter: 0; batch classifier loss: 0.382599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1; iter: 200; batch classifier loss: 0.495708\n",
      "epoch 2; iter: 0; batch classifier loss: 0.384346\n",
      "epoch 2; iter: 200; batch classifier loss: 0.480904\n",
      "epoch 3; iter: 0; batch classifier loss: 0.415745\n",
      "epoch 3; iter: 200; batch classifier loss: 0.332185\n",
      "epoch 4; iter: 0; batch classifier loss: 0.409826\n",
      "epoch 4; iter: 200; batch classifier loss: 0.389285\n",
      "epoch 5; iter: 0; batch classifier loss: 0.483524\n",
      "epoch 5; iter: 200; batch classifier loss: 0.468053\n",
      "epoch 6; iter: 0; batch classifier loss: 0.402540\n",
      "epoch 6; iter: 200; batch classifier loss: 0.403393\n",
      "epoch 7; iter: 0; batch classifier loss: 0.457146\n",
      "epoch 7; iter: 200; batch classifier loss: 0.422553\n",
      "epoch 8; iter: 0; batch classifier loss: 0.436558\n",
      "epoch 8; iter: 200; batch classifier loss: 0.414937\n",
      "epoch 9; iter: 0; batch classifier loss: 0.440835\n",
      "epoch 9; iter: 200; batch classifier loss: 0.401713\n",
      "epoch 10; iter: 0; batch classifier loss: 0.441734\n",
      "epoch 10; iter: 200; batch classifier loss: 0.394101\n",
      "epoch 11; iter: 0; batch classifier loss: 0.398194\n",
      "epoch 11; iter: 200; batch classifier loss: 0.335300\n",
      "epoch 12; iter: 0; batch classifier loss: 0.404335\n",
      "epoch 12; iter: 200; batch classifier loss: 0.450147\n",
      "epoch 13; iter: 0; batch classifier loss: 0.455953\n",
      "epoch 13; iter: 200; batch classifier loss: 0.459777\n",
      "epoch 14; iter: 0; batch classifier loss: 0.397739\n",
      "epoch 14; iter: 200; batch classifier loss: 0.462202\n",
      "epoch 15; iter: 0; batch classifier loss: 0.434362\n",
      "epoch 15; iter: 200; batch classifier loss: 0.387825\n",
      "epoch 16; iter: 0; batch classifier loss: 0.377030\n",
      "epoch 16; iter: 200; batch classifier loss: 0.438551\n",
      "epoch 17; iter: 0; batch classifier loss: 0.383692\n",
      "epoch 17; iter: 200; batch classifier loss: 0.322345\n",
      "epoch 18; iter: 0; batch classifier loss: 0.457111\n",
      "epoch 18; iter: 200; batch classifier loss: 0.452941\n",
      "epoch 19; iter: 0; batch classifier loss: 0.434708\n",
      "epoch 19; iter: 200; batch classifier loss: 0.424476\n",
      "epoch 20; iter: 0; batch classifier loss: 0.460872\n",
      "epoch 20; iter: 200; batch classifier loss: 0.392687\n",
      "epoch 21; iter: 0; batch classifier loss: 0.388361\n",
      "epoch 21; iter: 200; batch classifier loss: 0.434633\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437746\n",
      "epoch 22; iter: 200; batch classifier loss: 0.294411\n",
      "epoch 23; iter: 0; batch classifier loss: 0.454029\n",
      "epoch 23; iter: 200; batch classifier loss: 0.379358\n",
      "epoch 24; iter: 0; batch classifier loss: 0.410072\n",
      "epoch 24; iter: 200; batch classifier loss: 0.438869\n",
      "epoch 25; iter: 0; batch classifier loss: 0.360695\n",
      "epoch 25; iter: 200; batch classifier loss: 0.312067\n",
      "epoch 26; iter: 0; batch classifier loss: 0.425848\n",
      "epoch 26; iter: 200; batch classifier loss: 0.488449\n",
      "epoch 27; iter: 0; batch classifier loss: 0.457310\n",
      "epoch 27; iter: 200; batch classifier loss: 0.411433\n",
      "epoch 28; iter: 0; batch classifier loss: 0.390820\n",
      "epoch 28; iter: 200; batch classifier loss: 0.383757\n",
      "epoch 29; iter: 0; batch classifier loss: 0.454063\n",
      "epoch 29; iter: 200; batch classifier loss: 0.463749\n",
      "epoch 30; iter: 0; batch classifier loss: 0.362379\n",
      "epoch 30; iter: 200; batch classifier loss: 0.391858\n",
      "epoch 31; iter: 0; batch classifier loss: 0.372589\n",
      "epoch 31; iter: 200; batch classifier loss: 0.452933\n",
      "epoch 32; iter: 0; batch classifier loss: 0.469523\n",
      "epoch 32; iter: 200; batch classifier loss: 0.409108\n",
      "epoch 33; iter: 0; batch classifier loss: 0.447360\n",
      "epoch 33; iter: 200; batch classifier loss: 0.301402\n",
      "epoch 34; iter: 0; batch classifier loss: 0.319849\n",
      "epoch 34; iter: 200; batch classifier loss: 0.419780\n",
      "epoch 35; iter: 0; batch classifier loss: 0.410101\n",
      "epoch 35; iter: 200; batch classifier loss: 0.352633\n",
      "epoch 36; iter: 0; batch classifier loss: 0.379914\n",
      "epoch 36; iter: 200; batch classifier loss: 0.406943\n",
      "epoch 37; iter: 0; batch classifier loss: 0.372521\n",
      "epoch 37; iter: 200; batch classifier loss: 0.410811\n",
      "epoch 38; iter: 0; batch classifier loss: 0.388687\n",
      "epoch 38; iter: 200; batch classifier loss: 0.404633\n",
      "epoch 39; iter: 0; batch classifier loss: 0.446770\n",
      "epoch 39; iter: 200; batch classifier loss: 0.421157\n",
      "epoch 40; iter: 0; batch classifier loss: 0.337272\n",
      "epoch 40; iter: 200; batch classifier loss: 0.438853\n",
      "epoch 41; iter: 0; batch classifier loss: 0.467682\n",
      "epoch 41; iter: 200; batch classifier loss: 0.356521\n",
      "epoch 42; iter: 0; batch classifier loss: 0.344324\n",
      "epoch 42; iter: 200; batch classifier loss: 0.424140\n",
      "epoch 43; iter: 0; batch classifier loss: 0.352024\n",
      "epoch 43; iter: 200; batch classifier loss: 0.445375\n",
      "epoch 44; iter: 0; batch classifier loss: 0.462330\n",
      "epoch 44; iter: 200; batch classifier loss: 0.443082\n",
      "epoch 45; iter: 0; batch classifier loss: 0.493957\n",
      "epoch 45; iter: 200; batch classifier loss: 0.398874\n",
      "epoch 46; iter: 0; batch classifier loss: 0.496750\n",
      "epoch 46; iter: 200; batch classifier loss: 0.383026\n",
      "epoch 47; iter: 0; batch classifier loss: 0.403687\n",
      "epoch 47; iter: 200; batch classifier loss: 0.465589\n",
      "epoch 48; iter: 0; batch classifier loss: 0.433669\n",
      "epoch 48; iter: 200; batch classifier loss: 0.445817\n",
      "epoch 49; iter: 0; batch classifier loss: 0.362958\n",
      "epoch 49; iter: 200; batch classifier loss: 0.462918\n",
      "run = 10\n",
      "epoch 0; iter: 0; batch classifier loss: 0.694872; batch adversarial loss: 0.802350\n",
      "epoch 0; iter: 200; batch classifier loss: 0.739780; batch adversarial loss: 0.651966\n",
      "epoch 0; iter: 400; batch classifier loss: 0.457373; batch adversarial loss: 0.579667\n",
      "epoch 0; iter: 600; batch classifier loss: 0.438661; batch adversarial loss: 0.560408\n",
      "epoch 0; iter: 800; batch classifier loss: 0.451987; batch adversarial loss: 0.526860\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.453898; batch adversarial loss: 0.529679\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.483713; batch adversarial loss: 0.464665\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.379046; batch adversarial loss: 0.464275\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.361257; batch adversarial loss: 0.459381\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.461643; batch adversarial loss: 0.451816\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.331834; batch adversarial loss: 0.424367\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.517498; batch adversarial loss: 0.463643\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.395303; batch adversarial loss: 0.458686\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.480295; batch adversarial loss: 0.362682\n",
      "epoch 1; iter: 0; batch classifier loss: 0.386441; batch adversarial loss: 0.429822\n",
      "epoch 1; iter: 200; batch classifier loss: 0.439060; batch adversarial loss: 0.429989\n",
      "epoch 1; iter: 400; batch classifier loss: 0.405227; batch adversarial loss: 0.420710\n",
      "epoch 1; iter: 600; batch classifier loss: 0.344095; batch adversarial loss: 0.438844\n",
      "epoch 1; iter: 800; batch classifier loss: 0.467833; batch adversarial loss: 0.421874\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.327307; batch adversarial loss: 0.357924\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.439804; batch adversarial loss: 0.461020\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.336447; batch adversarial loss: 0.488452\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.340772; batch adversarial loss: 0.377659\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.382662; batch adversarial loss: 0.444985\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.388756; batch adversarial loss: 0.383302\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.418201; batch adversarial loss: 0.353945\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.442403; batch adversarial loss: 0.446980\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.404281; batch adversarial loss: 0.406671\n",
      "epoch 2; iter: 0; batch classifier loss: 0.429920; batch adversarial loss: 0.459966\n",
      "epoch 2; iter: 200; batch classifier loss: 0.374727; batch adversarial loss: 0.407183\n",
      "epoch 2; iter: 400; batch classifier loss: 0.494607; batch adversarial loss: 0.459939\n",
      "epoch 2; iter: 600; batch classifier loss: 0.413297; batch adversarial loss: 0.459524\n",
      "epoch 2; iter: 800; batch classifier loss: 0.375357; batch adversarial loss: 0.393107\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.406182; batch adversarial loss: 0.527953\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.439265; batch adversarial loss: 0.352366\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.400034; batch adversarial loss: 0.462770\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.462336; batch adversarial loss: 0.428479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2; iter: 1800; batch classifier loss: 0.369482; batch adversarial loss: 0.329248\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.436598; batch adversarial loss: 0.420530\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.415968; batch adversarial loss: 0.528737\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.422712; batch adversarial loss: 0.377812\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.436362; batch adversarial loss: 0.445465\n",
      "epoch 3; iter: 0; batch classifier loss: 0.436300; batch adversarial loss: 0.365303\n",
      "epoch 3; iter: 200; batch classifier loss: 0.470948; batch adversarial loss: 0.459708\n",
      "epoch 3; iter: 400; batch classifier loss: 0.419492; batch adversarial loss: 0.516648\n",
      "epoch 3; iter: 600; batch classifier loss: 0.418075; batch adversarial loss: 0.476755\n",
      "epoch 3; iter: 800; batch classifier loss: 0.514241; batch adversarial loss: 0.473955\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.415059; batch adversarial loss: 0.405543\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.471861; batch adversarial loss: 0.433327\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.457206; batch adversarial loss: 0.434075\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.473637; batch adversarial loss: 0.433066\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.447974; batch adversarial loss: 0.326339\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.405695; batch adversarial loss: 0.378000\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.443645; batch adversarial loss: 0.460137\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.447720; batch adversarial loss: 0.408672\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.466190; batch adversarial loss: 0.390301\n",
      "epoch 4; iter: 0; batch classifier loss: 0.387313; batch adversarial loss: 0.353574\n",
      "epoch 4; iter: 200; batch classifier loss: 0.434388; batch adversarial loss: 0.380018\n",
      "epoch 4; iter: 400; batch classifier loss: 0.400894; batch adversarial loss: 0.446653\n",
      "epoch 4; iter: 600; batch classifier loss: 0.436875; batch adversarial loss: 0.296804\n",
      "epoch 4; iter: 800; batch classifier loss: 0.470740; batch adversarial loss: 0.497861\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.422903; batch adversarial loss: 0.553501\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.410387; batch adversarial loss: 0.284300\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.458540; batch adversarial loss: 0.433216\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.335121; batch adversarial loss: 0.406824\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.414932; batch adversarial loss: 0.448249\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.343034; batch adversarial loss: 0.431942\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.467735; batch adversarial loss: 0.432369\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.384468; batch adversarial loss: 0.429285\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.381806; batch adversarial loss: 0.378284\n",
      "epoch 5; iter: 0; batch classifier loss: 0.441099; batch adversarial loss: 0.448590\n",
      "epoch 5; iter: 200; batch classifier loss: 0.404651; batch adversarial loss: 0.378634\n",
      "epoch 5; iter: 400; batch classifier loss: 0.497142; batch adversarial loss: 0.459329\n",
      "epoch 5; iter: 600; batch classifier loss: 0.395026; batch adversarial loss: 0.340348\n",
      "epoch 5; iter: 800; batch classifier loss: 0.377448; batch adversarial loss: 0.416107\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.366628; batch adversarial loss: 0.386938\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.423089; batch adversarial loss: 0.446382\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.445550; batch adversarial loss: 0.526210\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.374118; batch adversarial loss: 0.502137\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.442136; batch adversarial loss: 0.464032\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.430284; batch adversarial loss: 0.408995\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.470509; batch adversarial loss: 0.354047\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.471971; batch adversarial loss: 0.406376\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.370971; batch adversarial loss: 0.390754\n",
      "epoch 6; iter: 0; batch classifier loss: 0.294334; batch adversarial loss: 0.420762\n",
      "epoch 6; iter: 200; batch classifier loss: 0.365938; batch adversarial loss: 0.396385\n",
      "epoch 6; iter: 400; batch classifier loss: 0.446981; batch adversarial loss: 0.421003\n",
      "epoch 6; iter: 600; batch classifier loss: 0.389962; batch adversarial loss: 0.422853\n",
      "epoch 6; iter: 800; batch classifier loss: 0.516133; batch adversarial loss: 0.376681\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.367658; batch adversarial loss: 0.338020\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.446303; batch adversarial loss: 0.336335\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.365382; batch adversarial loss: 0.419241\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.413548; batch adversarial loss: 0.367738\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.397540; batch adversarial loss: 0.513366\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.448475; batch adversarial loss: 0.353300\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.458632; batch adversarial loss: 0.405004\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.496457; batch adversarial loss: 0.338799\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.415630; batch adversarial loss: 0.352308\n",
      "epoch 7; iter: 0; batch classifier loss: 0.385630; batch adversarial loss: 0.436909\n",
      "epoch 7; iter: 200; batch classifier loss: 0.402726; batch adversarial loss: 0.514017\n",
      "epoch 7; iter: 400; batch classifier loss: 0.556158; batch adversarial loss: 0.494018\n",
      "epoch 7; iter: 600; batch classifier loss: 0.430459; batch adversarial loss: 0.379111\n",
      "epoch 7; iter: 800; batch classifier loss: 0.438457; batch adversarial loss: 0.325732\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.438572; batch adversarial loss: 0.338105\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.412922; batch adversarial loss: 0.335865\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.497309; batch adversarial loss: 0.324140\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.414671; batch adversarial loss: 0.420505\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.375955; batch adversarial loss: 0.337036\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.411570; batch adversarial loss: 0.405360\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.485924; batch adversarial loss: 0.476493\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.376015; batch adversarial loss: 0.418855\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.369129; batch adversarial loss: 0.405094\n",
      "epoch 8; iter: 0; batch classifier loss: 0.369939; batch adversarial loss: 0.437525\n",
      "epoch 8; iter: 200; batch classifier loss: 0.424365; batch adversarial loss: 0.435527\n",
      "epoch 8; iter: 400; batch classifier loss: 0.419678; batch adversarial loss: 0.366555\n",
      "epoch 8; iter: 600; batch classifier loss: 0.333949; batch adversarial loss: 0.433999\n",
      "epoch 8; iter: 800; batch classifier loss: 0.496917; batch adversarial loss: 0.324512\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.403159; batch adversarial loss: 0.351493\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.401279; batch adversarial loss: 0.445420\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.423412; batch adversarial loss: 0.351951\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.375971; batch adversarial loss: 0.474204\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.403092; batch adversarial loss: 0.391388\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.470461; batch adversarial loss: 0.455227\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.317717; batch adversarial loss: 0.365338\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.437294; batch adversarial loss: 0.406364\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.494038; batch adversarial loss: 0.353520\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474610; batch adversarial loss: 0.432516\n",
      "epoch 9; iter: 200; batch classifier loss: 0.482676; batch adversarial loss: 0.418759\n",
      "epoch 9; iter: 400; batch classifier loss: 0.339353; batch adversarial loss: 0.441503\n",
      "epoch 9; iter: 600; batch classifier loss: 0.478032; batch adversarial loss: 0.475645\n",
      "epoch 9; iter: 800; batch classifier loss: 0.411900; batch adversarial loss: 0.408686\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.451958; batch adversarial loss: 0.381855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9; iter: 1200; batch classifier loss: 0.376791; batch adversarial loss: 0.419737\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.474521; batch adversarial loss: 0.392157\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.475562; batch adversarial loss: 0.501221\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.347586; batch adversarial loss: 0.417104\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.445530; batch adversarial loss: 0.349778\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.432975; batch adversarial loss: 0.421971\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.517556; batch adversarial loss: 0.366867\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.383273; batch adversarial loss: 0.391954\n",
      "epoch 10; iter: 0; batch classifier loss: 0.335462; batch adversarial loss: 0.543910\n",
      "epoch 10; iter: 200; batch classifier loss: 0.380476; batch adversarial loss: 0.434575\n",
      "epoch 10; iter: 400; batch classifier loss: 0.335923; batch adversarial loss: 0.431208\n",
      "epoch 10; iter: 600; batch classifier loss: 0.437118; batch adversarial loss: 0.473742\n",
      "epoch 10; iter: 800; batch classifier loss: 0.429304; batch adversarial loss: 0.338328\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.461672; batch adversarial loss: 0.461729\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.415599; batch adversarial loss: 0.381172\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.412135; batch adversarial loss: 0.367015\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.378206; batch adversarial loss: 0.406961\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.488826; batch adversarial loss: 0.523309\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.369482; batch adversarial loss: 0.520454\n",
      "epoch 10; iter: 2200; batch classifier loss: 0.382311; batch adversarial loss: 0.487606\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.395717; batch adversarial loss: 0.420224\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.475493; batch adversarial loss: 0.456464\n",
      "epoch 11; iter: 0; batch classifier loss: 0.419661; batch adversarial loss: 0.430002\n",
      "epoch 11; iter: 200; batch classifier loss: 0.386141; batch adversarial loss: 0.365793\n",
      "epoch 11; iter: 400; batch classifier loss: 0.440323; batch adversarial loss: 0.460806\n",
      "epoch 11; iter: 600; batch classifier loss: 0.505752; batch adversarial loss: 0.486852\n",
      "epoch 11; iter: 800; batch classifier loss: 0.318192; batch adversarial loss: 0.375751\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.524280; batch adversarial loss: 0.502927\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.394252; batch adversarial loss: 0.365221\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.370170; batch adversarial loss: 0.448164\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.472376; batch adversarial loss: 0.312099\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.429326; batch adversarial loss: 0.478444\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.375428; batch adversarial loss: 0.408210\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.376135; batch adversarial loss: 0.448153\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.406946; batch adversarial loss: 0.418947\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.405577; batch adversarial loss: 0.309291\n",
      "epoch 12; iter: 0; batch classifier loss: 0.383202; batch adversarial loss: 0.431044\n",
      "epoch 12; iter: 200; batch classifier loss: 0.423963; batch adversarial loss: 0.392611\n",
      "epoch 12; iter: 400; batch classifier loss: 0.425285; batch adversarial loss: 0.482677\n",
      "epoch 12; iter: 600; batch classifier loss: 0.367154; batch adversarial loss: 0.459158\n",
      "epoch 12; iter: 800; batch classifier loss: 0.416771; batch adversarial loss: 0.431304\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.462277; batch adversarial loss: 0.381880\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.410692; batch adversarial loss: 0.487354\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.391726; batch adversarial loss: 0.391799\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.384161; batch adversarial loss: 0.407838\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.391504; batch adversarial loss: 0.461562\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.408754; batch adversarial loss: 0.420061\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.414762; batch adversarial loss: 0.383930\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.430000; batch adversarial loss: 0.409455\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.413570; batch adversarial loss: 0.419597\n",
      "epoch 13; iter: 0; batch classifier loss: 0.418118; batch adversarial loss: 0.489086\n",
      "epoch 13; iter: 200; batch classifier loss: 0.468575; batch adversarial loss: 0.378433\n",
      "epoch 13; iter: 400; batch classifier loss: 0.315341; batch adversarial loss: 0.448423\n",
      "epoch 13; iter: 600; batch classifier loss: 0.403375; batch adversarial loss: 0.582104\n",
      "epoch 13; iter: 800; batch classifier loss: 0.386334; batch adversarial loss: 0.394067\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.524553; batch adversarial loss: 0.431867\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.448767; batch adversarial loss: 0.406811\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.364407; batch adversarial loss: 0.445527\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.373350; batch adversarial loss: 0.472184\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.434118; batch adversarial loss: 0.368496\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.434900; batch adversarial loss: 0.406842\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.461787; batch adversarial loss: 0.404095\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.413222; batch adversarial loss: 0.431713\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.426361; batch adversarial loss: 0.526537\n",
      "epoch 14; iter: 0; batch classifier loss: 0.438897; batch adversarial loss: 0.434747\n",
      "epoch 14; iter: 200; batch classifier loss: 0.433243; batch adversarial loss: 0.449700\n",
      "epoch 14; iter: 400; batch classifier loss: 0.431561; batch adversarial loss: 0.417989\n",
      "epoch 14; iter: 600; batch classifier loss: 0.456934; batch adversarial loss: 0.365320\n",
      "epoch 14; iter: 800; batch classifier loss: 0.384908; batch adversarial loss: 0.435625\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.407823; batch adversarial loss: 0.378116\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.362327; batch adversarial loss: 0.418394\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.439597; batch adversarial loss: 0.450925\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.446991; batch adversarial loss: 0.487820\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.426796; batch adversarial loss: 0.378580\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.428576; batch adversarial loss: 0.443761\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.488216; batch adversarial loss: 0.381542\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.466702; batch adversarial loss: 0.462869\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.421685; batch adversarial loss: 0.354398\n",
      "epoch 15; iter: 0; batch classifier loss: 0.359397; batch adversarial loss: 0.381289\n",
      "epoch 15; iter: 200; batch classifier loss: 0.407210; batch adversarial loss: 0.339639\n",
      "epoch 15; iter: 400; batch classifier loss: 0.395982; batch adversarial loss: 0.430917\n",
      "epoch 15; iter: 600; batch classifier loss: 0.361641; batch adversarial loss: 0.501111\n",
      "epoch 15; iter: 800; batch classifier loss: 0.424064; batch adversarial loss: 0.365207\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.507075; batch adversarial loss: 0.431696\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.425895; batch adversarial loss: 0.476079\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.349388; batch adversarial loss: 0.430872\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.458354; batch adversarial loss: 0.498857\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.462450; batch adversarial loss: 0.451664\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.416419; batch adversarial loss: 0.526995\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.475436; batch adversarial loss: 0.487853\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.424541; batch adversarial loss: 0.393821\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.321213; batch adversarial loss: 0.393649\n",
      "epoch 16; iter: 0; batch classifier loss: 0.442034; batch adversarial loss: 0.379151\n",
      "epoch 16; iter: 200; batch classifier loss: 0.463515; batch adversarial loss: 0.379693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16; iter: 400; batch classifier loss: 0.468191; batch adversarial loss: 0.366602\n",
      "epoch 16; iter: 600; batch classifier loss: 0.447212; batch adversarial loss: 0.366175\n",
      "epoch 16; iter: 800; batch classifier loss: 0.403097; batch adversarial loss: 0.459726\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.408984; batch adversarial loss: 0.486168\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.406548; batch adversarial loss: 0.540992\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.467928; batch adversarial loss: 0.436580\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.417052; batch adversarial loss: 0.405213\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.380924; batch adversarial loss: 0.556972\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.391235; batch adversarial loss: 0.392682\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.421689; batch adversarial loss: 0.417353\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.452969; batch adversarial loss: 0.401350\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.461554; batch adversarial loss: 0.365808\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377830; batch adversarial loss: 0.448371\n",
      "epoch 17; iter: 200; batch classifier loss: 0.395690; batch adversarial loss: 0.456655\n",
      "epoch 17; iter: 400; batch classifier loss: 0.390238; batch adversarial loss: 0.282820\n",
      "epoch 17; iter: 600; batch classifier loss: 0.455154; batch adversarial loss: 0.418440\n",
      "epoch 17; iter: 800; batch classifier loss: 0.366580; batch adversarial loss: 0.461312\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.356320; batch adversarial loss: 0.458219\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.452119; batch adversarial loss: 0.363367\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.437036; batch adversarial loss: 0.444346\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.405041; batch adversarial loss: 0.460799\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.322209; batch adversarial loss: 0.432548\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.406277; batch adversarial loss: 0.481476\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.427010; batch adversarial loss: 0.463381\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.427803; batch adversarial loss: 0.391312\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.391490; batch adversarial loss: 0.421036\n",
      "epoch 18; iter: 0; batch classifier loss: 0.427128; batch adversarial loss: 0.477851\n",
      "epoch 18; iter: 200; batch classifier loss: 0.454208; batch adversarial loss: 0.475937\n",
      "epoch 18; iter: 400; batch classifier loss: 0.311349; batch adversarial loss: 0.554729\n",
      "epoch 18; iter: 600; batch classifier loss: 0.495017; batch adversarial loss: 0.417353\n",
      "epoch 18; iter: 800; batch classifier loss: 0.409283; batch adversarial loss: 0.474267\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.402408; batch adversarial loss: 0.404604\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.465499; batch adversarial loss: 0.457951\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.419009; batch adversarial loss: 0.415549\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.414805; batch adversarial loss: 0.433664\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.320496; batch adversarial loss: 0.474515\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.403888; batch adversarial loss: 0.431321\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.420314; batch adversarial loss: 0.447501\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.357464; batch adversarial loss: 0.390020\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.421508; batch adversarial loss: 0.378954\n",
      "epoch 19; iter: 0; batch classifier loss: 0.468058; batch adversarial loss: 0.418451\n",
      "epoch 19; iter: 200; batch classifier loss: 0.451957; batch adversarial loss: 0.371836\n",
      "epoch 19; iter: 400; batch classifier loss: 0.450307; batch adversarial loss: 0.381150\n",
      "epoch 19; iter: 600; batch classifier loss: 0.365678; batch adversarial loss: 0.322708\n",
      "epoch 19; iter: 800; batch classifier loss: 0.506366; batch adversarial loss: 0.489086\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.383100; batch adversarial loss: 0.361498\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.399163; batch adversarial loss: 0.476596\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.448256; batch adversarial loss: 0.338327\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.328920; batch adversarial loss: 0.508873\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.443624; batch adversarial loss: 0.456453\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.391173; batch adversarial loss: 0.408089\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.451170; batch adversarial loss: 0.319597\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.346677; batch adversarial loss: 0.430898\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.399273; batch adversarial loss: 0.418377\n",
      "epoch 20; iter: 0; batch classifier loss: 0.402970; batch adversarial loss: 0.437661\n",
      "epoch 20; iter: 200; batch classifier loss: 0.420789; batch adversarial loss: 0.458978\n",
      "epoch 20; iter: 400; batch classifier loss: 0.421486; batch adversarial loss: 0.436403\n",
      "epoch 20; iter: 600; batch classifier loss: 0.403276; batch adversarial loss: 0.502363\n",
      "epoch 20; iter: 800; batch classifier loss: 0.380718; batch adversarial loss: 0.474402\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.413474; batch adversarial loss: 0.459842\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.372301; batch adversarial loss: 0.406723\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.463790; batch adversarial loss: 0.422822\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.361501; batch adversarial loss: 0.351825\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.390602; batch adversarial loss: 0.380743\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.432857; batch adversarial loss: 0.392181\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.409574; batch adversarial loss: 0.434009\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.440410; batch adversarial loss: 0.419415\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.368675; batch adversarial loss: 0.407615\n",
      "epoch 21; iter: 0; batch classifier loss: 0.398580; batch adversarial loss: 0.428219\n",
      "epoch 21; iter: 200; batch classifier loss: 0.394576; batch adversarial loss: 0.448171\n",
      "epoch 21; iter: 400; batch classifier loss: 0.425036; batch adversarial loss: 0.362460\n",
      "epoch 21; iter: 600; batch classifier loss: 0.502596; batch adversarial loss: 0.590325\n",
      "epoch 21; iter: 800; batch classifier loss: 0.541810; batch adversarial loss: 0.405680\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.480791; batch adversarial loss: 0.503932\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.428207; batch adversarial loss: 0.448011\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.414043; batch adversarial loss: 0.323071\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.476309; batch adversarial loss: 0.512353\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.482296; batch adversarial loss: 0.448024\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.485311; batch adversarial loss: 0.434368\n",
      "epoch 21; iter: 2200; batch classifier loss: 0.455669; batch adversarial loss: 0.477048\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.460929; batch adversarial loss: 0.537437\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.408142; batch adversarial loss: 0.389497\n",
      "epoch 22; iter: 0; batch classifier loss: 0.404885; batch adversarial loss: 0.402331\n",
      "epoch 22; iter: 200; batch classifier loss: 0.473379; batch adversarial loss: 0.392995\n",
      "epoch 22; iter: 400; batch classifier loss: 0.334473; batch adversarial loss: 0.488677\n",
      "epoch 22; iter: 600; batch classifier loss: 0.404091; batch adversarial loss: 0.474401\n",
      "epoch 22; iter: 800; batch classifier loss: 0.453411; batch adversarial loss: 0.447617\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.470273; batch adversarial loss: 0.465228\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.430934; batch adversarial loss: 0.442468\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.471707; batch adversarial loss: 0.418249\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.496457; batch adversarial loss: 0.424595\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.430748; batch adversarial loss: 0.294169\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.408526; batch adversarial loss: 0.445921\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.322165; batch adversarial loss: 0.393810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22; iter: 2400; batch classifier loss: 0.403380; batch adversarial loss: 0.378088\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.419038; batch adversarial loss: 0.369574\n",
      "epoch 23; iter: 0; batch classifier loss: 0.387538; batch adversarial loss: 0.308564\n",
      "epoch 23; iter: 200; batch classifier loss: 0.404250; batch adversarial loss: 0.456630\n",
      "epoch 23; iter: 400; batch classifier loss: 0.432043; batch adversarial loss: 0.393934\n",
      "epoch 23; iter: 600; batch classifier loss: 0.450469; batch adversarial loss: 0.418525\n",
      "epoch 23; iter: 800; batch classifier loss: 0.407853; batch adversarial loss: 0.474402\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.356107; batch adversarial loss: 0.391274\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.361430; batch adversarial loss: 0.375859\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.367484; batch adversarial loss: 0.478569\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.460158; batch adversarial loss: 0.376361\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.498817; batch adversarial loss: 0.472176\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.428096; batch adversarial loss: 0.380595\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.426775; batch adversarial loss: 0.375994\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.439972; batch adversarial loss: 0.447549\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.448963; batch adversarial loss: 0.449674\n",
      "epoch 24; iter: 0; batch classifier loss: 0.395225; batch adversarial loss: 0.483743\n",
      "epoch 24; iter: 200; batch classifier loss: 0.500029; batch adversarial loss: 0.447806\n",
      "epoch 24; iter: 400; batch classifier loss: 0.429245; batch adversarial loss: 0.337309\n",
      "epoch 24; iter: 600; batch classifier loss: 0.416412; batch adversarial loss: 0.330068\n",
      "epoch 24; iter: 800; batch classifier loss: 0.365545; batch adversarial loss: 0.367637\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.405095; batch adversarial loss: 0.432846\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.479875; batch adversarial loss: 0.338619\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.359121; batch adversarial loss: 0.552674\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.322457; batch adversarial loss: 0.379128\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.343363; batch adversarial loss: 0.486442\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.425501; batch adversarial loss: 0.395178\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.449125; batch adversarial loss: 0.405283\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.426455; batch adversarial loss: 0.434961\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.430285; batch adversarial loss: 0.502328\n",
      "epoch 25; iter: 0; batch classifier loss: 0.422146; batch adversarial loss: 0.448335\n",
      "epoch 25; iter: 200; batch classifier loss: 0.360715; batch adversarial loss: 0.458366\n",
      "epoch 25; iter: 400; batch classifier loss: 0.450948; batch adversarial loss: 0.389314\n",
      "epoch 25; iter: 600; batch classifier loss: 0.501270; batch adversarial loss: 0.365829\n",
      "epoch 25; iter: 800; batch classifier loss: 0.411973; batch adversarial loss: 0.353901\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.400039; batch adversarial loss: 0.526216\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.434042; batch adversarial loss: 0.350618\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.452682; batch adversarial loss: 0.362552\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.419735; batch adversarial loss: 0.356020\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.400035; batch adversarial loss: 0.404292\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.381579; batch adversarial loss: 0.514289\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.401451; batch adversarial loss: 0.377292\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.373711; batch adversarial loss: 0.352016\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.440755; batch adversarial loss: 0.332837\n",
      "epoch 26; iter: 0; batch classifier loss: 0.445359; batch adversarial loss: 0.430979\n",
      "epoch 26; iter: 200; batch classifier loss: 0.438493; batch adversarial loss: 0.503679\n",
      "epoch 26; iter: 400; batch classifier loss: 0.449763; batch adversarial loss: 0.416585\n",
      "epoch 26; iter: 600; batch classifier loss: 0.458537; batch adversarial loss: 0.450497\n",
      "epoch 26; iter: 800; batch classifier loss: 0.395494; batch adversarial loss: 0.474884\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.398656; batch adversarial loss: 0.366644\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.443528; batch adversarial loss: 0.526551\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.401061; batch adversarial loss: 0.538725\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.471077; batch adversarial loss: 0.411523\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.471766; batch adversarial loss: 0.434596\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.375409; batch adversarial loss: 0.461146\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.564118; batch adversarial loss: 0.434214\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.441963; batch adversarial loss: 0.475512\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.463447; batch adversarial loss: 0.436153\n",
      "epoch 27; iter: 0; batch classifier loss: 0.323638; batch adversarial loss: 0.552659\n",
      "epoch 27; iter: 200; batch classifier loss: 0.387984; batch adversarial loss: 0.349144\n",
      "epoch 27; iter: 400; batch classifier loss: 0.383470; batch adversarial loss: 0.388525\n",
      "epoch 27; iter: 600; batch classifier loss: 0.469213; batch adversarial loss: 0.444081\n",
      "epoch 27; iter: 800; batch classifier loss: 0.395158; batch adversarial loss: 0.325649\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.379572; batch adversarial loss: 0.405507\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.339530; batch adversarial loss: 0.360671\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.416267; batch adversarial loss: 0.460324\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.387870; batch adversarial loss: 0.499150\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.497104; batch adversarial loss: 0.365438\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.336290; batch adversarial loss: 0.459954\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.435184; batch adversarial loss: 0.408857\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.450433; batch adversarial loss: 0.390909\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.394134; batch adversarial loss: 0.381448\n",
      "epoch 28; iter: 0; batch classifier loss: 0.408787; batch adversarial loss: 0.512330\n",
      "epoch 28; iter: 200; batch classifier loss: 0.339504; batch adversarial loss: 0.428977\n",
      "epoch 28; iter: 400; batch classifier loss: 0.370679; batch adversarial loss: 0.378538\n",
      "epoch 28; iter: 600; batch classifier loss: 0.404481; batch adversarial loss: 0.379127\n",
      "epoch 28; iter: 800; batch classifier loss: 0.371171; batch adversarial loss: 0.392922\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.499208; batch adversarial loss: 0.432093\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.470099; batch adversarial loss: 0.280666\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.396264; batch adversarial loss: 0.320857\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.377466; batch adversarial loss: 0.381591\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.441677; batch adversarial loss: 0.381121\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.446597; batch adversarial loss: 0.448363\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.467149; batch adversarial loss: 0.483078\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.392730; batch adversarial loss: 0.555080\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.464815; batch adversarial loss: 0.380678\n",
      "epoch 29; iter: 0; batch classifier loss: 0.444728; batch adversarial loss: 0.452310\n",
      "epoch 29; iter: 200; batch classifier loss: 0.484050; batch adversarial loss: 0.458096\n",
      "epoch 29; iter: 400; batch classifier loss: 0.389433; batch adversarial loss: 0.395053\n",
      "epoch 29; iter: 600; batch classifier loss: 0.388171; batch adversarial loss: 0.461705\n",
      "epoch 29; iter: 800; batch classifier loss: 0.452200; batch adversarial loss: 0.532139\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.346044; batch adversarial loss: 0.449782\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.436490; batch adversarial loss: 0.431057\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.342134; batch adversarial loss: 0.360257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29; iter: 1600; batch classifier loss: 0.396513; batch adversarial loss: 0.445156\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.406867; batch adversarial loss: 0.352731\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.452345; batch adversarial loss: 0.545007\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.345480; batch adversarial loss: 0.375858\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.454056; batch adversarial loss: 0.481210\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.344368; batch adversarial loss: 0.492034\n",
      "epoch 30; iter: 0; batch classifier loss: 0.537450; batch adversarial loss: 0.429932\n",
      "epoch 30; iter: 200; batch classifier loss: 0.427737; batch adversarial loss: 0.472210\n",
      "epoch 30; iter: 400; batch classifier loss: 0.436737; batch adversarial loss: 0.460688\n",
      "epoch 30; iter: 600; batch classifier loss: 0.380234; batch adversarial loss: 0.363357\n",
      "epoch 30; iter: 800; batch classifier loss: 0.435596; batch adversarial loss: 0.497348\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.355707; batch adversarial loss: 0.381255\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.417276; batch adversarial loss: 0.349497\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.453599; batch adversarial loss: 0.412220\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.493586; batch adversarial loss: 0.458230\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.411678; batch adversarial loss: 0.363800\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.379654; batch adversarial loss: 0.406672\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.444647; batch adversarial loss: 0.324018\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.445774; batch adversarial loss: 0.433140\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.535960; batch adversarial loss: 0.415710\n",
      "epoch 31; iter: 0; batch classifier loss: 0.401115; batch adversarial loss: 0.365983\n",
      "epoch 31; iter: 200; batch classifier loss: 0.455235; batch adversarial loss: 0.434968\n",
      "epoch 31; iter: 400; batch classifier loss: 0.450459; batch adversarial loss: 0.450543\n",
      "epoch 31; iter: 600; batch classifier loss: 0.434477; batch adversarial loss: 0.502084\n",
      "epoch 31; iter: 800; batch classifier loss: 0.374837; batch adversarial loss: 0.447962\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.422544; batch adversarial loss: 0.444249\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.417934; batch adversarial loss: 0.392091\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.407460; batch adversarial loss: 0.474114\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.465808; batch adversarial loss: 0.419864\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.405541; batch adversarial loss: 0.474278\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.364840; batch adversarial loss: 0.471656\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.361854; batch adversarial loss: 0.406389\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.354865; batch adversarial loss: 0.310680\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.454871; batch adversarial loss: 0.472253\n",
      "epoch 32; iter: 0; batch classifier loss: 0.409593; batch adversarial loss: 0.487568\n",
      "epoch 32; iter: 200; batch classifier loss: 0.438832; batch adversarial loss: 0.476469\n",
      "epoch 32; iter: 400; batch classifier loss: 0.453081; batch adversarial loss: 0.405584\n",
      "epoch 32; iter: 600; batch classifier loss: 0.379303; batch adversarial loss: 0.392738\n",
      "epoch 32; iter: 800; batch classifier loss: 0.502344; batch adversarial loss: 0.534924\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.371898; batch adversarial loss: 0.295188\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.391717; batch adversarial loss: 0.392958\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.385843; batch adversarial loss: 0.434481\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.408742; batch adversarial loss: 0.474003\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.371773; batch adversarial loss: 0.445139\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.415275; batch adversarial loss: 0.518574\n",
      "epoch 32; iter: 2200; batch classifier loss: 0.456655; batch adversarial loss: 0.420496\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.344761; batch adversarial loss: 0.513908\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.463276; batch adversarial loss: 0.374816\n",
      "epoch 33; iter: 0; batch classifier loss: 0.337689; batch adversarial loss: 0.418902\n",
      "epoch 33; iter: 200; batch classifier loss: 0.522657; batch adversarial loss: 0.366589\n",
      "epoch 33; iter: 400; batch classifier loss: 0.381882; batch adversarial loss: 0.337485\n",
      "epoch 33; iter: 600; batch classifier loss: 0.349825; batch adversarial loss: 0.391222\n",
      "epoch 33; iter: 800; batch classifier loss: 0.443837; batch adversarial loss: 0.513362\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.560710; batch adversarial loss: 0.449958\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.365132; batch adversarial loss: 0.417392\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.374019; batch adversarial loss: 0.401858\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.643703; batch adversarial loss: 0.377072\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.398705; batch adversarial loss: 0.388344\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.370664; batch adversarial loss: 0.308731\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.413808; batch adversarial loss: 0.407229\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.418342; batch adversarial loss: 0.379287\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.437261; batch adversarial loss: 0.511966\n",
      "epoch 34; iter: 0; batch classifier loss: 0.401576; batch adversarial loss: 0.419966\n",
      "epoch 34; iter: 200; batch classifier loss: 0.414190; batch adversarial loss: 0.419471\n",
      "epoch 34; iter: 400; batch classifier loss: 0.366209; batch adversarial loss: 0.377204\n",
      "epoch 34; iter: 600; batch classifier loss: 0.366294; batch adversarial loss: 0.270676\n",
      "epoch 34; iter: 800; batch classifier loss: 0.488838; batch adversarial loss: 0.388436\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.347957; batch adversarial loss: 0.449412\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.517739; batch adversarial loss: 0.326199\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.339503; batch adversarial loss: 0.491597\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.381699; batch adversarial loss: 0.394499\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.437654; batch adversarial loss: 0.492295\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.438261; batch adversarial loss: 0.378491\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.402171; batch adversarial loss: 0.365095\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.430774; batch adversarial loss: 0.447321\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.392421; batch adversarial loss: 0.401735\n",
      "epoch 35; iter: 0; batch classifier loss: 0.416280; batch adversarial loss: 0.438091\n",
      "epoch 35; iter: 200; batch classifier loss: 0.469939; batch adversarial loss: 0.418590\n",
      "epoch 35; iter: 400; batch classifier loss: 0.354046; batch adversarial loss: 0.460668\n",
      "epoch 35; iter: 600; batch classifier loss: 0.388481; batch adversarial loss: 0.458355\n",
      "epoch 35; iter: 800; batch classifier loss: 0.447851; batch adversarial loss: 0.434140\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.323322; batch adversarial loss: 0.493634\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.442629; batch adversarial loss: 0.436174\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.431793; batch adversarial loss: 0.447497\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.496697; batch adversarial loss: 0.324262\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.437023; batch adversarial loss: 0.560695\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.436394; batch adversarial loss: 0.338309\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.411940; batch adversarial loss: 0.381883\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.436650; batch adversarial loss: 0.444730\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.388850; batch adversarial loss: 0.404451\n",
      "epoch 36; iter: 0; batch classifier loss: 0.362270; batch adversarial loss: 0.501392\n",
      "epoch 36; iter: 200; batch classifier loss: 0.379650; batch adversarial loss: 0.500920\n",
      "epoch 36; iter: 400; batch classifier loss: 0.379450; batch adversarial loss: 0.486125\n",
      "epoch 36; iter: 600; batch classifier loss: 0.385174; batch adversarial loss: 0.312084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36; iter: 800; batch classifier loss: 0.390808; batch adversarial loss: 0.396236\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.453802; batch adversarial loss: 0.307620\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.387284; batch adversarial loss: 0.472167\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.433837; batch adversarial loss: 0.443491\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.384697; batch adversarial loss: 0.403410\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.363342; batch adversarial loss: 0.436926\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.342745; batch adversarial loss: 0.449431\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.403660; batch adversarial loss: 0.456996\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.384143; batch adversarial loss: 0.395990\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.451345; batch adversarial loss: 0.496878\n",
      "epoch 37; iter: 0; batch classifier loss: 0.389882; batch adversarial loss: 0.479393\n",
      "epoch 37; iter: 200; batch classifier loss: 0.398585; batch adversarial loss: 0.328369\n",
      "epoch 37; iter: 400; batch classifier loss: 0.511803; batch adversarial loss: 0.486107\n",
      "epoch 37; iter: 600; batch classifier loss: 0.401489; batch adversarial loss: 0.419250\n",
      "epoch 37; iter: 800; batch classifier loss: 0.428044; batch adversarial loss: 0.350326\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.454055; batch adversarial loss: 0.486785\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.499660; batch adversarial loss: 0.405435\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.454935; batch adversarial loss: 0.471458\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.342451; batch adversarial loss: 0.336985\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.367334; batch adversarial loss: 0.446546\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.411954; batch adversarial loss: 0.395138\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.415111; batch adversarial loss: 0.499665\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.442726; batch adversarial loss: 0.394502\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.375834; batch adversarial loss: 0.379390\n",
      "epoch 38; iter: 0; batch classifier loss: 0.381985; batch adversarial loss: 0.406579\n",
      "epoch 38; iter: 200; batch classifier loss: 0.440053; batch adversarial loss: 0.459797\n",
      "epoch 38; iter: 400; batch classifier loss: 0.403834; batch adversarial loss: 0.411074\n",
      "epoch 38; iter: 600; batch classifier loss: 0.338499; batch adversarial loss: 0.373998\n",
      "epoch 38; iter: 800; batch classifier loss: 0.431742; batch adversarial loss: 0.390259\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.475782; batch adversarial loss: 0.434381\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.469747; batch adversarial loss: 0.434043\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.408664; batch adversarial loss: 0.324535\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.444025; batch adversarial loss: 0.488146\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.493456; batch adversarial loss: 0.405242\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.427337; batch adversarial loss: 0.392455\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.440807; batch adversarial loss: 0.447366\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.395380; batch adversarial loss: 0.352830\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.428658; batch adversarial loss: 0.503527\n",
      "epoch 39; iter: 0; batch classifier loss: 0.463070; batch adversarial loss: 0.312176\n",
      "epoch 39; iter: 200; batch classifier loss: 0.457750; batch adversarial loss: 0.392072\n",
      "epoch 39; iter: 400; batch classifier loss: 0.405121; batch adversarial loss: 0.352429\n",
      "epoch 39; iter: 600; batch classifier loss: 0.408552; batch adversarial loss: 0.387560\n",
      "epoch 39; iter: 800; batch classifier loss: 0.418266; batch adversarial loss: 0.463496\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.366328; batch adversarial loss: 0.446622\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.448982; batch adversarial loss: 0.446733\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.451748; batch adversarial loss: 0.281103\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.473485; batch adversarial loss: 0.367023\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.387232; batch adversarial loss: 0.271503\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.412195; batch adversarial loss: 0.405974\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.422484; batch adversarial loss: 0.485080\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.411988; batch adversarial loss: 0.504032\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.376439; batch adversarial loss: 0.257258\n",
      "epoch 40; iter: 0; batch classifier loss: 0.546257; batch adversarial loss: 0.420388\n",
      "epoch 40; iter: 200; batch classifier loss: 0.399625; batch adversarial loss: 0.485828\n",
      "epoch 40; iter: 400; batch classifier loss: 0.350778; batch adversarial loss: 0.434604\n",
      "epoch 40; iter: 600; batch classifier loss: 0.343735; batch adversarial loss: 0.378645\n",
      "epoch 40; iter: 800; batch classifier loss: 0.432858; batch adversarial loss: 0.378293\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.415998; batch adversarial loss: 0.457997\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.337526; batch adversarial loss: 0.410022\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.375086; batch adversarial loss: 0.420423\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.350228; batch adversarial loss: 0.430575\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.447649; batch adversarial loss: 0.417157\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.481078; batch adversarial loss: 0.388687\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.414496; batch adversarial loss: 0.389121\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.454367; batch adversarial loss: 0.341388\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.442955; batch adversarial loss: 0.472064\n",
      "epoch 41; iter: 0; batch classifier loss: 0.433794; batch adversarial loss: 0.444687\n",
      "epoch 41; iter: 200; batch classifier loss: 0.389788; batch adversarial loss: 0.393275\n",
      "epoch 41; iter: 400; batch classifier loss: 0.477807; batch adversarial loss: 0.425038\n",
      "epoch 41; iter: 600; batch classifier loss: 0.492305; batch adversarial loss: 0.361915\n",
      "epoch 41; iter: 800; batch classifier loss: 0.362865; batch adversarial loss: 0.432533\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.402316; batch adversarial loss: 0.501341\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.473045; batch adversarial loss: 0.421637\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.371385; batch adversarial loss: 0.433618\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.385862; batch adversarial loss: 0.485410\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.461567; batch adversarial loss: 0.353564\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.429713; batch adversarial loss: 0.406122\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.411467; batch adversarial loss: 0.436285\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.353684; batch adversarial loss: 0.401204\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.436872; batch adversarial loss: 0.447859\n",
      "epoch 42; iter: 0; batch classifier loss: 0.431330; batch adversarial loss: 0.447747\n",
      "epoch 42; iter: 200; batch classifier loss: 0.457825; batch adversarial loss: 0.490041\n",
      "epoch 42; iter: 400; batch classifier loss: 0.439924; batch adversarial loss: 0.449920\n",
      "epoch 42; iter: 600; batch classifier loss: 0.390275; batch adversarial loss: 0.448359\n",
      "epoch 42; iter: 800; batch classifier loss: 0.500238; batch adversarial loss: 0.418184\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.385433; batch adversarial loss: 0.347423\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.419115; batch adversarial loss: 0.389074\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.409554; batch adversarial loss: 0.406738\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.356059; batch adversarial loss: 0.491385\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.394931; batch adversarial loss: 0.397673\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.314266; batch adversarial loss: 0.378911\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.470002; batch adversarial loss: 0.529166\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.394663; batch adversarial loss: 0.363561\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.389354; batch adversarial loss: 0.378830\n",
      "epoch 43; iter: 0; batch classifier loss: 0.448686; batch adversarial loss: 0.406518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43; iter: 200; batch classifier loss: 0.343786; batch adversarial loss: 0.365337\n",
      "epoch 43; iter: 400; batch classifier loss: 0.449322; batch adversarial loss: 0.395909\n",
      "epoch 43; iter: 600; batch classifier loss: 0.414859; batch adversarial loss: 0.421613\n",
      "epoch 43; iter: 800; batch classifier loss: 0.372838; batch adversarial loss: 0.410844\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.379193; batch adversarial loss: 0.347368\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.482476; batch adversarial loss: 0.392459\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.379573; batch adversarial loss: 0.435180\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.307621; batch adversarial loss: 0.319997\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.444666; batch adversarial loss: 0.366638\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.482000; batch adversarial loss: 0.431522\n",
      "epoch 43; iter: 2200; batch classifier loss: 0.410441; batch adversarial loss: 0.444483\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.365343; batch adversarial loss: 0.377278\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.455592; batch adversarial loss: 0.379068\n",
      "epoch 44; iter: 0; batch classifier loss: 0.355555; batch adversarial loss: 0.408570\n",
      "epoch 44; iter: 200; batch classifier loss: 0.447581; batch adversarial loss: 0.472526\n",
      "epoch 44; iter: 400; batch classifier loss: 0.368046; batch adversarial loss: 0.378783\n",
      "epoch 44; iter: 600; batch classifier loss: 0.369972; batch adversarial loss: 0.323769\n",
      "epoch 44; iter: 800; batch classifier loss: 0.458840; batch adversarial loss: 0.403008\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.379326; batch adversarial loss: 0.372071\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.416581; batch adversarial loss: 0.408560\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.392295; batch adversarial loss: 0.339558\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.463001; batch adversarial loss: 0.377750\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.335350; batch adversarial loss: 0.499930\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.530288; batch adversarial loss: 0.376316\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.356188; batch adversarial loss: 0.431532\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.482693; batch adversarial loss: 0.512192\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.397961; batch adversarial loss: 0.446995\n",
      "epoch 45; iter: 0; batch classifier loss: 0.414476; batch adversarial loss: 0.433316\n",
      "epoch 45; iter: 200; batch classifier loss: 0.426674; batch adversarial loss: 0.421162\n",
      "epoch 45; iter: 400; batch classifier loss: 0.421406; batch adversarial loss: 0.324440\n",
      "epoch 45; iter: 600; batch classifier loss: 0.408703; batch adversarial loss: 0.471893\n",
      "epoch 45; iter: 800; batch classifier loss: 0.381795; batch adversarial loss: 0.405007\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.458980; batch adversarial loss: 0.534104\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.389368; batch adversarial loss: 0.378365\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.441793; batch adversarial loss: 0.377723\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.463535; batch adversarial loss: 0.408141\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.478634; batch adversarial loss: 0.433449\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.365380; batch adversarial loss: 0.432550\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.379129; batch adversarial loss: 0.464305\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.370206; batch adversarial loss: 0.377261\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.499028; batch adversarial loss: 0.399508\n",
      "epoch 46; iter: 0; batch classifier loss: 0.422287; batch adversarial loss: 0.351161\n",
      "epoch 46; iter: 200; batch classifier loss: 0.476186; batch adversarial loss: 0.484607\n",
      "epoch 46; iter: 400; batch classifier loss: 0.363093; batch adversarial loss: 0.446716\n",
      "epoch 46; iter: 600; batch classifier loss: 0.474704; batch adversarial loss: 0.339480\n",
      "epoch 46; iter: 800; batch classifier loss: 0.382156; batch adversarial loss: 0.364817\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.458561; batch adversarial loss: 0.391792\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.377389; batch adversarial loss: 0.353565\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.380624; batch adversarial loss: 0.379813\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.440687; batch adversarial loss: 0.379712\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.492684; batch adversarial loss: 0.394224\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.420164; batch adversarial loss: 0.376001\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.449691; batch adversarial loss: 0.368966\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.330853; batch adversarial loss: 0.487924\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.434061; batch adversarial loss: 0.299769\n",
      "epoch 47; iter: 0; batch classifier loss: 0.308042; batch adversarial loss: 0.449797\n",
      "epoch 47; iter: 200; batch classifier loss: 0.450054; batch adversarial loss: 0.474234\n",
      "epoch 47; iter: 400; batch classifier loss: 0.445410; batch adversarial loss: 0.395522\n",
      "epoch 47; iter: 600; batch classifier loss: 0.426883; batch adversarial loss: 0.337713\n",
      "epoch 47; iter: 800; batch classifier loss: 0.427467; batch adversarial loss: 0.516266\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.488855; batch adversarial loss: 0.364652\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.473161; batch adversarial loss: 0.367012\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.356477; batch adversarial loss: 0.364992\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.344698; batch adversarial loss: 0.409849\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.364254; batch adversarial loss: 0.475583\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.326160; batch adversarial loss: 0.402524\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.411965; batch adversarial loss: 0.402135\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.440169; batch adversarial loss: 0.419217\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.413985; batch adversarial loss: 0.338143\n",
      "epoch 48; iter: 0; batch classifier loss: 0.367220; batch adversarial loss: 0.433679\n",
      "epoch 48; iter: 200; batch classifier loss: 0.408416; batch adversarial loss: 0.453628\n",
      "epoch 48; iter: 400; batch classifier loss: 0.445199; batch adversarial loss: 0.364634\n",
      "epoch 48; iter: 600; batch classifier loss: 0.336866; batch adversarial loss: 0.393577\n",
      "epoch 48; iter: 800; batch classifier loss: 0.451318; batch adversarial loss: 0.312319\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.367308; batch adversarial loss: 0.338971\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.395694; batch adversarial loss: 0.451051\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.452870; batch adversarial loss: 0.463084\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.468720; batch adversarial loss: 0.516876\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.360388; batch adversarial loss: 0.445098\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.415253; batch adversarial loss: 0.460005\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.495728; batch adversarial loss: 0.498671\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.348584; batch adversarial loss: 0.310632\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.335348; batch adversarial loss: 0.394854\n",
      "epoch 49; iter: 0; batch classifier loss: 0.323327; batch adversarial loss: 0.545287\n",
      "epoch 49; iter: 200; batch classifier loss: 0.442598; batch adversarial loss: 0.458136\n",
      "epoch 49; iter: 400; batch classifier loss: 0.444293; batch adversarial loss: 0.484243\n",
      "epoch 49; iter: 600; batch classifier loss: 0.393673; batch adversarial loss: 0.405206\n",
      "epoch 49; iter: 800; batch classifier loss: 0.388564; batch adversarial loss: 0.500226\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.430881; batch adversarial loss: 0.408092\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.465361; batch adversarial loss: 0.418577\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.395814; batch adversarial loss: 0.469272\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.399031; batch adversarial loss: 0.511123\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.428641; batch adversarial loss: 0.498637\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.389927; batch adversarial loss: 0.552776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49; iter: 2200; batch classifier loss: 0.454148; batch adversarial loss: 0.506286\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.397160; batch adversarial loss: 0.425485\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.513186; batch adversarial loss: 0.415462\n",
      "epoch 0; iter: 0; batch classifier loss: 0.684576\n",
      "epoch 0; iter: 200; batch classifier loss: 0.467033\n",
      "epoch 0; iter: 400; batch classifier loss: 0.457456\n",
      "epoch 0; iter: 600; batch classifier loss: 0.415328\n",
      "epoch 0; iter: 800; batch classifier loss: 0.402838\n",
      "epoch 0; iter: 1000; batch classifier loss: 0.427323\n",
      "epoch 0; iter: 1200; batch classifier loss: 0.397328\n",
      "epoch 0; iter: 1400; batch classifier loss: 0.446333\n",
      "epoch 0; iter: 1600; batch classifier loss: 0.523566\n",
      "epoch 0; iter: 1800; batch classifier loss: 0.491534\n",
      "epoch 0; iter: 2000; batch classifier loss: 0.503630\n",
      "epoch 0; iter: 2200; batch classifier loss: 0.439405\n",
      "epoch 0; iter: 2400; batch classifier loss: 0.458016\n",
      "epoch 0; iter: 2600; batch classifier loss: 0.434569\n",
      "epoch 1; iter: 0; batch classifier loss: 0.434259\n",
      "epoch 1; iter: 200; batch classifier loss: 0.442873\n",
      "epoch 1; iter: 400; batch classifier loss: 0.367947\n",
      "epoch 1; iter: 600; batch classifier loss: 0.399184\n",
      "epoch 1; iter: 800; batch classifier loss: 0.403993\n",
      "epoch 1; iter: 1000; batch classifier loss: 0.392887\n",
      "epoch 1; iter: 1200; batch classifier loss: 0.471009\n",
      "epoch 1; iter: 1400; batch classifier loss: 0.337992\n",
      "epoch 1; iter: 1600; batch classifier loss: 0.406172\n",
      "epoch 1; iter: 1800; batch classifier loss: 0.479467\n",
      "epoch 1; iter: 2000; batch classifier loss: 0.387470\n",
      "epoch 1; iter: 2200; batch classifier loss: 0.354332\n",
      "epoch 1; iter: 2400; batch classifier loss: 0.352093\n",
      "epoch 1; iter: 2600; batch classifier loss: 0.400572\n",
      "epoch 2; iter: 0; batch classifier loss: 0.437734\n",
      "epoch 2; iter: 200; batch classifier loss: 0.429721\n",
      "epoch 2; iter: 400; batch classifier loss: 0.436034\n",
      "epoch 2; iter: 600; batch classifier loss: 0.429602\n",
      "epoch 2; iter: 800; batch classifier loss: 0.412911\n",
      "epoch 2; iter: 1000; batch classifier loss: 0.397453\n",
      "epoch 2; iter: 1200; batch classifier loss: 0.366237\n",
      "epoch 2; iter: 1400; batch classifier loss: 0.340468\n",
      "epoch 2; iter: 1600; batch classifier loss: 0.395879\n",
      "epoch 2; iter: 1800; batch classifier loss: 0.507251\n",
      "epoch 2; iter: 2000; batch classifier loss: 0.308792\n",
      "epoch 2; iter: 2200; batch classifier loss: 0.377524\n",
      "epoch 2; iter: 2400; batch classifier loss: 0.515146\n",
      "epoch 2; iter: 2600; batch classifier loss: 0.447845\n",
      "epoch 3; iter: 0; batch classifier loss: 0.402582\n",
      "epoch 3; iter: 200; batch classifier loss: 0.389768\n",
      "epoch 3; iter: 400; batch classifier loss: 0.498458\n",
      "epoch 3; iter: 600; batch classifier loss: 0.357210\n",
      "epoch 3; iter: 800; batch classifier loss: 0.416933\n",
      "epoch 3; iter: 1000; batch classifier loss: 0.508403\n",
      "epoch 3; iter: 1200; batch classifier loss: 0.382303\n",
      "epoch 3; iter: 1400; batch classifier loss: 0.350975\n",
      "epoch 3; iter: 1600; batch classifier loss: 0.443182\n",
      "epoch 3; iter: 1800; batch classifier loss: 0.405068\n",
      "epoch 3; iter: 2000; batch classifier loss: 0.460178\n",
      "epoch 3; iter: 2200; batch classifier loss: 0.425385\n",
      "epoch 3; iter: 2400; batch classifier loss: 0.350684\n",
      "epoch 3; iter: 2600; batch classifier loss: 0.472150\n",
      "epoch 4; iter: 0; batch classifier loss: 0.422003\n",
      "epoch 4; iter: 200; batch classifier loss: 0.440793\n",
      "epoch 4; iter: 400; batch classifier loss: 0.377718\n",
      "epoch 4; iter: 600; batch classifier loss: 0.428199\n",
      "epoch 4; iter: 800; batch classifier loss: 0.467536\n",
      "epoch 4; iter: 1000; batch classifier loss: 0.437972\n",
      "epoch 4; iter: 1200; batch classifier loss: 0.418573\n",
      "epoch 4; iter: 1400; batch classifier loss: 0.404975\n",
      "epoch 4; iter: 1600; batch classifier loss: 0.365671\n",
      "epoch 4; iter: 1800; batch classifier loss: 0.401361\n",
      "epoch 4; iter: 2000; batch classifier loss: 0.428635\n",
      "epoch 4; iter: 2200; batch classifier loss: 0.370577\n",
      "epoch 4; iter: 2400; batch classifier loss: 0.406455\n",
      "epoch 4; iter: 2600; batch classifier loss: 0.517125\n",
      "epoch 5; iter: 0; batch classifier loss: 0.413992\n",
      "epoch 5; iter: 200; batch classifier loss: 0.443242\n",
      "epoch 5; iter: 400; batch classifier loss: 0.351180\n",
      "epoch 5; iter: 600; batch classifier loss: 0.414399\n",
      "epoch 5; iter: 800; batch classifier loss: 0.348736\n",
      "epoch 5; iter: 1000; batch classifier loss: 0.400609\n",
      "epoch 5; iter: 1200; batch classifier loss: 0.376476\n",
      "epoch 5; iter: 1400; batch classifier loss: 0.334062\n",
      "epoch 5; iter: 1600; batch classifier loss: 0.442268\n",
      "epoch 5; iter: 1800; batch classifier loss: 0.428986\n",
      "epoch 5; iter: 2000; batch classifier loss: 0.329121\n",
      "epoch 5; iter: 2200; batch classifier loss: 0.463074\n",
      "epoch 5; iter: 2400; batch classifier loss: 0.470264\n",
      "epoch 5; iter: 2600; batch classifier loss: 0.457483\n",
      "epoch 6; iter: 0; batch classifier loss: 0.386165\n",
      "epoch 6; iter: 200; batch classifier loss: 0.577376\n",
      "epoch 6; iter: 400; batch classifier loss: 0.459506\n",
      "epoch 6; iter: 600; batch classifier loss: 0.429606\n",
      "epoch 6; iter: 800; batch classifier loss: 0.377363\n",
      "epoch 6; iter: 1000; batch classifier loss: 0.384828\n",
      "epoch 6; iter: 1200; batch classifier loss: 0.395917\n",
      "epoch 6; iter: 1400; batch classifier loss: 0.462755\n",
      "epoch 6; iter: 1600; batch classifier loss: 0.355731\n",
      "epoch 6; iter: 1800; batch classifier loss: 0.379287\n",
      "epoch 6; iter: 2000; batch classifier loss: 0.464567\n",
      "epoch 6; iter: 2200; batch classifier loss: 0.416353\n",
      "epoch 6; iter: 2400; batch classifier loss: 0.371200\n",
      "epoch 6; iter: 2600; batch classifier loss: 0.328554\n",
      "epoch 7; iter: 0; batch classifier loss: 0.395213\n",
      "epoch 7; iter: 200; batch classifier loss: 0.410553\n",
      "epoch 7; iter: 400; batch classifier loss: 0.446612\n",
      "epoch 7; iter: 600; batch classifier loss: 0.393643\n",
      "epoch 7; iter: 800; batch classifier loss: 0.408267\n",
      "epoch 7; iter: 1000; batch classifier loss: 0.387362\n",
      "epoch 7; iter: 1200; batch classifier loss: 0.401058\n",
      "epoch 7; iter: 1400; batch classifier loss: 0.437905\n",
      "epoch 7; iter: 1600; batch classifier loss: 0.463490\n",
      "epoch 7; iter: 1800; batch classifier loss: 0.529796\n",
      "epoch 7; iter: 2000; batch classifier loss: 0.418067\n",
      "epoch 7; iter: 2200; batch classifier loss: 0.450917\n",
      "epoch 7; iter: 2400; batch classifier loss: 0.364679\n",
      "epoch 7; iter: 2600; batch classifier loss: 0.476210\n",
      "epoch 8; iter: 0; batch classifier loss: 0.379432\n",
      "epoch 8; iter: 200; batch classifier loss: 0.486625\n",
      "epoch 8; iter: 400; batch classifier loss: 0.330456\n",
      "epoch 8; iter: 600; batch classifier loss: 0.485405\n",
      "epoch 8; iter: 800; batch classifier loss: 0.445424\n",
      "epoch 8; iter: 1000; batch classifier loss: 0.314300\n",
      "epoch 8; iter: 1200; batch classifier loss: 0.488597\n",
      "epoch 8; iter: 1400; batch classifier loss: 0.387626\n",
      "epoch 8; iter: 1600; batch classifier loss: 0.326111\n",
      "epoch 8; iter: 1800; batch classifier loss: 0.428758\n",
      "epoch 8; iter: 2000; batch classifier loss: 0.417701\n",
      "epoch 8; iter: 2200; batch classifier loss: 0.404160\n",
      "epoch 8; iter: 2400; batch classifier loss: 0.456984\n",
      "epoch 8; iter: 2600; batch classifier loss: 0.394934\n",
      "epoch 9; iter: 0; batch classifier loss: 0.460388\n",
      "epoch 9; iter: 200; batch classifier loss: 0.337642\n",
      "epoch 9; iter: 400; batch classifier loss: 0.420258\n",
      "epoch 9; iter: 600; batch classifier loss: 0.418509\n",
      "epoch 9; iter: 800; batch classifier loss: 0.502620\n",
      "epoch 9; iter: 1000; batch classifier loss: 0.347220\n",
      "epoch 9; iter: 1200; batch classifier loss: 0.515147\n",
      "epoch 9; iter: 1400; batch classifier loss: 0.416077\n",
      "epoch 9; iter: 1600; batch classifier loss: 0.423768\n",
      "epoch 9; iter: 1800; batch classifier loss: 0.460663\n",
      "epoch 9; iter: 2000; batch classifier loss: 0.356906\n",
      "epoch 9; iter: 2200; batch classifier loss: 0.468847\n",
      "epoch 9; iter: 2400; batch classifier loss: 0.376751\n",
      "epoch 9; iter: 2600; batch classifier loss: 0.440324\n",
      "epoch 10; iter: 0; batch classifier loss: 0.393284\n",
      "epoch 10; iter: 200; batch classifier loss: 0.470979\n",
      "epoch 10; iter: 400; batch classifier loss: 0.510080\n",
      "epoch 10; iter: 600; batch classifier loss: 0.337534\n",
      "epoch 10; iter: 800; batch classifier loss: 0.487248\n",
      "epoch 10; iter: 1000; batch classifier loss: 0.398963\n",
      "epoch 10; iter: 1200; batch classifier loss: 0.402178\n",
      "epoch 10; iter: 1400; batch classifier loss: 0.468109\n",
      "epoch 10; iter: 1600; batch classifier loss: 0.490615\n",
      "epoch 10; iter: 1800; batch classifier loss: 0.366233\n",
      "epoch 10; iter: 2000; batch classifier loss: 0.357442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10; iter: 2200; batch classifier loss: 0.442214\n",
      "epoch 10; iter: 2400; batch classifier loss: 0.461125\n",
      "epoch 10; iter: 2600; batch classifier loss: 0.400083\n",
      "epoch 11; iter: 0; batch classifier loss: 0.463539\n",
      "epoch 11; iter: 200; batch classifier loss: 0.423023\n",
      "epoch 11; iter: 400; batch classifier loss: 0.337540\n",
      "epoch 11; iter: 600; batch classifier loss: 0.409869\n",
      "epoch 11; iter: 800; batch classifier loss: 0.471308\n",
      "epoch 11; iter: 1000; batch classifier loss: 0.379230\n",
      "epoch 11; iter: 1200; batch classifier loss: 0.390613\n",
      "epoch 11; iter: 1400; batch classifier loss: 0.382479\n",
      "epoch 11; iter: 1600; batch classifier loss: 0.403061\n",
      "epoch 11; iter: 1800; batch classifier loss: 0.433174\n",
      "epoch 11; iter: 2000; batch classifier loss: 0.445084\n",
      "epoch 11; iter: 2200; batch classifier loss: 0.419988\n",
      "epoch 11; iter: 2400; batch classifier loss: 0.453287\n",
      "epoch 11; iter: 2600; batch classifier loss: 0.383391\n",
      "epoch 12; iter: 0; batch classifier loss: 0.437461\n",
      "epoch 12; iter: 200; batch classifier loss: 0.480676\n",
      "epoch 12; iter: 400; batch classifier loss: 0.423596\n",
      "epoch 12; iter: 600; batch classifier loss: 0.408244\n",
      "epoch 12; iter: 800; batch classifier loss: 0.459095\n",
      "epoch 12; iter: 1000; batch classifier loss: 0.492066\n",
      "epoch 12; iter: 1200; batch classifier loss: 0.467617\n",
      "epoch 12; iter: 1400; batch classifier loss: 0.408176\n",
      "epoch 12; iter: 1600; batch classifier loss: 0.462069\n",
      "epoch 12; iter: 1800; batch classifier loss: 0.454263\n",
      "epoch 12; iter: 2000; batch classifier loss: 0.444100\n",
      "epoch 12; iter: 2200; batch classifier loss: 0.436663\n",
      "epoch 12; iter: 2400; batch classifier loss: 0.387679\n",
      "epoch 12; iter: 2600; batch classifier loss: 0.354142\n",
      "epoch 13; iter: 0; batch classifier loss: 0.379842\n",
      "epoch 13; iter: 200; batch classifier loss: 0.428340\n",
      "epoch 13; iter: 400; batch classifier loss: 0.414269\n",
      "epoch 13; iter: 600; batch classifier loss: 0.388123\n",
      "epoch 13; iter: 800; batch classifier loss: 0.396301\n",
      "epoch 13; iter: 1000; batch classifier loss: 0.497706\n",
      "epoch 13; iter: 1200; batch classifier loss: 0.412765\n",
      "epoch 13; iter: 1400; batch classifier loss: 0.398715\n",
      "epoch 13; iter: 1600; batch classifier loss: 0.438166\n",
      "epoch 13; iter: 1800; batch classifier loss: 0.554203\n",
      "epoch 13; iter: 2000; batch classifier loss: 0.412449\n",
      "epoch 13; iter: 2200; batch classifier loss: 0.308909\n",
      "epoch 13; iter: 2400; batch classifier loss: 0.449723\n",
      "epoch 13; iter: 2600; batch classifier loss: 0.323289\n",
      "epoch 14; iter: 0; batch classifier loss: 0.265651\n",
      "epoch 14; iter: 200; batch classifier loss: 0.418030\n",
      "epoch 14; iter: 400; batch classifier loss: 0.389460\n",
      "epoch 14; iter: 600; batch classifier loss: 0.460467\n",
      "epoch 14; iter: 800; batch classifier loss: 0.450564\n",
      "epoch 14; iter: 1000; batch classifier loss: 0.386998\n",
      "epoch 14; iter: 1200; batch classifier loss: 0.513625\n",
      "epoch 14; iter: 1400; batch classifier loss: 0.328926\n",
      "epoch 14; iter: 1600; batch classifier loss: 0.382945\n",
      "epoch 14; iter: 1800; batch classifier loss: 0.429775\n",
      "epoch 14; iter: 2000; batch classifier loss: 0.400757\n",
      "epoch 14; iter: 2200; batch classifier loss: 0.415714\n",
      "epoch 14; iter: 2400; batch classifier loss: 0.390992\n",
      "epoch 14; iter: 2600; batch classifier loss: 0.391066\n",
      "epoch 15; iter: 0; batch classifier loss: 0.418917\n",
      "epoch 15; iter: 200; batch classifier loss: 0.392200\n",
      "epoch 15; iter: 400; batch classifier loss: 0.361851\n",
      "epoch 15; iter: 600; batch classifier loss: 0.328657\n",
      "epoch 15; iter: 800; batch classifier loss: 0.457946\n",
      "epoch 15; iter: 1000; batch classifier loss: 0.399013\n",
      "epoch 15; iter: 1200; batch classifier loss: 0.403105\n",
      "epoch 15; iter: 1400; batch classifier loss: 0.443247\n",
      "epoch 15; iter: 1600; batch classifier loss: 0.388145\n",
      "epoch 15; iter: 1800; batch classifier loss: 0.393591\n",
      "epoch 15; iter: 2000; batch classifier loss: 0.390779\n",
      "epoch 15; iter: 2200; batch classifier loss: 0.426867\n",
      "epoch 15; iter: 2400; batch classifier loss: 0.526538\n",
      "epoch 15; iter: 2600; batch classifier loss: 0.380425\n",
      "epoch 16; iter: 0; batch classifier loss: 0.423127\n",
      "epoch 16; iter: 200; batch classifier loss: 0.399135\n",
      "epoch 16; iter: 400; batch classifier loss: 0.411165\n",
      "epoch 16; iter: 600; batch classifier loss: 0.422751\n",
      "epoch 16; iter: 800; batch classifier loss: 0.366788\n",
      "epoch 16; iter: 1000; batch classifier loss: 0.491056\n",
      "epoch 16; iter: 1200; batch classifier loss: 0.413917\n",
      "epoch 16; iter: 1400; batch classifier loss: 0.397619\n",
      "epoch 16; iter: 1600; batch classifier loss: 0.444354\n",
      "epoch 16; iter: 1800; batch classifier loss: 0.460058\n",
      "epoch 16; iter: 2000; batch classifier loss: 0.499608\n",
      "epoch 16; iter: 2200; batch classifier loss: 0.466583\n",
      "epoch 16; iter: 2400; batch classifier loss: 0.385477\n",
      "epoch 16; iter: 2600; batch classifier loss: 0.456668\n",
      "epoch 17; iter: 0; batch classifier loss: 0.366301\n",
      "epoch 17; iter: 200; batch classifier loss: 0.471308\n",
      "epoch 17; iter: 400; batch classifier loss: 0.349646\n",
      "epoch 17; iter: 600; batch classifier loss: 0.310377\n",
      "epoch 17; iter: 800; batch classifier loss: 0.497131\n",
      "epoch 17; iter: 1000; batch classifier loss: 0.491335\n",
      "epoch 17; iter: 1200; batch classifier loss: 0.380790\n",
      "epoch 17; iter: 1400; batch classifier loss: 0.377191\n",
      "epoch 17; iter: 1600; batch classifier loss: 0.474278\n",
      "epoch 17; iter: 1800; batch classifier loss: 0.422704\n",
      "epoch 17; iter: 2000; batch classifier loss: 0.392240\n",
      "epoch 17; iter: 2200; batch classifier loss: 0.433931\n",
      "epoch 17; iter: 2400; batch classifier loss: 0.427269\n",
      "epoch 17; iter: 2600; batch classifier loss: 0.475107\n",
      "epoch 18; iter: 0; batch classifier loss: 0.455329\n",
      "epoch 18; iter: 200; batch classifier loss: 0.388032\n",
      "epoch 18; iter: 400; batch classifier loss: 0.424605\n",
      "epoch 18; iter: 600; batch classifier loss: 0.384952\n",
      "epoch 18; iter: 800; batch classifier loss: 0.442656\n",
      "epoch 18; iter: 1000; batch classifier loss: 0.548681\n",
      "epoch 18; iter: 1200; batch classifier loss: 0.454355\n",
      "epoch 18; iter: 1400; batch classifier loss: 0.494831\n",
      "epoch 18; iter: 1600; batch classifier loss: 0.342309\n",
      "epoch 18; iter: 1800; batch classifier loss: 0.437311\n",
      "epoch 18; iter: 2000; batch classifier loss: 0.491351\n",
      "epoch 18; iter: 2200; batch classifier loss: 0.432437\n",
      "epoch 18; iter: 2400; batch classifier loss: 0.426825\n",
      "epoch 18; iter: 2600; batch classifier loss: 0.430909\n",
      "epoch 19; iter: 0; batch classifier loss: 0.508823\n",
      "epoch 19; iter: 200; batch classifier loss: 0.417675\n",
      "epoch 19; iter: 400; batch classifier loss: 0.575872\n",
      "epoch 19; iter: 600; batch classifier loss: 0.452624\n",
      "epoch 19; iter: 800; batch classifier loss: 0.369262\n",
      "epoch 19; iter: 1000; batch classifier loss: 0.405326\n",
      "epoch 19; iter: 1200; batch classifier loss: 0.419891\n",
      "epoch 19; iter: 1400; batch classifier loss: 0.345161\n",
      "epoch 19; iter: 1600; batch classifier loss: 0.443591\n",
      "epoch 19; iter: 1800; batch classifier loss: 0.450092\n",
      "epoch 19; iter: 2000; batch classifier loss: 0.476955\n",
      "epoch 19; iter: 2200; batch classifier loss: 0.415075\n",
      "epoch 19; iter: 2400; batch classifier loss: 0.344687\n",
      "epoch 19; iter: 2600; batch classifier loss: 0.339881\n",
      "epoch 20; iter: 0; batch classifier loss: 0.353464\n",
      "epoch 20; iter: 200; batch classifier loss: 0.342479\n",
      "epoch 20; iter: 400; batch classifier loss: 0.493900\n",
      "epoch 20; iter: 600; batch classifier loss: 0.449922\n",
      "epoch 20; iter: 800; batch classifier loss: 0.341858\n",
      "epoch 20; iter: 1000; batch classifier loss: 0.395860\n",
      "epoch 20; iter: 1200; batch classifier loss: 0.456478\n",
      "epoch 20; iter: 1400; batch classifier loss: 0.413616\n",
      "epoch 20; iter: 1600; batch classifier loss: 0.439510\n",
      "epoch 20; iter: 1800; batch classifier loss: 0.477576\n",
      "epoch 20; iter: 2000; batch classifier loss: 0.401643\n",
      "epoch 20; iter: 2200; batch classifier loss: 0.443610\n",
      "epoch 20; iter: 2400; batch classifier loss: 0.361310\n",
      "epoch 20; iter: 2600; batch classifier loss: 0.427012\n",
      "epoch 21; iter: 0; batch classifier loss: 0.410349\n",
      "epoch 21; iter: 200; batch classifier loss: 0.425459\n",
      "epoch 21; iter: 400; batch classifier loss: 0.404485\n",
      "epoch 21; iter: 600; batch classifier loss: 0.438259\n",
      "epoch 21; iter: 800; batch classifier loss: 0.383213\n",
      "epoch 21; iter: 1000; batch classifier loss: 0.423104\n",
      "epoch 21; iter: 1200; batch classifier loss: 0.464899\n",
      "epoch 21; iter: 1400; batch classifier loss: 0.422742\n",
      "epoch 21; iter: 1600; batch classifier loss: 0.408769\n",
      "epoch 21; iter: 1800; batch classifier loss: 0.420113\n",
      "epoch 21; iter: 2000; batch classifier loss: 0.390486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 2200; batch classifier loss: 0.384206\n",
      "epoch 21; iter: 2400; batch classifier loss: 0.464515\n",
      "epoch 21; iter: 2600; batch classifier loss: 0.323959\n",
      "epoch 22; iter: 0; batch classifier loss: 0.376280\n",
      "epoch 22; iter: 200; batch classifier loss: 0.422313\n",
      "epoch 22; iter: 400; batch classifier loss: 0.460690\n",
      "epoch 22; iter: 600; batch classifier loss: 0.348093\n",
      "epoch 22; iter: 800; batch classifier loss: 0.403570\n",
      "epoch 22; iter: 1000; batch classifier loss: 0.412800\n",
      "epoch 22; iter: 1200; batch classifier loss: 0.412587\n",
      "epoch 22; iter: 1400; batch classifier loss: 0.368787\n",
      "epoch 22; iter: 1600; batch classifier loss: 0.332754\n",
      "epoch 22; iter: 1800; batch classifier loss: 0.411166\n",
      "epoch 22; iter: 2000; batch classifier loss: 0.531528\n",
      "epoch 22; iter: 2200; batch classifier loss: 0.481967\n",
      "epoch 22; iter: 2400; batch classifier loss: 0.467074\n",
      "epoch 22; iter: 2600; batch classifier loss: 0.383130\n",
      "epoch 23; iter: 0; batch classifier loss: 0.320191\n",
      "epoch 23; iter: 200; batch classifier loss: 0.440116\n",
      "epoch 23; iter: 400; batch classifier loss: 0.386018\n",
      "epoch 23; iter: 600; batch classifier loss: 0.386774\n",
      "epoch 23; iter: 800; batch classifier loss: 0.386371\n",
      "epoch 23; iter: 1000; batch classifier loss: 0.450662\n",
      "epoch 23; iter: 1200; batch classifier loss: 0.389240\n",
      "epoch 23; iter: 1400; batch classifier loss: 0.370751\n",
      "epoch 23; iter: 1600; batch classifier loss: 0.396536\n",
      "epoch 23; iter: 1800; batch classifier loss: 0.407942\n",
      "epoch 23; iter: 2000; batch classifier loss: 0.474123\n",
      "epoch 23; iter: 2200; batch classifier loss: 0.492413\n",
      "epoch 23; iter: 2400; batch classifier loss: 0.390689\n",
      "epoch 23; iter: 2600; batch classifier loss: 0.378114\n",
      "epoch 24; iter: 0; batch classifier loss: 0.403963\n",
      "epoch 24; iter: 200; batch classifier loss: 0.392081\n",
      "epoch 24; iter: 400; batch classifier loss: 0.348053\n",
      "epoch 24; iter: 600; batch classifier loss: 0.427233\n",
      "epoch 24; iter: 800; batch classifier loss: 0.352344\n",
      "epoch 24; iter: 1000; batch classifier loss: 0.406706\n",
      "epoch 24; iter: 1200; batch classifier loss: 0.326098\n",
      "epoch 24; iter: 1400; batch classifier loss: 0.313737\n",
      "epoch 24; iter: 1600; batch classifier loss: 0.402912\n",
      "epoch 24; iter: 1800; batch classifier loss: 0.459001\n",
      "epoch 24; iter: 2000; batch classifier loss: 0.427721\n",
      "epoch 24; iter: 2200; batch classifier loss: 0.406516\n",
      "epoch 24; iter: 2400; batch classifier loss: 0.380932\n",
      "epoch 24; iter: 2600; batch classifier loss: 0.334481\n",
      "epoch 25; iter: 0; batch classifier loss: 0.465320\n",
      "epoch 25; iter: 200; batch classifier loss: 0.439112\n",
      "epoch 25; iter: 400; batch classifier loss: 0.424786\n",
      "epoch 25; iter: 600; batch classifier loss: 0.531514\n",
      "epoch 25; iter: 800; batch classifier loss: 0.374629\n",
      "epoch 25; iter: 1000; batch classifier loss: 0.391729\n",
      "epoch 25; iter: 1200; batch classifier loss: 0.466027\n",
      "epoch 25; iter: 1400; batch classifier loss: 0.426642\n",
      "epoch 25; iter: 1600; batch classifier loss: 0.440604\n",
      "epoch 25; iter: 1800; batch classifier loss: 0.422573\n",
      "epoch 25; iter: 2000; batch classifier loss: 0.384664\n",
      "epoch 25; iter: 2200; batch classifier loss: 0.443288\n",
      "epoch 25; iter: 2400; batch classifier loss: 0.466636\n",
      "epoch 25; iter: 2600; batch classifier loss: 0.445161\n",
      "epoch 26; iter: 0; batch classifier loss: 0.349787\n",
      "epoch 26; iter: 200; batch classifier loss: 0.401499\n",
      "epoch 26; iter: 400; batch classifier loss: 0.330378\n",
      "epoch 26; iter: 600; batch classifier loss: 0.402166\n",
      "epoch 26; iter: 800; batch classifier loss: 0.404370\n",
      "epoch 26; iter: 1000; batch classifier loss: 0.382374\n",
      "epoch 26; iter: 1200; batch classifier loss: 0.391471\n",
      "epoch 26; iter: 1400; batch classifier loss: 0.452413\n",
      "epoch 26; iter: 1600; batch classifier loss: 0.452256\n",
      "epoch 26; iter: 1800; batch classifier loss: 0.409326\n",
      "epoch 26; iter: 2000; batch classifier loss: 0.483973\n",
      "epoch 26; iter: 2200; batch classifier loss: 0.429502\n",
      "epoch 26; iter: 2400; batch classifier loss: 0.475546\n",
      "epoch 26; iter: 2600; batch classifier loss: 0.323310\n",
      "epoch 27; iter: 0; batch classifier loss: 0.351902\n",
      "epoch 27; iter: 200; batch classifier loss: 0.360390\n",
      "epoch 27; iter: 400; batch classifier loss: 0.437346\n",
      "epoch 27; iter: 600; batch classifier loss: 0.404180\n",
      "epoch 27; iter: 800; batch classifier loss: 0.509713\n",
      "epoch 27; iter: 1000; batch classifier loss: 0.411593\n",
      "epoch 27; iter: 1200; batch classifier loss: 0.478032\n",
      "epoch 27; iter: 1400; batch classifier loss: 0.389313\n",
      "epoch 27; iter: 1600; batch classifier loss: 0.459703\n",
      "epoch 27; iter: 1800; batch classifier loss: 0.386856\n",
      "epoch 27; iter: 2000; batch classifier loss: 0.447271\n",
      "epoch 27; iter: 2200; batch classifier loss: 0.443498\n",
      "epoch 27; iter: 2400; batch classifier loss: 0.441793\n",
      "epoch 27; iter: 2600; batch classifier loss: 0.436801\n",
      "epoch 28; iter: 0; batch classifier loss: 0.490645\n",
      "epoch 28; iter: 200; batch classifier loss: 0.345686\n",
      "epoch 28; iter: 400; batch classifier loss: 0.395111\n",
      "epoch 28; iter: 600; batch classifier loss: 0.367758\n",
      "epoch 28; iter: 800; batch classifier loss: 0.415091\n",
      "epoch 28; iter: 1000; batch classifier loss: 0.396227\n",
      "epoch 28; iter: 1200; batch classifier loss: 0.394566\n",
      "epoch 28; iter: 1400; batch classifier loss: 0.392595\n",
      "epoch 28; iter: 1600; batch classifier loss: 0.456500\n",
      "epoch 28; iter: 1800; batch classifier loss: 0.474642\n",
      "epoch 28; iter: 2000; batch classifier loss: 0.368523\n",
      "epoch 28; iter: 2200; batch classifier loss: 0.353488\n",
      "epoch 28; iter: 2400; batch classifier loss: 0.393794\n",
      "epoch 28; iter: 2600; batch classifier loss: 0.332036\n",
      "epoch 29; iter: 0; batch classifier loss: 0.426325\n",
      "epoch 29; iter: 200; batch classifier loss: 0.408623\n",
      "epoch 29; iter: 400; batch classifier loss: 0.403926\n",
      "epoch 29; iter: 600; batch classifier loss: 0.446722\n",
      "epoch 29; iter: 800; batch classifier loss: 0.477619\n",
      "epoch 29; iter: 1000; batch classifier loss: 0.421529\n",
      "epoch 29; iter: 1200; batch classifier loss: 0.428856\n",
      "epoch 29; iter: 1400; batch classifier loss: 0.460895\n",
      "epoch 29; iter: 1600; batch classifier loss: 0.389647\n",
      "epoch 29; iter: 1800; batch classifier loss: 0.367919\n",
      "epoch 29; iter: 2000; batch classifier loss: 0.436096\n",
      "epoch 29; iter: 2200; batch classifier loss: 0.362721\n",
      "epoch 29; iter: 2400; batch classifier loss: 0.456771\n",
      "epoch 29; iter: 2600; batch classifier loss: 0.381606\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488462\n",
      "epoch 30; iter: 200; batch classifier loss: 0.339830\n",
      "epoch 30; iter: 400; batch classifier loss: 0.429708\n",
      "epoch 30; iter: 600; batch classifier loss: 0.409375\n",
      "epoch 30; iter: 800; batch classifier loss: 0.357530\n",
      "epoch 30; iter: 1000; batch classifier loss: 0.351912\n",
      "epoch 30; iter: 1200; batch classifier loss: 0.458730\n",
      "epoch 30; iter: 1400; batch classifier loss: 0.395200\n",
      "epoch 30; iter: 1600; batch classifier loss: 0.509176\n",
      "epoch 30; iter: 1800; batch classifier loss: 0.482517\n",
      "epoch 30; iter: 2000; batch classifier loss: 0.403479\n",
      "epoch 30; iter: 2200; batch classifier loss: 0.422445\n",
      "epoch 30; iter: 2400; batch classifier loss: 0.399650\n",
      "epoch 30; iter: 2600; batch classifier loss: 0.420568\n",
      "epoch 31; iter: 0; batch classifier loss: 0.494202\n",
      "epoch 31; iter: 200; batch classifier loss: 0.426468\n",
      "epoch 31; iter: 400; batch classifier loss: 0.370941\n",
      "epoch 31; iter: 600; batch classifier loss: 0.364038\n",
      "epoch 31; iter: 800; batch classifier loss: 0.422510\n",
      "epoch 31; iter: 1000; batch classifier loss: 0.437288\n",
      "epoch 31; iter: 1200; batch classifier loss: 0.453116\n",
      "epoch 31; iter: 1400; batch classifier loss: 0.449610\n",
      "epoch 31; iter: 1600; batch classifier loss: 0.517945\n",
      "epoch 31; iter: 1800; batch classifier loss: 0.437346\n",
      "epoch 31; iter: 2000; batch classifier loss: 0.405929\n",
      "epoch 31; iter: 2200; batch classifier loss: 0.420199\n",
      "epoch 31; iter: 2400; batch classifier loss: 0.405821\n",
      "epoch 31; iter: 2600; batch classifier loss: 0.349262\n",
      "epoch 32; iter: 0; batch classifier loss: 0.440551\n",
      "epoch 32; iter: 200; batch classifier loss: 0.420970\n",
      "epoch 32; iter: 400; batch classifier loss: 0.484796\n",
      "epoch 32; iter: 600; batch classifier loss: 0.441435\n",
      "epoch 32; iter: 800; batch classifier loss: 0.446281\n",
      "epoch 32; iter: 1000; batch classifier loss: 0.484109\n",
      "epoch 32; iter: 1200; batch classifier loss: 0.402346\n",
      "epoch 32; iter: 1400; batch classifier loss: 0.497690\n",
      "epoch 32; iter: 1600; batch classifier loss: 0.310616\n",
      "epoch 32; iter: 1800; batch classifier loss: 0.392654\n",
      "epoch 32; iter: 2000; batch classifier loss: 0.374883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32; iter: 2200; batch classifier loss: 0.434445\n",
      "epoch 32; iter: 2400; batch classifier loss: 0.414074\n",
      "epoch 32; iter: 2600; batch classifier loss: 0.293256\n",
      "epoch 33; iter: 0; batch classifier loss: 0.458931\n",
      "epoch 33; iter: 200; batch classifier loss: 0.420616\n",
      "epoch 33; iter: 400; batch classifier loss: 0.317273\n",
      "epoch 33; iter: 600; batch classifier loss: 0.403576\n",
      "epoch 33; iter: 800; batch classifier loss: 0.514409\n",
      "epoch 33; iter: 1000; batch classifier loss: 0.512089\n",
      "epoch 33; iter: 1200; batch classifier loss: 0.448947\n",
      "epoch 33; iter: 1400; batch classifier loss: 0.406845\n",
      "epoch 33; iter: 1600; batch classifier loss: 0.371962\n",
      "epoch 33; iter: 1800; batch classifier loss: 0.330346\n",
      "epoch 33; iter: 2000; batch classifier loss: 0.409295\n",
      "epoch 33; iter: 2200; batch classifier loss: 0.366557\n",
      "epoch 33; iter: 2400; batch classifier loss: 0.438069\n",
      "epoch 33; iter: 2600; batch classifier loss: 0.380374\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445388\n",
      "epoch 34; iter: 200; batch classifier loss: 0.403386\n",
      "epoch 34; iter: 400; batch classifier loss: 0.429813\n",
      "epoch 34; iter: 600; batch classifier loss: 0.435330\n",
      "epoch 34; iter: 800; batch classifier loss: 0.411301\n",
      "epoch 34; iter: 1000; batch classifier loss: 0.398312\n",
      "epoch 34; iter: 1200; batch classifier loss: 0.426947\n",
      "epoch 34; iter: 1400; batch classifier loss: 0.553424\n",
      "epoch 34; iter: 1600; batch classifier loss: 0.393936\n",
      "epoch 34; iter: 1800; batch classifier loss: 0.363743\n",
      "epoch 34; iter: 2000; batch classifier loss: 0.483354\n",
      "epoch 34; iter: 2200; batch classifier loss: 0.436791\n",
      "epoch 34; iter: 2400; batch classifier loss: 0.332534\n",
      "epoch 34; iter: 2600; batch classifier loss: 0.487393\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461390\n",
      "epoch 35; iter: 200; batch classifier loss: 0.413934\n",
      "epoch 35; iter: 400; batch classifier loss: 0.404961\n",
      "epoch 35; iter: 600; batch classifier loss: 0.492811\n",
      "epoch 35; iter: 800; batch classifier loss: 0.489646\n",
      "epoch 35; iter: 1000; batch classifier loss: 0.428306\n",
      "epoch 35; iter: 1200; batch classifier loss: 0.407709\n",
      "epoch 35; iter: 1400; batch classifier loss: 0.403322\n",
      "epoch 35; iter: 1600; batch classifier loss: 0.360070\n",
      "epoch 35; iter: 1800; batch classifier loss: 0.393974\n",
      "epoch 35; iter: 2000; batch classifier loss: 0.352373\n",
      "epoch 35; iter: 2200; batch classifier loss: 0.425896\n",
      "epoch 35; iter: 2400; batch classifier loss: 0.382206\n",
      "epoch 35; iter: 2600; batch classifier loss: 0.377165\n",
      "epoch 36; iter: 0; batch classifier loss: 0.354689\n",
      "epoch 36; iter: 200; batch classifier loss: 0.359219\n",
      "epoch 36; iter: 400; batch classifier loss: 0.344805\n",
      "epoch 36; iter: 600; batch classifier loss: 0.422204\n",
      "epoch 36; iter: 800; batch classifier loss: 0.376771\n",
      "epoch 36; iter: 1000; batch classifier loss: 0.409028\n",
      "epoch 36; iter: 1200; batch classifier loss: 0.445780\n",
      "epoch 36; iter: 1400; batch classifier loss: 0.313743\n",
      "epoch 36; iter: 1600; batch classifier loss: 0.427722\n",
      "epoch 36; iter: 1800; batch classifier loss: 0.404146\n",
      "epoch 36; iter: 2000; batch classifier loss: 0.384780\n",
      "epoch 36; iter: 2200; batch classifier loss: 0.434243\n",
      "epoch 36; iter: 2400; batch classifier loss: 0.488817\n",
      "epoch 36; iter: 2600; batch classifier loss: 0.409908\n",
      "epoch 37; iter: 0; batch classifier loss: 0.323950\n",
      "epoch 37; iter: 200; batch classifier loss: 0.509852\n",
      "epoch 37; iter: 400; batch classifier loss: 0.394634\n",
      "epoch 37; iter: 600; batch classifier loss: 0.448056\n",
      "epoch 37; iter: 800; batch classifier loss: 0.444721\n",
      "epoch 37; iter: 1000; batch classifier loss: 0.406417\n",
      "epoch 37; iter: 1200; batch classifier loss: 0.392841\n",
      "epoch 37; iter: 1400; batch classifier loss: 0.455179\n",
      "epoch 37; iter: 1600; batch classifier loss: 0.325392\n",
      "epoch 37; iter: 1800; batch classifier loss: 0.552497\n",
      "epoch 37; iter: 2000; batch classifier loss: 0.437396\n",
      "epoch 37; iter: 2200; batch classifier loss: 0.448433\n",
      "epoch 37; iter: 2400; batch classifier loss: 0.401420\n",
      "epoch 37; iter: 2600; batch classifier loss: 0.346647\n",
      "epoch 38; iter: 0; batch classifier loss: 0.428094\n",
      "epoch 38; iter: 200; batch classifier loss: 0.396809\n",
      "epoch 38; iter: 400; batch classifier loss: 0.462661\n",
      "epoch 38; iter: 600; batch classifier loss: 0.440665\n",
      "epoch 38; iter: 800; batch classifier loss: 0.370653\n",
      "epoch 38; iter: 1000; batch classifier loss: 0.432186\n",
      "epoch 38; iter: 1200; batch classifier loss: 0.418236\n",
      "epoch 38; iter: 1400; batch classifier loss: 0.419670\n",
      "epoch 38; iter: 1600; batch classifier loss: 0.452417\n",
      "epoch 38; iter: 1800; batch classifier loss: 0.491931\n",
      "epoch 38; iter: 2000; batch classifier loss: 0.416947\n",
      "epoch 38; iter: 2200; batch classifier loss: 0.407271\n",
      "epoch 38; iter: 2400; batch classifier loss: 0.373800\n",
      "epoch 38; iter: 2600; batch classifier loss: 0.393598\n",
      "epoch 39; iter: 0; batch classifier loss: 0.407972\n",
      "epoch 39; iter: 200; batch classifier loss: 0.416303\n",
      "epoch 39; iter: 400; batch classifier loss: 0.415369\n",
      "epoch 39; iter: 600; batch classifier loss: 0.445698\n",
      "epoch 39; iter: 800; batch classifier loss: 0.414492\n",
      "epoch 39; iter: 1000; batch classifier loss: 0.388837\n",
      "epoch 39; iter: 1200; batch classifier loss: 0.332113\n",
      "epoch 39; iter: 1400; batch classifier loss: 0.413637\n",
      "epoch 39; iter: 1600; batch classifier loss: 0.456414\n",
      "epoch 39; iter: 1800; batch classifier loss: 0.438101\n",
      "epoch 39; iter: 2000; batch classifier loss: 0.387119\n",
      "epoch 39; iter: 2200; batch classifier loss: 0.394529\n",
      "epoch 39; iter: 2400; batch classifier loss: 0.518856\n",
      "epoch 39; iter: 2600; batch classifier loss: 0.377853\n",
      "epoch 40; iter: 0; batch classifier loss: 0.480208\n",
      "epoch 40; iter: 200; batch classifier loss: 0.300929\n",
      "epoch 40; iter: 400; batch classifier loss: 0.341267\n",
      "epoch 40; iter: 600; batch classifier loss: 0.416053\n",
      "epoch 40; iter: 800; batch classifier loss: 0.348713\n",
      "epoch 40; iter: 1000; batch classifier loss: 0.479391\n",
      "epoch 40; iter: 1200; batch classifier loss: 0.415414\n",
      "epoch 40; iter: 1400; batch classifier loss: 0.389920\n",
      "epoch 40; iter: 1600; batch classifier loss: 0.465152\n",
      "epoch 40; iter: 1800; batch classifier loss: 0.385733\n",
      "epoch 40; iter: 2000; batch classifier loss: 0.440484\n",
      "epoch 40; iter: 2200; batch classifier loss: 0.359925\n",
      "epoch 40; iter: 2400; batch classifier loss: 0.425949\n",
      "epoch 40; iter: 2600; batch classifier loss: 0.495667\n",
      "epoch 41; iter: 0; batch classifier loss: 0.409544\n",
      "epoch 41; iter: 200; batch classifier loss: 0.476696\n",
      "epoch 41; iter: 400; batch classifier loss: 0.387050\n",
      "epoch 41; iter: 600; batch classifier loss: 0.449141\n",
      "epoch 41; iter: 800; batch classifier loss: 0.411913\n",
      "epoch 41; iter: 1000; batch classifier loss: 0.345302\n",
      "epoch 41; iter: 1200; batch classifier loss: 0.405960\n",
      "epoch 41; iter: 1400; batch classifier loss: 0.441918\n",
      "epoch 41; iter: 1600; batch classifier loss: 0.363103\n",
      "epoch 41; iter: 1800; batch classifier loss: 0.367228\n",
      "epoch 41; iter: 2000; batch classifier loss: 0.494876\n",
      "epoch 41; iter: 2200; batch classifier loss: 0.385301\n",
      "epoch 41; iter: 2400; batch classifier loss: 0.422058\n",
      "epoch 41; iter: 2600; batch classifier loss: 0.463610\n",
      "epoch 42; iter: 0; batch classifier loss: 0.307995\n",
      "epoch 42; iter: 200; batch classifier loss: 0.359481\n",
      "epoch 42; iter: 400; batch classifier loss: 0.409277\n",
      "epoch 42; iter: 600; batch classifier loss: 0.434782\n",
      "epoch 42; iter: 800; batch classifier loss: 0.459239\n",
      "epoch 42; iter: 1000; batch classifier loss: 0.467705\n",
      "epoch 42; iter: 1200; batch classifier loss: 0.344517\n",
      "epoch 42; iter: 1400; batch classifier loss: 0.386737\n",
      "epoch 42; iter: 1600; batch classifier loss: 0.523922\n",
      "epoch 42; iter: 1800; batch classifier loss: 0.408053\n",
      "epoch 42; iter: 2000; batch classifier loss: 0.432928\n",
      "epoch 42; iter: 2200; batch classifier loss: 0.338402\n",
      "epoch 42; iter: 2400; batch classifier loss: 0.298334\n",
      "epoch 42; iter: 2600; batch classifier loss: 0.407791\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414538\n",
      "epoch 43; iter: 200; batch classifier loss: 0.379108\n",
      "epoch 43; iter: 400; batch classifier loss: 0.385295\n",
      "epoch 43; iter: 600; batch classifier loss: 0.464799\n",
      "epoch 43; iter: 800; batch classifier loss: 0.459029\n",
      "epoch 43; iter: 1000; batch classifier loss: 0.346293\n",
      "epoch 43; iter: 1200; batch classifier loss: 0.463313\n",
      "epoch 43; iter: 1400; batch classifier loss: 0.453093\n",
      "epoch 43; iter: 1600; batch classifier loss: 0.442527\n",
      "epoch 43; iter: 1800; batch classifier loss: 0.434420\n",
      "epoch 43; iter: 2000; batch classifier loss: 0.501540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43; iter: 2200; batch classifier loss: 0.476779\n",
      "epoch 43; iter: 2400; batch classifier loss: 0.477373\n",
      "epoch 43; iter: 2600; batch classifier loss: 0.488902\n",
      "epoch 44; iter: 0; batch classifier loss: 0.289174\n",
      "epoch 44; iter: 200; batch classifier loss: 0.439974\n",
      "epoch 44; iter: 400; batch classifier loss: 0.391435\n",
      "epoch 44; iter: 600; batch classifier loss: 0.337072\n",
      "epoch 44; iter: 800; batch classifier loss: 0.411448\n",
      "epoch 44; iter: 1000; batch classifier loss: 0.425814\n",
      "epoch 44; iter: 1200; batch classifier loss: 0.375711\n",
      "epoch 44; iter: 1400; batch classifier loss: 0.490960\n",
      "epoch 44; iter: 1600; batch classifier loss: 0.377234\n",
      "epoch 44; iter: 1800; batch classifier loss: 0.377988\n",
      "epoch 44; iter: 2000; batch classifier loss: 0.374928\n",
      "epoch 44; iter: 2200; batch classifier loss: 0.364781\n",
      "epoch 44; iter: 2400; batch classifier loss: 0.452705\n",
      "epoch 44; iter: 2600; batch classifier loss: 0.514269\n",
      "epoch 45; iter: 0; batch classifier loss: 0.392461\n",
      "epoch 45; iter: 200; batch classifier loss: 0.440745\n",
      "epoch 45; iter: 400; batch classifier loss: 0.404783\n",
      "epoch 45; iter: 600; batch classifier loss: 0.384122\n",
      "epoch 45; iter: 800; batch classifier loss: 0.382662\n",
      "epoch 45; iter: 1000; batch classifier loss: 0.360764\n",
      "epoch 45; iter: 1200; batch classifier loss: 0.413470\n",
      "epoch 45; iter: 1400; batch classifier loss: 0.482414\n",
      "epoch 45; iter: 1600; batch classifier loss: 0.446683\n",
      "epoch 45; iter: 1800; batch classifier loss: 0.474930\n",
      "epoch 45; iter: 2000; batch classifier loss: 0.412432\n",
      "epoch 45; iter: 2200; batch classifier loss: 0.422322\n",
      "epoch 45; iter: 2400; batch classifier loss: 0.427868\n",
      "epoch 45; iter: 2600; batch classifier loss: 0.452372\n",
      "epoch 46; iter: 0; batch classifier loss: 0.510418\n",
      "epoch 46; iter: 200; batch classifier loss: 0.458108\n",
      "epoch 46; iter: 400; batch classifier loss: 0.426166\n",
      "epoch 46; iter: 600; batch classifier loss: 0.393030\n",
      "epoch 46; iter: 800; batch classifier loss: 0.415018\n",
      "epoch 46; iter: 1000; batch classifier loss: 0.400848\n",
      "epoch 46; iter: 1200; batch classifier loss: 0.380842\n",
      "epoch 46; iter: 1400; batch classifier loss: 0.372796\n",
      "epoch 46; iter: 1600; batch classifier loss: 0.414918\n",
      "epoch 46; iter: 1800; batch classifier loss: 0.415810\n",
      "epoch 46; iter: 2000; batch classifier loss: 0.437220\n",
      "epoch 46; iter: 2200; batch classifier loss: 0.378144\n",
      "epoch 46; iter: 2400; batch classifier loss: 0.348717\n",
      "epoch 46; iter: 2600; batch classifier loss: 0.404145\n",
      "epoch 47; iter: 0; batch classifier loss: 0.441518\n",
      "epoch 47; iter: 200; batch classifier loss: 0.400243\n",
      "epoch 47; iter: 400; batch classifier loss: 0.489223\n",
      "epoch 47; iter: 600; batch classifier loss: 0.376722\n",
      "epoch 47; iter: 800; batch classifier loss: 0.358456\n",
      "epoch 47; iter: 1000; batch classifier loss: 0.426347\n",
      "epoch 47; iter: 1200; batch classifier loss: 0.383361\n",
      "epoch 47; iter: 1400; batch classifier loss: 0.363708\n",
      "epoch 47; iter: 1600; batch classifier loss: 0.310859\n",
      "epoch 47; iter: 1800; batch classifier loss: 0.418579\n",
      "epoch 47; iter: 2000; batch classifier loss: 0.479788\n",
      "epoch 47; iter: 2200; batch classifier loss: 0.419066\n",
      "epoch 47; iter: 2400; batch classifier loss: 0.376109\n",
      "epoch 47; iter: 2600; batch classifier loss: 0.430923\n",
      "epoch 48; iter: 0; batch classifier loss: 0.371761\n",
      "epoch 48; iter: 200; batch classifier loss: 0.543081\n",
      "epoch 48; iter: 400; batch classifier loss: 0.391628\n",
      "epoch 48; iter: 600; batch classifier loss: 0.370615\n",
      "epoch 48; iter: 800; batch classifier loss: 0.386631\n",
      "epoch 48; iter: 1000; batch classifier loss: 0.425521\n",
      "epoch 48; iter: 1200; batch classifier loss: 0.401807\n",
      "epoch 48; iter: 1400; batch classifier loss: 0.457569\n",
      "epoch 48; iter: 1600; batch classifier loss: 0.440138\n",
      "epoch 48; iter: 1800; batch classifier loss: 0.299557\n",
      "epoch 48; iter: 2000; batch classifier loss: 0.367227\n",
      "epoch 48; iter: 2200; batch classifier loss: 0.384699\n",
      "epoch 48; iter: 2400; batch classifier loss: 0.414767\n",
      "epoch 48; iter: 2600; batch classifier loss: 0.425632\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429387\n",
      "epoch 49; iter: 200; batch classifier loss: 0.431282\n",
      "epoch 49; iter: 400; batch classifier loss: 0.343332\n",
      "epoch 49; iter: 600; batch classifier loss: 0.380206\n",
      "epoch 49; iter: 800; batch classifier loss: 0.423584\n",
      "epoch 49; iter: 1000; batch classifier loss: 0.443731\n",
      "epoch 49; iter: 1200; batch classifier loss: 0.468885\n",
      "epoch 49; iter: 1400; batch classifier loss: 0.428149\n",
      "epoch 49; iter: 1600; batch classifier loss: 0.379921\n",
      "epoch 49; iter: 1800; batch classifier loss: 0.410136\n",
      "epoch 49; iter: 2000; batch classifier loss: 0.365273\n",
      "epoch 49; iter: 2200; batch classifier loss: 0.327537\n",
      "epoch 49; iter: 2400; batch classifier loss: 0.511150\n",
      "epoch 49; iter: 2600; batch classifier loss: 0.381270\n",
      "epoch 0; iter: 0; batch classifier loss: 0.647402; batch adversarial loss: 0.609155\n",
      "epoch 0; iter: 200; batch classifier loss: 0.380132; batch adversarial loss: 0.594728\n",
      "epoch 1; iter: 0; batch classifier loss: 0.501237; batch adversarial loss: 0.588586\n",
      "epoch 1; iter: 200; batch classifier loss: 0.380145; batch adversarial loss: 0.522305\n",
      "epoch 2; iter: 0; batch classifier loss: 0.459159; batch adversarial loss: 0.594580\n",
      "epoch 2; iter: 200; batch classifier loss: 0.444488; batch adversarial loss: 0.525448\n",
      "epoch 3; iter: 0; batch classifier loss: 0.415215; batch adversarial loss: 0.540211\n",
      "epoch 3; iter: 200; batch classifier loss: 0.519181; batch adversarial loss: 0.556309\n",
      "epoch 4; iter: 0; batch classifier loss: 0.584283; batch adversarial loss: 0.520107\n",
      "epoch 4; iter: 200; batch classifier loss: 0.429127; batch adversarial loss: 0.461160\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541320; batch adversarial loss: 0.397333\n",
      "epoch 5; iter: 200; batch classifier loss: 0.447771; batch adversarial loss: 0.434781\n",
      "epoch 6; iter: 0; batch classifier loss: 0.445769; batch adversarial loss: 0.401056\n",
      "epoch 6; iter: 200; batch classifier loss: 0.472696; batch adversarial loss: 0.493390\n",
      "epoch 7; iter: 0; batch classifier loss: 0.454294; batch adversarial loss: 0.441390\n",
      "epoch 7; iter: 200; batch classifier loss: 0.416815; batch adversarial loss: 0.469931\n",
      "epoch 8; iter: 0; batch classifier loss: 0.421757; batch adversarial loss: 0.406200\n",
      "epoch 8; iter: 200; batch classifier loss: 0.433455; batch adversarial loss: 0.401543\n",
      "epoch 9; iter: 0; batch classifier loss: 0.443238; batch adversarial loss: 0.399316\n",
      "epoch 9; iter: 200; batch classifier loss: 0.500624; batch adversarial loss: 0.343551\n",
      "epoch 10; iter: 0; batch classifier loss: 0.450842; batch adversarial loss: 0.454846\n",
      "epoch 10; iter: 200; batch classifier loss: 0.445562; batch adversarial loss: 0.428442\n",
      "epoch 11; iter: 0; batch classifier loss: 0.348626; batch adversarial loss: 0.436707\n",
      "epoch 11; iter: 200; batch classifier loss: 0.495973; batch adversarial loss: 0.440304\n",
      "epoch 12; iter: 0; batch classifier loss: 0.477759; batch adversarial loss: 0.332661\n",
      "epoch 12; iter: 200; batch classifier loss: 0.443686; batch adversarial loss: 0.439100\n",
      "epoch 13; iter: 0; batch classifier loss: 0.400583; batch adversarial loss: 0.328431\n",
      "epoch 13; iter: 200; batch classifier loss: 0.413744; batch adversarial loss: 0.334493\n",
      "epoch 14; iter: 0; batch classifier loss: 0.393977; batch adversarial loss: 0.338649\n",
      "epoch 14; iter: 200; batch classifier loss: 0.389143; batch adversarial loss: 0.351147\n",
      "epoch 15; iter: 0; batch classifier loss: 0.435728; batch adversarial loss: 0.352275\n",
      "epoch 15; iter: 200; batch classifier loss: 0.436910; batch adversarial loss: 0.380321\n",
      "epoch 16; iter: 0; batch classifier loss: 0.415809; batch adversarial loss: 0.279604\n",
      "epoch 16; iter: 200; batch classifier loss: 0.412218; batch adversarial loss: 0.392881\n",
      "epoch 17; iter: 0; batch classifier loss: 0.410112; batch adversarial loss: 0.532402\n",
      "epoch 17; iter: 200; batch classifier loss: 0.339579; batch adversarial loss: 0.418471\n",
      "epoch 18; iter: 0; batch classifier loss: 0.356878; batch adversarial loss: 0.333081\n",
      "epoch 18; iter: 200; batch classifier loss: 0.380933; batch adversarial loss: 0.468937\n",
      "epoch 19; iter: 0; batch classifier loss: 0.420158; batch adversarial loss: 0.393264\n",
      "epoch 19; iter: 200; batch classifier loss: 0.382083; batch adversarial loss: 0.459450\n",
      "epoch 20; iter: 0; batch classifier loss: 0.438480; batch adversarial loss: 0.357920\n",
      "epoch 20; iter: 200; batch classifier loss: 0.420250; batch adversarial loss: 0.391398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21; iter: 0; batch classifier loss: 0.411605; batch adversarial loss: 0.376724\n",
      "epoch 21; iter: 200; batch classifier loss: 0.408953; batch adversarial loss: 0.436764\n",
      "epoch 22; iter: 0; batch classifier loss: 0.476702; batch adversarial loss: 0.420509\n",
      "epoch 22; iter: 200; batch classifier loss: 0.378084; batch adversarial loss: 0.388220\n",
      "epoch 23; iter: 0; batch classifier loss: 0.400600; batch adversarial loss: 0.320062\n",
      "epoch 23; iter: 200; batch classifier loss: 0.371322; batch adversarial loss: 0.436332\n",
      "epoch 24; iter: 0; batch classifier loss: 0.418785; batch adversarial loss: 0.445719\n",
      "epoch 24; iter: 200; batch classifier loss: 0.459529; batch adversarial loss: 0.411823\n",
      "epoch 25; iter: 0; batch classifier loss: 0.400217; batch adversarial loss: 0.347935\n",
      "epoch 25; iter: 200; batch classifier loss: 0.352912; batch adversarial loss: 0.343624\n",
      "epoch 26; iter: 0; batch classifier loss: 0.359474; batch adversarial loss: 0.487309\n",
      "epoch 26; iter: 200; batch classifier loss: 0.357444; batch adversarial loss: 0.436272\n",
      "epoch 27; iter: 0; batch classifier loss: 0.487324; batch adversarial loss: 0.460303\n",
      "epoch 27; iter: 200; batch classifier loss: 0.390031; batch adversarial loss: 0.328337\n",
      "epoch 28; iter: 0; batch classifier loss: 0.511126; batch adversarial loss: 0.424604\n",
      "epoch 28; iter: 200; batch classifier loss: 0.403448; batch adversarial loss: 0.379679\n",
      "epoch 29; iter: 0; batch classifier loss: 0.443220; batch adversarial loss: 0.424884\n",
      "epoch 29; iter: 200; batch classifier loss: 0.365541; batch adversarial loss: 0.341016\n",
      "epoch 30; iter: 0; batch classifier loss: 0.348983; batch adversarial loss: 0.467354\n",
      "epoch 30; iter: 200; batch classifier loss: 0.384311; batch adversarial loss: 0.361651\n",
      "epoch 31; iter: 0; batch classifier loss: 0.359686; batch adversarial loss: 0.466292\n",
      "epoch 31; iter: 200; batch classifier loss: 0.395698; batch adversarial loss: 0.444079\n",
      "epoch 32; iter: 0; batch classifier loss: 0.388674; batch adversarial loss: 0.395429\n",
      "epoch 32; iter: 200; batch classifier loss: 0.415416; batch adversarial loss: 0.376242\n",
      "epoch 33; iter: 0; batch classifier loss: 0.471726; batch adversarial loss: 0.309473\n",
      "epoch 33; iter: 200; batch classifier loss: 0.393267; batch adversarial loss: 0.430816\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466262; batch adversarial loss: 0.406509\n",
      "epoch 34; iter: 200; batch classifier loss: 0.371343; batch adversarial loss: 0.343354\n",
      "epoch 35; iter: 0; batch classifier loss: 0.422377; batch adversarial loss: 0.427440\n",
      "epoch 35; iter: 200; batch classifier loss: 0.452155; batch adversarial loss: 0.425817\n",
      "epoch 36; iter: 0; batch classifier loss: 0.465024; batch adversarial loss: 0.368594\n",
      "epoch 36; iter: 200; batch classifier loss: 0.413539; batch adversarial loss: 0.447197\n",
      "epoch 37; iter: 0; batch classifier loss: 0.368367; batch adversarial loss: 0.506928\n",
      "epoch 37; iter: 200; batch classifier loss: 0.464179; batch adversarial loss: 0.467129\n",
      "epoch 38; iter: 0; batch classifier loss: 0.410991; batch adversarial loss: 0.325418\n",
      "epoch 38; iter: 200; batch classifier loss: 0.376936; batch adversarial loss: 0.389245\n",
      "epoch 39; iter: 0; batch classifier loss: 0.352477; batch adversarial loss: 0.374949\n",
      "epoch 39; iter: 200; batch classifier loss: 0.330438; batch adversarial loss: 0.440732\n",
      "epoch 40; iter: 0; batch classifier loss: 0.424515; batch adversarial loss: 0.357936\n",
      "epoch 40; iter: 200; batch classifier loss: 0.375224; batch adversarial loss: 0.469047\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410859; batch adversarial loss: 0.372811\n",
      "epoch 41; iter: 200; batch classifier loss: 0.316301; batch adversarial loss: 0.479586\n",
      "epoch 42; iter: 0; batch classifier loss: 0.391094; batch adversarial loss: 0.388526\n",
      "epoch 42; iter: 200; batch classifier loss: 0.491441; batch adversarial loss: 0.486608\n",
      "epoch 43; iter: 0; batch classifier loss: 0.440712; batch adversarial loss: 0.465163\n",
      "epoch 43; iter: 200; batch classifier loss: 0.316261; batch adversarial loss: 0.364604\n",
      "epoch 44; iter: 0; batch classifier loss: 0.512235; batch adversarial loss: 0.390324\n",
      "epoch 44; iter: 200; batch classifier loss: 0.401360; batch adversarial loss: 0.426253\n",
      "epoch 45; iter: 0; batch classifier loss: 0.413192; batch adversarial loss: 0.410708\n",
      "epoch 45; iter: 200; batch classifier loss: 0.376005; batch adversarial loss: 0.492311\n",
      "epoch 46; iter: 0; batch classifier loss: 0.371968; batch adversarial loss: 0.376071\n",
      "epoch 46; iter: 200; batch classifier loss: 0.365352; batch adversarial loss: 0.474776\n",
      "epoch 47; iter: 0; batch classifier loss: 0.386608; batch adversarial loss: 0.490947\n",
      "epoch 47; iter: 200; batch classifier loss: 0.350183; batch adversarial loss: 0.431688\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401419; batch adversarial loss: 0.432737\n",
      "epoch 48; iter: 200; batch classifier loss: 0.513912; batch adversarial loss: 0.432959\n",
      "epoch 49; iter: 0; batch classifier loss: 0.433689; batch adversarial loss: 0.352807\n",
      "epoch 49; iter: 200; batch classifier loss: 0.500474; batch adversarial loss: 0.378855\n",
      "epoch 0; iter: 0; batch classifier loss: 0.680133\n",
      "epoch 0; iter: 200; batch classifier loss: 0.420367\n",
      "epoch 1; iter: 0; batch classifier loss: 0.439262\n",
      "epoch 1; iter: 200; batch classifier loss: 0.387729\n",
      "epoch 2; iter: 0; batch classifier loss: 0.482543\n",
      "epoch 2; iter: 200; batch classifier loss: 0.437975\n",
      "epoch 3; iter: 0; batch classifier loss: 0.359969\n",
      "epoch 3; iter: 200; batch classifier loss: 0.372681\n",
      "epoch 4; iter: 0; batch classifier loss: 0.372586\n",
      "epoch 4; iter: 200; batch classifier loss: 0.369091\n",
      "epoch 5; iter: 0; batch classifier loss: 0.368462\n",
      "epoch 5; iter: 200; batch classifier loss: 0.376968\n",
      "epoch 6; iter: 0; batch classifier loss: 0.410169\n",
      "epoch 6; iter: 200; batch classifier loss: 0.426618\n",
      "epoch 7; iter: 0; batch classifier loss: 0.461652\n",
      "epoch 7; iter: 200; batch classifier loss: 0.346567\n",
      "epoch 8; iter: 0; batch classifier loss: 0.368111\n",
      "epoch 8; iter: 200; batch classifier loss: 0.383254\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516469\n",
      "epoch 9; iter: 200; batch classifier loss: 0.423266\n",
      "epoch 10; iter: 0; batch classifier loss: 0.305125\n",
      "epoch 10; iter: 200; batch classifier loss: 0.432315\n",
      "epoch 11; iter: 0; batch classifier loss: 0.475483\n",
      "epoch 11; iter: 200; batch classifier loss: 0.477409\n",
      "epoch 12; iter: 0; batch classifier loss: 0.342314\n",
      "epoch 12; iter: 200; batch classifier loss: 0.411798\n",
      "epoch 13; iter: 0; batch classifier loss: 0.462607\n",
      "epoch 13; iter: 200; batch classifier loss: 0.375873\n",
      "epoch 14; iter: 0; batch classifier loss: 0.401875\n",
      "epoch 14; iter: 200; batch classifier loss: 0.372540\n",
      "epoch 15; iter: 0; batch classifier loss: 0.395048\n",
      "epoch 15; iter: 200; batch classifier loss: 0.473310\n",
      "epoch 16; iter: 0; batch classifier loss: 0.460953\n",
      "epoch 16; iter: 200; batch classifier loss: 0.430230\n",
      "epoch 17; iter: 0; batch classifier loss: 0.439149\n",
      "epoch 17; iter: 200; batch classifier loss: 0.432775\n",
      "epoch 18; iter: 0; batch classifier loss: 0.442677\n",
      "epoch 18; iter: 200; batch classifier loss: 0.395945\n",
      "epoch 19; iter: 0; batch classifier loss: 0.527538\n",
      "epoch 19; iter: 200; batch classifier loss: 0.357070\n",
      "epoch 20; iter: 0; batch classifier loss: 0.368266\n",
      "epoch 20; iter: 200; batch classifier loss: 0.464314\n",
      "epoch 21; iter: 0; batch classifier loss: 0.454700\n",
      "epoch 21; iter: 200; batch classifier loss: 0.378925\n",
      "epoch 22; iter: 0; batch classifier loss: 0.378998\n",
      "epoch 22; iter: 200; batch classifier loss: 0.402735\n",
      "epoch 23; iter: 0; batch classifier loss: 0.431342\n",
      "epoch 23; iter: 200; batch classifier loss: 0.383689\n",
      "epoch 24; iter: 0; batch classifier loss: 0.402903\n",
      "epoch 24; iter: 200; batch classifier loss: 0.380644\n",
      "epoch 25; iter: 0; batch classifier loss: 0.360545\n",
      "epoch 25; iter: 200; batch classifier loss: 0.349373\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440917\n",
      "epoch 26; iter: 200; batch classifier loss: 0.456412\n",
      "epoch 27; iter: 0; batch classifier loss: 0.400093\n",
      "epoch 27; iter: 200; batch classifier loss: 0.456244\n",
      "epoch 28; iter: 0; batch classifier loss: 0.462056\n",
      "epoch 28; iter: 200; batch classifier loss: 0.507860\n",
      "epoch 29; iter: 0; batch classifier loss: 0.610266\n",
      "epoch 29; iter: 200; batch classifier loss: 0.336292\n",
      "epoch 30; iter: 0; batch classifier loss: 0.435578\n",
      "epoch 30; iter: 200; batch classifier loss: 0.518311\n",
      "epoch 31; iter: 0; batch classifier loss: 0.509088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31; iter: 200; batch classifier loss: 0.353875\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445848\n",
      "epoch 32; iter: 200; batch classifier loss: 0.405246\n",
      "epoch 33; iter: 0; batch classifier loss: 0.472004\n",
      "epoch 33; iter: 200; batch classifier loss: 0.446375\n",
      "epoch 34; iter: 0; batch classifier loss: 0.415029\n",
      "epoch 34; iter: 200; batch classifier loss: 0.390512\n",
      "epoch 35; iter: 0; batch classifier loss: 0.398497\n",
      "epoch 35; iter: 200; batch classifier loss: 0.406129\n",
      "epoch 36; iter: 0; batch classifier loss: 0.394259\n",
      "epoch 36; iter: 200; batch classifier loss: 0.367196\n",
      "epoch 37; iter: 0; batch classifier loss: 0.457523\n",
      "epoch 37; iter: 200; batch classifier loss: 0.401122\n",
      "epoch 38; iter: 0; batch classifier loss: 0.412706\n",
      "epoch 38; iter: 200; batch classifier loss: 0.385262\n",
      "epoch 39; iter: 0; batch classifier loss: 0.478746\n",
      "epoch 39; iter: 200; batch classifier loss: 0.414013\n",
      "epoch 40; iter: 0; batch classifier loss: 0.385285\n",
      "epoch 40; iter: 200; batch classifier loss: 0.429646\n",
      "epoch 41; iter: 0; batch classifier loss: 0.453956\n",
      "epoch 41; iter: 200; batch classifier loss: 0.390880\n",
      "epoch 42; iter: 0; batch classifier loss: 0.440978\n",
      "epoch 42; iter: 200; batch classifier loss: 0.489939\n",
      "epoch 43; iter: 0; batch classifier loss: 0.523189\n",
      "epoch 43; iter: 200; batch classifier loss: 0.384742\n",
      "epoch 44; iter: 0; batch classifier loss: 0.429400\n",
      "epoch 44; iter: 200; batch classifier loss: 0.423690\n",
      "epoch 45; iter: 0; batch classifier loss: 0.356511\n",
      "epoch 45; iter: 200; batch classifier loss: 0.438700\n",
      "epoch 46; iter: 0; batch classifier loss: 0.424157\n",
      "epoch 46; iter: 200; batch classifier loss: 0.348567\n",
      "epoch 47; iter: 0; batch classifier loss: 0.446531\n",
      "epoch 47; iter: 200; batch classifier loss: 0.466795\n",
      "epoch 48; iter: 0; batch classifier loss: 0.439506\n",
      "epoch 48; iter: 200; batch classifier loss: 0.411844\n",
      "epoch 49; iter: 0; batch classifier loss: 0.454517\n",
      "epoch 49; iter: 200; batch classifier loss: 0.478391\n",
      "\n",
      "prediction completed\n",
      "compiled all metrics\n",
      "all files saved to csv\n"
     ]
    }
   ],
   "source": [
    "privileged_groups = [{'race': 1}]\n",
    "unprivileged_groups = [{'race': 0}]\n",
    "\n",
    "print(\"Classification with Adult data set\\n\")\n",
    "dataset_orig = load_preproc_data_adult()\n",
    "\n",
    "matrix_accuracy_reweigh = {}\n",
    "matrix_accuracy_nonreweigh = {}\n",
    "matrix_fairness_reweigh = {}\n",
    "matrix_fairness_nonreweigh = {}\n",
    "\n",
    "runs = 10\n",
    "\n",
    "for i in range(0, runs):\n",
    "    print('run =', i+1)\n",
    "    \n",
    "    train, test = dataset_orig.split([0.7], shuffle=True)\n",
    "    train_transformed = reweighing_data(train, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # with reweighing\n",
    "    accuracy_reweigh, fairness_metrics_reweigh = make_prediction(train_transformed, test, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # Without reweighing\n",
    "    accuracy_nonreweigh, fairness_metrics_nonreweigh = make_prediction(train, test, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # store values for each run\n",
    "    matrix_accuracy_reweigh[i] = accuracy_reweigh\n",
    "    matrix_fairness_reweigh[i] = fairness_metrics_reweigh\n",
    "    matrix_accuracy_nonreweigh[i] = accuracy_nonreweigh\n",
    "    matrix_fairness_nonreweigh[i] = fairness_metrics_nonreweigh\n",
    "\n",
    "print('\\nprediction completed')\n",
    "\n",
    "metrics_adversarial_reweigh = []\n",
    "metrics_prejudice_reweigh = []\n",
    "metrics_nondebiasing_reweigh = []\n",
    "metrics_ensemble_reweigh = []\n",
    "metrics_adversarial_nonreweigh = []\n",
    "metrics_prejudice_nonreweigh = []\n",
    "metrics_nondebiasing_nonreweigh = []\n",
    "metrics_ensemble_nonreweigh = []\n",
    "\n",
    "for i in range(0, runs):\n",
    "    \n",
    "    # with reweighing\n",
    "    metrics_adversarial_reweigh.append(matrix_fairness_reweigh[i][0])\n",
    "    metrics_prejudice_reweigh.append(matrix_fairness_reweigh[i][1])\n",
    "    metrics_nondebiasing_reweigh.append(matrix_fairness_reweigh[i][2])\n",
    "    metrics_ensemble_reweigh.append(matrix_fairness_reweigh[i][3])\n",
    "    \n",
    "    # without reweighing\n",
    "    metrics_adversarial_nonreweigh.append(matrix_fairness_nonreweigh[i][0])\n",
    "    metrics_prejudice_nonreweigh.append(matrix_fairness_nonreweigh[i][1])\n",
    "    metrics_nondebiasing_nonreweigh.append(matrix_fairness_nonreweigh[i][2])\n",
    "    metrics_ensemble_nonreweigh.append(matrix_fairness_nonreweigh[i][3])\n",
    "\n",
    "print('compiled all metrics')\n",
    "\n",
    "\n",
    "# create data frame for all metrics\n",
    "columns = ['Adversarial Debiasing', 'Prejudice Remover', 'Nondebiasing', 'Ensemble']\n",
    "accuracy_reweigh = np.array(list(matrix_accuracy_reweigh.values()))\n",
    "accuracy_nonreweigh = np.array(list(matrix_accuracy_nonreweigh.values()))\n",
    "adult_accuracy_reweigh = pd.DataFrame(accuracy_reweigh, columns=columns)\n",
    "adult_accuracy_nonreweigh = pd.DataFrame(accuracy_nonreweigh, columns=columns)\n",
    "\n",
    "# fairness metrics\n",
    "columns = ['Mean Difference', 'Disparate Impact', 'Equal Opportunity Difference', 'Average Odds Difference', 'Theil Index']\n",
    "adult_adversarial_reweigh = pd.DataFrame(metrics_adversarial_reweigh, columns=columns)\n",
    "adult_prejudice_reweigh = pd.DataFrame(metrics_prejudice_reweigh, columns=columns)\n",
    "adult_nondebiasing_reweigh = pd.DataFrame(metrics_nondebiasing_reweigh, columns=columns)\n",
    "adult_ensemble_reweigh = pd.DataFrame(metrics_ensemble_reweigh, columns=columns)\n",
    "\n",
    "adult_adversarial_nonreweigh = pd.DataFrame(metrics_adversarial_nonreweigh, columns=columns)\n",
    "adult_prejudice_nonreweigh = pd.DataFrame(metrics_prejudice_nonreweigh, columns=columns)\n",
    "adult_nondebiasing_nonreweigh = pd.DataFrame(metrics_nondebiasing_nonreweigh, columns=columns)\n",
    "adult_ensemble_nonreweigh = pd.DataFrame(metrics_ensemble_nonreweigh, columns=columns)\n",
    "\n",
    "\n",
    "# save to csv\n",
    "adult_accuracy_reweigh.to_csv(\"results-11feb/race/adult/reweighed/accuracy.csv\", encoding='utf-8')\n",
    "adult_adversarial_reweigh.to_csv(\"results-11feb/race/adult/reweighed/adversarial.csv\", encoding='utf-8')\n",
    "adult_prejudice_reweigh.to_csv(\"results-11feb/race/adult/reweighed/prejudice.csv\", encoding='utf-8')\n",
    "adult_nondebiasing_reweigh.to_csv(\"results-11feb/race/adult/reweighed/neural_net.csv\", encoding='utf-8')\n",
    "adult_ensemble_reweigh.to_csv(\"results-11feb/race/adult/reweighed/ensemble.csv\", encoding='utf-8')\n",
    "\n",
    "adult_accuracy_nonreweigh.to_csv(\"results-11feb/race/adult/non-reweighed/accuracy.csv\", encoding='utf-8')\n",
    "adult_adversarial_nonreweigh.to_csv(\"results-11feb/race/adult/non-reweighed/adversarial.csv\", encoding='utf-8')\n",
    "adult_prejudice_nonreweigh.to_csv(\"results-11feb/race/adult/non-reweighed/prejudice.csv\", encoding='utf-8')\n",
    "adult_nondebiasing_nonreweigh.to_csv(\"results-11feb/race/adult/non-reweighed/neural_net.csv\", encoding='utf-8')\n",
    "adult_ensemble_nonreweigh.to_csv(\"results-11feb/race/adult/non-reweighed/ensemble.csv\", encoding='utf-8')\n",
    "\n",
    "print('all files saved to csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
