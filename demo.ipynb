{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "from aif360.algorithms.inprocessing import PrejudiceRemover\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import errno\n",
    "import math\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_compasdataset(df):\n",
    "    df = df[['age', 'c_charge_degree', 'race', 'age_cat', 'score_text',\n",
    "                 'sex', 'priors_count', 'days_b_screening_arrest', 'decile_score',\n",
    "                 'is_recid', 'two_year_recid', 'c_jail_in', 'c_jail_out']]\n",
    "\n",
    "    # Indices of data samples to keep\n",
    "    ix = df['days_b_screening_arrest'] <= 30\n",
    "    ix = (df['days_b_screening_arrest'] >= -30) & ix\n",
    "    ix = (df['is_recid'] != -1) & ix\n",
    "    ix = (df['c_charge_degree'] != \"O\") & ix\n",
    "    ix = (df['score_text'] != 'N/A') & ix\n",
    "    df = df.loc[ix,:]\n",
    "    df['length_of_stay'] = (pd.to_datetime(df['c_jail_out']) - pd.to_datetime(df['c_jail_in'])).apply(lambda x: x.days)\n",
    "\n",
    "    # Restrict races to African-American and Caucasian\n",
    "    df = df.loc[~df['race'].isin(['Native American','Hispanic','Asian','Other']),:]\n",
    "\n",
    "    df = df[['sex','race','age_cat','c_charge_degree','score_text','priors_count','is_recid', 'two_year_recid','length_of_stay']]\n",
    "\n",
    "    df['priors_count'] = df['priors_count'].apply(lambda x: 0 if x <= 0 else ('1 to 3' if 1 <= x <= 3 else 'More than 3'))\n",
    "    df['length_of_stay'] = df['length_of_stay'].apply(lambda x: '<week' if x <= 7 else ('<3months' if 8 < x <= 93 else '>3months'))\n",
    "    df['score_text'] = df['score_text'].apply(lambda x: 'MediumHigh' if (x == 'High')| (x == 'Medium') else x)\n",
    "    df['age_cat'] = df['age_cat'].apply(lambda x: '25 to 45' if x == '25 - 45' else x)\n",
    "\n",
    "    df['sex'] = df['sex'].replace({'Female': 1.0, 'Male': 0.0})\n",
    "    df['race'] = df['race'].apply(lambda x: 1.0 if x == 'Caucasian' else 0.0)\n",
    "\n",
    "    df = df[['two_year_recid', 'sex', 'race', 'age_cat', 'priors_count', 'c_charge_degree']]\n",
    "\n",
    "    protected_attributes = ['sex', 'race']\n",
    "    label_name = 'two_year_recid'\n",
    "    categorical_features = ['age_cat', 'priors_count', 'c_charge_degree']\n",
    "    features = categorical_features + [label_name] + protected_attributes\n",
    "\n",
    "    # privileged classes\n",
    "    privileged_classes = {\"sex\": [1.0], \"race\": [1.0]}\n",
    "\n",
    "    # protected attribute maps\n",
    "    protected_attribute_map = {\"sex\": {0.0: 'Male', 1.0: 'Female'},\n",
    "                                \"race\": {1.0: 'Caucasian', 0.0: 'Not Caucasian'}}\n",
    "\n",
    "\n",
    "    data = StandardDataset(df, label_name, favorable_classes=[0],\n",
    "                           protected_attribute_names=protected_attributes,\n",
    "                           privileged_classes=[privileged_classes[x] for x in protected_attributes],\n",
    "                           categorical_features=categorical_features,\n",
    "                           features_to_keep=features,\n",
    "                           metadata={'label_maps': [{1.0: 'Did recid.', 0.0: 'No recid.'}],\n",
    "                                     'protected_attribute_maps': [protected_attribute_map[x] for x in protected_attributes]})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_germandataset(df):\n",
    "    def group_credit_hist(x):\n",
    "        if x in ['no credits taken/ all credits paid back duly', 'all credits at this bank paid back duly', 'existing credits paid back duly till now']:\n",
    "            return 'None/Paid'\n",
    "        elif x == 'delay in paying off in the past':\n",
    "            return 'Delay'\n",
    "        elif x == 'critical account/ other credits existing (not at this bank)':\n",
    "            return 'Other'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    def group_employ(x):\n",
    "        if x == 'unemployed':\n",
    "            return 'Unemployed'\n",
    "        elif x in ['... < 1 year ', '1 <= ... < 4 years']:\n",
    "            return '1-4 years'\n",
    "        elif x in ['4 <= ... < 7 years', '.. >= 7 years']:\n",
    "            return '4+ years'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    def group_savings(x):\n",
    "        if x in ['... < 100 DM', '100 <= ... < 500 DM']:\n",
    "            return '<500'\n",
    "        elif x in ['500 <= ... < 1000 DM ', '.. >= 1000 DM ']:\n",
    "            return '500+'\n",
    "        elif x == 'unknown/ no savings account':\n",
    "            return 'Unknown/None'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    def group_status(x):\n",
    "        if x in ['< 0 DM', '0 <= ... < 200 DM']:\n",
    "            return '<200'\n",
    "        elif x in ['>= 200 DM / salary assignments for at least 1 year']:\n",
    "            return '200+'\n",
    "        elif x == 'no checking account':\n",
    "            return 'None'\n",
    "        else:\n",
    "            return 'NA'\n",
    "\n",
    "    status_map = {'male : divorced/separated': 1.0,\n",
    "                'male : single': 1.0,\n",
    "                'male : married/widowed': 1.0,\n",
    "                'female : divorced/separated/married': 0.0,\n",
    "                'female : single': 0.0}\n",
    "\n",
    "    df['personal_status_sex'] = df['personal_status_sex'].replace(status_map)\n",
    "    df['credit_history'] = df['credit_history'].apply(lambda x: group_credit_hist(x))\n",
    "    df['savings'] = df['savings'].apply(lambda x: group_savings(x))\n",
    "    df['present_emp_since'] = df['present_emp_since'].apply(lambda x: group_employ(x))\n",
    "    df['age'] = df['age'].apply(lambda x: np.float(x >= 25))\n",
    "    df['account_check_status'] = df['account_check_status'].apply(lambda x: group_status(x))\n",
    "\n",
    "    df = df.rename(columns = {'default': 'credit', 'present_emp_since': 'employment', 'account_check_status': 'status', 'personal_status_sex': 'sex'})\n",
    "\n",
    "    protected_attribute = ['sex', 'age']\n",
    "    label_name = 'credit'\n",
    "    categorical_features = ['credit_history', 'savings', 'employment']\n",
    "    features = categorical_features + [label_name] + protected_attribute\n",
    "\n",
    "    privileged_class = {'sex': [1.0], 'age': [1.0]}\n",
    "\n",
    "    protected_attribute_map = {\"sex\": {1.0: 'male', 0.0: 'female'},\n",
    "                            \"age\": {1.0: 'old', 0.0: 'young'}}\n",
    "\n",
    "    data = StandardDataset(df, label_name, favorable_classes=[1],\n",
    "                            protected_attribute_names=protected_attribute,\n",
    "                            privileged_classes=[privileged_class[x] for x in protected_attribute],\n",
    "                            categorical_features=categorical_features,\n",
    "                            features_to_keep=features,\n",
    "                            metadata={'label_maps': [{1.0: 'Good Credit', 2.0: 'Bad Credit'}],\n",
    "                                    'protected_attribute_maps': [protected_attribute_map[x] for x in protected_attribute]})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Reweighing ##############\n",
    "\n",
    "def reweighing_data(train, unprivileged_group, privileged_group):\n",
    "    RW = Reweighing(unprivileged_groups=unprivileged_group, privileged_groups=privileged_group)\n",
    "    RW.fit(train)\n",
    "    train_transformed = RW.transform(train)\n",
    "\n",
    "    # change weights to whole numbers\n",
    "    for i in range(train_transformed.instance_weights.size):\n",
    "        train_transformed.instance_weights[i] = (round(train_transformed.instance_weights[i] / 0.1) * 0.1) * 10\n",
    "        weights = copy.deepcopy(train_transformed.instance_weights)\n",
    "\n",
    "    # change train_transformed.features and train_transformed.labels and train_transformed.protected_attributes according to the weights of each instance\n",
    "    for i in range(train_transformed.features.shape[0]):\n",
    "        row = copy.deepcopy(train_transformed.features[i])\n",
    "        row_label = copy.deepcopy(train_transformed.labels[i])\n",
    "        row_protected_attributes = copy.deepcopy(train_transformed.protected_attributes[i])\n",
    "        row_protected_attributes.resize(1,2)\n",
    "        row.resize(1,train_transformed.features.shape[1])\n",
    "        row_label.resize(1,1)\n",
    "        weight = int(weights[i])\n",
    "        for j in range(weight-1):\n",
    "            train_transformed.features = np.concatenate((train_transformed.features,row))\n",
    "            train_transformed.labels = np.concatenate((train_transformed.labels,row_label))\n",
    "            train_transformed.protected_attributes = np.concatenate((train_transformed.protected_attributes,row_protected_attributes))\n",
    "\n",
    "    # change the train_transformed to a numpy array of ones to match number of rows in features\n",
    "    train_transformed.instance_weights = np.ones(train_transformed.features.shape[0])\n",
    "\n",
    "    return train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_rates(input_data, output_data, attribute_name, privileged=None, unprivileged=None, favourable=None, unfavourable=None):\n",
    "\n",
    "    index_attribute = input_data.feature_names.index(attribute_name)\n",
    "    privileged = float(privileged)\n",
    "    unprivileged = float(unprivileged)\n",
    "    \n",
    "    input_priv = input_data.labels[np.where(input_data.features[:,index_attribute] == privileged)]\n",
    "    output_priv = output_data.labels[np.where(output_data.features[:,index_attribute] == privileged)]\n",
    "    priv_labels = np.concatenate((input_priv, output_priv), axis=1)\n",
    "    \n",
    "    input_unpriv = input_data.labels[np.where(input_data.features[:,index_attribute] == unprivileged)]\n",
    "    output_unpriv = output_data.labels[np.where(output_data.features[:,index_attribute] == unprivileged)]\n",
    "    unpriv_labels = np.concatenate((input_unpriv, output_unpriv), axis=1)\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(priv_labels.shape[0]):\n",
    "        input_label = priv_labels[i][0]\n",
    "        output_label = priv_labels[i][1]\n",
    "        if input_label == output_label:\n",
    "            if input_label == unfavourable:\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                tp = tp + 1\n",
    "        else:\n",
    "            if input_label == favourable and output_label == unfavourable:\n",
    "                fn = fn + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "    \n",
    "    rates_privileged = [tp,fp,tn,fn]\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(unpriv_labels.shape[0]):\n",
    "        input_label = unpriv_labels[i][0]\n",
    "        output_label = unpriv_labels[i][1]\n",
    "        if input_label == output_label:\n",
    "            if input_label == unfavourable:\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                tp = tp + 1\n",
    "        else:\n",
    "            if input_label == favourable and output_label == unfavourable:\n",
    "                fn = fn + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "                \n",
    "    rates_unprivileged = [tp,fp,tn,fn]  \n",
    "    \n",
    "    rates_list = [rates_privileged, rates_unprivileged]\n",
    "    \n",
    "    return rates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_opp_diff(input_data, output_data, attribute_name, privileged, unprivileged, favourable, unfavourable):\n",
    "    rates_both = output_rates(input_data, output_data, attribute_name, privileged, unprivileged, favourable, unfavourable)\n",
    "    \n",
    "    # [tp, fp, tn, fn]\n",
    "    outcome_privileged = rates_both[0]\n",
    "    outcome_unprivileged = rates_both[1]\n",
    "    \n",
    "    # true positive rate = tp / (tp + fn)\n",
    "    tpr_privileged = outcome_privileged[0] / (outcome_privileged[0] + outcome_privileged[3])\n",
    "    tpr_unprivileged = outcome_unprivileged[0] / (outcome_unprivileged[0] + outcome_unprivileged[3])\n",
    "\n",
    "    fairness = tpr_unprivileged - tpr_privileged\n",
    "    \n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_odds_diff(input_data, output_data, attribute_name, privileged, unprivileged, favourable, unfavourable):\n",
    "    rates_both = output_rates(input_data, output_data, attribute_name, privileged, unprivileged, favourable, unfavourable)\n",
    "    \n",
    "    # [tp, fp, tn, fn]\n",
    "    outcome_privileged = rates_both[0]\n",
    "    outcome_unprivileged = rates_both[1]\n",
    "    \n",
    "    # true positive rate = tp / (tp + fn)\n",
    "    tpr_privileged = outcome_privileged[0] / (outcome_privileged[0] + outcome_privileged[3])\n",
    "    tpr_unprivileged = outcome_unprivileged[0] / (outcome_unprivileged[0] + outcome_unprivileged[3])\n",
    "\n",
    "    # false positive rate = fp / (fp + tn)\n",
    "    fpr_privileged = outcome_privileged[1] / (outcome_privileged[1] + outcome_privileged[2])\n",
    "    fpr_unprivileged = outcome_unprivileged[1] / (outcome_unprivileged[1] + outcome_unprivileged[2])\n",
    "    \n",
    "    fpr_diff = fpr_unprivileged - fpr_privileged\n",
    "    tpr_diff = tpr_unprivileged - tpr_unprivileged\n",
    "    \n",
    "    fairness = (fpr_diff + tpr_diff) * 0.5\n",
    "    \n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(train, test, unprivileged_groups, privileged_groups):\n",
    "    \n",
    "    ################## adversarial debiasing #################\n",
    "\n",
    "    sess = tf.Session()\n",
    "    debiased_model_reweighing = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                                                     unprivileged_groups = unprivileged_groups,\n",
    "                                                     scope_name='debiased_classifier', debias=True, sess=sess)\n",
    "    debiased_model_reweighing.fit(train)\n",
    "    dataset_debiasing_test_reweighing = debiased_model_reweighing.predict(test)\n",
    "    sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    ##################### metrics #####################\n",
    "\n",
    "    metric_test = BinaryLabelDatasetMetric(dataset_debiasing_test_reweighing,\n",
    "                                           unprivileged_groups=unprivileged_groups,\n",
    "                                           privileged_groups=privileged_groups)\n",
    "    acc_test = ClassificationMetric(test, dataset_debiasing_test_reweighing,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "\n",
    "    accuracy_adversarial = accuracy_score(y_true = test.labels, y_pred = dataset_debiasing_test_reweighing.labels)\n",
    "    \n",
    "    metrics_adversarial = [metric_test.mean_difference(),acc_test.disparate_impact(), acc_test.equal_opportunity_difference(), acc_test.average_odds_difference(), acc_test.theil_index()]\n",
    "\n",
    "\n",
    "    ##################### prejudice remover #####################\n",
    "    prejudice_model_reweighing = PrejudiceRemover(eta=100, sensitive_attr='sex')\n",
    "    prejudice_model_reweighing.fit(train)\n",
    "    dataset_prejudice_test_reweighing = prejudice_model_reweighing.predict(test)\n",
    "\n",
    "    ##################### metrics #####################\n",
    "\n",
    "    metric_test = BinaryLabelDatasetMetric(dataset_prejudice_test_reweighing,\n",
    "                                           unprivileged_groups=unprivileged_groups,\n",
    "                                           privileged_groups=privileged_groups)\n",
    "    acc_test = ClassificationMetric(test, dataset_prejudice_test_reweighing,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    accuracy_prejudice = accuracy_score(y_true=test.labels, y_pred=dataset_prejudice_test_reweighing.labels)\n",
    "    \n",
    "    equal_opportunity_difference = equal_opp_diff(test, dataset_debiasing_test_reweighing,\n",
    "                                                  'sex', privileged=1, unprivileged=0, favourable=1, unfavourable=0)\n",
    "    \n",
    "    average_odds_difference = avg_odds_diff(test, dataset_debiasing_test_reweighing,\n",
    "                                                  'sex', privileged=1, unprivileged=0, favourable=1, unfavourable=0)\n",
    "    \n",
    "    if acc_test.disparate_impact() == math.inf:\n",
    "        disparate_impact = 5.0\n",
    "    else:\n",
    "        disparate_impact = acc_test.disparate_impact()\n",
    "    \n",
    "    metrics_prejudice = [metric_test.mean_difference(), disparate_impact, equal_opportunity_difference, average_odds_difference, acc_test.theil_index()]\n",
    "\n",
    "\n",
    "    ##################### normal neural net #####################\n",
    "    sess = tf.Session()\n",
    "    neural_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                                        unprivileged_groups = unprivileged_groups,\n",
    "                                        scope_name='debiased_classifier', debias=False, sess=sess)\n",
    "    neural_model.fit(train)\n",
    "    dataset_neural_test = neural_model.predict(test)\n",
    "    sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    ##################### metrics #####################\n",
    "\n",
    "    metric_test = BinaryLabelDatasetMetric(dataset_neural_test,\n",
    "                                           unprivileged_groups=unprivileged_groups,\n",
    "                                           privileged_groups=privileged_groups)\n",
    "    acc_test = ClassificationMetric(test, dataset_neural_test,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    accuracy_nondebiasing = accuracy_score(y_true=test.labels, y_pred=dataset_neural_test.labels)\n",
    "\n",
    "    metrics_nondebiasing = [metric_test.mean_difference(),acc_test.disparate_impact(), acc_test.equal_opportunity_difference(), acc_test.average_odds_difference(), acc_test.theil_index()]\n",
    "\n",
    "\n",
    "    ##################### ensemble #####################\n",
    "    pred_labels_test = []\n",
    "    for i in range(0, len(test.features)):\n",
    "        arr_test = mode([dataset_debiasing_test_reweighing.labels[i], dataset_prejudice_test_reweighing.labels[i], dataset_neural_test.labels[i]])\n",
    "        pred_labels_test.append(arr_test[0][0])\n",
    "        dataset_ensemble_test = test.copy()\n",
    "        dataset_ensemble_test.labels = np.array(pred_labels_test)\n",
    "\n",
    "\n",
    "    ##################### metrics #####################\n",
    "\n",
    "    metric_test = BinaryLabelDatasetMetric(dataset_ensemble_test,\n",
    "                                           unprivileged_groups=unprivileged_groups,\n",
    "                                           privileged_groups=privileged_groups)\n",
    "    acc_test = ClassificationMetric(test, dataset_ensemble_test,\n",
    "                                    unprivileged_groups=unprivileged_groups,\n",
    "                                    privileged_groups=privileged_groups)\n",
    "    accuracy_ensemble = accuracy_score(y_true=test.labels, y_pred=dataset_ensemble_test.labels)\n",
    "    \n",
    "    metrics_ensemble = [metric_test.mean_difference(),acc_test.disparate_impact(), acc_test.equal_opportunity_difference(), acc_test.average_odds_difference(), acc_test.theil_index()]\n",
    "\n",
    "    accuracy_scores = [accuracy_adversarial, accuracy_prejudice, accuracy_nondebiasing, accuracy_ensemble]\n",
    "    fairness_metrics = [metrics_adversarial, metrics_prejudice, metrics_nondebiasing, metrics_ensemble]\n",
    "    \n",
    "    return accuracy_scores, fairness_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "print(\"Classification with Compas data set\\n\")\n",
    "df = pd.read_csv('dataset/compas-scores-two-years.csv')\n",
    "dataset_orig = preprocess_compasdataset(df)\n",
    "\n",
    "matrix_accuracy_reweigh = {}\n",
    "matrix_accuracy_nonreweigh = {}\n",
    "matrix_fairness_reweigh = {}\n",
    "matrix_fairness_nonreweigh = {}\n",
    "\n",
    "runs = 10\n",
    "\n",
    "for i in range(0, runs):\n",
    "    print('run =', i+1)\n",
    "    \n",
    "    train, test = dataset_orig.split([0.7], shuffle=True)\n",
    "    train_transformed = reweighing_data(train, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # with reweighing\n",
    "    accuracy_reweigh, fairness_metrics_reweigh = make_prediction(train_transformed, test, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # Without reweighing\n",
    "    accuracy_nonreweigh, fairness_metrics_nonreweigh = make_prediction(train, test, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # store values for each run\n",
    "    matrix_accuracy_reweigh[i] = accuracy_reweigh\n",
    "    matrix_fairness_reweigh[i] = fairness_metrics_reweigh\n",
    "    matrix_accuracy_nonreweigh[i] = accuracy_nonreweigh\n",
    "    matrix_fairness_nonreweigh[i] = fairness_metrics_nonreweigh\n",
    "\n",
    "print('\\nprediction completed')\n",
    "\n",
    "metrics_adversarial_reweigh = []\n",
    "metrics_prejudice_reweigh = []\n",
    "metrics_nondebiasing_reweigh = []\n",
    "metrics_ensemble_reweigh = []\n",
    "metrics_adversarial_nonreweigh = []\n",
    "metrics_prejudice_nonreweigh = []\n",
    "metrics_nondebiasing_nonreweigh = []\n",
    "metrics_ensemble_nonreweigh = []\n",
    "\n",
    "# mean_difference_reweigh = []\n",
    "# disparate_impact_reweigh = []\n",
    "# equal_opportunity_difference_reweigh = []\n",
    "# average_odds_difference_reweigh = []\n",
    "# theil_index_reweigh = []\n",
    "# mean_difference_nonreweigh = []\n",
    "# disparate_impact_nonreweigh = []\n",
    "# equal_opportunity_difference_nonreweigh = []\n",
    "# average_odds_difference_nonreweigh = []\n",
    "# theil_index_nonreweigh = []\n",
    "\n",
    "for i in range(0, runs):\n",
    "    \n",
    "    # with reweighing\n",
    "    metrics_adversarial_reweigh.append(matrix_fairness_reweigh[i][0])\n",
    "    metrics_prejudice_reweigh.append(matrix_fairness_reweigh[i][1])\n",
    "    metrics_nondebiasing_reweigh.append(matrix_fairness_reweigh[i][2])\n",
    "    metrics_ensemble_reweigh.append(matrix_fairness_reweigh[i][3])\n",
    "    \n",
    "    # without reweighing\n",
    "    metrics_adversarial_nonreweigh.append(matrix_fairness_nonreweigh[i][0])\n",
    "    metrics_prejudice_nonreweigh.append(matrix_fairness_nonreweigh[i][1])\n",
    "    metrics_nondebiasing_nonreweigh.append(matrix_fairness_nonreweigh[i][2])\n",
    "    metrics_ensemble_nonreweigh.append(matrix_fairness_nonreweigh[i][3])\n",
    "\n",
    "print('compiled all metrics')\n",
    "\n",
    "\n",
    "# create data frame for all metrics\n",
    "columns = ['Adversarial Debiasing', 'Prejudice Remover', 'Nondebiasing', 'Ensemble']\n",
    "accuracy_reweigh = np.array(list(matrix_accuracy_reweigh.values()))\n",
    "accuracy_nonreweigh = np.array(list(matrix_accuracy_nonreweigh.values()))\n",
    "compas_accuracy_reweigh = pd.DataFrame(accuracy_reweigh, columns=columns)\n",
    "compas_accuracy_nonreweigh = pd.DataFrame(accuracy_nonreweigh, columns=columns)\n",
    "\n",
    "# fairness metrics\n",
    "columns = ['Mean Difference', 'Disparate Impact', 'Equal Opportunity Difference', 'Average Odds Difference', 'Theil Index']\n",
    "compas_adversarial_reweigh = pd.DataFrame(metrics_adversarial_reweigh, columns=columns)\n",
    "compas_prejudice_reweigh = pd.DataFrame(metrics_prejudice_reweigh, columns=columns)\n",
    "compas_nondebiasing_reweigh = pd.DataFrame(metrics_nondebiasing_reweigh, columns=columns)\n",
    "compas_ensemble_reweigh = pd.DataFrame(metrics_ensemble_reweigh, columns=columns)\n",
    "\n",
    "compas_adversarial_nonreweigh = pd.DataFrame(metrics_adversarial_nonreweigh, columns=columns)\n",
    "compas_prejudice_nonreweigh = pd.DataFrame(metrics_prejudice_nonreweigh, columns=columns)\n",
    "compas_nondebiasing_nonreweigh = pd.DataFrame(metrics_nondebiasing_nonreweigh, columns=columns)\n",
    "compas_ensemble_nonreweigh = pd.DataFrame(metrics_ensemble_nonreweigh, columns=columns)\n",
    "\n",
    "\n",
    "# save to csv\n",
    "compas_accuracy_reweigh.to_csv(\"results/compas/reweighed/accuracy.csv\", encoding='utf-8')\n",
    "compas_adversarial_reweigh.to_csv(\"results/compas/reweighed/adversarial.csv\", encoding='utf-8')\n",
    "compas_prejudice_reweigh.to_csv(\"results/compas/reweighed/prejudice.csv\", encoding='utf-8')\n",
    "compas_nondebiasing_reweigh.to_csv(\"results/compas/reweighed/neural_net.csv\", encoding='utf-8')\n",
    "compas_ensemble_reweigh.to_csv(\"results/compas/reweighed/ensemble.csv\", encoding='utf-8')\n",
    "\n",
    "compas_accuracy_nonreweigh.to_csv(\"results/compas/non-reweighed/accuracy.csv\", encoding='utf-8')\n",
    "compas_adversarial_nonreweigh.to_csv(\"results/compas/non-reweighed/adversarial.csv\", encoding='utf-8')\n",
    "compas_prejudice_nonreweigh.to_csv(\"results/compas/non-reweighed/prejudice.csv\", encoding='utf-8')\n",
    "compas_nondebiasing_nonreweigh.to_csv(\"results/compas/non-reweighed/neural_net.csv\", encoding='utf-8')\n",
    "compas_ensemble_nonreweigh.to_csv(\"results/compas/non-reweighed/ensemble.csv\", encoding='utf-8')\n",
    "\n",
    "print('all files saved to csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "print(\"Classification with German data set\\n\")\n",
    "df = pd.read_csv('dataset/german_credit.csv')\n",
    "dataset_orig = preprocess_germandataset(df)\n",
    "\n",
    "matrix_accuracy_reweigh = {}\n",
    "matrix_accuracy_nonreweigh = {}\n",
    "matrix_fairness_reweigh = {}\n",
    "matrix_fairness_nonreweigh = {}\n",
    "\n",
    "runs = 10\n",
    "\n",
    "for i in range(0, runs):\n",
    "    print('run =', i+1)\n",
    "    \n",
    "    train, test = dataset_orig.split([0.7], shuffle=True)\n",
    "    train_transformed = reweighing_data(train, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # with reweighing\n",
    "    accuracy_reweigh, fairness_metrics_reweigh = make_prediction(train_transformed, test, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # Without reweighing\n",
    "    accuracy_nonreweigh, fairness_metrics_nonreweigh = make_prediction(train, test, unprivileged_groups, privileged_groups)\n",
    "    \n",
    "    # store values for each run\n",
    "    matrix_accuracy_reweigh[i] = accuracy_reweigh\n",
    "    matrix_fairness_reweigh[i] = fairness_metrics_reweigh\n",
    "    matrix_accuracy_nonreweigh[i] = accuracy_nonreweigh\n",
    "    matrix_fairness_nonreweigh[i] = fairness_metrics_nonreweigh\n",
    "\n",
    "print('\\nprediction completed')\n",
    "\n",
    "metrics_adversarial_reweigh = []\n",
    "metrics_prejudice_reweigh = []\n",
    "metrics_nondebiasing_reweigh = []\n",
    "metrics_ensemble_reweigh = []\n",
    "metrics_adversarial_nonreweigh = []\n",
    "metrics_prejudice_nonreweigh = []\n",
    "metrics_nondebiasing_nonreweigh = []\n",
    "metrics_ensemble_nonreweigh = []\n",
    "\n",
    "for i in range(0, runs):\n",
    "    \n",
    "    # with reweighing\n",
    "    metrics_adversarial_reweigh.append(matrix_fairness_reweigh[i][0])\n",
    "    metrics_prejudice_reweigh.append(matrix_fairness_reweigh[i][1])\n",
    "    metrics_nondebiasing_reweigh.append(matrix_fairness_reweigh[i][2])\n",
    "    metrics_ensemble_reweigh.append(matrix_fairness_reweigh[i][3])\n",
    "    \n",
    "    # without reweighing\n",
    "    metrics_adversarial_nonreweigh.append(matrix_fairness_nonreweigh[i][0])\n",
    "    metrics_prejudice_nonreweigh.append(matrix_fairness_nonreweigh[i][1])\n",
    "    metrics_nondebiasing_nonreweigh.append(matrix_fairness_nonreweigh[i][2])\n",
    "    metrics_ensemble_nonreweigh.append(matrix_fairness_nonreweigh[i][3])\n",
    "\n",
    "print('compiled all metrics')\n",
    "\n",
    "\n",
    "# create data frame for all metrics\n",
    "columns = ['Adversarial Debiasing', 'Prejudice Remover', 'Nondebiasing', 'Ensemble']\n",
    "accuracy_reweigh = np.array(list(matrix_accuracy_reweigh.values()))\n",
    "accuracy_nonreweigh = np.array(list(matrix_accuracy_nonreweigh.values()))\n",
    "german_accuracy_reweigh = pd.DataFrame(accuracy_reweigh, columns=columns)\n",
    "german_accuracy_nonreweigh = pd.DataFrame(accuracy_nonreweigh, columns=columns)\n",
    "\n",
    "# fairness metrics\n",
    "columns = ['Mean Difference', 'Disparate Impact', 'Equal Opportunity Difference', 'Average Odds Difference', 'Theil Index']\n",
    "german_adversarial_reweigh = pd.DataFrame(metrics_adversarial_reweigh, columns=columns)\n",
    "german_prejudice_reweigh = pd.DataFrame(metrics_prejudice_reweigh, columns=columns)\n",
    "german_nondebiasing_reweigh = pd.DataFrame(metrics_nondebiasing_reweigh, columns=columns)\n",
    "german_ensemble_reweigh = pd.DataFrame(metrics_ensemble_reweigh, columns=columns)\n",
    "\n",
    "german_adversarial_nonreweigh = pd.DataFrame(metrics_adversarial_nonreweigh, columns=columns)\n",
    "german_prejudice_nonreweigh = pd.DataFrame(metrics_prejudice_nonreweigh, columns=columns)\n",
    "german_nondebiasing_nonreweigh = pd.DataFrame(metrics_nondebiasing_nonreweigh, columns=columns)\n",
    "german_ensemble_nonreweigh = pd.DataFrame(metrics_ensemble_nonreweigh, columns=columns)\n",
    "\n",
    "\n",
    "# save to csv\n",
    "german_accuracy_reweigh.to_csv(\"results/german/reweighed/accuracy.csv\", encoding='utf-8')\n",
    "german_adversarial_reweigh.to_csv(\"results/german/reweighed/adversarial.csv\", encoding='utf-8')\n",
    "german_prejudice_reweigh.to_csv(\"results/german/reweighed/prejudice.csv\", encoding='utf-8')\n",
    "german_nondebiasing_reweigh.to_csv(\"results/german/reweighed/neural_net.csv\", encoding='utf-8')\n",
    "german_ensemble_reweigh.to_csv(\"results/german/reweighed/ensemble.csv\", encoding='utf-8')\n",
    "\n",
    "german_accuracy_nonreweigh.to_csv(\"results/german/non-reweighed/accuracy.csv\", encoding='utf-8')\n",
    "german_adversarial_nonreweigh.to_csv(\"results/german/non-reweighed/adversarial.csv\", encoding='utf-8')\n",
    "german_prejudice_nonreweigh.to_csv(\"results/german/non-reweighed/prejudice.csv\", encoding='utf-8')\n",
    "german_nondebiasing_nonreweigh.to_csv(\"results/german/non-reweighed/neural_net.csv\", encoding='utf-8')\n",
    "german_ensemble_nonreweigh.to_csv(\"results/german/non-reweighed/ensemble.csv\", encoding='utf-8')\n",
    "\n",
    "print('all files saved to csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
